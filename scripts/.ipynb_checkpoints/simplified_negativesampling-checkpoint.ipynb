{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from  sklearn.preprocessing import LabelEncoder\n",
    "from  sklearn.preprocessing import OneHotEncoder\n",
    "import scipy \n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "\n",
    "from __future__ import division\n",
    "from scipy.special import erfinv\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import xgboost as xgb\n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rgf.sklearn import RGFClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 269)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_train = pd.read_csv(\"../data/train_dae.csv\")\n",
    "#df_test = pd.read_csv(\"../data/test_dae.csv\")\n",
    "#df_train = pd.read_csv(\"../data/sparse/train_good.csv\")vvvvvvvv\n",
    "#df_test = pd.read_csv(\"../data/sparse/test_good.csv\")vvvvvvvvvvvaaa\n",
    "df_train = pd.read_csv(\"../data/train2dae.csv\")\n",
    "df_test = pd.read_csv(\"../data/test2dae.csv\")\n",
    "df_labels = pd.read_csv(\"../data/labels_train.csv\" , header = None )[1]\n",
    "test_ids = pd.read_csv(\"../data/ids_test.csv\" , header = None)[1].values\n",
    "test_ids\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = df_labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns = range( df_train.shape[1] )\n",
    "df_test.columns = range( df_test.shape[1] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>259</th>\n",
       "      <th>260</th>\n",
       "      <th>261</th>\n",
       "      <th>262</th>\n",
       "      <th>263</th>\n",
       "      <th>264</th>\n",
       "      <th>265</th>\n",
       "      <th>266</th>\n",
       "      <th>267</th>\n",
       "      <th>268</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.291039</td>\n",
       "      <td>0.841895</td>\n",
       "      <td>-3.291039</td>\n",
       "      <td>0.516322</td>\n",
       "      <td>-3.291039</td>\n",
       "      <td>0.338145</td>\n",
       "      <td>-3.291039</td>\n",
       "      <td>0.179274</td>\n",
       "      <td>-3.291039</td>\n",
       "      <td>-3.291039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227612</td>\n",
       "      <td>-0.202060</td>\n",
       "      <td>0.164462</td>\n",
       "      <td>0.836695</td>\n",
       "      <td>0.189590</td>\n",
       "      <td>-0.665408</td>\n",
       "      <td>0.292410</td>\n",
       "      <td>-0.421812</td>\n",
       "      <td>0.216730</td>\n",
       "      <td>0.294641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227618</td>\n",
       "      <td>-1.008758</td>\n",
       "      <td>0.164467</td>\n",
       "      <td>-0.555492</td>\n",
       "      <td>0.189596</td>\n",
       "      <td>-0.429849</td>\n",
       "      <td>0.292404</td>\n",
       "      <td>-0.421819</td>\n",
       "      <td>0.216736</td>\n",
       "      <td>0.294634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227624</td>\n",
       "      <td>0.728682</td>\n",
       "      <td>0.164473</td>\n",
       "      <td>-0.786342</td>\n",
       "      <td>0.189602</td>\n",
       "      <td>0.834020</td>\n",
       "      <td>0.292398</td>\n",
       "      <td>-0.421826</td>\n",
       "      <td>0.216743</td>\n",
       "      <td>0.294628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227630</td>\n",
       "      <td>0.629847</td>\n",
       "      <td>0.164479</td>\n",
       "      <td>0.758521</td>\n",
       "      <td>0.189608</td>\n",
       "      <td>-0.540973</td>\n",
       "      <td>0.292391</td>\n",
       "      <td>-0.421833</td>\n",
       "      <td>0.216749</td>\n",
       "      <td>0.294622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 269 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9      ...          259  \\\n",
       "0    7    1    9    7    3    0    6    1    1    3    ...    -3.291039   \n",
       "1    4    1    4    2    3    0    1    0    0    1    ...     0.227612   \n",
       "2    7    0    9    7    0    1    1    1    1    3    ...     0.227618   \n",
       "3    7    0    9    7    0    0    6    0    1    0    ...     0.227624   \n",
       "4    7    0    4    7    0    0    4    1    1    3    ...     0.227630   \n",
       "\n",
       "        260       261       262       263       264       265       266  \\\n",
       "0  0.841895 -3.291039  0.516322 -3.291039  0.338145 -3.291039  0.179274   \n",
       "1 -0.202060  0.164462  0.836695  0.189590 -0.665408  0.292410 -0.421812   \n",
       "2 -1.008758  0.164467 -0.555492  0.189596 -0.429849  0.292404 -0.421819   \n",
       "3  0.728682  0.164473 -0.786342  0.189602  0.834020  0.292398 -0.421826   \n",
       "4  0.629847  0.164479  0.758521  0.189608 -0.540973  0.292391 -0.421833   \n",
       "\n",
       "        267       268  \n",
       "0 -3.291039 -3.291039  \n",
       "1  0.216730  0.294641  \n",
       "2  0.216736  0.294634  \n",
       "3  0.216743  0.294628  \n",
       "4  0.216749  0.294622  \n",
       "\n",
       "[5 rows x 269 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.loc[ : , 7 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train.head()\n",
    "for i in range( df_train.shape[1] ):\n",
    "    plt.hist( df_train.loc[ :,  i] , density = True )\n",
    "    plt.hist( df_test.loc[ :,  i] , density = True  , alpha = 0.7 )\n",
    "    plt.title( \" feat - {}\".format(i) )\n",
    "    plt.savefig( \"../data/graphics/feats/feat_{}\".format(  i ) , format = \"png\" )\n",
    "    plt.clf()\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356255, 221)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"y\"] = 0 \n",
    "df_test[\"y\"] = 1 \n",
    "df_adv = pd.concat( [df_train , df_test ] , axis = 0 )\n",
    "#print( df_adv.head() )\n",
    "labels_adv = df_adv[\"y\"].values \n",
    "df_adv = df_adv.drop( [\"y\"] , axis = 1 )\n",
    "adv = df_adv.loc[ : ,  range( 43, 264) ].values\n",
    "adv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.693147\tvalid_0's auc: 0.5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.693147\tvalid_0's auc: 0.5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.693147\tvalid_0's auc: 0.5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.693147\tvalid_0's auc: 0.5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.693147\tvalid_0's auc: 0.5\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "num_leaves = 15\n",
    "min_data_in_leaf = 2000\n",
    "feature_fraction = 0.5\n",
    "num_boost_round = 500\n",
    "\n",
    "params = {\"objective\": \"binary\",\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"learning_rate\": learning_rate,\n",
    "          \"metric\":[\"auc\" ,\"binary_logloss\"] , \n",
    "          \"num_leaves\": num_leaves,\n",
    "           \"max_bin\": 256,\n",
    "          \"feature_fraction\": feature_fraction,\n",
    "          \"verbosity\": 1,\n",
    "          \"drop_rate\": 0.1,\n",
    "          \"is_unbalance\": False,\n",
    "          \"max_drop\": 50,\n",
    "          \"min_child_samples\": 20,\n",
    "          \"min_child_weight\": 150,\n",
    "          \"min_split_gain\": 0.5,\n",
    "          \"max_depth\": -1, \n",
    "         \"lambda_l2\": 100 , \n",
    "          \"min_gain_to_split\" : 0.5 ,\n",
    "          \"bagging_freq\" : 1 , \n",
    "          \"subsample\" : 0.9 , \n",
    "}\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state= 666 )\n",
    "kf = kfold.split( adv , labels_adv ) \n",
    "\n",
    "cv_train = np.zeros( (len( adv ) , ))\n",
    "for i , (train_fold , validate ) in enumerate( kf ):\n",
    "    \n",
    "    X_train, X_validate, label_train, label_validate = adv[train_fold, :], adv[validate, :], labels_adv[train_fold],labels_adv[validate]\n",
    "    \n",
    "    dtrain = lgb.Dataset( X_train , label_train  )\n",
    "    dvalid = lgb.Dataset(  X_validate  , label_validate , reference=dtrain  )\n",
    "    \n",
    "    bst = lgb.train(params, dtrain , 500 , valid_sets=[ dvalid ] , verbose_eval = 300 , early_stopping_rounds = 100 )\n",
    "    \n",
    "    cv_train[ validate ] += bst.predict(  X_validate )\n",
    "\n",
    "s = roc_auc_score( labels_adv , cv_train )\n",
    "print(s)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_train.shape\n",
    "a = df_test.shape[0]\n",
    "cv_train2 = cv_train[ : -a ]\n",
    "cv_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.26495726496\n",
      "936\n",
      "(48744, 269)\n"
     ]
    }
   ],
   "source": [
    "cv_train3 = cv_train[:df_train.shape[0]]\n",
    "\n",
    "df_train_fine = df_train [  cv_train3 > 0.2 ]\n",
    "df_train_fine.shape\n",
    "labels_fine = labels_train[ cv_train3 > 0.3 ]\n",
    "print(float(labels_fine.sum())/labels_fine.shape[0]*100)\n",
    "print( labels_fine.shape[0] )\n",
    "print( df_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train_fine = df_train_fine.drop( [\"y\"] , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.693147\tvalid_0's auc: 0.5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.693147\tvalid_0's auc: 0.5\n"
     ]
    }
   ],
   "source": [
    "X_t = df_train_fine.values\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state= 666 )\n",
    "kf = kfold.split( df_train_fine , labels_fine ) \n",
    "\n",
    "cv_train_fine = np.zeros( (len( labels_fine ) , ))\n",
    "for i , (train_fold , validate ) in enumerate( kf ):\n",
    "    \n",
    "    X_train, X_validate, label_train, label_validate = X_t[train_fold, :], X_t[validate, :], labels_fine[train_fold],labels_fine[validate]\n",
    "    \n",
    "    dtrain = lgb.Dataset( X_train , label_train  )\n",
    "    dvalid = lgb.Dataset(  X_validate  , label_validate , reference=dtrain  )\n",
    "    \n",
    "    bst = lgb.train(params, dtrain , 10000 , valid_sets=[ dvalid ] , verbose_eval = 300 , early_stopping_rounds = 100 ) \n",
    "    cv_train_fine[ validate ] += bst.predict(  X_validate )\n",
    "\n",
    "s = roc_auc_score(  labels_fine , cv_train_fine )\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "438.0"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(labels_fine.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_data_indx = df_labels[ df_labels == 1 ]\n",
    "positive_data = df_train.iloc[ positive_data_indx.index ]\n",
    "#print( positive_data.shape )\n",
    "negative_data_indx = df_labels[  df_labels == 0 ]\n",
    "negative_data = df_train.iloc[  negative_data_indx.index ]\n",
    "#print( negative_data.shape )\n",
    "positive_ratio = float(len(positive_data)) / len(df_train)\n",
    "positive_ratio\n",
    "\n",
    "positive_data = None\n",
    "negative_data = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "num_leaves = 15\n",
    "min_data_in_leaf = 2000\n",
    "feature_fraction = 0.05\n",
    "num_boost_round = 10000\n",
    "ncat = 43\n",
    "params = {\"objective\": \"binary\",\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"learning_rate\": learning_rate,\n",
    "          \"metric\":[\"auc\" ,\"binary_logloss\"] , \n",
    "          \"num_leaves\": num_leaves,\n",
    "           \"max_bin\": 256,\n",
    "          \"feature_fraction\": feature_fraction,\n",
    "          \"verbosity\": 1,\n",
    "          \"drop_rate\": 0.1,\n",
    "          \"is_unbalance\": False,\n",
    "          \"max_drop\": 50,\n",
    "          \"min_child_samples\": 20,\n",
    "          \"min_child_weight\": 150,\n",
    "          \"min_split_gain\": 0.5,\n",
    "          \"max_depth\": -1, \n",
    "         \"lambda_l2\": 100 , \n",
    "          \"min_gain_to_split\" : 0.5 ,\n",
    "          \"bagging_freq\" : 1 , \n",
    "          \"subsample\" : 0.9 , \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "num_leaves = 15\n",
    "min_data_in_leaf = 2000\n",
    "feature_fraction = 0.9\n",
    "num_boost_round = 2000\n",
    "params_xgb = {\"booster\": \"gbtree\",\n",
    "         \"eta\" : learning_rate , \n",
    "          \"max_depth\" : 5 , \n",
    "          \"colsample_bytree\" : feature_fraction , \n",
    "          \"lambda\" : 100 , \n",
    "           \"tree_method\" : \"hist\" , \n",
    "          \"max_bin\" : 256 , \n",
    "          \"rate_drop\": 0.01 , \n",
    "          'objective': 'binary:logistic' , \n",
    "          \"eval_metric\" : \"auc\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NFOLDS = 2\n",
    "ncat = 43\n",
    "#X = features_train_t.values\n",
    "low = 0\n",
    "high = 43\n",
    "XX_test = df_test.loc[ : , range(low,high)].values\n",
    "\n",
    "XX_train = df_train.loc[ : , range(low,high)].values\n",
    "labels_full = df_labels.values\n",
    "# for xgb \n",
    "\n",
    "labels_train = df_labels.values\n",
    "final_cv_train = np.zeros(len( labels_train ))\n",
    "\n",
    "final_cv_pred = np.zeros(len( test_ids ))\n",
    "\n",
    "x_score = []\n",
    "x_score_xgb = []\n",
    "\n",
    "best_trees = []\n",
    "fold_scores = []\n",
    "N = 8\n",
    "\n",
    "oof_train_full = []\n",
    "oof_test_full = [] \n",
    "\n",
    "\n",
    "for s in range(N):\n",
    "    \n",
    "    \n",
    "    params['seed'] = s\n",
    "    \n",
    "    #x_train , x_val , y_train , y_val = train_test_split( df_train , df_labels , test_size = 0.2 , random_state=s)\n",
    "\n",
    "    # split the entire data set in k-folds\n",
    "    kfold = KFold(n_splits=NFOLDS, shuffle=True, random_state=s)\n",
    "    kf = kfold.split( df_train , df_labels )\n",
    "    \n",
    "    oof_train = np.zeros((len(df_train),))\n",
    "    \n",
    "    \n",
    "    oof_test = np.zeros((len(df_test),))\n",
    "    oof_test_skf = np.empty((NFOLDS, len(df_test)))\n",
    "    print( \"Doing {}\".format( s) )\n",
    "    random.seed( s )\n",
    "    \n",
    "    for i , (train_fold , validate ) in enumerate( kf ):\n",
    "        \n",
    "        X_train, X_validate, label_train, label_validate = XX_train[train_fold, :], XX_train[validate, :], labels_full[train_fold],labels_full[validate]\n",
    "\n",
    "        positive_indx = label_train[ label_train == 1 ]\n",
    "        positive_data = X_train[ label_train == 1  ]\n",
    "        positive_data = pd.DataFrame( positive_data )\n",
    "\n",
    "        negative_indx = label_train[ label_train == 0 ]\n",
    "        negative_data = X_train[  label_train == 0  ]\n",
    "    \n",
    "        negative_data = pd.DataFrame( negative_data )\n",
    "        negative_data = negative_data.sample( frac= positive_ratio / (1 - positive_ratio), random_state=s*5 )\n",
    "\n",
    "        print(positive_data.shape)\n",
    "        print(negative_data.shape )\n",
    "\n",
    "        labels = [ 0 for x in range( negative_data.shape[0]) ] + [ 1 for x in range( positive_data.shape[0]) ]\n",
    "\n",
    "        x_train_sampled = pd.concat( [ negative_data , positive_data] , axis = 0 )\n",
    "        x_train_sampled[\"y\"] = labels\n",
    "        x_train_sampled = x_train_sampled.sample(frac = 1 ,random_state = s )\n",
    "        labels_sampled = x_train_sampled[\"y\"].values\n",
    "    \n",
    "        x_train_sampled = x_train_sampled.drop( [\"y\"] , axis = 1 ).values\n",
    "        \n",
    "        dtrain = lgb.Dataset( x_train_sampled , labels_sampled , categorical_feature =  range( x_train_sampled.shape[0] )  )\n",
    "        dvalid = lgb.Dataset(  X_validate  , label_validate , reference=dtrain , categorical_feature =  range( x_train_sampled.shape[0] )  )\n",
    "        bst = lgb.train(params, dtrain , num_boost_round , valid_sets=[ dtrain ] , verbose_eval = 300 , early_stopping_rounds = 100 ) \n",
    "        \n",
    "        pred_validate = bst.predict( X_validate )\n",
    "        oof_train[ validate ] += pred_validate\n",
    "        \n",
    "        score = roc_auc_score( label_validate , pred_validate )\n",
    "        print( \"score validate:\" , score)\n",
    "        \n",
    "        oof_test_skf[i , : ] =  bst.predict( XX_test )\n",
    "        \n",
    "    oof_test[:] = oof_test_skf.mean( axis = 0 )\n",
    "    oof_train = oof_train.reshape(-1, 1)\n",
    "    oof_test = oof_test.reshape(-1, 1)\n",
    "    \n",
    "    oof_train_full.append( oof_train )\n",
    "    oof_test_full.append( oof_test )\n",
    "    print(\"Finnished\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = np.hstack( oof_train_full )\n",
    "new_test = np.hstack( oof_test_full )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "print( \"SUCCESS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48744, 8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.55716468, 0.80644295, 0.83315362, 0.79997785, 0.82828753,\n",
       "       0.81533616, 0.84582756, 0.50501656])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "num_leaves = 15\n",
    "min_data_in_leaf = 2000\n",
    "feature_fraction = 0.5\n",
    "num_boost_round = 10000\n",
    "params = {\"objective\": \"binary\",\n",
    "          \"boosting_type\": \"goss\",\n",
    "          \"learning_rate\": learning_rate,\n",
    "          \"metric\":[\"auc\" ,\"binary_logloss\"] , \n",
    "          \"num_leaves\": num_leaves,\n",
    "           \"max_bin\": 256,\n",
    "          \"feature_fraction\": feature_fraction,\n",
    "          \"verbosity\": 1,\n",
    "          \"drop_rate\": 0.01,\n",
    "          \"is_unbalance\": False,\n",
    "          \"max_drop\": 50,\n",
    "          \"min_child_samples\": 20,\n",
    "          \"min_child_weight\": 10,\n",
    "          \"min_split_gain\": 0.5,\n",
    "          \"max_depth\": -1, \n",
    "         \"lambda_l2\": 100 , \n",
    "          \"lambda_l1\": 100 , \n",
    "          \"min_gain_to_split\" : 0.5 ,\n",
    "         # \"bagging_freq\" : 1 , \n",
    "          \"subsample\" : 0.9\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightgbm model with oof_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.348557\ttraining's auc: 0.755914\tvalid_0's binary_logloss: 0.349311\tvalid_0's auc: 0.745795\n",
      "[200]\ttraining's binary_logloss: 0.270619\ttraining's auc: 0.759902\tvalid_0's binary_logloss: 0.271983\tvalid_0's auc: 0.751735\n",
      "[300]\ttraining's binary_logloss: 0.251454\ttraining's auc: 0.760934\tvalid_0's binary_logloss: 0.253332\tvalid_0's auc: 0.75332\n",
      "[400]\ttraining's binary_logloss: 0.246805\ttraining's auc: 0.762035\tvalid_0's binary_logloss: 0.248985\tvalid_0's auc: 0.754016\n",
      "[500]\ttraining's binary_logloss: 0.245603\ttraining's auc: 0.76267\tvalid_0's binary_logloss: 0.247891\tvalid_0's auc: 0.754324\n",
      "[600]\ttraining's binary_logloss: 0.245259\ttraining's auc: 0.762935\tvalid_0's binary_logloss: 0.247613\tvalid_0's auc: 0.754486\n",
      "[700]\ttraining's binary_logloss: 0.245088\ttraining's auc: 0.763284\tvalid_0's binary_logloss: 0.24748\tvalid_0's auc: 0.754681\n",
      "[800]\ttraining's binary_logloss: 0.244985\ttraining's auc: 0.763508\tvalid_0's binary_logloss: 0.247393\tvalid_0's auc: 0.754764\n",
      "[900]\ttraining's binary_logloss: 0.244923\ttraining's auc: 0.763665\tvalid_0's binary_logloss: 0.247354\tvalid_0's auc: 0.754811\n",
      "[1000]\ttraining's binary_logloss: 0.244893\ttraining's auc: 0.76375\tvalid_0's binary_logloss: 0.247332\tvalid_0's auc: 0.754831\n",
      "Early stopping, best iteration is:\n",
      "[966]\ttraining's binary_logloss: 0.244894\ttraining's auc: 0.763748\tvalid_0's binary_logloss: 0.247332\tvalid_0's auc: 0.754834\n",
      "fold 0  - 0.754831457188 \n",
      "SAVING FIGURE\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.34876\ttraining's auc: 0.753532\tvalid_0's binary_logloss: 0.349254\tvalid_0's auc: 0.752256\n",
      "[200]\ttraining's binary_logloss: 0.270907\ttraining's auc: 0.758732\tvalid_0's binary_logloss: 0.271554\tvalid_0's auc: 0.757201\n",
      "[300]\ttraining's binary_logloss: 0.251762\ttraining's auc: 0.75977\tvalid_0's binary_logloss: 0.252452\tvalid_0's auc: 0.758381\n",
      "[400]\ttraining's binary_logloss: 0.247122\ttraining's auc: 0.760626\tvalid_0's binary_logloss: 0.247866\tvalid_0's auc: 0.759286\n",
      "[500]\ttraining's binary_logloss: 0.24591\ttraining's auc: 0.761202\tvalid_0's binary_logloss: 0.246691\tvalid_0's auc: 0.759648\n",
      "[600]\ttraining's binary_logloss: 0.245561\ttraining's auc: 0.761475\tvalid_0's binary_logloss: 0.246358\tvalid_0's auc: 0.75975\n",
      "[700]\ttraining's binary_logloss: 0.245398\ttraining's auc: 0.761751\tvalid_0's binary_logloss: 0.246209\tvalid_0's auc: 0.759953\n",
      "[800]\ttraining's binary_logloss: 0.245307\ttraining's auc: 0.76196\tvalid_0's binary_logloss: 0.246131\tvalid_0's auc: 0.760115\n",
      "[900]\ttraining's binary_logloss: 0.245252\ttraining's auc: 0.762087\tvalid_0's binary_logloss: 0.246087\tvalid_0's auc: 0.760196\n",
      "[1000]\ttraining's binary_logloss: 0.245216\ttraining's auc: 0.762181\tvalid_0's binary_logloss: 0.246058\tvalid_0's auc: 0.760277\n",
      "[1100]\ttraining's binary_logloss: 0.245193\ttraining's auc: 0.762253\tvalid_0's binary_logloss: 0.24604\tvalid_0's auc: 0.760314\n",
      "Early stopping, best iteration is:\n",
      "[1098]\ttraining's binary_logloss: 0.245193\ttraining's auc: 0.762253\tvalid_0's binary_logloss: 0.24604\tvalid_0's auc: 0.760315\n",
      "fold 1  - 0.760314183294 \n",
      "SAVING FIGURE\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.348661\ttraining's auc: 0.755657\tvalid_0's binary_logloss: 0.34897\tvalid_0's auc: 0.75066\n",
      "[200]\ttraining's binary_logloss: 0.270759\ttraining's auc: 0.759823\tvalid_0's binary_logloss: 0.27143\tvalid_0's auc: 0.754099\n",
      "[300]\ttraining's binary_logloss: 0.251611\ttraining's auc: 0.760651\tvalid_0's binary_logloss: 0.252606\tvalid_0's auc: 0.754354\n",
      "[400]\ttraining's binary_logloss: 0.246978\ttraining's auc: 0.761438\tvalid_0's binary_logloss: 0.248208\tvalid_0's auc: 0.75535\n",
      "[500]\ttraining's binary_logloss: 0.245743\ttraining's auc: 0.762145\tvalid_0's binary_logloss: 0.247171\tvalid_0's auc: 0.755796\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-31c90bc6b139>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mdvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0mX_validate\u001b[0m  \u001b[0;34m,\u001b[0m \u001b[0mlabel_validate\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtrain\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mnum_boost_round\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvalid_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdvalid\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;31m#best_trees.append(bst.best_iteration)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mcv_pred\u001b[0m \u001b[0;34m+=\u001b[0m  \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0mnew_test\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/lightgbm/engine.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    199\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/lightgbm/basic.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1522\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1523\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1524\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1525\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_cv_train = np.zeros(len(labels_train))\n",
    "final_cv_pred = np.zeros(len( test_ids ))\n",
    "\n",
    "NFOLDS = 5 \n",
    "\n",
    "M = 16\n",
    "x_score = []\n",
    "fold_scores_lgb = []\n",
    "for s in range( M ):\n",
    "    \n",
    "    params['seed'] = s\n",
    "    \n",
    "    cv_train = np.zeros( len( labels_train ))\n",
    "    cv_pred = np.zeros( len( test_ids ) )\n",
    "    kfold = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=s)\n",
    "    kf  = kfold.split(  new_train , labels_train )\n",
    "    \n",
    "    fold_scores = []\n",
    "    \n",
    "    for i, (train_fold, validate) in enumerate(kf):\n",
    "        evals_result = {}\n",
    "        X_train, X_validate, label_train, label_validate = new_train[train_fold, :], new_train[validate, :], labels_train[train_fold], labels_train[validate]\n",
    "        \n",
    "    #X_train, X_validate, label_train, label_validate = X[train_fold, :], X[validate, :], labels_train[train_fold], labels_train[validate]\n",
    "        dtrain = lgb.Dataset( X_train , label_train  )\n",
    "    \n",
    "        dvalid = lgb.Dataset(  X_validate  , label_validate , reference=dtrain )\n",
    "        bst = lgb.train(params, dtrain , num_boost_round , valid_sets=[dvalid , dtrain ] , verbose_eval = 100 , evals_result=evals_result, early_stopping_rounds = 100 )\n",
    "    #best_trees.append(bst.best_iteration)    \n",
    "        cv_pred +=  bst.predict(  new_test , num_iteration = bst.best_iteration )\n",
    "    #cv_eval_total += bst.predict( x_val , num_iteration = bst.best_iteration )          \n",
    "        cv_train[validate] += bst.predict( X_validate )\n",
    "        score = roc_auc_score( label_validate , cv_train[validate])\n",
    "        print(\"fold {}  - {} \".format( i ,  score ) )\n",
    "        fold_scores_lgb.append( score )\n",
    "        \n",
    "        # save graphic\n",
    "        ax = lgb.plot_metric(evals_result, metric='auc' )\n",
    "        print(\"SAVING FIGURE\") \n",
    "        plt.savefig( \"../data/graphics/lgb/lc_s{}_f{}.png\".format( s , i ) , format = \"png\" )\n",
    "        #plt.show()\n",
    "        \n",
    "    cv_pred /= NFOLDS\n",
    "    \n",
    "    final_cv_train += cv_train\n",
    "    final_cv_pred += cv_pred\n",
    "    \n",
    "    print(\"cv score - on train:\")\n",
    "    print( roc_auc_score(labels_train, cv_train))\n",
    "    print( \"current score in fold:\", roc_auc_score( labels_train , final_cv_train / (s + 1.)), s+1)\n",
    "    \n",
    "    x_score.append(roc_auc_score( labels_train , cv_train))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.817345685997514\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print( np.array(x_score).mean())\n",
    "plt.hist( x_score )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred_lgb = final_cv_pred/M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist( final_pred_lgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist( fold_scores_lgb ) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGboost model with oof_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "num_leaves = 30\n",
    "min_data_in_leaf = 2000\n",
    "feature_fraction = 0.9\n",
    "num_boost_round = 5000\n",
    "params = {\"booster\": \"gbtree\",\n",
    "         \"eta\" : learning_rate , \n",
    "          \"max_depth\" : 5 , \n",
    "          \"colsample_bytree\" : feature_fraction , \n",
    "          \"lambda\" : 100 , \n",
    "          \"gamma\" : 20 , \n",
    "          \"alpha\" : 100 , \n",
    "           \"tree_method\" : \"hist\" , \n",
    "          \"max_bin\" : 256 , \n",
    "          \"rate_drop\": 0.01 , \n",
    "          'objective': 'binary:logistic' , \n",
    "          \"eval_metric\" : \"auc\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.773623\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.802357\n",
      "[200]\teval-auc:0.808022\n",
      "[300]\teval-auc:0.81059\n",
      "[400]\teval-auc:0.811442\n",
      "[500]\teval-auc:0.81199\n",
      "[600]\teval-auc:0.81222\n",
      "[700]\teval-auc:0.812309\n",
      "[800]\teval-auc:0.812322\n",
      "[900]\teval-auc:0.812361\n",
      "[1000]\teval-auc:0.812383\n",
      "Stopping. Best iteration:\n",
      "[958]\teval-auc:0.812383\n",
      "\n",
      "fold 0 - 0.812382612035\n",
      "[0]\teval-auc:0.772279\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.80515\n",
      "[200]\teval-auc:0.809367\n",
      "[300]\teval-auc:0.811598\n",
      "[400]\teval-auc:0.812611\n",
      "[500]\teval-auc:0.813309\n",
      "[600]\teval-auc:0.813384\n",
      "[700]\teval-auc:0.813381\n",
      "[800]\teval-auc:0.813404\n",
      "[900]\teval-auc:0.813407\n",
      "[1000]\teval-auc:0.813423\n",
      "Stopping. Best iteration:\n",
      "[984]\teval-auc:0.813423\n",
      "\n",
      "fold 1 - 0.813423365624\n",
      "[0]\teval-auc:0.787589\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.814536\n",
      "[200]\teval-auc:0.818891\n",
      "[300]\teval-auc:0.821009\n",
      "[400]\teval-auc:0.821791\n",
      "[500]\teval-auc:0.822303\n",
      "[600]\teval-auc:0.822531\n",
      "[700]\teval-auc:0.822634\n",
      "[800]\teval-auc:0.82264\n",
      "[900]\teval-auc:0.822647\n",
      "Stopping. Best iteration:\n",
      "[842]\teval-auc:0.822647\n",
      "\n",
      "fold 2 - 0.822646869347\n",
      "[0]\teval-auc:0.773822\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.804074\n",
      "[200]\teval-auc:0.808826\n",
      "[300]\teval-auc:0.811128\n",
      "[400]\teval-auc:0.813059\n",
      "[500]\teval-auc:0.814024\n",
      "[600]\teval-auc:0.814443\n",
      "[700]\teval-auc:0.814555\n",
      "[800]\teval-auc:0.814576\n",
      "[900]\teval-auc:0.814585\n",
      "[1000]\teval-auc:0.814605\n",
      "Stopping. Best iteration:\n",
      "[970]\teval-auc:0.814605\n",
      "\n",
      "fold 3 - 0.814605039978\n",
      "[0]\teval-auc:0.776621\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.807694\n",
      "[200]\teval-auc:0.811865\n",
      "[300]\teval-auc:0.81481\n",
      "[400]\teval-auc:0.816026\n",
      "[500]\teval-auc:0.816918\n",
      "[600]\teval-auc:0.817262\n",
      "[700]\teval-auc:0.817392\n",
      "[800]\teval-auc:0.817436\n",
      "Stopping. Best iteration:\n",
      "[751]\teval-auc:0.817439\n",
      "\n",
      "fold 4 - 0.817439482748\n",
      "[0]\teval-auc:0.777038\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.804919\n",
      "[200]\teval-auc:0.808694\n",
      "[300]\teval-auc:0.812069\n",
      "[400]\teval-auc:0.81365\n",
      "[500]\teval-auc:0.814668\n",
      "[600]\teval-auc:0.815058\n",
      "[700]\teval-auc:0.815203\n",
      "[800]\teval-auc:0.81522\n",
      "[900]\teval-auc:0.815226\n",
      "Stopping. Best iteration:\n",
      "[866]\teval-auc:0.815226\n",
      "\n",
      "fold 5 - 0.815226081856\n",
      "[0]\teval-auc:0.782211\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.809918\n",
      "[200]\teval-auc:0.815313\n",
      "[300]\teval-auc:0.81674\n",
      "[400]\teval-auc:0.817387\n",
      "[500]\teval-auc:0.818328\n",
      "[600]\teval-auc:0.818508\n",
      "[700]\teval-auc:0.818599\n",
      "Stopping. Best iteration:\n",
      "[696]\teval-auc:0.818599\n",
      "\n",
      "fold 6 - 0.818599349019\n",
      "[0]\teval-auc:0.784341\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.812173\n",
      "[200]\teval-auc:0.817923\n",
      "[300]\teval-auc:0.819438\n",
      "[400]\teval-auc:0.820434\n",
      "[500]\teval-auc:0.820887\n",
      "[600]\teval-auc:0.820963\n",
      "[700]\teval-auc:0.821029\n",
      "[800]\teval-auc:0.821035\n",
      "Stopping. Best iteration:\n",
      "[798]\teval-auc:0.821036\n",
      "\n",
      "fold 7 - 0.821036480346\n",
      "[0]\teval-auc:0.77714\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.811683\n",
      "[200]\teval-auc:0.814616\n",
      "[300]\teval-auc:0.816316\n",
      "[400]\teval-auc:0.817265\n",
      "[500]\teval-auc:0.817782\n",
      "[600]\teval-auc:0.818\n",
      "[700]\teval-auc:0.818083\n",
      "Stopping. Best iteration:\n",
      "[693]\teval-auc:0.818083\n",
      "\n",
      "fold 8 - 0.818082624499\n",
      "[0]\teval-auc:0.777585\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.808401\n",
      "[200]\teval-auc:0.813919\n",
      "[300]\teval-auc:0.815741\n",
      "[400]\teval-auc:0.816371\n",
      "[500]\teval-auc:0.81711\n",
      "[600]\teval-auc:0.817329\n",
      "[700]\teval-auc:0.817398\n",
      "Stopping. Best iteration:\n",
      "[687]\teval-auc:0.817398\n",
      "\n",
      "fold 9 - 0.817398314418\n",
      "cv score - on train:\n",
      "0.8169910989599918\n",
      "('current score in fold:', 0.8169910989599918, 1)\n",
      "[0]\teval-auc:0.774051\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.803966\n",
      "[200]\teval-auc:0.806886\n",
      "[300]\teval-auc:0.80975\n",
      "[400]\teval-auc:0.811092\n",
      "[500]\teval-auc:0.812118\n",
      "[600]\teval-auc:0.812428\n",
      "[700]\teval-auc:0.812537\n",
      "[800]\teval-auc:0.81257\n",
      "[900]\teval-auc:0.812591\n",
      "[1000]\teval-auc:0.812608\n",
      "[1100]\teval-auc:0.812614\n",
      "Stopping. Best iteration:\n",
      "[1006]\teval-auc:0.812614\n",
      "\n",
      "fold 0 - 0.8126138637\n",
      "[0]\teval-auc:0.773708\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.803301\n",
      "[200]\teval-auc:0.808859\n",
      "[300]\teval-auc:0.810379\n",
      "[400]\teval-auc:0.811678\n",
      "[500]\teval-auc:0.812303\n",
      "[600]\teval-auc:0.812572\n",
      "[700]\teval-auc:0.812608\n",
      "[800]\teval-auc:0.812621\n",
      "[900]\teval-auc:0.812639\n",
      "[1000]\teval-auc:0.812656\n",
      "[1100]\teval-auc:0.812662\n",
      "Stopping. Best iteration:\n",
      "[1016]\teval-auc:0.812662\n",
      "\n",
      "fold 1 - 0.812662231085\n",
      "[0]\teval-auc:0.775203\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.80686\n",
      "[200]\teval-auc:0.812819\n",
      "[300]\teval-auc:0.81447\n",
      "[400]\teval-auc:0.815913\n",
      "[500]\teval-auc:0.816553\n",
      "[600]\teval-auc:0.816858\n",
      "[700]\teval-auc:0.816969\n",
      "[800]\teval-auc:0.816992\n",
      "Stopping. Best iteration:\n",
      "[797]\teval-auc:0.816992\n",
      "\n",
      "fold 2 - 0.816991746074\n",
      "[0]\teval-auc:0.778158\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.807893\n",
      "[200]\teval-auc:0.812517\n",
      "[300]\teval-auc:0.814226\n",
      "[400]\teval-auc:0.815023\n",
      "[500]\teval-auc:0.815995\n",
      "[600]\teval-auc:0.816284\n",
      "[700]\teval-auc:0.816344\n",
      "[800]\teval-auc:0.816402\n",
      "[900]\teval-auc:0.816417\n",
      "[1000]\teval-auc:0.816439\n",
      "Stopping. Best iteration:\n",
      "[969]\teval-auc:0.816439\n",
      "\n",
      "fold 3 - 0.816439189652\n",
      "[0]\teval-auc:0.777086\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.80824\n",
      "[200]\teval-auc:0.813409\n",
      "[300]\teval-auc:0.815052\n",
      "[400]\teval-auc:0.816274\n",
      "[500]\teval-auc:0.816782\n",
      "[600]\teval-auc:0.816993\n",
      "[700]\teval-auc:0.817019\n",
      "Stopping. Best iteration:\n",
      "[645]\teval-auc:0.817024\n",
      "\n",
      "fold 4 - 0.817023679945\n",
      "[0]\teval-auc:0.782686\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.81123\n",
      "[200]\teval-auc:0.815346\n",
      "[300]\teval-auc:0.817856\n",
      "[400]\teval-auc:0.818791\n",
      "[500]\teval-auc:0.819645\n",
      "[600]\teval-auc:0.819795\n",
      "[700]\teval-auc:0.819918\n",
      "[800]\teval-auc:0.819938\n",
      "[900]\teval-auc:0.819962\n",
      "[1000]\teval-auc:0.819967\n",
      "Stopping. Best iteration:\n",
      "[974]\teval-auc:0.819967\n",
      "\n",
      "fold 5 - 0.819967104623\n",
      "[0]\teval-auc:0.78556\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.814792\n",
      "[200]\teval-auc:0.818096\n",
      "[300]\teval-auc:0.81996\n",
      "[400]\teval-auc:0.8209\n",
      "[500]\teval-auc:0.821639\n",
      "[600]\teval-auc:0.821864\n",
      "[700]\teval-auc:0.821911\n",
      "Stopping. Best iteration:\n",
      "[631]\teval-auc:0.821931\n",
      "\n",
      "fold 6 - 0.82193072847\n",
      "[0]\teval-auc:0.777696\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.808403\n",
      "[200]\teval-auc:0.812907\n",
      "[300]\teval-auc:0.815041\n",
      "[400]\teval-auc:0.8155\n",
      "[500]\teval-auc:0.816234\n",
      "[600]\teval-auc:0.816337\n",
      "[700]\teval-auc:0.816384\n",
      "[800]\teval-auc:0.816406\n",
      "[900]\teval-auc:0.816415\n",
      "Stopping. Best iteration:\n",
      "[848]\teval-auc:0.816415\n",
      "\n",
      "fold 7 - 0.816415056954\n",
      "[0]\teval-auc:0.791088\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.81707\n",
      "[200]\teval-auc:0.822524\n",
      "[300]\teval-auc:0.824639\n",
      "[400]\teval-auc:0.825725\n",
      "[500]\teval-auc:0.826538\n",
      "[600]\teval-auc:0.82688\n",
      "[700]\teval-auc:0.826982\n",
      "[800]\teval-auc:0.826996\n",
      "[900]\teval-auc:0.826999\n",
      "Stopping. Best iteration:\n",
      "[811]\teval-auc:0.827\n",
      "\n",
      "fold 8 - 0.826999692822\n",
      "[0]\teval-auc:0.768449\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.799115\n",
      "[200]\teval-auc:0.802916\n",
      "[300]\teval-auc:0.806263\n",
      "[400]\teval-auc:0.807988\n",
      "[500]\teval-auc:0.809057\n",
      "[600]\teval-auc:0.809517\n",
      "[700]\teval-auc:0.809654\n",
      "[800]\teval-auc:0.809662\n",
      "Stopping. Best iteration:\n",
      "[731]\teval-auc:0.809662\n",
      "\n",
      "fold 9 - 0.809662298135\n",
      "cv score - on train:\n",
      "0.8169969756172765\n",
      "('current score in fold:', 0.8170543794890502, 2)\n",
      "[0]\teval-auc:0.774883\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.808906\n",
      "[200]\teval-auc:0.811681\n",
      "[300]\teval-auc:0.814155\n",
      "[400]\teval-auc:0.815526\n",
      "[500]\teval-auc:0.816175\n",
      "[600]\teval-auc:0.81637\n",
      "[700]\teval-auc:0.816431\n",
      "[800]\teval-auc:0.816439\n",
      "[900]\teval-auc:0.816442\n",
      "Stopping. Best iteration:\n",
      "[824]\teval-auc:0.816442\n",
      "\n",
      "fold 0 - 0.816442409396\n",
      "[0]\teval-auc:0.776177\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.804596\n",
      "[200]\teval-auc:0.81075\n",
      "[300]\teval-auc:0.812324\n",
      "[400]\teval-auc:0.813279\n",
      "[500]\teval-auc:0.814142\n",
      "[600]\teval-auc:0.814235\n",
      "[700]\teval-auc:0.814275\n",
      "[800]\teval-auc:0.814274\n",
      "[900]\teval-auc:0.814282\n",
      "Stopping. Best iteration:\n",
      "[898]\teval-auc:0.814282\n",
      "\n",
      "fold 1 - 0.814281555484\n",
      "[0]\teval-auc:0.78025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.81286\n",
      "[200]\teval-auc:0.818208\n",
      "[300]\teval-auc:0.820663\n",
      "[400]\teval-auc:0.821669\n",
      "[500]\teval-auc:0.822434\n",
      "[600]\teval-auc:0.822779\n",
      "[700]\teval-auc:0.822914\n",
      "[800]\teval-auc:0.822924\n",
      "[900]\teval-auc:0.822934\n",
      "Stopping. Best iteration:\n",
      "[829]\teval-auc:0.822934\n",
      "\n",
      "fold 2 - 0.82293420296\n",
      "[0]\teval-auc:0.768242\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.806563\n",
      "[200]\teval-auc:0.810642\n",
      "[300]\teval-auc:0.813001\n",
      "[400]\teval-auc:0.813768\n",
      "[500]\teval-auc:0.814538\n",
      "[600]\teval-auc:0.814844\n",
      "[700]\teval-auc:0.814946\n",
      "[800]\teval-auc:0.814947\n",
      "Stopping. Best iteration:\n",
      "[726]\teval-auc:0.814947\n",
      "\n",
      "fold 3 - 0.814947458274\n",
      "[0]\teval-auc:0.77332\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.807521\n",
      "[200]\teval-auc:0.813185\n",
      "[300]\teval-auc:0.814934\n",
      "[400]\teval-auc:0.815729\n",
      "[500]\teval-auc:0.816522\n",
      "[600]\teval-auc:0.816712\n",
      "[700]\teval-auc:0.816773\n",
      "Stopping. Best iteration:\n",
      "[688]\teval-auc:0.816773\n",
      "\n",
      "fold 4 - 0.816773366259\n",
      "[0]\teval-auc:0.77257\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.80049\n",
      "[200]\teval-auc:0.804663\n",
      "[300]\teval-auc:0.807647\n",
      "[400]\teval-auc:0.808916\n",
      "[500]\teval-auc:0.810011\n",
      "[600]\teval-auc:0.810428\n",
      "[700]\teval-auc:0.810628\n",
      "[800]\teval-auc:0.810645\n",
      "[900]\teval-auc:0.810666\n",
      "Stopping. Best iteration:\n",
      "[860]\teval-auc:0.810666\n",
      "\n",
      "fold 5 - 0.810666363775\n",
      "[0]\teval-auc:0.777166\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.811195\n",
      "[200]\teval-auc:0.816158\n",
      "[300]\teval-auc:0.817943\n",
      "[400]\teval-auc:0.818771\n",
      "[500]\teval-auc:0.819229\n",
      "[600]\teval-auc:0.819369\n",
      "[700]\teval-auc:0.819407\n",
      "Stopping. Best iteration:\n",
      "[663]\teval-auc:0.819407\n",
      "\n",
      "fold 6 - 0.819407082059\n",
      "[0]\teval-auc:0.77059\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.803566\n",
      "[200]\teval-auc:0.809071\n",
      "[300]\teval-auc:0.811581\n",
      "[400]\teval-auc:0.812846\n",
      "[500]\teval-auc:0.813814\n",
      "[600]\teval-auc:0.814065\n",
      "[700]\teval-auc:0.814184\n",
      "Stopping. Best iteration:\n",
      "[638]\teval-auc:0.8142\n",
      "\n",
      "fold 7 - 0.814199885988\n",
      "[0]\teval-auc:0.771492\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.80966\n",
      "[200]\teval-auc:0.813379\n",
      "[300]\teval-auc:0.815807\n",
      "[400]\teval-auc:0.817318\n",
      "[500]\teval-auc:0.818044\n",
      "[600]\teval-auc:0.818239\n",
      "[700]\teval-auc:0.818297\n",
      "[800]\teval-auc:0.81831\n",
      "[900]\teval-auc:0.818357\n",
      "Stopping. Best iteration:\n",
      "[861]\teval-auc:0.818357\n",
      "\n",
      "fold 8 - 0.818356543796\n",
      "[0]\teval-auc:0.781654\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.815965\n",
      "[200]\teval-auc:0.818547\n",
      "[300]\teval-auc:0.820497\n",
      "[400]\teval-auc:0.821323\n",
      "[500]\teval-auc:0.822053\n",
      "[600]\teval-auc:0.822344\n",
      "[700]\teval-auc:0.822443\n",
      "[800]\teval-auc:0.822464\n",
      "Stopping. Best iteration:\n",
      "[731]\teval-auc:0.822464\n",
      "\n",
      "fold 9 - 0.822463964971\n",
      "cv score - on train:\n",
      "0.8169521350856134\n",
      "('current score in fold:', 0.8170596511743172, 3)\n",
      "[0]\teval-auc:0.768224\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.802668\n",
      "[200]\teval-auc:0.807434\n",
      "[300]\teval-auc:0.809863\n",
      "[400]\teval-auc:0.811661\n",
      "[500]\teval-auc:0.812423\n",
      "[600]\teval-auc:0.81273\n",
      "[700]\teval-auc:0.812788\n",
      "[800]\teval-auc:0.812802\n",
      "[900]\teval-auc:0.812812\n",
      "Stopping. Best iteration:\n",
      "[855]\teval-auc:0.812812\n",
      "\n",
      "fold 0 - 0.812811835184\n",
      "[0]\teval-auc:0.782685\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.81371\n",
      "[200]\teval-auc:0.81844\n",
      "[300]\teval-auc:0.820228\n",
      "[400]\teval-auc:0.821207\n",
      "[500]\teval-auc:0.821838\n",
      "[600]\teval-auc:0.821922\n",
      "[700]\teval-auc:0.821963\n",
      "[800]\teval-auc:0.821978\n",
      "[900]\teval-auc:0.821981\n",
      "Stopping. Best iteration:\n",
      "[835]\teval-auc:0.821982\n",
      "\n",
      "fold 1 - 0.821981522177\n",
      "[0]\teval-auc:0.776069\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.806201\n",
      "[200]\teval-auc:0.810592\n",
      "[300]\teval-auc:0.812381\n",
      "[400]\teval-auc:0.813496\n",
      "[500]\teval-auc:0.814362\n",
      "[600]\teval-auc:0.814799\n",
      "[700]\teval-auc:0.814908\n",
      "[800]\teval-auc:0.814927\n",
      "[900]\teval-auc:0.814935\n",
      "[1000]\teval-auc:0.814947\n",
      "Stopping. Best iteration:\n",
      "[934]\teval-auc:0.814947\n",
      "\n",
      "fold 2 - 0.814947052244\n",
      "[0]\teval-auc:0.775988\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.805291\n",
      "[200]\teval-auc:0.809331\n",
      "[300]\teval-auc:0.810502\n",
      "[400]\teval-auc:0.812364\n",
      "[500]\teval-auc:0.813179\n",
      "[600]\teval-auc:0.813462\n",
      "[700]\teval-auc:0.813518\n",
      "[800]\teval-auc:0.813508\n",
      "Stopping. Best iteration:\n",
      "[738]\teval-auc:0.81352\n",
      "\n",
      "fold 3 - 0.813520485055\n",
      "[0]\teval-auc:0.780376\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.807906\n",
      "[200]\teval-auc:0.81212\n",
      "[300]\teval-auc:0.815213\n",
      "[400]\teval-auc:0.816408\n",
      "[500]\teval-auc:0.817082\n",
      "[600]\teval-auc:0.817405\n",
      "[700]\teval-auc:0.817422\n",
      "Stopping. Best iteration:\n",
      "[620]\teval-auc:0.817425\n",
      "\n",
      "fold 4 - 0.817424609243\n",
      "[0]\teval-auc:0.773209\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.804848\n",
      "[200]\teval-auc:0.810153\n",
      "[300]\teval-auc:0.812144\n",
      "[400]\teval-auc:0.81339\n",
      "[500]\teval-auc:0.814108\n",
      "[600]\teval-auc:0.814359\n",
      "[700]\teval-auc:0.814444\n",
      "Stopping. Best iteration:\n",
      "[680]\teval-auc:0.814444\n",
      "\n",
      "fold 5 - 0.814443917676\n",
      "[0]\teval-auc:0.782741\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.811866\n",
      "[200]\teval-auc:0.815719\n",
      "[300]\teval-auc:0.817131\n",
      "[400]\teval-auc:0.817954\n",
      "[500]\teval-auc:0.818767\n",
      "[600]\teval-auc:0.819004\n",
      "[700]\teval-auc:0.819138\n",
      "[800]\teval-auc:0.819145\n",
      "[900]\teval-auc:0.819152\n",
      "[1000]\teval-auc:0.819156\n",
      "Stopping. Best iteration:\n",
      "[901]\teval-auc:0.819157\n",
      "\n",
      "fold 6 - 0.819156701421\n",
      "[0]\teval-auc:0.779502\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.807705\n",
      "[200]\teval-auc:0.814002\n",
      "[300]\teval-auc:0.815712\n",
      "[400]\teval-auc:0.817529\n",
      "[500]\teval-auc:0.818646\n",
      "[600]\teval-auc:0.818992\n",
      "[700]\teval-auc:0.819095\n",
      "[800]\teval-auc:0.81914\n",
      "[900]\teval-auc:0.819151\n",
      "[1000]\teval-auc:0.819165\n",
      "[1100]\teval-auc:0.819182\n",
      "[1200]\teval-auc:0.819187\n",
      "Stopping. Best iteration:\n",
      "[1141]\teval-auc:0.819187\n",
      "\n",
      "fold 7 - 0.819186525608\n",
      "[0]\teval-auc:0.783356\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.811293\n",
      "[200]\teval-auc:0.815497\n",
      "[300]\teval-auc:0.817327\n",
      "[400]\teval-auc:0.817996\n",
      "[500]\teval-auc:0.818492\n",
      "[600]\teval-auc:0.818595\n",
      "[700]\teval-auc:0.818592\n",
      "Stopping. Best iteration:\n",
      "[608]\teval-auc:0.818601\n",
      "\n",
      "fold 8 - 0.818600859826\n",
      "[0]\teval-auc:0.783436\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.809588\n",
      "[200]\teval-auc:0.814377\n",
      "[300]\teval-auc:0.81692\n",
      "[400]\teval-auc:0.817704\n",
      "[500]\teval-auc:0.818361\n",
      "[600]\teval-auc:0.818596\n",
      "[700]\teval-auc:0.818662\n",
      "[800]\teval-auc:0.818674\n",
      "[900]\teval-auc:0.8187\n",
      "[1000]\teval-auc:0.818703\n",
      "Stopping. Best iteration:\n",
      "[950]\teval-auc:0.818703\n",
      "\n",
      "fold 9 - 0.818703188498\n",
      "cv score - on train:\n",
      "0.8169759855605842\n",
      "('current score in fold:', 0.8170686931227179, 4)\n",
      "[0]\teval-auc:0.781202\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.81142\n",
      "[200]\teval-auc:0.815776\n",
      "[300]\teval-auc:0.818204\n",
      "[400]\teval-auc:0.819597\n",
      "[500]\teval-auc:0.820139\n",
      "[600]\teval-auc:0.820398\n",
      "[700]\teval-auc:0.820496\n",
      "[800]\teval-auc:0.820511\n",
      "[900]\teval-auc:0.820515\n",
      "Stopping. Best iteration:\n",
      "[869]\teval-auc:0.820515\n",
      "\n",
      "fold 0 - 0.820514544358\n",
      "[0]\teval-auc:0.778075\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.805551\n",
      "[200]\teval-auc:0.81064\n",
      "[300]\teval-auc:0.813369\n",
      "[400]\teval-auc:0.814729\n",
      "[500]\teval-auc:0.81558\n",
      "[600]\teval-auc:0.815857\n",
      "[700]\teval-auc:0.815942\n",
      "[800]\teval-auc:0.815954\n",
      "Stopping. Best iteration:\n",
      "[789]\teval-auc:0.815955\n",
      "\n",
      "fold 1 - 0.815954803463\n",
      "[0]\teval-auc:0.781815\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.815678\n",
      "[200]\teval-auc:0.821001\n",
      "[300]\teval-auc:0.823063\n",
      "[400]\teval-auc:0.824577\n",
      "[500]\teval-auc:0.825208\n",
      "[600]\teval-auc:0.825515\n",
      "[700]\teval-auc:0.825599\n",
      "[800]\teval-auc:0.825642\n",
      "[900]\teval-auc:0.825644\n",
      "[1000]\teval-auc:0.825648\n",
      "[1100]\teval-auc:0.825652\n",
      "[1200]\teval-auc:0.825656\n",
      "[1300]\teval-auc:0.825657\n",
      "Stopping. Best iteration:\n",
      "[1233]\teval-auc:0.825657\n",
      "\n",
      "fold 2 - 0.825656667041\n",
      "[0]\teval-auc:0.776182\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.809035\n",
      "[200]\teval-auc:0.812123\n",
      "[300]\teval-auc:0.814526\n",
      "[400]\teval-auc:0.81578\n",
      "[500]\teval-auc:0.816672\n",
      "[600]\teval-auc:0.817024\n",
      "[700]\teval-auc:0.817073\n",
      "Stopping. Best iteration:\n",
      "[658]\teval-auc:0.817074\n",
      "\n",
      "fold 3 - 0.817073614463\n",
      "[0]\teval-auc:0.78117\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.808899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\teval-auc:0.813399\n",
      "[300]\teval-auc:0.815625\n",
      "[400]\teval-auc:0.816587\n",
      "[500]\teval-auc:0.81746\n",
      "[600]\teval-auc:0.817739\n",
      "[700]\teval-auc:0.817818\n",
      "[800]\teval-auc:0.81787\n",
      "Stopping. Best iteration:\n",
      "[763]\teval-auc:0.81787\n",
      "\n",
      "fold 4 - 0.817870244537\n",
      "[0]\teval-auc:0.773783\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.804501\n",
      "[200]\teval-auc:0.810222\n",
      "[300]\teval-auc:0.81164\n",
      "[400]\teval-auc:0.812656\n",
      "[500]\teval-auc:0.813284\n",
      "[600]\teval-auc:0.813726\n",
      "[700]\teval-auc:0.813773\n",
      "Stopping. Best iteration:\n",
      "[675]\teval-auc:0.813773\n",
      "\n",
      "fold 5 - 0.813772658489\n",
      "[0]\teval-auc:0.777402\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.806866\n",
      "[200]\teval-auc:0.810417\n",
      "[300]\teval-auc:0.81222\n",
      "[400]\teval-auc:0.813191\n",
      "[500]\teval-auc:0.813732\n",
      "[600]\teval-auc:0.814022\n",
      "[700]\teval-auc:0.814061\n",
      "[800]\teval-auc:0.814075\n",
      "[900]\teval-auc:0.814081\n",
      "Stopping. Best iteration:\n",
      "[873]\teval-auc:0.814081\n",
      "\n",
      "fold 6 - 0.814080795909\n",
      "[0]\teval-auc:0.777673\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.807679\n",
      "[200]\teval-auc:0.811775\n",
      "[300]\teval-auc:0.813556\n",
      "[400]\teval-auc:0.814413\n",
      "[500]\teval-auc:0.81518\n",
      "[600]\teval-auc:0.815333\n",
      "[700]\teval-auc:0.815377\n",
      "Stopping. Best iteration:\n",
      "[605]\teval-auc:0.815392\n",
      "\n",
      "fold 7 - 0.815392140804\n",
      "[0]\teval-auc:0.773791\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.802794\n",
      "[200]\teval-auc:0.807638\n",
      "[300]\teval-auc:0.810304\n",
      "[400]\teval-auc:0.811202\n",
      "[500]\teval-auc:0.811973\n",
      "[600]\teval-auc:0.812188\n",
      "[700]\teval-auc:0.812299\n",
      "[800]\teval-auc:0.812348\n",
      "[900]\teval-auc:0.812355\n",
      "[1000]\teval-auc:0.812358\n",
      "Stopping. Best iteration:\n",
      "[907]\teval-auc:0.812358\n",
      "\n",
      "fold 8 - 0.812358126665\n",
      "[0]\teval-auc:0.782378\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.808803\n",
      "[200]\teval-auc:0.813196\n",
      "[300]\teval-auc:0.815316\n",
      "[400]\teval-auc:0.81624\n",
      "[500]\teval-auc:0.816989\n",
      "[600]\teval-auc:0.817226\n",
      "[700]\teval-auc:0.817255\n",
      "[800]\teval-auc:0.817266\n",
      "[900]\teval-auc:0.817269\n",
      "Stopping. Best iteration:\n",
      "[801]\teval-auc:0.817269\n",
      "\n",
      "fold 9 - 0.817268948001\n",
      "cv score - on train:\n",
      "0.8168863529463182\n",
      "('current score in fold:', 0.8170580500753671, 5)\n",
      "[0]\teval-auc:0.780768\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.809321\n",
      "[200]\teval-auc:0.814699\n",
      "[300]\teval-auc:0.81641\n",
      "[400]\teval-auc:0.817603\n",
      "[500]\teval-auc:0.818448\n",
      "[600]\teval-auc:0.818592\n",
      "Stopping. Best iteration:\n",
      "[576]\teval-auc:0.818625\n",
      "\n",
      "fold 0 - 0.818625288632\n",
      "[0]\teval-auc:0.781273\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.813955\n",
      "[200]\teval-auc:0.817415\n",
      "[300]\teval-auc:0.819514\n",
      "[400]\teval-auc:0.820724\n",
      "[500]\teval-auc:0.821383\n",
      "[600]\teval-auc:0.821512\n",
      "[700]\teval-auc:0.821573\n",
      "[800]\teval-auc:0.821586\n",
      "Stopping. Best iteration:\n",
      "[795]\teval-auc:0.821588\n",
      "\n",
      "fold 1 - 0.821587673466\n",
      "[0]\teval-auc:0.774951\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.809054\n",
      "[200]\teval-auc:0.812339\n",
      "[300]\teval-auc:0.814667\n",
      "[400]\teval-auc:0.815672\n",
      "[500]\teval-auc:0.81651\n",
      "[600]\teval-auc:0.816703\n",
      "[700]\teval-auc:0.816679\n",
      "Stopping. Best iteration:\n",
      "[630]\teval-auc:0.816711\n",
      "\n",
      "fold 2 - 0.816710802084\n",
      "[0]\teval-auc:0.784039\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.812625\n",
      "[200]\teval-auc:0.818337\n",
      "[300]\teval-auc:0.819714\n",
      "[400]\teval-auc:0.820739\n",
      "[500]\teval-auc:0.821424\n",
      "[600]\teval-auc:0.8216\n",
      "[700]\teval-auc:0.821607\n",
      "[800]\teval-auc:0.821607\n",
      "Stopping. Best iteration:\n",
      "[706]\teval-auc:0.82161\n",
      "\n",
      "fold 3 - 0.821609534954\n",
      "[0]\teval-auc:0.772219\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.801803\n",
      "[200]\teval-auc:0.806762\n",
      "[300]\teval-auc:0.80904\n",
      "[400]\teval-auc:0.810304\n",
      "[500]\teval-auc:0.811088\n",
      "[600]\teval-auc:0.811376\n",
      "[700]\teval-auc:0.811503\n",
      "Stopping. Best iteration:\n",
      "[668]\teval-auc:0.811503\n",
      "\n",
      "fold 4 - 0.811502731646\n",
      "[0]\teval-auc:0.779913\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.809102\n",
      "[200]\teval-auc:0.812669\n",
      "[300]\teval-auc:0.81549\n",
      "[400]\teval-auc:0.816414\n",
      "[500]\teval-auc:0.817394\n",
      "[600]\teval-auc:0.817708\n",
      "[700]\teval-auc:0.817825\n",
      "[800]\teval-auc:0.817829\n",
      "Stopping. Best iteration:\n",
      "[721]\teval-auc:0.817829\n",
      "\n",
      "fold 5 - 0.81782943814\n",
      "[0]\teval-auc:0.782224\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.811853\n",
      "[200]\teval-auc:0.815999\n",
      "[300]\teval-auc:0.817564\n",
      "[400]\teval-auc:0.818465\n",
      "[500]\teval-auc:0.819115\n",
      "[600]\teval-auc:0.819387\n",
      "[700]\teval-auc:0.819468\n",
      "Stopping. Best iteration:\n",
      "[672]\teval-auc:0.819469\n",
      "\n",
      "fold 6 - 0.819468533424\n",
      "[0]\teval-auc:0.770254\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.800184\n",
      "[200]\teval-auc:0.805907\n",
      "[300]\teval-auc:0.807692\n",
      "[400]\teval-auc:0.809135\n",
      "[500]\teval-auc:0.809912\n",
      "[600]\teval-auc:0.810294\n",
      "[700]\teval-auc:0.81046\n",
      "[800]\teval-auc:0.810469\n",
      "Stopping. Best iteration:\n",
      "[749]\teval-auc:0.810469\n",
      "\n",
      "fold 7 - 0.810468662897\n",
      "[0]\teval-auc:0.780578\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.807977\n",
      "[200]\teval-auc:0.811514\n",
      "[300]\teval-auc:0.8135\n",
      "[400]\teval-auc:0.814796\n",
      "[500]\teval-auc:0.815401\n",
      "[600]\teval-auc:0.815563\n",
      "Stopping. Best iteration:\n",
      "[597]\teval-auc:0.815566\n",
      "\n",
      "fold 8 - 0.815566218559\n",
      "[0]\teval-auc:0.775352\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.80691\n",
      "[200]\teval-auc:0.811304\n",
      "[300]\teval-auc:0.814083\n",
      "[400]\teval-auc:0.815312\n",
      "[500]\teval-auc:0.816192\n",
      "[600]\teval-auc:0.816694\n",
      "[700]\teval-auc:0.816834\n",
      "[800]\teval-auc:0.816864\n",
      "Stopping. Best iteration:\n",
      "[799]\teval-auc:0.816864\n",
      "\n",
      "fold 9 - 0.81686422987\n",
      "cv score - on train:\n",
      "0.8169202484789864\n",
      "('current score in fold:', 0.817058720952357, 6)\n",
      "[0]\teval-auc:0.776052\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.801456\n",
      "[200]\teval-auc:0.805972\n",
      "[300]\teval-auc:0.808372\n",
      "[400]\teval-auc:0.809268\n",
      "[500]\teval-auc:0.810168\n",
      "[600]\teval-auc:0.810467\n",
      "[700]\teval-auc:0.810589\n",
      "[800]\teval-auc:0.810603\n",
      "[900]\teval-auc:0.810619\n",
      "[1000]\teval-auc:0.810626\n",
      "[1100]\teval-auc:0.810632\n",
      "[1200]\teval-auc:0.810642\n",
      "Stopping. Best iteration:\n",
      "[1137]\teval-auc:0.810642\n",
      "\n",
      "fold 0 - 0.810642354925\n",
      "[0]\teval-auc:0.779983\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.810209\n",
      "[200]\teval-auc:0.814131\n",
      "[300]\teval-auc:0.816965\n",
      "[400]\teval-auc:0.818226\n",
      "[500]\teval-auc:0.818824\n",
      "[600]\teval-auc:0.819016\n",
      "[700]\teval-auc:0.819122\n",
      "[800]\teval-auc:0.819147\n",
      "[900]\teval-auc:0.819159\n",
      "[1000]\teval-auc:0.819166\n",
      "[1100]\teval-auc:0.819175\n",
      "[1200]\teval-auc:0.819181\n",
      "Stopping. Best iteration:\n",
      "[1179]\teval-auc:0.819181\n",
      "\n",
      "fold 1 - 0.81918102918\n",
      "[0]\teval-auc:0.776197\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.810476\n",
      "[200]\teval-auc:0.814\n",
      "[300]\teval-auc:0.816392\n",
      "[400]\teval-auc:0.817529\n",
      "[500]\teval-auc:0.818152\n",
      "[600]\teval-auc:0.818257\n",
      "[700]\teval-auc:0.81832\n",
      "[800]\teval-auc:0.818323\n",
      "[900]\teval-auc:0.818329\n",
      "Stopping. Best iteration:\n",
      "[839]\teval-auc:0.818329\n",
      "\n",
      "fold 2 - 0.818328701818\n",
      "[0]\teval-auc:0.769406\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.801412\n",
      "[200]\teval-auc:0.80561\n",
      "[300]\teval-auc:0.807444\n",
      "[400]\teval-auc:0.808759\n",
      "[500]\teval-auc:0.809581\n",
      "[600]\teval-auc:0.810005\n",
      "[700]\teval-auc:0.810041\n",
      "[800]\teval-auc:0.810059\n",
      "[900]\teval-auc:0.810091\n",
      "[1000]\teval-auc:0.81011\n",
      "[1100]\teval-auc:0.810111\n",
      "[1200]\teval-auc:0.810119\n",
      "Stopping. Best iteration:\n",
      "[1149]\teval-auc:0.810119\n",
      "\n",
      "fold 3 - 0.810118740578\n",
      "[0]\teval-auc:0.779429\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.808455\n",
      "[200]\teval-auc:0.814285\n",
      "[300]\teval-auc:0.816356\n",
      "[400]\teval-auc:0.817198\n",
      "[500]\teval-auc:0.817718\n",
      "[600]\teval-auc:0.817893\n",
      "[700]\teval-auc:0.817896\n",
      "Stopping. Best iteration:\n",
      "[605]\teval-auc:0.81791\n",
      "\n",
      "fold 4 - 0.817910234891\n",
      "[0]\teval-auc:0.787382\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.817004\n",
      "[200]\teval-auc:0.819719\n",
      "[300]\teval-auc:0.822155\n",
      "[400]\teval-auc:0.822695\n",
      "[500]\teval-auc:0.823235\n",
      "[600]\teval-auc:0.823367\n",
      "[700]\teval-auc:0.823372\n",
      "Stopping. Best iteration:\n",
      "[605]\teval-auc:0.823383\n",
      "\n",
      "fold 5 - 0.823383160838\n",
      "[0]\teval-auc:0.777241\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.808278\n",
      "[200]\teval-auc:0.812767\n",
      "[300]\teval-auc:0.814269\n",
      "[400]\teval-auc:0.815579\n",
      "[500]\teval-auc:0.81641\n",
      "[600]\teval-auc:0.816556\n",
      "[700]\teval-auc:0.816591\n",
      "[800]\teval-auc:0.816602\n",
      "[900]\teval-auc:0.816618\n",
      "[1000]\teval-auc:0.816623\n",
      "[1100]\teval-auc:0.816659\n",
      "[1200]\teval-auc:0.816663\n",
      "[1300]\teval-auc:0.816662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping. Best iteration:\n",
      "[1212]\teval-auc:0.816664\n",
      "\n",
      "fold 6 - 0.816663734371\n",
      "[0]\teval-auc:0.773583\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.804039\n",
      "[200]\teval-auc:0.809117\n",
      "[300]\teval-auc:0.811747\n",
      "[400]\teval-auc:0.81327\n",
      "[500]\teval-auc:0.814404\n",
      "[600]\teval-auc:0.814687\n",
      "[700]\teval-auc:0.814714\n",
      "[800]\teval-auc:0.81474\n",
      "[900]\teval-auc:0.814755\n",
      "[1000]\teval-auc:0.814779\n",
      "[1100]\teval-auc:0.814791\n",
      "[1200]\teval-auc:0.814801\n",
      "Stopping. Best iteration:\n",
      "[1152]\teval-auc:0.814801\n",
      "\n",
      "fold 7 - 0.814801180071\n",
      "[0]\teval-auc:0.78372\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.811024\n",
      "[200]\teval-auc:0.815238\n",
      "[300]\teval-auc:0.817065\n",
      "[400]\teval-auc:0.818458\n",
      "[500]\teval-auc:0.819153\n",
      "[600]\teval-auc:0.819464\n",
      "[700]\teval-auc:0.819501\n",
      "[800]\teval-auc:0.819515\n",
      "[900]\teval-auc:0.819522\n",
      "[1000]\teval-auc:0.819545\n",
      "[1100]\teval-auc:0.819563\n",
      "[1200]\teval-auc:0.819572\n",
      "Stopping. Best iteration:\n",
      "[1119]\teval-auc:0.819572\n",
      "\n",
      "fold 8 - 0.819572458421\n",
      "[0]\teval-auc:0.782134\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.811585\n",
      "[200]\teval-auc:0.816636\n",
      "[300]\teval-auc:0.818674\n",
      "[400]\teval-auc:0.82021\n",
      "[500]\teval-auc:0.820961\n",
      "[600]\teval-auc:0.82135\n",
      "[700]\teval-auc:0.821409\n",
      "[800]\teval-auc:0.821413\n",
      "[900]\teval-auc:0.821432\n",
      "[1000]\teval-auc:0.821437\n",
      "[1100]\teval-auc:0.821444\n",
      "Stopping. Best iteration:\n",
      "[1004]\teval-auc:0.821444\n",
      "\n",
      "fold 9 - 0.821444006298\n",
      "cv score - on train:\n",
      "0.8170879291809254\n",
      "('current score in fold:', 0.8170812099374808, 7)\n",
      "[0]\teval-auc:0.774571\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.805663\n",
      "[200]\teval-auc:0.810822\n",
      "[300]\teval-auc:0.813031\n",
      "[400]\teval-auc:0.814126\n",
      "[500]\teval-auc:0.814766\n",
      "[600]\teval-auc:0.815003\n",
      "[700]\teval-auc:0.815046\n",
      "[800]\teval-auc:0.815054\n",
      "Stopping. Best iteration:\n",
      "[787]\teval-auc:0.815054\n",
      "\n",
      "fold 0 - 0.815053987619\n",
      "[0]\teval-auc:0.787664\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.816542\n",
      "[200]\teval-auc:0.821139\n",
      "[300]\teval-auc:0.823219\n",
      "[400]\teval-auc:0.824228\n",
      "[500]\teval-auc:0.825009\n",
      "[600]\teval-auc:0.825286\n",
      "[700]\teval-auc:0.825369\n",
      "[800]\teval-auc:0.82537\n",
      "[900]\teval-auc:0.825371\n",
      "Stopping. Best iteration:\n",
      "[844]\teval-auc:0.825371\n",
      "\n",
      "fold 1 - 0.825370715353\n",
      "[0]\teval-auc:0.786939\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.814914\n",
      "[200]\teval-auc:0.820696\n",
      "[300]\teval-auc:0.822785\n",
      "[400]\teval-auc:0.824016\n",
      "[500]\teval-auc:0.824735\n",
      "[600]\teval-auc:0.8249\n",
      "[700]\teval-auc:0.824946\n",
      "[800]\teval-auc:0.824977\n",
      "[900]\teval-auc:0.824989\n",
      "[1000]\teval-auc:0.825007\n",
      "Stopping. Best iteration:\n",
      "[940]\teval-auc:0.825007\n",
      "\n",
      "fold 2 - 0.825006941325\n",
      "[0]\teval-auc:0.776105\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.809759\n",
      "[200]\teval-auc:0.814266\n",
      "[300]\teval-auc:0.816246\n",
      "[400]\teval-auc:0.817475\n",
      "[500]\teval-auc:0.817987\n",
      "[600]\teval-auc:0.818163\n",
      "[700]\teval-auc:0.818159\n",
      "Stopping. Best iteration:\n",
      "[602]\teval-auc:0.818168\n",
      "\n",
      "fold 3 - 0.818167550807\n",
      "[0]\teval-auc:0.783495\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.810909\n",
      "[200]\teval-auc:0.815465\n",
      "[300]\teval-auc:0.817276\n",
      "[400]\teval-auc:0.818075\n",
      "[500]\teval-auc:0.818497\n",
      "[600]\teval-auc:0.818657\n",
      "[700]\teval-auc:0.818714\n",
      "[800]\teval-auc:0.818724\n",
      "Stopping. Best iteration:\n",
      "[766]\teval-auc:0.818725\n",
      "\n",
      "fold 4 - 0.818724829994\n",
      "[0]\teval-auc:0.765326\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.794848\n",
      "[200]\teval-auc:0.797391\n",
      "[300]\teval-auc:0.800293\n",
      "[400]\teval-auc:0.801087\n",
      "[500]\teval-auc:0.801761\n",
      "[600]\teval-auc:0.802234\n",
      "[700]\teval-auc:0.80232\n",
      "[800]\teval-auc:0.802334\n",
      "[900]\teval-auc:0.802346\n",
      "[1000]\teval-auc:0.802351\n",
      "Stopping. Best iteration:\n",
      "[924]\teval-auc:0.802351\n",
      "\n",
      "fold 5 - 0.802350855196\n",
      "[0]\teval-auc:0.77885\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.809102\n",
      "[200]\teval-auc:0.814334\n",
      "[300]\teval-auc:0.816559\n",
      "[400]\teval-auc:0.818109\n",
      "[500]\teval-auc:0.818907\n",
      "[600]\teval-auc:0.819182\n",
      "[700]\teval-auc:0.819325\n",
      "Stopping. Best iteration:\n",
      "[642]\teval-auc:0.819343\n",
      "\n",
      "fold 6 - 0.819343164944\n",
      "[0]\teval-auc:0.778957\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.807652\n",
      "[200]\teval-auc:0.812613\n",
      "[300]\teval-auc:0.814727\n",
      "[400]\teval-auc:0.815834\n",
      "[500]\teval-auc:0.816894\n",
      "[600]\teval-auc:0.8171\n",
      "[700]\teval-auc:0.817179\n",
      "Stopping. Best iteration:\n",
      "[649]\teval-auc:0.817197\n",
      "\n",
      "fold 7 - 0.817196628802\n",
      "[0]\teval-auc:0.77593\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.804133\n",
      "[200]\teval-auc:0.807685\n",
      "[300]\teval-auc:0.810524\n",
      "[400]\teval-auc:0.811748\n",
      "[500]\teval-auc:0.812746\n",
      "[600]\teval-auc:0.813107\n",
      "[700]\teval-auc:0.813291\n",
      "[800]\teval-auc:0.813308\n",
      "Stopping. Best iteration:\n",
      "[747]\teval-auc:0.813308\n",
      "\n",
      "fold 8 - 0.813307569132\n",
      "[0]\teval-auc:0.775934\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.808582\n",
      "[200]\teval-auc:0.812784\n",
      "[300]\teval-auc:0.814738\n",
      "[400]\teval-auc:0.815799\n",
      "[500]\teval-auc:0.816457\n",
      "[600]\teval-auc:0.816718\n",
      "[700]\teval-auc:0.816768\n",
      "[800]\teval-auc:0.816778\n",
      "[900]\teval-auc:0.816786\n",
      "Stopping. Best iteration:\n",
      "[899]\teval-auc:0.816786\n",
      "\n",
      "fold 9 - 0.816785703535\n",
      "cv score - on train:\n",
      "0.8170416651018689\n",
      "('current score in fold:', 0.8170876818057228, 8)\n",
      "[0]\teval-auc:0.787001\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.816854\n",
      "[200]\teval-auc:0.819969\n",
      "[300]\teval-auc:0.821291\n",
      "[400]\teval-auc:0.822103\n",
      "[500]\teval-auc:0.82245\n",
      "[600]\teval-auc:0.822424\n",
      "Stopping. Best iteration:\n",
      "[526]\teval-auc:0.822496\n",
      "\n",
      "fold 0 - 0.822495541403\n",
      "[0]\teval-auc:0.773777\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.805775\n",
      "[200]\teval-auc:0.810052\n",
      "[300]\teval-auc:0.811296\n",
      "[400]\teval-auc:0.813243\n",
      "[500]\teval-auc:0.81426\n",
      "[600]\teval-auc:0.814821\n",
      "[700]\teval-auc:0.814891\n",
      "[800]\teval-auc:0.814911\n",
      "[900]\teval-auc:0.814916\n",
      "[1000]\teval-auc:0.814929\n",
      "Stopping. Best iteration:\n",
      "[986]\teval-auc:0.814929\n",
      "\n",
      "fold 1 - 0.814929243929\n",
      "[0]\teval-auc:0.778977\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.806327\n",
      "[200]\teval-auc:0.810806\n",
      "[300]\teval-auc:0.813177\n",
      "[400]\teval-auc:0.814161\n",
      "[500]\teval-auc:0.814975\n",
      "[600]\teval-auc:0.815205\n",
      "[700]\teval-auc:0.815286\n",
      "[800]\teval-auc:0.8153\n",
      "[900]\teval-auc:0.815313\n",
      "Stopping. Best iteration:\n",
      "[888]\teval-auc:0.815313\n",
      "\n",
      "fold 2 - 0.81531249313\n",
      "[0]\teval-auc:0.772221\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.802941\n",
      "[200]\teval-auc:0.807235\n",
      "[300]\teval-auc:0.81007\n",
      "[400]\teval-auc:0.811437\n",
      "[500]\teval-auc:0.812337\n",
      "[600]\teval-auc:0.812625\n",
      "[700]\teval-auc:0.812781\n",
      "[800]\teval-auc:0.812794\n",
      "[900]\teval-auc:0.812796\n",
      "Stopping. Best iteration:\n",
      "[824]\teval-auc:0.812796\n",
      "\n",
      "fold 3 - 0.81279642743\n",
      "[0]\teval-auc:0.78309\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.813433\n",
      "[200]\teval-auc:0.818066\n",
      "[300]\teval-auc:0.820116\n",
      "[400]\teval-auc:0.821029\n",
      "[500]\teval-auc:0.821575\n",
      "[600]\teval-auc:0.82172\n",
      "[700]\teval-auc:0.821791\n",
      "Stopping. Best iteration:\n",
      "[690]\teval-auc:0.821791\n",
      "\n",
      "fold 4 - 0.821791293748\n",
      "[0]\teval-auc:0.783198\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.811721\n",
      "[200]\teval-auc:0.816291\n",
      "[300]\teval-auc:0.818425\n",
      "[400]\teval-auc:0.819411\n",
      "[500]\teval-auc:0.820172\n",
      "[600]\teval-auc:0.820295\n",
      "[700]\teval-auc:0.820378\n",
      "[800]\teval-auc:0.820404\n",
      "[900]\teval-auc:0.820423\n",
      "[1000]\teval-auc:0.82043\n",
      "Stopping. Best iteration:\n",
      "[961]\teval-auc:0.82043\n",
      "\n",
      "fold 5 - 0.820429609015\n",
      "[0]\teval-auc:0.770103\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.801491\n",
      "[200]\teval-auc:0.806742\n",
      "[300]\teval-auc:0.809796\n",
      "[400]\teval-auc:0.810677\n",
      "[500]\teval-auc:0.811511\n",
      "[600]\teval-auc:0.8118\n",
      "[700]\teval-auc:0.811821\n",
      "[800]\teval-auc:0.81183\n",
      "[900]\teval-auc:0.811848\n",
      "Stopping. Best iteration:\n",
      "[888]\teval-auc:0.811848\n",
      "\n",
      "fold 6 - 0.811848236409\n",
      "[0]\teval-auc:0.780549\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.808158\n",
      "[200]\teval-auc:0.812574\n",
      "[300]\teval-auc:0.815216\n",
      "[400]\teval-auc:0.816438\n",
      "[500]\teval-auc:0.817483\n",
      "[600]\teval-auc:0.817898\n",
      "[700]\teval-auc:0.818055\n",
      "Stopping. Best iteration:\n",
      "[654]\teval-auc:0.818055\n",
      "\n",
      "fold 7 - 0.818054596177\n",
      "[0]\teval-auc:0.780922\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.809827\n",
      "[200]\teval-auc:0.814861\n",
      "[300]\teval-auc:0.81664\n",
      "[400]\teval-auc:0.818001\n",
      "[500]\teval-auc:0.818798\n",
      "[600]\teval-auc:0.819124\n",
      "[700]\teval-auc:0.819178\n",
      "[800]\teval-auc:0.819186\n",
      "[900]\teval-auc:0.819216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\teval-auc:0.819224\n",
      "Stopping. Best iteration:\n",
      "[977]\teval-auc:0.819224\n",
      "\n",
      "fold 8 - 0.819223996473\n",
      "[0]\teval-auc:0.773286\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.804415\n",
      "[200]\teval-auc:0.809162\n",
      "[300]\teval-auc:0.810829\n",
      "[400]\teval-auc:0.812246\n",
      "[500]\teval-auc:0.812808\n",
      "[600]\teval-auc:0.812961\n",
      "[700]\teval-auc:0.813023\n",
      "[800]\teval-auc:0.813026\n",
      "Stopping. Best iteration:\n",
      "[786]\teval-auc:0.813026\n",
      "\n",
      "fold 9 - 0.813026224076\n",
      "cv score - on train:\n",
      "0.8168464202332283\n",
      "('current score in fold:', 0.8170816695623174, 9)\n",
      "[0]\teval-auc:0.777198\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.804581\n",
      "[200]\teval-auc:0.810192\n",
      "[300]\teval-auc:0.812124\n",
      "[400]\teval-auc:0.813816\n",
      "[500]\teval-auc:0.814893\n",
      "[600]\teval-auc:0.815216\n",
      "[700]\teval-auc:0.815361\n",
      "[800]\teval-auc:0.815372\n",
      "[900]\teval-auc:0.815412\n",
      "Stopping. Best iteration:\n",
      "[896]\teval-auc:0.815412\n",
      "\n",
      "fold 0 - 0.815411585723\n",
      "[0]\teval-auc:0.777809\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.807618\n",
      "[200]\teval-auc:0.812068\n",
      "[300]\teval-auc:0.81517\n",
      "[400]\teval-auc:0.816319\n",
      "[500]\teval-auc:0.817294\n",
      "[600]\teval-auc:0.817604\n",
      "[700]\teval-auc:0.817744\n",
      "[800]\teval-auc:0.817755\n",
      "[900]\teval-auc:0.817793\n",
      "[1000]\teval-auc:0.817806\n",
      "[1100]\teval-auc:0.817809\n",
      "Stopping. Best iteration:\n",
      "[1021]\teval-auc:0.817809\n",
      "\n",
      "fold 1 - 0.817808820094\n",
      "[0]\teval-auc:0.772855\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.804138\n",
      "[200]\teval-auc:0.807967\n",
      "[300]\teval-auc:0.811289\n",
      "[400]\teval-auc:0.812465\n",
      "[500]\teval-auc:0.813521\n",
      "[600]\teval-auc:0.814171\n",
      "[700]\teval-auc:0.81436\n",
      "[800]\teval-auc:0.8144\n",
      "[900]\teval-auc:0.814442\n",
      "[1000]\teval-auc:0.814452\n",
      "Stopping. Best iteration:\n",
      "[982]\teval-auc:0.814452\n",
      "\n",
      "fold 2 - 0.814452451206\n",
      "[0]\teval-auc:0.783233\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.813433\n",
      "[200]\teval-auc:0.81686\n",
      "[300]\teval-auc:0.81948\n",
      "[400]\teval-auc:0.820499\n",
      "[500]\teval-auc:0.821335\n",
      "[600]\teval-auc:0.821567\n",
      "[700]\teval-auc:0.821629\n",
      "[800]\teval-auc:0.821652\n",
      "Stopping. Best iteration:\n",
      "[777]\teval-auc:0.821652\n",
      "\n",
      "fold 3 - 0.821651932992\n",
      "[0]\teval-auc:0.779984\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.808682\n",
      "[200]\teval-auc:0.813884\n",
      "[300]\teval-auc:0.816158\n",
      "[400]\teval-auc:0.817123\n",
      "[500]\teval-auc:0.817864\n",
      "[600]\teval-auc:0.818111\n",
      "[700]\teval-auc:0.81818\n",
      "[800]\teval-auc:0.818202\n",
      "[900]\teval-auc:0.818215\n",
      "Stopping. Best iteration:\n",
      "[856]\teval-auc:0.81822\n",
      "\n",
      "fold 4 - 0.818220249175\n",
      "[0]\teval-auc:0.777373\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.804041\n",
      "[200]\teval-auc:0.809872\n",
      "[300]\teval-auc:0.812173\n",
      "[400]\teval-auc:0.81315\n",
      "[500]\teval-auc:0.813744\n",
      "[600]\teval-auc:0.814021\n",
      "[700]\teval-auc:0.814025\n",
      "[800]\teval-auc:0.814042\n",
      "Stopping. Best iteration:\n",
      "[797]\teval-auc:0.814042\n",
      "\n",
      "fold 5 - 0.814042185486\n",
      "[0]\teval-auc:0.772058\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.803137\n",
      "[200]\teval-auc:0.807135\n",
      "[300]\teval-auc:0.809722\n",
      "[400]\teval-auc:0.811197\n",
      "[500]\teval-auc:0.811776\n",
      "[600]\teval-auc:0.811966\n",
      "[700]\teval-auc:0.812063\n",
      "[800]\teval-auc:0.812089\n",
      "[900]\teval-auc:0.812106\n",
      "[1000]\teval-auc:0.812119\n",
      "[1100]\teval-auc:0.812135\n",
      "Stopping. Best iteration:\n",
      "[1051]\teval-auc:0.812135\n",
      "\n",
      "fold 6 - 0.812135332509\n",
      "[0]\teval-auc:0.779071\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.810146\n",
      "[200]\teval-auc:0.813357\n",
      "[300]\teval-auc:0.815642\n",
      "[400]\teval-auc:0.816405\n",
      "[500]\teval-auc:0.816833\n",
      "[600]\teval-auc:0.816853\n",
      "Stopping. Best iteration:\n",
      "[578]\teval-auc:0.816862\n",
      "\n",
      "fold 7 - 0.816862227338\n",
      "[0]\teval-auc:0.786673\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.814684\n",
      "[200]\teval-auc:0.819598\n",
      "[300]\teval-auc:0.820642\n",
      "[400]\teval-auc:0.821553\n",
      "[500]\teval-auc:0.821785\n",
      "[600]\teval-auc:0.821847\n",
      "[700]\teval-auc:0.821895\n",
      "[800]\teval-auc:0.8219\n",
      "Stopping. Best iteration:\n",
      "[716]\teval-auc:0.8219\n",
      "\n",
      "fold 8 - 0.821899528879\n",
      "[0]\teval-auc:0.779244\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.810623\n",
      "[200]\teval-auc:0.814114\n",
      "[300]\teval-auc:0.816241\n",
      "[400]\teval-auc:0.817511\n",
      "[500]\teval-auc:0.818468\n",
      "[600]\teval-auc:0.818768\n",
      "[700]\teval-auc:0.818839\n",
      "Stopping. Best iteration:\n",
      "[639]\teval-auc:0.818855\n",
      "\n",
      "fold 9 - 0.81885473955\n",
      "cv score - on train:\n",
      "0.8170573315330517\n",
      "('current score in fold:', 0.8170953830688731, 10)\n",
      "[0]\teval-auc:0.774128\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.80193\n",
      "[200]\teval-auc:0.807596\n",
      "[300]\teval-auc:0.809897\n",
      "[400]\teval-auc:0.811008\n",
      "[500]\teval-auc:0.811692\n",
      "[600]\teval-auc:0.812133\n",
      "[700]\teval-auc:0.812312\n",
      "[800]\teval-auc:0.812351\n",
      "[900]\teval-auc:0.812352\n",
      "Stopping. Best iteration:\n",
      "[878]\teval-auc:0.812352\n",
      "\n",
      "fold 0 - 0.812351540085\n",
      "[0]\teval-auc:0.776387\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.807667\n",
      "[200]\teval-auc:0.812235\n",
      "[300]\teval-auc:0.814292\n",
      "[400]\teval-auc:0.815561\n",
      "[500]\teval-auc:0.816384\n",
      "[600]\teval-auc:0.816636\n",
      "[700]\teval-auc:0.816706\n",
      "[800]\teval-auc:0.816717\n",
      "[900]\teval-auc:0.816724\n",
      "Stopping. Best iteration:\n",
      "[896]\teval-auc:0.816724\n",
      "\n",
      "fold 1 - 0.816724400514\n",
      "[0]\teval-auc:0.781325\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.811217\n",
      "[200]\teval-auc:0.816042\n",
      "[300]\teval-auc:0.817995\n",
      "[400]\teval-auc:0.819048\n",
      "[500]\teval-auc:0.819953\n",
      "[600]\teval-auc:0.820133\n",
      "[700]\teval-auc:0.820222\n",
      "[800]\teval-auc:0.820229\n",
      "[900]\teval-auc:0.820248\n",
      "[1000]\teval-auc:0.820269\n",
      "[1100]\teval-auc:0.820271\n",
      "Stopping. Best iteration:\n",
      "[1039]\teval-auc:0.820271\n",
      "\n",
      "fold 2 - 0.820271083311\n",
      "[0]\teval-auc:0.782097\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.807601\n",
      "[200]\teval-auc:0.811714\n",
      "[300]\teval-auc:0.814074\n",
      "[400]\teval-auc:0.815381\n",
      "[500]\teval-auc:0.816051\n",
      "[600]\teval-auc:0.81632\n",
      "[700]\teval-auc:0.816366\n",
      "Stopping. Best iteration:\n",
      "[637]\teval-auc:0.816379\n",
      "\n",
      "fold 3 - 0.816378584392\n",
      "[0]\teval-auc:0.783413\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.817744\n",
      "[200]\teval-auc:0.820275\n",
      "[300]\teval-auc:0.822366\n",
      "[400]\teval-auc:0.823558\n",
      "[500]\teval-auc:0.824226\n",
      "[600]\teval-auc:0.824507\n",
      "[700]\teval-auc:0.824498\n",
      "Stopping. Best iteration:\n",
      "[602]\teval-auc:0.824511\n",
      "\n",
      "fold 4 - 0.824510701922\n",
      "[0]\teval-auc:0.775351\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.805328\n",
      "[200]\teval-auc:0.809773\n",
      "[300]\teval-auc:0.812388\n",
      "[400]\teval-auc:0.813536\n",
      "[500]\teval-auc:0.814139\n",
      "[600]\teval-auc:0.814374\n",
      "[700]\teval-auc:0.814516\n",
      "[800]\teval-auc:0.814538\n",
      "[900]\teval-auc:0.814572\n",
      "[1000]\teval-auc:0.814582\n",
      "[1100]\teval-auc:0.814597\n",
      "[1200]\teval-auc:0.814607\n",
      "Stopping. Best iteration:\n",
      "[1115]\teval-auc:0.814607\n",
      "\n",
      "fold 5 - 0.814606630116\n",
      "[0]\teval-auc:0.770775\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.801983\n",
      "[200]\teval-auc:0.806183\n",
      "[300]\teval-auc:0.80853\n",
      "[400]\teval-auc:0.809538\n",
      "[500]\teval-auc:0.810404\n",
      "[600]\teval-auc:0.810572\n",
      "[700]\teval-auc:0.810608\n",
      "[800]\teval-auc:0.810662\n",
      "[900]\teval-auc:0.810688\n",
      "Stopping. Best iteration:\n",
      "[884]\teval-auc:0.810688\n",
      "\n",
      "fold 6 - 0.810687758426\n",
      "[0]\teval-auc:0.780998\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.814063\n",
      "[200]\teval-auc:0.818095\n",
      "[300]\teval-auc:0.820686\n",
      "[400]\teval-auc:0.821558\n",
      "[500]\teval-auc:0.82214\n",
      "[600]\teval-auc:0.822131\n",
      "Stopping. Best iteration:\n",
      "[525]\teval-auc:0.822165\n",
      "\n",
      "fold 7 - 0.82216451161\n",
      "[0]\teval-auc:0.779124\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.807314\n",
      "[200]\teval-auc:0.81263\n",
      "[300]\teval-auc:0.814255\n",
      "[400]\teval-auc:0.815695\n",
      "[500]\teval-auc:0.816445\n",
      "[600]\teval-auc:0.816655\n",
      "[700]\teval-auc:0.816713\n",
      "[800]\teval-auc:0.816741\n",
      "Stopping. Best iteration:\n",
      "[772]\teval-auc:0.816741\n",
      "\n",
      "fold 8 - 0.816741042083\n",
      "[0]\teval-auc:0.781216\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.809992\n",
      "[200]\teval-auc:0.812396\n",
      "[300]\teval-auc:0.814316\n",
      "[400]\teval-auc:0.815179\n",
      "[500]\teval-auc:0.815914\n",
      "[600]\teval-auc:0.816273\n",
      "[700]\teval-auc:0.816343\n",
      "[800]\teval-auc:0.81637\n",
      "[900]\teval-auc:0.816373\n",
      "Stopping. Best iteration:\n",
      "[870]\teval-auc:0.816373\n",
      "\n",
      "fold 9 - 0.816372704471\n",
      "cv score - on train:\n",
      "0.816931098503573\n",
      "('current score in fold:', 0.8170891934164083, 11)\n",
      "[0]\teval-auc:0.772158\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.801462\n",
      "[200]\teval-auc:0.805513\n",
      "[300]\teval-auc:0.80836\n",
      "[400]\teval-auc:0.809987\n",
      "[500]\teval-auc:0.810896\n",
      "[600]\teval-auc:0.811324\n",
      "[700]\teval-auc:0.811433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[800]\teval-auc:0.811464\n",
      "[900]\teval-auc:0.811478\n",
      "Stopping. Best iteration:\n",
      "[834]\teval-auc:0.811478\n",
      "\n",
      "fold 0 - 0.81147832713\n",
      "[0]\teval-auc:0.779821\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.808848\n",
      "[200]\teval-auc:0.814735\n",
      "[300]\teval-auc:0.816706\n",
      "[400]\teval-auc:0.817202\n",
      "[500]\teval-auc:0.818069\n",
      "[600]\teval-auc:0.818247\n",
      "[700]\teval-auc:0.818407\n",
      "[800]\teval-auc:0.818498\n",
      "[900]\teval-auc:0.818519\n",
      "Stopping. Best iteration:\n",
      "[844]\teval-auc:0.818519\n",
      "\n",
      "fold 1 - 0.818519393263\n",
      "[0]\teval-auc:0.777119\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.810024\n",
      "[200]\teval-auc:0.815179\n",
      "[300]\teval-auc:0.817368\n",
      "[400]\teval-auc:0.818463\n",
      "[500]\teval-auc:0.819202\n",
      "[600]\teval-auc:0.819387\n",
      "Stopping. Best iteration:\n",
      "[596]\teval-auc:0.819398\n",
      "\n",
      "fold 2 - 0.819397777753\n",
      "[0]\teval-auc:0.783136\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.811381\n",
      "[200]\teval-auc:0.814675\n",
      "[300]\teval-auc:0.816088\n",
      "[400]\teval-auc:0.817117\n",
      "[500]\teval-auc:0.817697\n",
      "[600]\teval-auc:0.817928\n",
      "[700]\teval-auc:0.818048\n",
      "[800]\teval-auc:0.818054\n",
      "Stopping. Best iteration:\n",
      "[710]\teval-auc:0.818054\n",
      "\n",
      "fold 3 - 0.818054446632\n",
      "[0]\teval-auc:0.77794\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.807872\n",
      "[200]\teval-auc:0.812409\n",
      "[300]\teval-auc:0.81365\n",
      "[400]\teval-auc:0.815042\n",
      "[500]\teval-auc:0.815859\n",
      "[600]\teval-auc:0.815938\n",
      "Stopping. Best iteration:\n",
      "[599]\teval-auc:0.815942\n",
      "\n",
      "fold 4 - 0.81594162531\n",
      "[0]\teval-auc:0.779435\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.808601\n",
      "[200]\teval-auc:0.813456\n",
      "[300]\teval-auc:0.815311\n",
      "[400]\teval-auc:0.816102\n",
      "[500]\teval-auc:0.816945\n",
      "[600]\teval-auc:0.817045\n",
      "Stopping. Best iteration:\n",
      "[596]\teval-auc:0.817096\n",
      "\n",
      "fold 5 - 0.817096131162\n",
      "[0]\teval-auc:0.785059\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.810646\n",
      "[200]\teval-auc:0.815437\n",
      "[300]\teval-auc:0.817207\n",
      "[400]\teval-auc:0.818648\n",
      "[500]\teval-auc:0.819325\n",
      "[600]\teval-auc:0.819689\n",
      "[700]\teval-auc:0.819758\n",
      "[800]\teval-auc:0.819765\n",
      "Stopping. Best iteration:\n",
      "[765]\teval-auc:0.819766\n",
      "\n",
      "fold 6 - 0.819766390461\n",
      "[0]\teval-auc:0.771759\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.805399\n",
      "[200]\teval-auc:0.809566\n",
      "[300]\teval-auc:0.812324\n",
      "[400]\teval-auc:0.813617\n",
      "[500]\teval-auc:0.814504\n",
      "[600]\teval-auc:0.814821\n",
      "[700]\teval-auc:0.81484\n",
      "Stopping. Best iteration:\n",
      "[611]\teval-auc:0.814851\n",
      "\n",
      "fold 7 - 0.81485140728\n",
      "[0]\teval-auc:0.780024\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.809333\n",
      "[200]\teval-auc:0.814234\n",
      "[300]\teval-auc:0.815787\n",
      "[400]\teval-auc:0.817421\n",
      "[500]\teval-auc:0.818362\n",
      "[600]\teval-auc:0.818684\n",
      "[700]\teval-auc:0.818703\n",
      "[800]\teval-auc:0.818731\n",
      "[900]\teval-auc:0.818736\n",
      "Stopping. Best iteration:\n",
      "[833]\teval-auc:0.818736\n",
      "\n",
      "fold 8 - 0.818736198207\n",
      "[0]\teval-auc:0.779229\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.807017\n",
      "[200]\teval-auc:0.81263\n",
      "[300]\teval-auc:0.814787\n",
      "[400]\teval-auc:0.815992\n",
      "[500]\teval-auc:0.816872\n",
      "[600]\teval-auc:0.817229\n",
      "[700]\teval-auc:0.817296\n",
      "[800]\teval-auc:0.817308\n",
      "[900]\teval-auc:0.817321\n",
      "[1000]\teval-auc:0.817345\n",
      "[1100]\teval-auc:0.817357\n",
      "[1200]\teval-auc:0.817386\n",
      "[1300]\teval-auc:0.817393\n",
      "Stopping. Best iteration:\n",
      "[1212]\teval-auc:0.817393\n",
      "\n",
      "fold 9 - 0.817393090732\n",
      "cv score - on train:\n",
      "0.8170439810382062\n",
      "('current score in fold:', 0.8170954486176019, 12)\n",
      "[0]\teval-auc:0.774356\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.803809\n",
      "[200]\teval-auc:0.808189\n",
      "[300]\teval-auc:0.810026\n",
      "[400]\teval-auc:0.811367\n",
      "[500]\teval-auc:0.812072\n",
      "[600]\teval-auc:0.812355\n",
      "[700]\teval-auc:0.81239\n",
      "Stopping. Best iteration:\n",
      "[645]\teval-auc:0.812392\n",
      "\n",
      "fold 0 - 0.812391623042\n",
      "[0]\teval-auc:0.77862\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.807811\n",
      "[200]\teval-auc:0.810963\n",
      "[300]\teval-auc:0.812667\n",
      "[400]\teval-auc:0.813706\n",
      "[500]\teval-auc:0.81414\n",
      "[600]\teval-auc:0.814347\n",
      "[700]\teval-auc:0.814379\n",
      "[800]\teval-auc:0.81439\n",
      "Stopping. Best iteration:\n",
      "[725]\teval-auc:0.81439\n",
      "\n",
      "fold 1 - 0.814389580728\n",
      "[0]\teval-auc:0.776162\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.806892\n",
      "[200]\teval-auc:0.813421\n",
      "[300]\teval-auc:0.815322\n",
      "[400]\teval-auc:0.816534\n",
      "[500]\teval-auc:0.817668\n",
      "[600]\teval-auc:0.818034\n",
      "[700]\teval-auc:0.818152\n",
      "[800]\teval-auc:0.818202\n",
      "[900]\teval-auc:0.818279\n",
      "[1000]\teval-auc:0.818303\n",
      "Stopping. Best iteration:\n",
      "[965]\teval-auc:0.818303\n",
      "\n",
      "fold 2 - 0.8183027088\n",
      "[0]\teval-auc:0.776333\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.808263\n",
      "[200]\teval-auc:0.813733\n",
      "[300]\teval-auc:0.815945\n",
      "[400]\teval-auc:0.81686\n",
      "[500]\teval-auc:0.817471\n",
      "[600]\teval-auc:0.8176\n",
      "[700]\teval-auc:0.817727\n",
      "[800]\teval-auc:0.817755\n",
      "[900]\teval-auc:0.817759\n",
      "Stopping. Best iteration:\n",
      "[836]\teval-auc:0.817759\n",
      "\n",
      "fold 3 - 0.81775899955\n",
      "[0]\teval-auc:0.779414\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.813196\n",
      "[200]\teval-auc:0.816542\n",
      "[300]\teval-auc:0.819263\n",
      "[400]\teval-auc:0.820869\n",
      "[500]\teval-auc:0.821495\n",
      "[600]\teval-auc:0.821844\n",
      "[700]\teval-auc:0.821967\n",
      "[800]\teval-auc:0.821969\n",
      "[900]\teval-auc:0.821981\n",
      "[1000]\teval-auc:0.821984\n",
      "[1100]\teval-auc:0.821988\n",
      "[1200]\teval-auc:0.821998\n",
      "[1300]\teval-auc:0.82201\n",
      "Stopping. Best iteration:\n",
      "[1261]\teval-auc:0.822011\n",
      "\n",
      "fold 4 - 0.822011233571\n",
      "[0]\teval-auc:0.778636\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.806208\n",
      "[200]\teval-auc:0.811568\n",
      "[300]\teval-auc:0.813062\n",
      "[400]\teval-auc:0.81429\n",
      "[500]\teval-auc:0.814962\n",
      "[600]\teval-auc:0.815343\n",
      "[700]\teval-auc:0.815449\n",
      "[800]\teval-auc:0.815482\n",
      "[900]\teval-auc:0.815488\n",
      "Stopping. Best iteration:\n",
      "[832]\teval-auc:0.815488\n",
      "\n",
      "fold 5 - 0.815487812793\n",
      "[0]\teval-auc:0.778777\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.811761\n",
      "[200]\teval-auc:0.816285\n",
      "[300]\teval-auc:0.81809\n",
      "[400]\teval-auc:0.819258\n",
      "[500]\teval-auc:0.81994\n",
      "[600]\teval-auc:0.820231\n",
      "[700]\teval-auc:0.820346\n",
      "[800]\teval-auc:0.82035\n",
      "Stopping. Best iteration:\n",
      "[714]\teval-auc:0.82035\n",
      "\n",
      "fold 6 - 0.820349640377\n",
      "[0]\teval-auc:0.781719\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.806439\n",
      "[200]\teval-auc:0.811495\n",
      "[300]\teval-auc:0.814639\n",
      "[400]\teval-auc:0.815853\n",
      "[500]\teval-auc:0.816844\n",
      "[600]\teval-auc:0.817189\n",
      "[700]\teval-auc:0.817288\n",
      "Stopping. Best iteration:\n",
      "[655]\teval-auc:0.817312\n",
      "\n",
      "fold 7 - 0.817312369451\n",
      "[0]\teval-auc:0.777816\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.807202\n",
      "[200]\teval-auc:0.811234\n",
      "[300]\teval-auc:0.813128\n",
      "[400]\teval-auc:0.814036\n",
      "[500]\teval-auc:0.814741\n",
      "[600]\teval-auc:0.814842\n",
      "[700]\teval-auc:0.814873\n",
      "Stopping. Best iteration:\n",
      "[655]\teval-auc:0.814874\n",
      "\n",
      "fold 8 - 0.814874147777\n",
      "[0]\teval-auc:0.781422\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.810708\n",
      "[200]\teval-auc:0.815067\n",
      "[300]\teval-auc:0.817122\n",
      "[400]\teval-auc:0.817973\n",
      "[500]\teval-auc:0.818886\n",
      "[600]\teval-auc:0.819054\n",
      "[700]\teval-auc:0.819113\n",
      "[800]\teval-auc:0.819124\n",
      "[900]\teval-auc:0.819146\n",
      "[1000]\teval-auc:0.819154\n",
      "Stopping. Best iteration:\n",
      "[960]\teval-auc:0.819155\n",
      "\n",
      "fold 9 - 0.819154641878\n",
      "cv score - on train:\n",
      "0.8170929249202936\n",
      "('current score in fold:', 0.8171040241012986, 13)\n",
      "[0]\teval-auc:0.782715\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.813045\n",
      "[200]\teval-auc:0.817136\n",
      "[300]\teval-auc:0.819199\n",
      "[400]\teval-auc:0.82022\n",
      "[500]\teval-auc:0.820937\n",
      "[600]\teval-auc:0.821262\n",
      "[700]\teval-auc:0.821305\n",
      "Stopping. Best iteration:\n",
      "[655]\teval-auc:0.82131\n",
      "\n",
      "fold 0 - 0.821309913603\n",
      "[0]\teval-auc:0.786169\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.816021\n",
      "[200]\teval-auc:0.81966\n",
      "[300]\teval-auc:0.821835\n",
      "[400]\teval-auc:0.822809\n",
      "[500]\teval-auc:0.823293\n",
      "[600]\teval-auc:0.82332\n",
      "Stopping. Best iteration:\n",
      "[591]\teval-auc:0.823327\n",
      "\n",
      "fold 1 - 0.82332680509\n",
      "[0]\teval-auc:0.77366\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.803639\n",
      "[200]\teval-auc:0.809289\n",
      "[300]\teval-auc:0.811765\n",
      "[400]\teval-auc:0.812814\n",
      "[500]\teval-auc:0.8134\n",
      "[600]\teval-auc:0.813527\n",
      "Stopping. Best iteration:\n",
      "[582]\teval-auc:0.813529\n",
      "\n",
      "fold 2 - 0.813529111403\n",
      "[0]\teval-auc:0.785054\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.809635\n",
      "[200]\teval-auc:0.813561\n",
      "[300]\teval-auc:0.815823\n",
      "[400]\teval-auc:0.816442\n",
      "[500]\teval-auc:0.817001\n",
      "[600]\teval-auc:0.817505\n",
      "[700]\teval-auc:0.817532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping. Best iteration:\n",
      "[683]\teval-auc:0.817537\n",
      "\n",
      "fold 3 - 0.817536530946\n",
      "[0]\teval-auc:0.768033\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.798881\n",
      "[200]\teval-auc:0.802121\n",
      "[300]\teval-auc:0.803595\n",
      "[400]\teval-auc:0.804941\n",
      "[500]\teval-auc:0.805565\n",
      "[600]\teval-auc:0.805861\n",
      "[700]\teval-auc:0.805865\n",
      "Stopping. Best iteration:\n",
      "[619]\teval-auc:0.805878\n",
      "\n",
      "fold 4 - 0.805877490726\n",
      "[0]\teval-auc:0.772592\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.804585\n",
      "[200]\teval-auc:0.809653\n",
      "[300]\teval-auc:0.81207\n",
      "[400]\teval-auc:0.813663\n",
      "[500]\teval-auc:0.814473\n",
      "[600]\teval-auc:0.81481\n",
      "[700]\teval-auc:0.814877\n",
      "[800]\teval-auc:0.814879\n",
      "Stopping. Best iteration:\n",
      "[709]\teval-auc:0.814881\n",
      "\n",
      "fold 5 - 0.814880945916\n",
      "[0]\teval-auc:0.776436\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.807085\n",
      "[200]\teval-auc:0.812469\n",
      "[300]\teval-auc:0.814456\n",
      "[400]\teval-auc:0.815454\n",
      "[500]\teval-auc:0.816412\n",
      "[600]\teval-auc:0.816499\n",
      "[700]\teval-auc:0.81654\n",
      "[800]\teval-auc:0.816558\n",
      "Stopping. Best iteration:\n",
      "[798]\teval-auc:0.816558\n",
      "\n",
      "fold 6 - 0.816557813968\n",
      "[0]\teval-auc:0.782504\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.812045\n",
      "[200]\teval-auc:0.816517\n",
      "[300]\teval-auc:0.818702\n",
      "[400]\teval-auc:0.819553\n",
      "[500]\teval-auc:0.820299\n",
      "[600]\teval-auc:0.820694\n",
      "[700]\teval-auc:0.820824\n",
      "Stopping. Best iteration:\n",
      "[699]\teval-auc:0.820824\n",
      "\n",
      "fold 7 - 0.820824197702\n",
      "[0]\teval-auc:0.779423\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.806279\n",
      "[200]\teval-auc:0.810407\n",
      "[300]\teval-auc:0.812205\n",
      "[400]\teval-auc:0.814038\n",
      "[500]\teval-auc:0.814959\n",
      "[600]\teval-auc:0.815448\n",
      "[700]\teval-auc:0.815643\n",
      "[800]\teval-auc:0.815693\n",
      "[900]\teval-auc:0.815711\n",
      "[1000]\teval-auc:0.815722\n",
      "Stopping. Best iteration:\n",
      "[907]\teval-auc:0.815722\n",
      "\n",
      "fold 8 - 0.815722202262\n",
      "[0]\teval-auc:0.77733\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.810526\n",
      "[200]\teval-auc:0.815833\n",
      "[300]\teval-auc:0.818348\n",
      "[400]\teval-auc:0.819761\n",
      "[500]\teval-auc:0.820577\n",
      "[600]\teval-auc:0.820749\n",
      "[700]\teval-auc:0.820838\n",
      "[800]\teval-auc:0.820851\n",
      "[900]\teval-auc:0.820854\n",
      "Stopping. Best iteration:\n",
      "[804]\teval-auc:0.820854\n",
      "\n",
      "fold 9 - 0.820853843727\n",
      "cv score - on train:\n",
      "0.8169180140510681\n",
      "('current score in fold:', 0.8171010313030875, 14)\n",
      "[0]\teval-auc:0.770359\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.8028\n",
      "[200]\teval-auc:0.808223\n",
      "[300]\teval-auc:0.811231\n",
      "[400]\teval-auc:0.812451\n",
      "[500]\teval-auc:0.813362\n",
      "[600]\teval-auc:0.813719\n",
      "[700]\teval-auc:0.813769\n",
      "[800]\teval-auc:0.813776\n",
      "[900]\teval-auc:0.813788\n",
      "[1000]\teval-auc:0.813793\n",
      "[1100]\teval-auc:0.813807\n",
      "Stopping. Best iteration:\n",
      "[1097]\teval-auc:0.813807\n",
      "\n",
      "fold 0 - 0.813807320036\n",
      "[0]\teval-auc:0.768852\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.801401\n",
      "[200]\teval-auc:0.803926\n",
      "[300]\teval-auc:0.806364\n",
      "[400]\teval-auc:0.807828\n",
      "[500]\teval-auc:0.808543\n",
      "[600]\teval-auc:0.808763\n",
      "[700]\teval-auc:0.808836\n",
      "[800]\teval-auc:0.808854\n",
      "[900]\teval-auc:0.808884\n",
      "[1000]\teval-auc:0.808926\n",
      "[1100]\teval-auc:0.808932\n",
      "[1200]\teval-auc:0.808932\n",
      "Stopping. Best iteration:\n",
      "[1137]\teval-auc:0.808934\n",
      "\n",
      "fold 1 - 0.808934138537\n",
      "[0]\teval-auc:0.78086\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.808053\n",
      "[200]\teval-auc:0.812346\n",
      "[300]\teval-auc:0.814675\n",
      "[400]\teval-auc:0.816063\n",
      "[500]\teval-auc:0.817077\n",
      "[600]\teval-auc:0.817384\n",
      "[700]\teval-auc:0.817369\n",
      "Stopping. Best iteration:\n",
      "[602]\teval-auc:0.817389\n",
      "\n",
      "fold 2 - 0.817389078092\n",
      "[0]\teval-auc:0.788159\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.81889\n",
      "[200]\teval-auc:0.823453\n",
      "[300]\teval-auc:0.824916\n",
      "[400]\teval-auc:0.826247\n",
      "[500]\teval-auc:0.826955\n",
      "[600]\teval-auc:0.827191\n",
      "[700]\teval-auc:0.827289\n",
      "[800]\teval-auc:0.827325\n",
      "[900]\teval-auc:0.827345\n",
      "Stopping. Best iteration:\n",
      "[826]\teval-auc:0.827345\n",
      "\n",
      "fold 3 - 0.827344567702\n",
      "[0]\teval-auc:0.779781\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.809841\n",
      "[200]\teval-auc:0.814404\n",
      "[300]\teval-auc:0.816865\n",
      "[400]\teval-auc:0.817728\n",
      "[500]\teval-auc:0.818487\n",
      "[600]\teval-auc:0.81874\n",
      "[700]\teval-auc:0.818759\n",
      "Stopping. Best iteration:\n",
      "[625]\teval-auc:0.818759\n",
      "\n",
      "fold 4 - 0.818759164426\n",
      "[0]\teval-auc:0.781124\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.810317\n",
      "[200]\teval-auc:0.81524\n",
      "[300]\teval-auc:0.817676\n",
      "[400]\teval-auc:0.818974\n",
      "[500]\teval-auc:0.819543\n",
      "[600]\teval-auc:0.819774\n",
      "[700]\teval-auc:0.819819\n",
      "[800]\teval-auc:0.819822\n",
      "[900]\teval-auc:0.81984\n",
      "Stopping. Best iteration:\n",
      "[890]\teval-auc:0.81984\n",
      "\n",
      "fold 5 - 0.819840329591\n",
      "[0]\teval-auc:0.7866\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.815389\n",
      "[200]\teval-auc:0.819516\n",
      "[300]\teval-auc:0.821121\n",
      "[400]\teval-auc:0.822108\n",
      "[500]\teval-auc:0.822649\n",
      "[600]\teval-auc:0.822902\n",
      "[700]\teval-auc:0.822968\n",
      "[800]\teval-auc:0.822987\n",
      "Stopping. Best iteration:\n",
      "[747]\teval-auc:0.822987\n",
      "\n",
      "fold 6 - 0.82298749525\n",
      "[0]\teval-auc:0.77806\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.806779\n",
      "[200]\teval-auc:0.81175\n",
      "[300]\teval-auc:0.813163\n",
      "[400]\teval-auc:0.813914\n",
      "[500]\teval-auc:0.814415\n",
      "[600]\teval-auc:0.814605\n",
      "[700]\teval-auc:0.814688\n",
      "Stopping. Best iteration:\n",
      "[660]\teval-auc:0.814688\n",
      "\n",
      "fold 7 - 0.814688004945\n",
      "[0]\teval-auc:0.771677\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.803545\n",
      "[200]\teval-auc:0.807729\n",
      "[300]\teval-auc:0.809611\n",
      "[400]\teval-auc:0.811144\n",
      "[500]\teval-auc:0.811841\n",
      "[600]\teval-auc:0.812079\n",
      "[700]\teval-auc:0.812101\n",
      "[800]\teval-auc:0.812102\n",
      "Stopping. Best iteration:\n",
      "[717]\teval-auc:0.812102\n",
      "\n",
      "fold 8 - 0.812101567397\n",
      "[0]\teval-auc:0.777336\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.802418\n",
      "[200]\teval-auc:0.807991\n",
      "[300]\teval-auc:0.811231\n",
      "[400]\teval-auc:0.812055\n",
      "[500]\teval-auc:0.812829\n",
      "[600]\teval-auc:0.813187\n",
      "[700]\teval-auc:0.813287\n",
      "[800]\teval-auc:0.8133\n",
      "Stopping. Best iteration:\n",
      "[765]\teval-auc:0.8133\n",
      "\n",
      "fold 9 - 0.813300499695\n",
      "cv score - on train:\n",
      "0.8168037367534835\n",
      "('current score in fold:', 0.8170909747031139, 15)\n",
      "[0]\teval-auc:0.766839\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.796141\n",
      "[200]\teval-auc:0.80112\n",
      "[300]\teval-auc:0.803859\n",
      "[400]\teval-auc:0.804924\n",
      "[500]\teval-auc:0.806141\n",
      "[600]\teval-auc:0.806631\n",
      "[700]\teval-auc:0.806754\n",
      "[800]\teval-auc:0.806775\n",
      "[900]\teval-auc:0.806784\n",
      "Stopping. Best iteration:\n",
      "[885]\teval-auc:0.806784\n",
      "\n",
      "fold 0 - 0.806783563586\n",
      "[0]\teval-auc:0.780976\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.811452\n",
      "[200]\teval-auc:0.817179\n",
      "[300]\teval-auc:0.818843\n",
      "[400]\teval-auc:0.819644\n",
      "[500]\teval-auc:0.820239\n",
      "[600]\teval-auc:0.820361\n",
      "[700]\teval-auc:0.820373\n",
      "[800]\teval-auc:0.820397\n",
      "[900]\teval-auc:0.82041\n",
      "[1000]\teval-auc:0.820412\n",
      "[1100]\teval-auc:0.820413\n",
      "[1200]\teval-auc:0.820415\n",
      "[1300]\teval-auc:0.820419\n",
      "[1400]\teval-auc:0.820421\n",
      "Stopping. Best iteration:\n",
      "[1324]\teval-auc:0.820422\n",
      "\n",
      "fold 1 - 0.820421599196\n",
      "[0]\teval-auc:0.780166\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.811262\n",
      "[200]\teval-auc:0.815597\n",
      "[300]\teval-auc:0.81714\n",
      "[400]\teval-auc:0.817609\n",
      "[500]\teval-auc:0.818122\n",
      "[600]\teval-auc:0.818135\n",
      "[700]\teval-auc:0.818073\n",
      "Stopping. Best iteration:\n",
      "[602]\teval-auc:0.818136\n",
      "\n",
      "fold 2 - 0.818135780771\n",
      "[0]\teval-auc:0.777909\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.809594\n",
      "[200]\teval-auc:0.813662\n",
      "[300]\teval-auc:0.81604\n",
      "[400]\teval-auc:0.817471\n",
      "[500]\teval-auc:0.818244\n",
      "[600]\teval-auc:0.818614\n",
      "[700]\teval-auc:0.818738\n",
      "[800]\teval-auc:0.818764\n",
      "[900]\teval-auc:0.818772\n",
      "Stopping. Best iteration:\n",
      "[810]\teval-auc:0.818772\n",
      "\n",
      "fold 3 - 0.818772014907\n",
      "[0]\teval-auc:0.773533\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.803755\n",
      "[200]\teval-auc:0.808249\n",
      "[300]\teval-auc:0.810847\n",
      "[400]\teval-auc:0.812786\n",
      "[500]\teval-auc:0.813637\n",
      "[600]\teval-auc:0.814128\n",
      "[700]\teval-auc:0.81444\n",
      "[800]\teval-auc:0.814496\n",
      "[900]\teval-auc:0.814538\n",
      "[1000]\teval-auc:0.814538\n",
      "Stopping. Best iteration:\n",
      "[949]\teval-auc:0.81454\n",
      "\n",
      "fold 4 - 0.814540217709\n",
      "[0]\teval-auc:0.782862\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.813995\n",
      "[200]\teval-auc:0.818662\n",
      "[300]\teval-auc:0.820123\n",
      "[400]\teval-auc:0.820821\n",
      "[500]\teval-auc:0.821655\n",
      "[600]\teval-auc:0.821884\n",
      "[700]\teval-auc:0.821938\n",
      "[800]\teval-auc:0.821947\n",
      "[900]\teval-auc:0.821949\n",
      "[1000]\teval-auc:0.821952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping. Best iteration:\n",
      "[920]\teval-auc:0.821952\n",
      "\n",
      "fold 5 - 0.821951907068\n",
      "[0]\teval-auc:0.780268\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.810752\n",
      "[200]\teval-auc:0.81544\n",
      "[300]\teval-auc:0.817723\n",
      "[400]\teval-auc:0.818756\n",
      "[500]\teval-auc:0.81941\n",
      "[600]\teval-auc:0.819661\n",
      "[700]\teval-auc:0.819698\n",
      "[800]\teval-auc:0.81972\n",
      "[900]\teval-auc:0.819728\n",
      "[1000]\teval-auc:0.819739\n",
      "[1100]\teval-auc:0.819746\n",
      "Stopping. Best iteration:\n",
      "[1038]\teval-auc:0.819746\n",
      "\n",
      "fold 6 - 0.819746236865\n",
      "[0]\teval-auc:0.778242\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.807684\n",
      "[200]\teval-auc:0.812113\n",
      "[300]\teval-auc:0.814076\n",
      "[400]\teval-auc:0.815484\n",
      "[500]\teval-auc:0.816368\n",
      "[600]\teval-auc:0.816425\n",
      "[700]\teval-auc:0.8164\n",
      "Stopping. Best iteration:\n",
      "[616]\teval-auc:0.816444\n",
      "\n",
      "fold 7 - 0.816444474933\n",
      "[0]\teval-auc:0.777151\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.803301\n",
      "[200]\teval-auc:0.809402\n",
      "[300]\teval-auc:0.811615\n",
      "[400]\teval-auc:0.812967\n",
      "[500]\teval-auc:0.813679\n",
      "[600]\teval-auc:0.813983\n",
      "[700]\teval-auc:0.814027\n",
      "Stopping. Best iteration:\n",
      "[640]\teval-auc:0.814036\n",
      "\n",
      "fold 8 - 0.814035778135\n",
      "[0]\teval-auc:0.782925\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.812633\n",
      "[200]\teval-auc:0.815662\n",
      "[300]\teval-auc:0.818309\n",
      "[400]\teval-auc:0.819489\n",
      "[500]\teval-auc:0.820332\n",
      "[600]\teval-auc:0.820613\n",
      "[700]\teval-auc:0.820761\n",
      "[800]\teval-auc:0.82077\n",
      "[900]\teval-auc:0.820788\n",
      "[1000]\teval-auc:0.820791\n",
      "Stopping. Best iteration:\n",
      "[961]\teval-auc:0.820791\n",
      "\n",
      "fold 9 - 0.820791016958\n",
      "cv score - on train:\n",
      "0.8170577410701096\n",
      "('current score in fold:', 0.817095887794085, 16)\n",
      "[0]\teval-auc:0.774609\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.805345\n",
      "[200]\teval-auc:0.809345\n",
      "[300]\teval-auc:0.810481\n",
      "[400]\teval-auc:0.81142\n",
      "[500]\teval-auc:0.812149\n",
      "[600]\teval-auc:0.81227\n",
      "[700]\teval-auc:0.812339\n",
      "[800]\teval-auc:0.812364\n",
      "[900]\teval-auc:0.812371\n",
      "Stopping. Best iteration:\n",
      "[869]\teval-auc:0.812371\n",
      "\n",
      "fold 0 - 0.812370837176\n",
      "[0]\teval-auc:0.777515\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.806061\n",
      "[200]\teval-auc:0.809378\n",
      "[300]\teval-auc:0.81248\n",
      "[400]\teval-auc:0.813451\n",
      "[500]\teval-auc:0.814151\n",
      "[600]\teval-auc:0.814461\n",
      "Stopping. Best iteration:\n",
      "[599]\teval-auc:0.814461\n",
      "\n",
      "fold 1 - 0.814460849607\n",
      "[0]\teval-auc:0.776634\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.807092\n",
      "[200]\teval-auc:0.810636\n",
      "[300]\teval-auc:0.812353\n",
      "[400]\teval-auc:0.813457\n",
      "[500]\teval-auc:0.814114\n",
      "[600]\teval-auc:0.814161\n",
      "[700]\teval-auc:0.814216\n",
      "Stopping. Best iteration:\n",
      "[696]\teval-auc:0.814216\n",
      "\n",
      "fold 2 - 0.814216120609\n",
      "[0]\teval-auc:0.786926\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.813233\n",
      "[200]\teval-auc:0.817205\n",
      "[300]\teval-auc:0.819658\n",
      "[400]\teval-auc:0.820952\n",
      "[500]\teval-auc:0.821781\n",
      "[600]\teval-auc:0.822142\n",
      "[700]\teval-auc:0.822239\n",
      "Stopping. Best iteration:\n",
      "[683]\teval-auc:0.822239\n",
      "\n",
      "fold 3 - 0.822238603023\n",
      "[0]\teval-auc:0.768641\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.802615\n",
      "[200]\teval-auc:0.806597\n",
      "[300]\teval-auc:0.809019\n",
      "[400]\teval-auc:0.810364\n",
      "[500]\teval-auc:0.811055\n",
      "[600]\teval-auc:0.811224\n",
      "[700]\teval-auc:0.811278\n",
      "Stopping. Best iteration:\n",
      "[623]\teval-auc:0.811299\n",
      "\n",
      "fold 4 - 0.811298840677\n",
      "[0]\teval-auc:0.779149\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.808455\n",
      "[200]\teval-auc:0.813329\n",
      "[300]\teval-auc:0.815507\n",
      "[400]\teval-auc:0.816798\n",
      "[500]\teval-auc:0.817472\n",
      "[600]\teval-auc:0.817836\n",
      "[700]\teval-auc:0.817944\n",
      "[800]\teval-auc:0.817976\n",
      "Stopping. Best iteration:\n",
      "[791]\teval-auc:0.817976\n",
      "\n",
      "fold 5 - 0.817975617805\n",
      "[0]\teval-auc:0.784937\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.815609\n",
      "[200]\teval-auc:0.819607\n",
      "[300]\teval-auc:0.821592\n",
      "[400]\teval-auc:0.822664\n",
      "[500]\teval-auc:0.823523\n",
      "[600]\teval-auc:0.823783\n",
      "[700]\teval-auc:0.823845\n",
      "[800]\teval-auc:0.823858\n",
      "Stopping. Best iteration:\n",
      "[780]\teval-auc:0.823858\n",
      "\n",
      "fold 6 - 0.823857620345\n",
      "[0]\teval-auc:0.779221\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.809424\n",
      "[200]\teval-auc:0.813581\n",
      "[300]\teval-auc:0.817437\n",
      "[400]\teval-auc:0.818397\n",
      "[500]\teval-auc:0.81916\n",
      "[600]\teval-auc:0.819598\n",
      "[700]\teval-auc:0.819667\n",
      "Stopping. Best iteration:\n",
      "[642]\teval-auc:0.819682\n",
      "\n",
      "fold 7 - 0.819681614231\n",
      "[0]\teval-auc:0.782445\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.811566\n",
      "[200]\teval-auc:0.816982\n",
      "[300]\teval-auc:0.818969\n",
      "[400]\teval-auc:0.820086\n",
      "[500]\teval-auc:0.820648\n",
      "[600]\teval-auc:0.820672\n",
      "[700]\teval-auc:0.820675\n",
      "Stopping. Best iteration:\n",
      "[619]\teval-auc:0.820687\n",
      "\n",
      "fold 8 - 0.82068669288\n",
      "[0]\teval-auc:0.774671\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.802822\n",
      "[200]\teval-auc:0.807443\n",
      "[300]\teval-auc:0.810995\n",
      "[400]\teval-auc:0.812194\n",
      "[500]\teval-auc:0.813126\n",
      "[600]\teval-auc:0.813628\n",
      "Stopping. Best iteration:\n",
      "[588]\teval-auc:0.81366\n",
      "\n",
      "fold 9 - 0.813659694074\n",
      "cv score - on train:\n",
      "0.816940290287818\n",
      "('current score in fold:', 0.8170961206345696, 17)\n",
      "[0]\teval-auc:0.769515\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.802348\n",
      "[200]\teval-auc:0.806718\n",
      "[300]\teval-auc:0.80915\n",
      "[400]\teval-auc:0.810486\n",
      "[500]\teval-auc:0.811254\n",
      "[600]\teval-auc:0.811509\n",
      "[700]\teval-auc:0.811503\n",
      "Stopping. Best iteration:\n",
      "[630]\teval-auc:0.811528\n",
      "\n",
      "fold 0 - 0.811528304387\n",
      "[0]\teval-auc:0.779553\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.812449\n",
      "[200]\teval-auc:0.816117\n",
      "[300]\teval-auc:0.817953\n",
      "[400]\teval-auc:0.819137\n",
      "[500]\teval-auc:0.819968\n",
      "[600]\teval-auc:0.820143\n",
      "[700]\teval-auc:0.820219\n",
      "[800]\teval-auc:0.820225\n",
      "Stopping. Best iteration:\n",
      "[708]\teval-auc:0.820225\n",
      "\n",
      "fold 1 - 0.820224681964\n",
      "[0]\teval-auc:0.783284\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.812072\n",
      "[200]\teval-auc:0.81508\n",
      "[300]\teval-auc:0.817273\n",
      "[400]\teval-auc:0.818065\n",
      "[500]\teval-auc:0.818871\n",
      "[600]\teval-auc:0.819043\n",
      "[700]\teval-auc:0.819099\n",
      "[800]\teval-auc:0.819102\n",
      "[900]\teval-auc:0.819116\n",
      "[1000]\teval-auc:0.819119\n",
      "[1100]\teval-auc:0.819142\n",
      "[1200]\teval-auc:0.819161\n",
      "Stopping. Best iteration:\n",
      "[1171]\teval-auc:0.819161\n",
      "\n",
      "fold 2 - 0.819161098113\n",
      "[0]\teval-auc:0.780128\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.811075\n",
      "[200]\teval-auc:0.813428\n",
      "[300]\teval-auc:0.815394\n",
      "[400]\teval-auc:0.81644\n",
      "[500]\teval-auc:0.817103\n",
      "[600]\teval-auc:0.817391\n",
      "[700]\teval-auc:0.817448\n",
      "[800]\teval-auc:0.817451\n",
      "Stopping. Best iteration:\n",
      "[777]\teval-auc:0.817451\n",
      "\n",
      "fold 3 - 0.817450894317\n",
      "[0]\teval-auc:0.781014\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.810053\n",
      "[200]\teval-auc:0.814657\n",
      "[300]\teval-auc:0.816504\n",
      "[400]\teval-auc:0.8178\n",
      "[500]\teval-auc:0.818781\n",
      "[600]\teval-auc:0.819172\n",
      "[700]\teval-auc:0.819255\n",
      "[800]\teval-auc:0.819272\n",
      "[900]\teval-auc:0.819283\n",
      "[1000]\teval-auc:0.819295\n",
      "Stopping. Best iteration:\n",
      "[976]\teval-auc:0.819295\n",
      "\n",
      "fold 4 - 0.819295372814\n",
      "[0]\teval-auc:0.780464\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.809437\n",
      "[200]\teval-auc:0.813554\n",
      "[300]\teval-auc:0.816187\n",
      "[400]\teval-auc:0.817619\n",
      "[500]\teval-auc:0.818523\n",
      "[600]\teval-auc:0.818687\n",
      "[700]\teval-auc:0.818819\n",
      "[800]\teval-auc:0.81885\n",
      "[900]\teval-auc:0.818875\n",
      "[1000]\teval-auc:0.818882\n",
      "Stopping. Best iteration:\n",
      "[906]\teval-auc:0.818882\n",
      "\n",
      "fold 5 - 0.81888192745\n",
      "[0]\teval-auc:0.782249\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.810839\n",
      "[200]\teval-auc:0.81615\n",
      "[300]\teval-auc:0.818369\n",
      "[400]\teval-auc:0.819736\n",
      "[500]\teval-auc:0.820528\n",
      "[600]\teval-auc:0.820646\n",
      "[700]\teval-auc:0.82071\n",
      "[800]\teval-auc:0.820749\n",
      "Stopping. Best iteration:\n",
      "[784]\teval-auc:0.820749\n",
      "\n",
      "fold 6 - 0.820748864016\n",
      "[0]\teval-auc:0.770375\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.801988\n",
      "[200]\teval-auc:0.807575\n",
      "[300]\teval-auc:0.809952\n",
      "[400]\teval-auc:0.810611\n",
      "[500]\teval-auc:0.81134\n",
      "[600]\teval-auc:0.811583\n",
      "[700]\teval-auc:0.811726\n",
      "[800]\teval-auc:0.81173\n",
      "Stopping. Best iteration:\n",
      "[757]\teval-auc:0.81173\n",
      "\n",
      "fold 7 - 0.811730193918\n",
      "[0]\teval-auc:0.781884\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.809615\n",
      "[200]\teval-auc:0.815475\n",
      "[300]\teval-auc:0.817094\n",
      "[400]\teval-auc:0.818477\n",
      "[500]\teval-auc:0.819331\n",
      "[600]\teval-auc:0.819567\n",
      "[700]\teval-auc:0.819561\n",
      "Stopping. Best iteration:\n",
      "[601]\teval-auc:0.819571\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 8 - 0.819571211292\n",
      "[0]\teval-auc:0.776167\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.804525\n",
      "[200]\teval-auc:0.807549\n",
      "[300]\teval-auc:0.809909\n",
      "[400]\teval-auc:0.810945\n",
      "[500]\teval-auc:0.811845\n",
      "[600]\teval-auc:0.812045\n",
      "[700]\teval-auc:0.812109\n",
      "Stopping. Best iteration:\n",
      "[688]\teval-auc:0.81211\n",
      "\n",
      "fold 9 - 0.812110454078\n",
      "cv score - on train:\n",
      "0.8169983221449134\n",
      "('current score in fold:', 0.8170981462327874, 18)\n",
      "[0]\teval-auc:0.780864\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.812549\n",
      "[200]\teval-auc:0.815465\n",
      "[300]\teval-auc:0.817079\n",
      "[400]\teval-auc:0.818327\n",
      "[500]\teval-auc:0.81913\n",
      "[600]\teval-auc:0.819388\n",
      "[700]\teval-auc:0.819413\n",
      "[800]\teval-auc:0.819426\n",
      "[900]\teval-auc:0.819429\n",
      "Stopping. Best iteration:\n",
      "[861]\teval-auc:0.819429\n",
      "\n",
      "fold 0 - 0.819429170252\n",
      "[0]\teval-auc:0.775035\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.805518\n",
      "[200]\teval-auc:0.809488\n",
      "[300]\teval-auc:0.812945\n",
      "[400]\teval-auc:0.813838\n",
      "[500]\teval-auc:0.814586\n",
      "[600]\teval-auc:0.814898\n",
      "[700]\teval-auc:0.81494\n",
      "Stopping. Best iteration:\n",
      "[651]\teval-auc:0.814944\n",
      "\n",
      "fold 1 - 0.81494434538\n",
      "[0]\teval-auc:0.779773\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.807774\n",
      "[200]\teval-auc:0.811687\n",
      "[300]\teval-auc:0.814621\n",
      "[400]\teval-auc:0.815887\n",
      "[500]\teval-auc:0.816635\n",
      "[600]\teval-auc:0.816852\n",
      "[700]\teval-auc:0.816954\n",
      "[800]\teval-auc:0.81697\n",
      "[900]\teval-auc:0.816982\n",
      "Stopping. Best iteration:\n",
      "[847]\teval-auc:0.816982\n",
      "\n",
      "fold 2 - 0.816982022733\n",
      "[0]\teval-auc:0.779979\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.805091\n",
      "[200]\teval-auc:0.81103\n",
      "[300]\teval-auc:0.813301\n",
      "[400]\teval-auc:0.814475\n",
      "[500]\teval-auc:0.815346\n",
      "[600]\teval-auc:0.815755\n",
      "[700]\teval-auc:0.815803\n",
      "Stopping. Best iteration:\n",
      "[651]\teval-auc:0.81582\n",
      "\n",
      "fold 3 - 0.815819673963\n",
      "[0]\teval-auc:0.780915\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.810331\n",
      "[200]\teval-auc:0.814272\n",
      "[300]\teval-auc:0.816186\n",
      "[400]\teval-auc:0.817012\n",
      "[500]\teval-auc:0.817797\n",
      "[600]\teval-auc:0.818238\n",
      "[700]\teval-auc:0.818366\n",
      "[800]\teval-auc:0.818396\n",
      "[900]\teval-auc:0.818413\n",
      "[1000]\teval-auc:0.818437\n",
      "[1100]\teval-auc:0.818458\n",
      "[1200]\teval-auc:0.818463\n",
      "Stopping. Best iteration:\n",
      "[1131]\teval-auc:0.818463\n",
      "\n",
      "fold 4 - 0.818462641722\n",
      "[0]\teval-auc:0.779924\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.813099\n",
      "[200]\teval-auc:0.815677\n",
      "[300]\teval-auc:0.818097\n",
      "[400]\teval-auc:0.818765\n",
      "[500]\teval-auc:0.819365\n",
      "[600]\teval-auc:0.819652\n",
      "[700]\teval-auc:0.819804\n",
      "[800]\teval-auc:0.819829\n",
      "[900]\teval-auc:0.819838\n",
      "[1000]\teval-auc:0.819852\n",
      "[1100]\teval-auc:0.819873\n",
      "[1200]\teval-auc:0.819888\n",
      "[1300]\teval-auc:0.819899\n",
      "[1400]\teval-auc:0.8199\n",
      "Stopping. Best iteration:\n",
      "[1328]\teval-auc:0.819902\n",
      "\n",
      "fold 5 - 0.819901693267\n",
      "[0]\teval-auc:0.778616\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.808796\n",
      "[200]\teval-auc:0.812894\n",
      "[300]\teval-auc:0.815479\n",
      "[400]\teval-auc:0.81684\n",
      "[500]\teval-auc:0.817593\n",
      "[600]\teval-auc:0.817646\n",
      "[700]\teval-auc:0.817676\n",
      "[800]\teval-auc:0.817686\n",
      "[900]\teval-auc:0.817697\n",
      "[1000]\teval-auc:0.8177\n",
      "[1100]\teval-auc:0.817707\n",
      "[1200]\teval-auc:0.817714\n",
      "[1300]\teval-auc:0.817729\n",
      "[1400]\teval-auc:0.817731\n",
      "Stopping. Best iteration:\n",
      "[1325]\teval-auc:0.817731\n",
      "\n",
      "fold 6 - 0.817731319099\n",
      "[0]\teval-auc:0.775844\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.807332\n",
      "[200]\teval-auc:0.81189\n",
      "[300]\teval-auc:0.814175\n",
      "[400]\teval-auc:0.815452\n",
      "[500]\teval-auc:0.816319\n",
      "[600]\teval-auc:0.816519\n",
      "[700]\teval-auc:0.816567\n",
      "[800]\teval-auc:0.81658\n",
      "[900]\teval-auc:0.816587\n",
      "Stopping. Best iteration:\n",
      "[849]\teval-auc:0.816587\n",
      "\n",
      "fold 7 - 0.816586982522\n",
      "[0]\teval-auc:0.772825\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.800891\n",
      "[200]\teval-auc:0.807243\n",
      "[300]\teval-auc:0.808993\n",
      "[400]\teval-auc:0.810102\n",
      "[500]\teval-auc:0.810573\n",
      "[600]\teval-auc:0.81093\n",
      "[700]\teval-auc:0.811022\n",
      "[800]\teval-auc:0.811053\n",
      "[900]\teval-auc:0.811054\n",
      "Stopping. Best iteration:\n",
      "[828]\teval-auc:0.811054\n",
      "\n",
      "fold 8 - 0.811054350058\n",
      "[0]\teval-auc:0.779124\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.811709\n",
      "[200]\teval-auc:0.815872\n",
      "[300]\teval-auc:0.81707\n",
      "[400]\teval-auc:0.817913\n",
      "[500]\teval-auc:0.818596\n",
      "[600]\teval-auc:0.81876\n",
      "[700]\teval-auc:0.818798\n",
      "[800]\teval-auc:0.818801\n",
      "Stopping. Best iteration:\n",
      "[769]\teval-auc:0.818801\n",
      "\n",
      "fold 9 - 0.818800713945\n",
      "cv score - on train:\n",
      "0.8169000020441228\n",
      "('current score in fold:', 0.8170936522261891, 19)\n",
      "[0]\teval-auc:0.78567\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.812908\n",
      "[200]\teval-auc:0.817244\n",
      "[300]\teval-auc:0.818981\n",
      "[400]\teval-auc:0.820093\n",
      "[500]\teval-auc:0.820753\n",
      "[600]\teval-auc:0.820936\n",
      "[700]\teval-auc:0.820983\n",
      "[800]\teval-auc:0.82099\n",
      "[900]\teval-auc:0.820997\n",
      "[1000]\teval-auc:0.821011\n",
      "[1100]\teval-auc:0.821022\n",
      "[1200]\teval-auc:0.821025\n",
      "[1300]\teval-auc:0.82103\n",
      "Stopping. Best iteration:\n",
      "[1290]\teval-auc:0.82103\n",
      "\n",
      "fold 0 - 0.821030045236\n",
      "[0]\teval-auc:0.773834\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.802802\n",
      "[200]\teval-auc:0.808354\n",
      "[300]\teval-auc:0.810993\n",
      "[400]\teval-auc:0.812383\n",
      "[500]\teval-auc:0.813531\n",
      "[600]\teval-auc:0.813926\n",
      "[700]\teval-auc:0.814053\n",
      "[800]\teval-auc:0.814093\n",
      "[900]\teval-auc:0.814116\n",
      "[1000]\teval-auc:0.814182\n",
      "[1100]\teval-auc:0.814212\n",
      "[1200]\teval-auc:0.814238\n",
      "[1300]\teval-auc:0.814277\n",
      "Stopping. Best iteration:\n",
      "[1234]\teval-auc:0.814277\n",
      "\n",
      "fold 1 - 0.814276804226\n",
      "[0]\teval-auc:0.77442\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.804659\n",
      "[200]\teval-auc:0.80964\n",
      "[300]\teval-auc:0.812152\n",
      "[400]\teval-auc:0.813347\n",
      "[500]\teval-auc:0.814101\n",
      "[600]\teval-auc:0.814413\n",
      "[700]\teval-auc:0.814421\n",
      "[800]\teval-auc:0.81445\n",
      "Stopping. Best iteration:\n",
      "[774]\teval-auc:0.81445\n",
      "\n",
      "fold 2 - 0.814450129001\n",
      "[0]\teval-auc:0.776592\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.808615\n",
      "[200]\teval-auc:0.813857\n",
      "[300]\teval-auc:0.815952\n",
      "[400]\teval-auc:0.817003\n",
      "[500]\teval-auc:0.817872\n",
      "[600]\teval-auc:0.818155\n",
      "[700]\teval-auc:0.818215\n",
      "Stopping. Best iteration:\n",
      "[682]\teval-auc:0.818215\n",
      "\n",
      "fold 3 - 0.818214742844\n",
      "[0]\teval-auc:0.772524\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.804385\n",
      "[200]\teval-auc:0.808446\n",
      "[300]\teval-auc:0.810809\n",
      "[400]\teval-auc:0.811812\n",
      "[500]\teval-auc:0.812642\n",
      "[600]\teval-auc:0.812796\n",
      "[700]\teval-auc:0.812818\n",
      "Stopping. Best iteration:\n",
      "[621]\teval-auc:0.812838\n",
      "\n",
      "fold 4 - 0.812837756969\n",
      "[0]\teval-auc:0.779091\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.809849\n",
      "[200]\teval-auc:0.81482\n",
      "[300]\teval-auc:0.817606\n",
      "[400]\teval-auc:0.818495\n",
      "[500]\teval-auc:0.819265\n",
      "[600]\teval-auc:0.819544\n",
      "[700]\teval-auc:0.819664\n",
      "[800]\teval-auc:0.819679\n",
      "Stopping. Best iteration:\n",
      "[789]\teval-auc:0.819679\n",
      "\n",
      "fold 5 - 0.819678935497\n",
      "[0]\teval-auc:0.775037\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.805019\n",
      "[200]\teval-auc:0.808726\n",
      "[300]\teval-auc:0.810823\n",
      "[400]\teval-auc:0.812345\n",
      "[500]\teval-auc:0.813263\n",
      "[600]\teval-auc:0.813487\n",
      "[700]\teval-auc:0.813515\n",
      "[800]\teval-auc:0.81354\n",
      "Stopping. Best iteration:\n",
      "[709]\teval-auc:0.813543\n",
      "\n",
      "fold 6 - 0.81354304124\n",
      "[0]\teval-auc:0.778037\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.809131\n",
      "[200]\teval-auc:0.81388\n",
      "[300]\teval-auc:0.815371\n",
      "[400]\teval-auc:0.816064\n",
      "[500]\teval-auc:0.817001\n",
      "[600]\teval-auc:0.817333\n",
      "[700]\teval-auc:0.817414\n",
      "[800]\teval-auc:0.817434\n",
      "[900]\teval-auc:0.817434\n",
      "Stopping. Best iteration:\n",
      "[800]\teval-auc:0.817434\n",
      "\n",
      "fold 7 - 0.817434338615\n",
      "[0]\teval-auc:0.788075\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.814344\n",
      "[200]\teval-auc:0.817747\n",
      "[300]\teval-auc:0.819252\n",
      "[400]\teval-auc:0.820487\n",
      "[500]\teval-auc:0.820776\n",
      "[600]\teval-auc:0.82088\n",
      "[700]\teval-auc:0.821012\n",
      "[800]\teval-auc:0.82102\n",
      "[900]\teval-auc:0.821022\n",
      "Stopping. Best iteration:\n",
      "[829]\teval-auc:0.821023\n",
      "\n",
      "fold 8 - 0.82102276906\n",
      "[0]\teval-auc:0.778415\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.811087\n",
      "[200]\teval-auc:0.813711\n",
      "[300]\teval-auc:0.816338\n",
      "[400]\teval-auc:0.817808\n",
      "[500]\teval-auc:0.818543\n",
      "[600]\teval-auc:0.818837\n",
      "[700]\teval-auc:0.818939\n",
      "[800]\teval-auc:0.818953\n",
      "[900]\teval-auc:0.818967\n",
      "[1000]\teval-auc:0.818974\n",
      "Stopping. Best iteration:\n",
      "[948]\teval-auc:0.818976\n",
      "\n",
      "fold 9 - 0.81897609584\n",
      "cv score - on train:\n",
      "0.8170550932577084\n",
      "('current score in fold:', 0.8170977547216298, 20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.772164\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.80337\n",
      "[200]\teval-auc:0.806587\n",
      "[300]\teval-auc:0.809412\n",
      "[400]\teval-auc:0.811276\n",
      "[500]\teval-auc:0.812142\n",
      "[600]\teval-auc:0.812504\n",
      "[700]\teval-auc:0.812572\n",
      "Stopping. Best iteration:\n",
      "[682]\teval-auc:0.812577\n",
      "\n",
      "fold 0 - 0.81257687939\n",
      "[0]\teval-auc:0.776395\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.806978\n",
      "[200]\teval-auc:0.813518\n",
      "[300]\teval-auc:0.814894\n",
      "[400]\teval-auc:0.815686\n",
      "[500]\teval-auc:0.816127\n",
      "[600]\teval-auc:0.816323\n",
      "[700]\teval-auc:0.816376\n",
      "Stopping. Best iteration:\n",
      "[618]\teval-auc:0.816377\n",
      "\n",
      "fold 1 - 0.816376917534\n",
      "[0]\teval-auc:0.776045\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.808862\n",
      "[200]\teval-auc:0.813353\n",
      "[300]\teval-auc:0.815592\n",
      "[400]\teval-auc:0.816619\n",
      "[500]\teval-auc:0.81711\n",
      "[600]\teval-auc:0.817348\n",
      "[700]\teval-auc:0.817376\n",
      "[800]\teval-auc:0.81738\n",
      "Stopping. Best iteration:\n",
      "[715]\teval-auc:0.81738\n",
      "\n",
      "fold 2 - 0.817380152564\n",
      "[0]\teval-auc:0.77539\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.804356\n",
      "[200]\teval-auc:0.809023\n",
      "[300]\teval-auc:0.811246\n",
      "[400]\teval-auc:0.811879\n",
      "[500]\teval-auc:0.812797\n",
      "[600]\teval-auc:0.813021\n",
      "[700]\teval-auc:0.813085\n",
      "Stopping. Best iteration:\n",
      "[648]\teval-auc:0.813088\n",
      "\n",
      "fold 3 - 0.813087579146\n",
      "[0]\teval-auc:0.780545\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.810162\n",
      "[200]\teval-auc:0.812749\n",
      "[300]\teval-auc:0.815567\n",
      "[400]\teval-auc:0.816561\n",
      "[500]\teval-auc:0.81734\n",
      "[600]\teval-auc:0.817621\n",
      "[700]\teval-auc:0.817702\n",
      "[800]\teval-auc:0.817709\n",
      "Stopping. Best iteration:\n",
      "[709]\teval-auc:0.817709\n",
      "\n",
      "fold 4 - 0.817708552153\n",
      "[0]\teval-auc:0.783544\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.811339\n",
      "[200]\teval-auc:0.817079\n",
      "[300]\teval-auc:0.818962\n",
      "[400]\teval-auc:0.820231\n",
      "[500]\teval-auc:0.820812\n",
      "[600]\teval-auc:0.82093\n",
      "[700]\teval-auc:0.821088\n",
      "Stopping. Best iteration:\n",
      "[650]\teval-auc:0.821093\n",
      "\n",
      "fold 5 - 0.82109317191\n",
      "[0]\teval-auc:0.773578\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.806817\n",
      "[200]\teval-auc:0.810257\n",
      "[300]\teval-auc:0.812969\n",
      "[400]\teval-auc:0.814195\n",
      "[500]\teval-auc:0.815167\n",
      "[600]\teval-auc:0.815659\n",
      "[700]\teval-auc:0.81582\n",
      "[800]\teval-auc:0.815834\n",
      "[900]\teval-auc:0.815838\n",
      "Stopping. Best iteration:\n",
      "[870]\teval-auc:0.815838\n",
      "\n",
      "fold 6 - 0.815838413256\n",
      "[0]\teval-auc:0.778006\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.806837\n",
      "[200]\teval-auc:0.812335\n",
      "[300]\teval-auc:0.814033\n",
      "[400]\teval-auc:0.814912\n",
      "[500]\teval-auc:0.815183\n",
      "[600]\teval-auc:0.815275\n",
      "Stopping. Best iteration:\n",
      "[597]\teval-auc:0.815281\n",
      "\n",
      "fold 7 - 0.815281438555\n",
      "[0]\teval-auc:0.788791\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.81584\n",
      "[200]\teval-auc:0.819744\n",
      "[300]\teval-auc:0.822159\n",
      "[400]\teval-auc:0.823647\n",
      "[500]\teval-auc:0.824547\n",
      "[600]\teval-auc:0.824868\n",
      "[700]\teval-auc:0.824919\n",
      "[800]\teval-auc:0.824945\n",
      "[900]\teval-auc:0.824961\n",
      "Stopping. Best iteration:\n",
      "[897]\teval-auc:0.824961\n",
      "\n",
      "fold 8 - 0.824960595016\n",
      "[0]\teval-auc:0.77998\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.807461\n",
      "[200]\teval-auc:0.811821\n",
      "[300]\teval-auc:0.814093\n",
      "[400]\teval-auc:0.815441\n",
      "[500]\teval-auc:0.816552\n",
      "[600]\teval-auc:0.816804\n",
      "[700]\teval-auc:0.816906\n",
      "[800]\teval-auc:0.816921\n",
      "Stopping. Best iteration:\n",
      "[776]\teval-auc:0.816921\n",
      "\n",
      "fold 9 - 0.816921077549\n",
      "cv score - on train:\n",
      "0.8170419585749276\n",
      "('current score in fold:', 0.8171027330050866, 21)\n",
      "[0]\teval-auc:0.786478\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.812951\n",
      "[200]\teval-auc:0.818254\n",
      "[300]\teval-auc:0.820988\n",
      "[400]\teval-auc:0.822293\n",
      "[500]\teval-auc:0.823051\n",
      "[600]\teval-auc:0.823338\n",
      "[700]\teval-auc:0.82342\n",
      "[800]\teval-auc:0.823432\n",
      "[900]\teval-auc:0.823443\n",
      "[1000]\teval-auc:0.823466\n",
      "[1100]\teval-auc:0.823472\n",
      "[1200]\teval-auc:0.823483\n",
      "[1300]\teval-auc:0.823496\n",
      "[1400]\teval-auc:0.823519\n",
      "[1500]\teval-auc:0.823535\n",
      "Stopping. Best iteration:\n",
      "[1459]\teval-auc:0.823535\n",
      "\n",
      "fold 0 - 0.823535447317\n",
      "[0]\teval-auc:0.771524\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.80052\n",
      "[200]\teval-auc:0.805365\n",
      "[300]\teval-auc:0.806985\n",
      "[400]\teval-auc:0.807911\n",
      "[500]\teval-auc:0.808564\n",
      "[600]\teval-auc:0.808792\n",
      "[700]\teval-auc:0.808793\n",
      "[800]\teval-auc:0.808823\n",
      "[900]\teval-auc:0.808824\n",
      "Stopping. Best iteration:\n",
      "[837]\teval-auc:0.808824\n",
      "\n",
      "fold 1 - 0.808824168626\n",
      "[0]\teval-auc:0.777864\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.809015\n",
      "[200]\teval-auc:0.813228\n",
      "[300]\teval-auc:0.815224\n",
      "[400]\teval-auc:0.816586\n",
      "[500]\teval-auc:0.817163\n",
      "[600]\teval-auc:0.817475\n",
      "[700]\teval-auc:0.817492\n",
      "Stopping. Best iteration:\n",
      "[686]\teval-auc:0.817492\n",
      "\n",
      "fold 2 - 0.817492494543\n",
      "[0]\teval-auc:0.778011\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.807107\n",
      "[200]\teval-auc:0.811893\n",
      "[300]\teval-auc:0.81405\n",
      "[400]\teval-auc:0.815069\n",
      "[500]\teval-auc:0.815993\n",
      "[600]\teval-auc:0.816326\n",
      "[700]\teval-auc:0.816421\n",
      "[800]\teval-auc:0.816427\n",
      "Stopping. Best iteration:\n",
      "[724]\teval-auc:0.816427\n",
      "\n",
      "fold 3 - 0.816427357807\n",
      "[0]\teval-auc:0.779101\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.809625\n",
      "[200]\teval-auc:0.813806\n",
      "[300]\teval-auc:0.815674\n",
      "[400]\teval-auc:0.816399\n",
      "[500]\teval-auc:0.81707\n",
      "[600]\teval-auc:0.817304\n",
      "[700]\teval-auc:0.8174\n",
      "Stopping. Best iteration:\n",
      "[680]\teval-auc:0.8174\n",
      "\n",
      "fold 4 - 0.81740029733\n",
      "[0]\teval-auc:0.777441\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.810202\n",
      "[200]\teval-auc:0.815076\n",
      "[300]\teval-auc:0.817196\n",
      "[400]\teval-auc:0.818342\n",
      "[500]\teval-auc:0.819268\n",
      "[600]\teval-auc:0.819501\n",
      "[700]\teval-auc:0.819587\n",
      "[800]\teval-auc:0.8196\n",
      "[900]\teval-auc:0.819609\n",
      "[1000]\teval-auc:0.819625\n",
      "[1100]\teval-auc:0.819631\n",
      "[1200]\teval-auc:0.81964\n",
      "[1300]\teval-auc:0.819642\n",
      "Stopping. Best iteration:\n",
      "[1202]\teval-auc:0.819642\n",
      "\n",
      "fold 5 - 0.81964247075\n",
      "[0]\teval-auc:0.781561\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.810661\n",
      "[200]\teval-auc:0.814711\n",
      "[300]\teval-auc:0.816685\n",
      "[400]\teval-auc:0.818031\n",
      "[500]\teval-auc:0.818655\n",
      "[600]\teval-auc:0.819009\n",
      "[700]\teval-auc:0.819144\n",
      "[800]\teval-auc:0.819146\n",
      "Stopping. Best iteration:\n",
      "[730]\teval-auc:0.819146\n",
      "\n",
      "fold 6 - 0.819145755197\n",
      "[0]\teval-auc:0.775861\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.805935\n",
      "[200]\teval-auc:0.810654\n",
      "[300]\teval-auc:0.81265\n",
      "[400]\teval-auc:0.81371\n",
      "[500]\teval-auc:0.814509\n",
      "[600]\teval-auc:0.814862\n",
      "[700]\teval-auc:0.814997\n",
      "Stopping. Best iteration:\n",
      "[688]\teval-auc:0.814997\n",
      "\n",
      "fold 7 - 0.814997428207\n",
      "[0]\teval-auc:0.783354\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.813717\n",
      "[200]\teval-auc:0.816828\n",
      "[300]\teval-auc:0.819409\n",
      "[400]\teval-auc:0.820301\n",
      "[500]\teval-auc:0.820924\n",
      "[600]\teval-auc:0.821214\n",
      "[700]\teval-auc:0.821239\n",
      "[800]\teval-auc:0.821253\n",
      "Stopping. Best iteration:\n",
      "[743]\teval-auc:0.821253\n",
      "\n",
      "fold 8 - 0.821253060239\n",
      "[0]\teval-auc:0.772041\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.802607\n",
      "[200]\teval-auc:0.806857\n",
      "[300]\teval-auc:0.809817\n",
      "[400]\teval-auc:0.811071\n",
      "[500]\teval-auc:0.811745\n",
      "[600]\teval-auc:0.811956\n",
      "[700]\teval-auc:0.811957\n",
      "Stopping. Best iteration:\n",
      "[613]\teval-auc:0.811963\n",
      "\n",
      "fold 9 - 0.811962644412\n",
      "cv score - on train:\n",
      "0.8169892412947674\n",
      "('current score in fold:', 0.8171028715836494, 22)\n",
      "[0]\teval-auc:0.7823\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.81046\n",
      "[200]\teval-auc:0.815896\n",
      "[300]\teval-auc:0.817271\n",
      "[400]\teval-auc:0.818736\n",
      "[500]\teval-auc:0.819752\n",
      "[600]\teval-auc:0.81997\n",
      "[700]\teval-auc:0.820004\n",
      "[800]\teval-auc:0.82001\n",
      "Stopping. Best iteration:\n",
      "[701]\teval-auc:0.82001\n",
      "\n",
      "fold 0 - 0.820010284089\n",
      "[0]\teval-auc:0.77553\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.807059\n",
      "[200]\teval-auc:0.81233\n",
      "[300]\teval-auc:0.814655\n",
      "[400]\teval-auc:0.815687\n",
      "[500]\teval-auc:0.816391\n",
      "[600]\teval-auc:0.816692\n",
      "[700]\teval-auc:0.81675\n",
      "[800]\teval-auc:0.816755\n",
      "[900]\teval-auc:0.816759\n",
      "Stopping. Best iteration:\n",
      "[810]\teval-auc:0.816759\n",
      "\n",
      "fold 1 - 0.816759140976\n",
      "[0]\teval-auc:0.775605\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.806917\n",
      "[200]\teval-auc:0.811177\n",
      "[300]\teval-auc:0.813518\n",
      "[400]\teval-auc:0.814739\n",
      "[500]\teval-auc:0.81559\n",
      "[600]\teval-auc:0.815825\n",
      "[700]\teval-auc:0.815877\n",
      "[800]\teval-auc:0.81589\n",
      "[900]\teval-auc:0.815932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\teval-auc:0.815941\n",
      "[1100]\teval-auc:0.815949\n",
      "Stopping. Best iteration:\n",
      "[1032]\teval-auc:0.815949\n",
      "\n",
      "fold 2 - 0.815948677403\n",
      "[0]\teval-auc:0.78346\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.810966\n",
      "[200]\teval-auc:0.816285\n",
      "[300]\teval-auc:0.817492\n",
      "[400]\teval-auc:0.818583\n",
      "[500]\teval-auc:0.81944\n",
      "[600]\teval-auc:0.819727\n",
      "[700]\teval-auc:0.819722\n",
      "Stopping. Best iteration:\n",
      "[646]\teval-auc:0.81975\n",
      "\n",
      "fold 3 - 0.819749563223\n",
      "[0]\teval-auc:0.78222\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.812312\n",
      "[200]\teval-auc:0.816855\n",
      "[300]\teval-auc:0.817811\n",
      "[400]\teval-auc:0.819408\n",
      "[500]\teval-auc:0.819954\n",
      "[600]\teval-auc:0.820096\n",
      "[700]\teval-auc:0.82019\n",
      "Stopping. Best iteration:\n",
      "[696]\teval-auc:0.82019\n",
      "\n",
      "fold 4 - 0.820189977118\n",
      "[0]\teval-auc:0.774829\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.802334\n",
      "[200]\teval-auc:0.807992\n",
      "[300]\teval-auc:0.810488\n",
      "[400]\teval-auc:0.811937\n",
      "[500]\teval-auc:0.81257\n",
      "[600]\teval-auc:0.812722\n",
      "[700]\teval-auc:0.812794\n",
      "[800]\teval-auc:0.812811\n",
      "[900]\teval-auc:0.812826\n",
      "Stopping. Best iteration:\n",
      "[839]\teval-auc:0.812826\n",
      "\n",
      "fold 5 - 0.812825864923\n",
      "[0]\teval-auc:0.785863\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.816067\n",
      "[200]\teval-auc:0.819904\n",
      "[300]\teval-auc:0.822261\n",
      "[400]\teval-auc:0.823123\n",
      "[500]\teval-auc:0.823877\n",
      "[600]\teval-auc:0.824091\n",
      "[700]\teval-auc:0.824128\n",
      "Stopping. Best iteration:\n",
      "[637]\teval-auc:0.824132\n",
      "\n",
      "fold 6 - 0.824131967229\n",
      "[0]\teval-auc:0.776435\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.807053\n",
      "[200]\teval-auc:0.810997\n",
      "[300]\teval-auc:0.8138\n",
      "[400]\teval-auc:0.814377\n",
      "[500]\teval-auc:0.815061\n",
      "[600]\teval-auc:0.815254\n",
      "[700]\teval-auc:0.815264\n",
      "Stopping. Best iteration:\n",
      "[633]\teval-auc:0.815281\n",
      "\n",
      "fold 7 - 0.815280569128\n",
      "[0]\teval-auc:0.77225\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.80111\n",
      "[200]\teval-auc:0.805625\n",
      "[300]\teval-auc:0.808097\n",
      "[400]\teval-auc:0.809332\n",
      "[500]\teval-auc:0.810322\n",
      "[600]\teval-auc:0.810778\n",
      "[700]\teval-auc:0.810887\n",
      "[800]\teval-auc:0.810899\n",
      "[900]\teval-auc:0.810914\n",
      "[1000]\teval-auc:0.810919\n",
      "Stopping. Best iteration:\n",
      "[924]\teval-auc:0.810919\n",
      "\n",
      "fold 8 - 0.810919075815\n",
      "[0]\teval-auc:0.77418\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.806642\n",
      "[200]\teval-auc:0.810219\n",
      "[300]\teval-auc:0.812458\n",
      "[400]\teval-auc:0.813496\n",
      "[500]\teval-auc:0.81434\n",
      "[600]\teval-auc:0.814519\n",
      "[700]\teval-auc:0.814585\n",
      "[800]\teval-auc:0.814588\n",
      "Stopping. Best iteration:\n",
      "[764]\teval-auc:0.814588\n",
      "\n",
      "fold 9 - 0.814588419955\n",
      "cv score - on train:\n",
      "0.8169474385191933\n",
      "('current score in fold:', 0.8171004209161746, 23)\n",
      "[0]\teval-auc:0.782125\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.810816\n",
      "[200]\teval-auc:0.814589\n",
      "[300]\teval-auc:0.81634\n",
      "[400]\teval-auc:0.817533\n",
      "[500]\teval-auc:0.818431\n",
      "[600]\teval-auc:0.818652\n",
      "Stopping. Best iteration:\n",
      "[599]\teval-auc:0.818672\n",
      "\n",
      "fold 0 - 0.818672430805\n",
      "[0]\teval-auc:0.781363\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.813192\n",
      "[200]\teval-auc:0.815926\n",
      "[300]\teval-auc:0.818418\n",
      "[400]\teval-auc:0.819781\n",
      "[500]\teval-auc:0.820532\n",
      "[600]\teval-auc:0.820866\n",
      "[700]\teval-auc:0.821005\n",
      "[800]\teval-auc:0.821019\n",
      "[900]\teval-auc:0.821039\n",
      "[1000]\teval-auc:0.821042\n",
      "Stopping. Best iteration:\n",
      "[915]\teval-auc:0.821042\n",
      "\n",
      "fold 1 - 0.821041506668\n",
      "[0]\teval-auc:0.781157\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.80805\n",
      "[200]\teval-auc:0.813096\n",
      "[300]\teval-auc:0.815683\n",
      "[400]\teval-auc:0.817127\n",
      "[500]\teval-auc:0.818098\n",
      "[600]\teval-auc:0.81821\n",
      "[700]\teval-auc:0.81826\n",
      "[800]\teval-auc:0.818264\n",
      "Stopping. Best iteration:\n",
      "[782]\teval-auc:0.818264\n",
      "\n",
      "fold 2 - 0.818263779822\n",
      "[0]\teval-auc:0.77247\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.804474\n",
      "[200]\teval-auc:0.808884\n",
      "[300]\teval-auc:0.81146\n",
      "[400]\teval-auc:0.812987\n",
      "[500]\teval-auc:0.81386\n",
      "[600]\teval-auc:0.81418\n",
      "[700]\teval-auc:0.814219\n",
      "[800]\teval-auc:0.814257\n",
      "[900]\teval-auc:0.814272\n",
      "[1000]\teval-auc:0.814295\n",
      "[1100]\teval-auc:0.814305\n",
      "Stopping. Best iteration:\n",
      "[1073]\teval-auc:0.814305\n",
      "\n",
      "fold 3 - 0.814304706295\n",
      "[0]\teval-auc:0.777982\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.808317\n",
      "[200]\teval-auc:0.812656\n",
      "[300]\teval-auc:0.814745\n",
      "[400]\teval-auc:0.815841\n",
      "[500]\teval-auc:0.816503\n",
      "[600]\teval-auc:0.816891\n",
      "[700]\teval-auc:0.816923\n",
      "[800]\teval-auc:0.816928\n",
      "Stopping. Best iteration:\n",
      "[708]\teval-auc:0.816928\n",
      "\n",
      "fold 4 - 0.816927949563\n",
      "[0]\teval-auc:0.778045\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.812079\n",
      "[200]\teval-auc:0.816023\n",
      "[300]\teval-auc:0.818342\n",
      "[400]\teval-auc:0.819269\n",
      "[500]\teval-auc:0.819768\n",
      "[600]\teval-auc:0.819787\n",
      "[700]\teval-auc:0.819878\n",
      "[800]\teval-auc:0.819883\n",
      "[900]\teval-auc:0.819896\n",
      "[1000]\teval-auc:0.819898\n",
      "Stopping. Best iteration:\n",
      "[905]\teval-auc:0.819898\n",
      "\n",
      "fold 5 - 0.819898087412\n",
      "[0]\teval-auc:0.778896\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.809349\n",
      "[200]\teval-auc:0.813323\n",
      "[300]\teval-auc:0.815822\n",
      "[400]\teval-auc:0.816748\n",
      "[500]\teval-auc:0.817353\n",
      "[600]\teval-auc:0.817519\n",
      "[700]\teval-auc:0.817529\n",
      "Stopping. Best iteration:\n",
      "[617]\teval-auc:0.817553\n",
      "\n",
      "fold 6 - 0.817552887084\n",
      "[0]\teval-auc:0.772829\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.804542\n",
      "[200]\teval-auc:0.807888\n",
      "[300]\teval-auc:0.810406\n",
      "[400]\teval-auc:0.811435\n",
      "[500]\teval-auc:0.81217\n",
      "[600]\teval-auc:0.812398\n",
      "[700]\teval-auc:0.812429\n",
      "Stopping. Best iteration:\n",
      "[618]\teval-auc:0.812437\n",
      "\n",
      "fold 7 - 0.812437365645\n",
      "[0]\teval-auc:0.775898\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.80307\n",
      "[200]\teval-auc:0.807682\n",
      "[300]\teval-auc:0.809827\n",
      "[400]\teval-auc:0.810796\n",
      "[500]\teval-auc:0.811611\n",
      "[600]\teval-auc:0.811909\n",
      "[700]\teval-auc:0.812019\n",
      "[800]\teval-auc:0.812037\n",
      "[900]\teval-auc:0.812039\n",
      "Stopping. Best iteration:\n",
      "[805]\teval-auc:0.812039\n",
      "\n",
      "fold 8 - 0.812039367755\n",
      "[0]\teval-auc:0.784091\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.81236\n",
      "[200]\teval-auc:0.81617\n",
      "[300]\teval-auc:0.817654\n",
      "[400]\teval-auc:0.818842\n",
      "[500]\teval-auc:0.819889\n",
      "[600]\teval-auc:0.820104\n",
      "[700]\teval-auc:0.820223\n",
      "[800]\teval-auc:0.820263\n",
      "[900]\teval-auc:0.820268\n",
      "Stopping. Best iteration:\n",
      "[816]\teval-auc:0.820268\n",
      "\n",
      "fold 9 - 0.820267736105\n",
      "cv score - on train:\n",
      "0.817049772767138\n",
      "('current score in fold:', 0.8171031887112492, 24)\n",
      "[0]\teval-auc:0.780763\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.809927\n",
      "[200]\teval-auc:0.813994\n",
      "[300]\teval-auc:0.815815\n",
      "[400]\teval-auc:0.817185\n",
      "[500]\teval-auc:0.817877\n",
      "[600]\teval-auc:0.818139\n",
      "[700]\teval-auc:0.818196\n",
      "Stopping. Best iteration:\n",
      "[655]\teval-auc:0.818212\n",
      "\n",
      "fold 0 - 0.818212299543\n",
      "[0]\teval-auc:0.781235\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.809384\n",
      "[200]\teval-auc:0.813615\n",
      "[300]\teval-auc:0.815451\n",
      "[400]\teval-auc:0.816699\n",
      "[500]\teval-auc:0.817159\n",
      "[600]\teval-auc:0.817395\n",
      "[700]\teval-auc:0.817424\n",
      "[800]\teval-auc:0.817457\n",
      "[900]\teval-auc:0.817463\n",
      "[1000]\teval-auc:0.817469\n",
      "Stopping. Best iteration:\n",
      "[914]\teval-auc:0.817469\n",
      "\n",
      "fold 1 - 0.817468894963\n",
      "[0]\teval-auc:0.78066\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.808188\n",
      "[200]\teval-auc:0.813383\n",
      "[300]\teval-auc:0.816202\n",
      "[400]\teval-auc:0.817199\n",
      "[500]\teval-auc:0.81818\n",
      "[600]\teval-auc:0.818443\n",
      "[700]\teval-auc:0.818586\n",
      "Stopping. Best iteration:\n",
      "[679]\teval-auc:0.818586\n",
      "\n",
      "fold 2 - 0.818585654444\n",
      "[0]\teval-auc:0.784156\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.814167\n",
      "[200]\teval-auc:0.818166\n",
      "[300]\teval-auc:0.820246\n",
      "[400]\teval-auc:0.82097\n",
      "[500]\teval-auc:0.821766\n",
      "[600]\teval-auc:0.822102\n",
      "[700]\teval-auc:0.822117\n",
      "[800]\teval-auc:0.822161\n",
      "[900]\teval-auc:0.82218\n",
      "[1000]\teval-auc:0.822193\n",
      "Stopping. Best iteration:\n",
      "[966]\teval-auc:0.822193\n",
      "\n",
      "fold 3 - 0.822192678939\n",
      "[0]\teval-auc:0.776419\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.808381\n",
      "[200]\teval-auc:0.81231\n",
      "[300]\teval-auc:0.814379\n",
      "[400]\teval-auc:0.816019\n",
      "[500]\teval-auc:0.816852\n",
      "[600]\teval-auc:0.817238\n",
      "[700]\teval-auc:0.817371\n",
      "[800]\teval-auc:0.817465\n",
      "[900]\teval-auc:0.817469\n",
      "Stopping. Best iteration:\n",
      "[836]\teval-auc:0.817469\n",
      "\n",
      "fold 4 - 0.817468880716\n",
      "[0]\teval-auc:0.774617\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.805968\n",
      "[200]\teval-auc:0.809921\n",
      "[300]\teval-auc:0.812227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\teval-auc:0.813327\n",
      "[500]\teval-auc:0.814156\n",
      "[600]\teval-auc:0.814286\n",
      "[700]\teval-auc:0.814374\n",
      "[800]\teval-auc:0.814395\n",
      "[900]\teval-auc:0.814414\n",
      "[1000]\teval-auc:0.814422\n",
      "Stopping. Best iteration:\n",
      "[942]\teval-auc:0.814422\n",
      "\n",
      "fold 5 - 0.814422132894\n",
      "[0]\teval-auc:0.785181\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.814383\n",
      "[200]\teval-auc:0.819416\n",
      "[300]\teval-auc:0.821647\n",
      "[400]\teval-auc:0.822456\n",
      "[500]\teval-auc:0.82277\n",
      "[600]\teval-auc:0.822783\n",
      "Stopping. Best iteration:\n",
      "[562]\teval-auc:0.82281\n",
      "\n",
      "fold 6 - 0.822809939788\n",
      "[0]\teval-auc:0.777\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.805331\n",
      "[200]\teval-auc:0.810449\n",
      "[300]\teval-auc:0.812301\n",
      "[400]\teval-auc:0.813376\n",
      "[500]\teval-auc:0.814308\n",
      "[600]\teval-auc:0.814527\n",
      "[700]\teval-auc:0.814535\n",
      "Stopping. Best iteration:\n",
      "[615]\teval-auc:0.814543\n",
      "\n",
      "fold 7 - 0.814542853444\n",
      "[0]\teval-auc:0.770548\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.804622\n",
      "[200]\teval-auc:0.808319\n",
      "[300]\teval-auc:0.810767\n",
      "[400]\teval-auc:0.811755\n",
      "[500]\teval-auc:0.812619\n",
      "[600]\teval-auc:0.813045\n",
      "[700]\teval-auc:0.813101\n",
      "[800]\teval-auc:0.813113\n",
      "[900]\teval-auc:0.813121\n",
      "[1000]\teval-auc:0.813129\n",
      "Stopping. Best iteration:\n",
      "[942]\teval-auc:0.813129\n",
      "\n",
      "fold 8 - 0.813129322405\n",
      "[0]\teval-auc:0.771905\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.802566\n",
      "[200]\teval-auc:0.806692\n",
      "[300]\teval-auc:0.80964\n",
      "[400]\teval-auc:0.810824\n",
      "[500]\teval-auc:0.811487\n",
      "[600]\teval-auc:0.811718\n",
      "[700]\teval-auc:0.811751\n",
      "Stopping. Best iteration:\n",
      "[671]\teval-auc:0.811751\n",
      "\n",
      "fold 9 - 0.811751053033\n",
      "cv score - on train:\n",
      "0.8169551203314708\n",
      "('current score in fold:', 0.817100795113918, 25)\n",
      "[0]\teval-auc:0.77186\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.801144\n",
      "[200]\teval-auc:0.80622\n",
      "[300]\teval-auc:0.808538\n",
      "[400]\teval-auc:0.809298\n",
      "[500]\teval-auc:0.810248\n",
      "[600]\teval-auc:0.8106\n",
      "[700]\teval-auc:0.810646\n",
      "[800]\teval-auc:0.810661\n",
      "Stopping. Best iteration:\n",
      "[796]\teval-auc:0.810661\n",
      "\n",
      "fold 0 - 0.810661053656\n",
      "[0]\teval-auc:0.783804\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.811891\n",
      "[200]\teval-auc:0.81627\n",
      "[300]\teval-auc:0.818035\n",
      "[400]\teval-auc:0.819346\n",
      "[500]\teval-auc:0.820057\n",
      "[600]\teval-auc:0.820223\n",
      "[700]\teval-auc:0.820298\n",
      "[800]\teval-auc:0.820304\n",
      "Stopping. Best iteration:\n",
      "[744]\teval-auc:0.820304\n",
      "\n",
      "fold 1 - 0.820304007326\n",
      "[0]\teval-auc:0.787481\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.815862\n",
      "[200]\teval-auc:0.821248\n",
      "[300]\teval-auc:0.82328\n",
      "[400]\teval-auc:0.823574\n",
      "[500]\teval-auc:0.824477\n",
      "[600]\teval-auc:0.824845\n",
      "[700]\teval-auc:0.824934\n",
      "[800]\teval-auc:0.824946\n",
      "Stopping. Best iteration:\n",
      "[729]\teval-auc:0.824947\n",
      "\n",
      "fold 2 - 0.824946535518\n",
      "[0]\teval-auc:0.775714\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.81088\n",
      "[200]\teval-auc:0.814095\n",
      "[300]\teval-auc:0.816243\n",
      "[400]\teval-auc:0.817353\n",
      "[500]\teval-auc:0.817946\n",
      "[600]\teval-auc:0.818117\n",
      "[700]\teval-auc:0.818156\n",
      "[800]\teval-auc:0.818162\n",
      "[900]\teval-auc:0.818169\n",
      "[1000]\teval-auc:0.818179\n",
      "Stopping. Best iteration:\n",
      "[927]\teval-auc:0.818179\n",
      "\n",
      "fold 3 - 0.818179183199\n",
      "[0]\teval-auc:0.786803\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.816013\n",
      "[200]\teval-auc:0.819909\n",
      "[300]\teval-auc:0.821785\n",
      "[400]\teval-auc:0.822987\n",
      "[500]\teval-auc:0.823987\n",
      "[600]\teval-auc:0.824348\n",
      "[700]\teval-auc:0.824426\n",
      "Stopping. Best iteration:\n",
      "[670]\teval-auc:0.824426\n",
      "\n",
      "fold 4 - 0.824426133792\n",
      "[0]\teval-auc:0.778646\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.809413\n",
      "[200]\teval-auc:0.813357\n",
      "[300]\teval-auc:0.815568\n",
      "[400]\teval-auc:0.816546\n",
      "[500]\teval-auc:0.816929\n",
      "[600]\teval-auc:0.817012\n",
      "[700]\teval-auc:0.817067\n",
      "[800]\teval-auc:0.817082\n",
      "Stopping. Best iteration:\n",
      "[737]\teval-auc:0.817082\n",
      "\n",
      "fold 5 - 0.817082356225\n",
      "[0]\teval-auc:0.776513\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.80696\n",
      "[200]\teval-auc:0.811806\n",
      "[300]\teval-auc:0.813639\n",
      "[400]\teval-auc:0.814978\n",
      "[500]\teval-auc:0.815784\n",
      "[600]\teval-auc:0.816057\n",
      "[700]\teval-auc:0.816078\n",
      "Stopping. Best iteration:\n",
      "[698]\teval-auc:0.816078\n",
      "\n",
      "fold 6 - 0.816078503302\n",
      "[0]\teval-auc:0.782988\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.81196\n",
      "[200]\teval-auc:0.81573\n",
      "[300]\teval-auc:0.817941\n",
      "[400]\teval-auc:0.819657\n",
      "[500]\teval-auc:0.820414\n",
      "[600]\teval-auc:0.820705\n",
      "[700]\teval-auc:0.820782\n",
      "[800]\teval-auc:0.820796\n",
      "[900]\teval-auc:0.820804\n",
      "[1000]\teval-auc:0.820818\n",
      "Stopping. Best iteration:\n",
      "[993]\teval-auc:0.820818\n",
      "\n",
      "fold 7 - 0.820818090335\n",
      "[0]\teval-auc:0.769441\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.798756\n",
      "[200]\teval-auc:0.803447\n",
      "[300]\teval-auc:0.805754\n",
      "[400]\teval-auc:0.807496\n",
      "[500]\teval-auc:0.808281\n",
      "[600]\teval-auc:0.808546\n",
      "[700]\teval-auc:0.808609\n",
      "[800]\teval-auc:0.808717\n",
      "[900]\teval-auc:0.808732\n",
      "[1000]\teval-auc:0.808746\n",
      "Stopping. Best iteration:\n",
      "[941]\teval-auc:0.808746\n",
      "\n",
      "fold 8 - 0.808746043538\n",
      "[0]\teval-auc:0.771339\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.798671\n",
      "[200]\teval-auc:0.80489\n",
      "[300]\teval-auc:0.80703\n",
      "[400]\teval-auc:0.807859\n",
      "[500]\teval-auc:0.808643\n",
      "[600]\teval-auc:0.808949\n",
      "[700]\teval-auc:0.808965\n",
      "[800]\teval-auc:0.809025\n",
      "[900]\teval-auc:0.809046\n",
      "[1000]\teval-auc:0.809058\n",
      "[1100]\teval-auc:0.80908\n",
      "Stopping. Best iteration:\n",
      "[1084]\teval-auc:0.80908\n",
      "\n",
      "fold 9 - 0.809079832128\n",
      "cv score - on train:\n",
      "0.8169290768952779\n",
      "('current score in fold:', 0.8170990037099084, 26)\n",
      "[0]\teval-auc:0.785447\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.819385\n",
      "[200]\teval-auc:0.821994\n",
      "[300]\teval-auc:0.824058\n",
      "[400]\teval-auc:0.825498\n",
      "[500]\teval-auc:0.826381\n",
      "[600]\teval-auc:0.826598\n",
      "[700]\teval-auc:0.826642\n",
      "[800]\teval-auc:0.826648\n",
      "Stopping. Best iteration:\n",
      "[710]\teval-auc:0.826648\n",
      "\n",
      "fold 0 - 0.826647550223\n",
      "[0]\teval-auc:0.782522\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.810373\n",
      "[200]\teval-auc:0.814847\n",
      "[300]\teval-auc:0.817162\n",
      "[400]\teval-auc:0.818229\n",
      "[500]\teval-auc:0.818919\n",
      "[600]\teval-auc:0.819125\n",
      "[700]\teval-auc:0.819241\n",
      "[800]\teval-auc:0.819249\n",
      "Stopping. Best iteration:\n",
      "[708]\teval-auc:0.81925\n",
      "\n",
      "fold 1 - 0.819250218049\n",
      "[0]\teval-auc:0.777341\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.807007\n",
      "[200]\teval-auc:0.810269\n",
      "[300]\teval-auc:0.81262\n",
      "[400]\teval-auc:0.813921\n",
      "[500]\teval-auc:0.814722\n",
      "[600]\teval-auc:0.815011\n",
      "[700]\teval-auc:0.815095\n",
      "[800]\teval-auc:0.815113\n",
      "[900]\teval-auc:0.815121\n",
      "Stopping. Best iteration:\n",
      "[815]\teval-auc:0.815121\n",
      "\n",
      "fold 2 - 0.815120946886\n",
      "[0]\teval-auc:0.773978\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.805983\n",
      "[200]\teval-auc:0.810203\n",
      "[300]\teval-auc:0.813047\n",
      "[400]\teval-auc:0.814179\n",
      "[500]\teval-auc:0.815033\n",
      "[600]\teval-auc:0.815292\n",
      "[700]\teval-auc:0.815354\n",
      "[800]\teval-auc:0.81538\n",
      "[900]\teval-auc:0.815396\n",
      "[1000]\teval-auc:0.815409\n",
      "[1100]\teval-auc:0.815412\n",
      "[1200]\teval-auc:0.815421\n",
      "Stopping. Best iteration:\n",
      "[1180]\teval-auc:0.815421\n",
      "\n",
      "fold 3 - 0.81542117372\n",
      "[0]\teval-auc:0.784383\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.8123\n",
      "[200]\teval-auc:0.817502\n",
      "[300]\teval-auc:0.819277\n",
      "[400]\teval-auc:0.820576\n",
      "[500]\teval-auc:0.821216\n",
      "[600]\teval-auc:0.821497\n",
      "[700]\teval-auc:0.821563\n",
      "Stopping. Best iteration:\n",
      "[638]\teval-auc:0.821585\n",
      "\n",
      "fold 4 - 0.821585230165\n",
      "[0]\teval-auc:0.776833\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.806516\n",
      "[200]\teval-auc:0.810754\n",
      "[300]\teval-auc:0.81292\n",
      "[400]\teval-auc:0.81408\n",
      "[500]\teval-auc:0.814821\n",
      "[600]\teval-auc:0.815118\n",
      "[700]\teval-auc:0.815098\n",
      "Stopping. Best iteration:\n",
      "[615]\teval-auc:0.815135\n",
      "\n",
      "fold 5 - 0.815134716893\n",
      "[0]\teval-auc:0.770328\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.802329\n",
      "[200]\teval-auc:0.807004\n",
      "[300]\teval-auc:0.809539\n",
      "[400]\teval-auc:0.811113\n",
      "[500]\teval-auc:0.812216\n",
      "[600]\teval-auc:0.812593\n",
      "[700]\teval-auc:0.812687\n",
      "[800]\teval-auc:0.812694\n",
      "Stopping. Best iteration:\n",
      "[717]\teval-auc:0.812694\n",
      "\n",
      "fold 6 - 0.812694281236\n",
      "[0]\teval-auc:0.782701\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.809356\n",
      "[200]\teval-auc:0.815032\n",
      "[300]\teval-auc:0.816286\n",
      "[400]\teval-auc:0.817087\n",
      "[500]\teval-auc:0.817755\n",
      "[600]\teval-auc:0.817848\n",
      "[700]\teval-auc:0.817909\n",
      "Stopping. Best iteration:\n",
      "[664]\teval-auc:0.81791\n",
      "\n",
      "fold 7 - 0.81790987939\n",
      "[0]\teval-auc:0.774841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.802379\n",
      "[200]\teval-auc:0.807441\n",
      "[300]\teval-auc:0.809906\n",
      "[400]\teval-auc:0.810958\n",
      "[500]\teval-auc:0.811611\n",
      "[600]\teval-auc:0.811834\n",
      "[700]\teval-auc:0.811846\n",
      "Stopping. Best iteration:\n",
      "[617]\teval-auc:0.811865\n",
      "\n",
      "fold 8 - 0.811864826781\n",
      "[0]\teval-auc:0.775859\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.805546\n",
      "[200]\teval-auc:0.811161\n",
      "[300]\teval-auc:0.812719\n",
      "[400]\teval-auc:0.813988\n",
      "[500]\teval-auc:0.814854\n",
      "[600]\teval-auc:0.815079\n",
      "[700]\teval-auc:0.815125\n",
      "[800]\teval-auc:0.815131\n",
      "[900]\teval-auc:0.815134\n",
      "[1000]\teval-auc:0.815148\n",
      "[1100]\teval-auc:0.815149\n",
      "Stopping. Best iteration:\n",
      "[1046]\teval-auc:0.815149\n",
      "\n",
      "fold 9 - 0.815149506616\n",
      "cv score - on train:\n",
      "0.8170146727765777\n",
      "('current score in fold:', 0.8171013144450967, 27)\n",
      "[0]\teval-auc:0.786791\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.81687\n",
      "[200]\teval-auc:0.821459\n",
      "[300]\teval-auc:0.823053\n",
      "[400]\teval-auc:0.824418\n",
      "[500]\teval-auc:0.825202\n",
      "[600]\teval-auc:0.825426\n",
      "[700]\teval-auc:0.825439\n",
      "[800]\teval-auc:0.825454\n",
      "[900]\teval-auc:0.82546\n",
      "Stopping. Best iteration:\n",
      "[829]\teval-auc:0.82546\n",
      "\n",
      "fold 0 - 0.825459970632\n",
      "[0]\teval-auc:0.781831\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.809844\n",
      "[200]\teval-auc:0.812985\n",
      "[300]\teval-auc:0.81515\n",
      "[400]\teval-auc:0.816412\n",
      "[500]\teval-auc:0.817094\n",
      "[600]\teval-auc:0.817342\n",
      "[700]\teval-auc:0.817427\n",
      "[800]\teval-auc:0.81743\n",
      "[900]\teval-auc:0.817433\n",
      "Stopping. Best iteration:\n",
      "[818]\teval-auc:0.817433\n",
      "\n",
      "fold 1 - 0.817433456414\n",
      "[0]\teval-auc:0.777794\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.808516\n",
      "[200]\teval-auc:0.813654\n",
      "[300]\teval-auc:0.816156\n",
      "[400]\teval-auc:0.817434\n",
      "[500]\teval-auc:0.81841\n",
      "[600]\teval-auc:0.818818\n",
      "[700]\teval-auc:0.818923\n",
      "[800]\teval-auc:0.818988\n",
      "[900]\teval-auc:0.81901\n",
      "[1000]\teval-auc:0.819026\n",
      "[1100]\teval-auc:0.819035\n",
      "Stopping. Best iteration:\n",
      "[1014]\teval-auc:0.819035\n",
      "\n",
      "fold 2 - 0.819034488111\n",
      "[0]\teval-auc:0.77621\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.804598\n",
      "[200]\teval-auc:0.808598\n",
      "[300]\teval-auc:0.811327\n",
      "[400]\teval-auc:0.812786\n",
      "[500]\teval-auc:0.813351\n",
      "[600]\teval-auc:0.813856\n",
      "[700]\teval-auc:0.81395\n",
      "[800]\teval-auc:0.813968\n",
      "[900]\teval-auc:0.813983\n",
      "[1000]\teval-auc:0.814031\n",
      "[1100]\teval-auc:0.81408\n",
      "[1200]\teval-auc:0.814085\n",
      "Stopping. Best iteration:\n",
      "[1185]\teval-auc:0.814085\n",
      "\n",
      "fold 3 - 0.814084567019\n",
      "[0]\teval-auc:0.779287\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.809122\n",
      "[200]\teval-auc:0.814171\n",
      "[300]\teval-auc:0.815573\n",
      "[400]\teval-auc:0.817629\n",
      "[500]\teval-auc:0.81841\n",
      "[600]\teval-auc:0.818643\n",
      "[700]\teval-auc:0.81868\n",
      "Stopping. Best iteration:\n",
      "[640]\teval-auc:0.818711\n",
      "\n",
      "fold 4 - 0.818710668821\n",
      "[0]\teval-auc:0.766098\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.802655\n",
      "[200]\teval-auc:0.806219\n",
      "[300]\teval-auc:0.80853\n",
      "[400]\teval-auc:0.809736\n",
      "[500]\teval-auc:0.810251\n",
      "[600]\teval-auc:0.810441\n",
      "[700]\teval-auc:0.810528\n",
      "Stopping. Best iteration:\n",
      "[647]\teval-auc:0.810535\n",
      "\n",
      "fold 5 - 0.810534607531\n",
      "[0]\teval-auc:0.781663\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.807397\n",
      "[200]\teval-auc:0.813048\n",
      "[300]\teval-auc:0.815173\n",
      "[400]\teval-auc:0.816104\n",
      "[500]\teval-auc:0.816718\n",
      "[600]\teval-auc:0.817005\n",
      "[700]\teval-auc:0.817155\n",
      "[800]\teval-auc:0.817168\n",
      "[900]\teval-auc:0.817187\n",
      "Stopping. Best iteration:\n",
      "[860]\teval-auc:0.817187\n",
      "\n",
      "fold 6 - 0.81718744281\n",
      "[0]\teval-auc:0.778302\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.811202\n",
      "[200]\teval-auc:0.81404\n",
      "[300]\teval-auc:0.816025\n",
      "[400]\teval-auc:0.817211\n",
      "[500]\teval-auc:0.817798\n",
      "[600]\teval-auc:0.818049\n",
      "[700]\teval-auc:0.818167\n",
      "Stopping. Best iteration:\n",
      "[697]\teval-auc:0.818173\n",
      "\n",
      "fold 7 - 0.818172823956\n",
      "[0]\teval-auc:0.779749\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.807276\n",
      "[200]\teval-auc:0.812034\n",
      "[300]\teval-auc:0.813695\n",
      "[400]\teval-auc:0.814769\n",
      "[500]\teval-auc:0.81557\n",
      "[600]\teval-auc:0.815646\n",
      "[700]\teval-auc:0.815722\n",
      "Stopping. Best iteration:\n",
      "[619]\teval-auc:0.815754\n",
      "\n",
      "fold 8 - 0.815754413809\n",
      "[0]\teval-auc:0.775013\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.804733\n",
      "[200]\teval-auc:0.810523\n",
      "[300]\teval-auc:0.812084\n",
      "[400]\teval-auc:0.813275\n",
      "[500]\teval-auc:0.81388\n",
      "[600]\teval-auc:0.814111\n",
      "[700]\teval-auc:0.814143\n",
      "[800]\teval-auc:0.81415\n",
      "[900]\teval-auc:0.814155\n",
      "[1000]\teval-auc:0.814154\n",
      "Stopping. Best iteration:\n",
      "[901]\teval-auc:0.814158\n",
      "\n",
      "fold 9 - 0.814157640402\n",
      "cv score - on train:\n",
      "0.8169489737131713\n",
      "('current score in fold:', 0.8171003778107606, 28)\n",
      "[0]\teval-auc:0.781595\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.810848\n",
      "[200]\teval-auc:0.814663\n",
      "[300]\teval-auc:0.816931\n",
      "[400]\teval-auc:0.818069\n",
      "[500]\teval-auc:0.818704\n",
      "[600]\teval-auc:0.818942\n",
      "[700]\teval-auc:0.818964\n",
      "[800]\teval-auc:0.818972\n",
      "Stopping. Best iteration:\n",
      "[720]\teval-auc:0.818972\n",
      "\n",
      "fold 0 - 0.81897199517\n",
      "[0]\teval-auc:0.775638\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.808674\n",
      "[200]\teval-auc:0.812425\n",
      "[300]\teval-auc:0.814907\n",
      "[400]\teval-auc:0.816019\n",
      "[500]\teval-auc:0.816851\n",
      "[600]\teval-auc:0.817028\n",
      "[700]\teval-auc:0.817063\n",
      "Stopping. Best iteration:\n",
      "[630]\teval-auc:0.81708\n",
      "\n",
      "fold 1 - 0.81708001121\n",
      "[0]\teval-auc:0.776536\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.803504\n",
      "[200]\teval-auc:0.807478\n",
      "[300]\teval-auc:0.811879\n",
      "[400]\teval-auc:0.812979\n",
      "[500]\teval-auc:0.813711\n",
      "[600]\teval-auc:0.813905\n",
      "[700]\teval-auc:0.813942\n",
      "[800]\teval-auc:0.813956\n",
      "Stopping. Best iteration:\n",
      "[748]\teval-auc:0.813956\n",
      "\n",
      "fold 2 - 0.813955606319\n",
      "[0]\teval-auc:0.777693\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.81038\n",
      "[200]\teval-auc:0.814033\n",
      "[300]\teval-auc:0.815653\n",
      "[400]\teval-auc:0.816682\n",
      "[500]\teval-auc:0.817502\n",
      "[600]\teval-auc:0.817971\n",
      "[700]\teval-auc:0.818123\n",
      "[800]\teval-auc:0.818129\n",
      "Stopping. Best iteration:\n",
      "[788]\teval-auc:0.818129\n",
      "\n",
      "fold 3 - 0.818129398271\n",
      "[0]\teval-auc:0.774383\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.803702\n",
      "[200]\teval-auc:0.807512\n",
      "[300]\teval-auc:0.810396\n",
      "[400]\teval-auc:0.811747\n",
      "[500]\teval-auc:0.812515\n",
      "[600]\teval-auc:0.812824\n",
      "[700]\teval-auc:0.812898\n",
      "[800]\teval-auc:0.812991\n",
      "[900]\teval-auc:0.812999\n",
      "Stopping. Best iteration:\n",
      "[862]\teval-auc:0.812999\n",
      "\n",
      "fold 4 - 0.812999221406\n",
      "[0]\teval-auc:0.777396\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.808948\n",
      "[200]\teval-auc:0.812791\n",
      "[300]\teval-auc:0.815049\n",
      "[400]\teval-auc:0.816175\n",
      "[500]\teval-auc:0.81698\n",
      "[600]\teval-auc:0.817273\n",
      "[700]\teval-auc:0.817312\n",
      "[800]\teval-auc:0.817318\n",
      "Stopping. Best iteration:\n",
      "[757]\teval-auc:0.817318\n",
      "\n",
      "fold 5 - 0.817318261827\n",
      "[0]\teval-auc:0.777717\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.807654\n",
      "[200]\teval-auc:0.812426\n",
      "[300]\teval-auc:0.814801\n",
      "[400]\teval-auc:0.815555\n",
      "[500]\teval-auc:0.816325\n",
      "[600]\teval-auc:0.816763\n",
      "[700]\teval-auc:0.81685\n",
      "Stopping. Best iteration:\n",
      "[666]\teval-auc:0.81685\n",
      "\n",
      "fold 6 - 0.816850119502\n",
      "[0]\teval-auc:0.785066\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.814997\n",
      "[200]\teval-auc:0.81903\n",
      "[300]\teval-auc:0.821257\n",
      "[400]\teval-auc:0.822245\n",
      "[500]\teval-auc:0.822807\n",
      "[600]\teval-auc:0.822861\n",
      "[700]\teval-auc:0.822877\n",
      "[800]\teval-auc:0.822884\n",
      "[900]\teval-auc:0.822875\n",
      "Stopping. Best iteration:\n",
      "[806]\teval-auc:0.82289\n",
      "\n",
      "fold 7 - 0.822889777389\n",
      "[0]\teval-auc:0.777896\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.806396\n",
      "[200]\teval-auc:0.812114\n",
      "[300]\teval-auc:0.814418\n",
      "[400]\teval-auc:0.815853\n",
      "[500]\teval-auc:0.817017\n",
      "[600]\teval-auc:0.81729\n",
      "[700]\teval-auc:0.817391\n",
      "[800]\teval-auc:0.817392\n",
      "Stopping. Best iteration:\n",
      "[714]\teval-auc:0.817392\n",
      "\n",
      "fold 8 - 0.817391686821\n",
      "[0]\teval-auc:0.777593\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.808072\n",
      "[200]\teval-auc:0.812491\n",
      "[300]\teval-auc:0.81515\n",
      "[400]\teval-auc:0.815961\n",
      "[500]\teval-auc:0.816571\n",
      "[600]\teval-auc:0.816738\n",
      "[700]\teval-auc:0.816786\n",
      "Stopping. Best iteration:\n",
      "[647]\teval-auc:0.81679\n",
      "\n",
      "fold 9 - 0.816789580323\n",
      "cv score - on train:\n",
      "0.8171513108830221\n",
      "('current score in fold:', 0.8171057665575074, 29)\n",
      "[0]\teval-auc:0.779017\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.806806\n",
      "[200]\teval-auc:0.812537\n",
      "[300]\teval-auc:0.813924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\teval-auc:0.814773\n",
      "[500]\teval-auc:0.815414\n",
      "[600]\teval-auc:0.81552\n",
      "[700]\teval-auc:0.815536\n",
      "Stopping. Best iteration:\n",
      "[675]\teval-auc:0.815536\n",
      "\n",
      "fold 0 - 0.815535631327\n",
      "[0]\teval-auc:0.764245\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.7972\n",
      "[200]\teval-auc:0.80103\n",
      "[300]\teval-auc:0.804431\n",
      "[400]\teval-auc:0.805605\n",
      "[500]\teval-auc:0.806535\n",
      "[600]\teval-auc:0.806845\n",
      "[700]\teval-auc:0.806888\n",
      "Stopping. Best iteration:\n",
      "[633]\teval-auc:0.806908\n",
      "\n",
      "fold 1 - 0.806907815766\n",
      "[0]\teval-auc:0.784907\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.814829\n",
      "[200]\teval-auc:0.817836\n",
      "[300]\teval-auc:0.81959\n",
      "[400]\teval-auc:0.82048\n",
      "[500]\teval-auc:0.821159\n",
      "[600]\teval-auc:0.82131\n",
      "[700]\teval-auc:0.821356\n",
      "[800]\teval-auc:0.821364\n",
      "Stopping. Best iteration:\n",
      "[799]\teval-auc:0.821364\n",
      "\n",
      "fold 2 - 0.821364442666\n",
      "[0]\teval-auc:0.77925\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.808873\n",
      "[200]\teval-auc:0.813207\n",
      "[300]\teval-auc:0.815909\n",
      "[400]\teval-auc:0.816509\n",
      "[500]\teval-auc:0.817233\n",
      "[600]\teval-auc:0.817642\n",
      "[700]\teval-auc:0.817749\n",
      "[800]\teval-auc:0.817746\n",
      "Stopping. Best iteration:\n",
      "[717]\teval-auc:0.81775\n",
      "\n",
      "fold 3 - 0.817749653746\n",
      "[0]\teval-auc:0.772935\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.806918\n",
      "[200]\teval-auc:0.80984\n",
      "[300]\teval-auc:0.811841\n",
      "[400]\teval-auc:0.813054\n",
      "[500]\teval-auc:0.813639\n",
      "[600]\teval-auc:0.813839\n",
      "[700]\teval-auc:0.813926\n",
      "Stopping. Best iteration:\n",
      "[627]\teval-auc:0.813936\n",
      "\n",
      "fold 4 - 0.813935903199\n",
      "[0]\teval-auc:0.780772\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.807514\n",
      "[200]\teval-auc:0.812317\n",
      "[300]\teval-auc:0.813928\n",
      "[400]\teval-auc:0.815489\n",
      "[500]\teval-auc:0.816394\n",
      "[600]\teval-auc:0.816776\n",
      "[700]\teval-auc:0.816805\n",
      "Stopping. Best iteration:\n",
      "[636]\teval-auc:0.816817\n",
      "\n",
      "fold 5 - 0.816817062189\n",
      "[0]\teval-auc:0.778993\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.807321\n",
      "[200]\teval-auc:0.812576\n",
      "[300]\teval-auc:0.815474\n",
      "[400]\teval-auc:0.816528\n",
      "[500]\teval-auc:0.817122\n",
      "[600]\teval-auc:0.817372\n",
      "[700]\teval-auc:0.817457\n",
      "[800]\teval-auc:0.817465\n",
      "[900]\teval-auc:0.817479\n",
      "[1000]\teval-auc:0.817482\n",
      "Stopping. Best iteration:\n",
      "[928]\teval-auc:0.817482\n",
      "\n",
      "fold 6 - 0.81748206444\n",
      "[0]\teval-auc:0.781532\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.812322\n",
      "[200]\teval-auc:0.816901\n",
      "[300]\teval-auc:0.819201\n",
      "[400]\teval-auc:0.820183\n",
      "[500]\teval-auc:0.820774\n",
      "[600]\teval-auc:0.820826\n",
      "Stopping. Best iteration:\n",
      "[547]\teval-auc:0.820859\n",
      "\n",
      "fold 7 - 0.820858554309\n",
      "[0]\teval-auc:0.776861\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.810048\n",
      "[200]\teval-auc:0.812879\n",
      "[300]\teval-auc:0.815467\n",
      "[400]\teval-auc:0.816492\n",
      "[500]\teval-auc:0.817448\n",
      "[600]\teval-auc:0.817717\n",
      "[700]\teval-auc:0.817758\n",
      "Stopping. Best iteration:\n",
      "[654]\teval-auc:0.817767\n",
      "\n",
      "fold 8 - 0.817767115249\n",
      "[0]\teval-auc:0.784462\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.812629\n",
      "[200]\teval-auc:0.817483\n",
      "[300]\teval-auc:0.819412\n",
      "[400]\teval-auc:0.820839\n",
      "[500]\teval-auc:0.821592\n",
      "[600]\teval-auc:0.821844\n",
      "[700]\teval-auc:0.821948\n",
      "[800]\teval-auc:0.821972\n",
      "[900]\teval-auc:0.821983\n",
      "[1000]\teval-auc:0.822004\n",
      "[1100]\teval-auc:0.82203\n",
      "[1200]\teval-auc:0.822043\n",
      "Stopping. Best iteration:\n",
      "[1170]\teval-auc:0.822043\n",
      "\n",
      "fold 9 - 0.822042998538\n",
      "cv score - on train:\n",
      "0.8169279763178713\n",
      "('current score in fold:', 0.8171032444276686, 30)\n",
      "[0]\teval-auc:0.772918\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.805951\n",
      "[200]\teval-auc:0.810122\n",
      "[300]\teval-auc:0.812932\n",
      "[400]\teval-auc:0.813838\n",
      "[500]\teval-auc:0.814382\n",
      "[600]\teval-auc:0.814706\n",
      "[700]\teval-auc:0.814785\n",
      "Stopping. Best iteration:\n",
      "[658]\teval-auc:0.814786\n",
      "\n",
      "fold 0 - 0.814785580684\n",
      "[0]\teval-auc:0.771004\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.799704\n",
      "[200]\teval-auc:0.806037\n",
      "[300]\teval-auc:0.808492\n",
      "[400]\teval-auc:0.809661\n",
      "[500]\teval-auc:0.810619\n",
      "[600]\teval-auc:0.810941\n",
      "[700]\teval-auc:0.811003\n",
      "[800]\teval-auc:0.811018\n",
      "Stopping. Best iteration:\n",
      "[757]\teval-auc:0.811018\n",
      "\n",
      "fold 1 - 0.811018267101\n",
      "[0]\teval-auc:0.782455\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.812854\n",
      "[200]\teval-auc:0.817321\n",
      "[300]\teval-auc:0.819667\n",
      "[400]\teval-auc:0.82083\n",
      "[500]\teval-auc:0.82158\n",
      "[600]\teval-auc:0.821694\n",
      "[700]\teval-auc:0.821707\n",
      "[800]\teval-auc:0.82172\n",
      "Stopping. Best iteration:\n",
      "[725]\teval-auc:0.82172\n",
      "\n",
      "fold 2 - 0.821719504866\n",
      "[0]\teval-auc:0.774486\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.80163\n",
      "[200]\teval-auc:0.806801\n",
      "[300]\teval-auc:0.808656\n",
      "[400]\teval-auc:0.810127\n",
      "[500]\teval-auc:0.810853\n",
      "[600]\teval-auc:0.811242\n",
      "[700]\teval-auc:0.811352\n",
      "[800]\teval-auc:0.811372\n",
      "Stopping. Best iteration:\n",
      "[743]\teval-auc:0.811372\n",
      "\n",
      "fold 3 - 0.811371576962\n",
      "[0]\teval-auc:0.777274\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.808562\n",
      "[200]\teval-auc:0.813428\n",
      "[300]\teval-auc:0.815123\n",
      "[400]\teval-auc:0.816558\n",
      "[500]\teval-auc:0.817242\n",
      "[600]\teval-auc:0.817455\n",
      "[700]\teval-auc:0.817491\n",
      "[800]\teval-auc:0.817511\n",
      "[900]\teval-auc:0.817528\n",
      "Stopping. Best iteration:\n",
      "[855]\teval-auc:0.817528\n",
      "\n",
      "fold 4 - 0.817528175284\n",
      "[0]\teval-auc:0.781774\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.814759\n",
      "[200]\teval-auc:0.817439\n",
      "[300]\teval-auc:0.819879\n",
      "[400]\teval-auc:0.820541\n",
      "[500]\teval-auc:0.82136\n",
      "[600]\teval-auc:0.821485\n",
      "[700]\teval-auc:0.821556\n",
      "[800]\teval-auc:0.821574\n",
      "[900]\teval-auc:0.821574\n",
      "[1000]\teval-auc:0.821586\n",
      "Stopping. Best iteration:\n",
      "[956]\teval-auc:0.821586\n",
      "\n",
      "fold 5 - 0.821585777355\n",
      "[0]\teval-auc:0.787736\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.81269\n",
      "[200]\teval-auc:0.817701\n",
      "[300]\teval-auc:0.820059\n",
      "[400]\teval-auc:0.821302\n",
      "[500]\teval-auc:0.822164\n",
      "[600]\teval-auc:0.82248\n",
      "[700]\teval-auc:0.822563\n",
      "[800]\teval-auc:0.822584\n",
      "[900]\teval-auc:0.822589\n",
      "Stopping. Best iteration:\n",
      "[884]\teval-auc:0.822589\n",
      "\n",
      "fold 6 - 0.822588478278\n",
      "[0]\teval-auc:0.778717\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.80961\n",
      "[200]\teval-auc:0.813383\n",
      "[300]\teval-auc:0.815142\n",
      "[400]\teval-auc:0.81661\n",
      "[500]\teval-auc:0.81763\n",
      "[600]\teval-auc:0.817929\n",
      "[700]\teval-auc:0.818009\n",
      "[800]\teval-auc:0.818018\n",
      "[900]\teval-auc:0.818045\n",
      "Stopping. Best iteration:\n",
      "[866]\teval-auc:0.818045\n",
      "\n",
      "fold 7 - 0.81804513938\n",
      "[0]\teval-auc:0.778545\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.805483\n",
      "[200]\teval-auc:0.811041\n",
      "[300]\teval-auc:0.812633\n",
      "[400]\teval-auc:0.81396\n",
      "[500]\teval-auc:0.814817\n",
      "[600]\teval-auc:0.814885\n",
      "[700]\teval-auc:0.814935\n",
      "Stopping. Best iteration:\n",
      "[691]\teval-auc:0.814935\n",
      "\n",
      "fold 8 - 0.814934872243\n",
      "[0]\teval-auc:0.779903\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.808508\n",
      "[200]\teval-auc:0.813311\n",
      "[300]\teval-auc:0.816043\n",
      "[400]\teval-auc:0.817233\n",
      "[500]\teval-auc:0.817707\n",
      "[600]\teval-auc:0.817989\n",
      "[700]\teval-auc:0.818066\n",
      "[800]\teval-auc:0.818093\n",
      "Stopping. Best iteration:\n",
      "[709]\teval-auc:0.818093\n",
      "\n",
      "fold 9 - 0.818092516009\n",
      "cv score - on train:\n",
      "0.8170856015598147\n",
      "('current score in fold:', 0.8171062017440679, 31)\n",
      "[0]\teval-auc:0.782004\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.81135\n",
      "[200]\teval-auc:0.814426\n",
      "[300]\teval-auc:0.815998\n",
      "[400]\teval-auc:0.81769\n",
      "[500]\teval-auc:0.818418\n",
      "[600]\teval-auc:0.818618\n",
      "[700]\teval-auc:0.818653\n",
      "[800]\teval-auc:0.818655\n",
      "Stopping. Best iteration:\n",
      "[742]\teval-auc:0.818655\n",
      "\n",
      "fold 0 - 0.818655292082\n",
      "[0]\teval-auc:0.78172\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.810643\n",
      "[200]\teval-auc:0.815213\n",
      "[300]\teval-auc:0.817034\n",
      "[400]\teval-auc:0.81764\n",
      "[500]\teval-auc:0.81807\n",
      "[600]\teval-auc:0.818201\n",
      "[700]\teval-auc:0.818283\n",
      "[800]\teval-auc:0.81829\n",
      "[900]\teval-auc:0.818327\n",
      "[1000]\teval-auc:0.818335\n",
      "Stopping. Best iteration:\n",
      "[995]\teval-auc:0.818335\n",
      "\n",
      "fold 1 - 0.818334699659\n",
      "[0]\teval-auc:0.777213\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.807946\n",
      "[200]\teval-auc:0.812324\n",
      "[300]\teval-auc:0.81469\n",
      "[400]\teval-auc:0.815537\n",
      "[500]\teval-auc:0.816158\n",
      "[600]\teval-auc:0.816246\n",
      "[700]\teval-auc:0.81629\n",
      "[800]\teval-auc:0.816297\n",
      "[900]\teval-auc:0.816301\n",
      "Stopping. Best iteration:\n",
      "[826]\teval-auc:0.816301\n",
      "\n",
      "fold 2 - 0.816300840409\n",
      "[0]\teval-auc:0.779298\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.810065\n",
      "[200]\teval-auc:0.813772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\teval-auc:0.81612\n",
      "[400]\teval-auc:0.817337\n",
      "[500]\teval-auc:0.818003\n",
      "[600]\teval-auc:0.818222\n",
      "[700]\teval-auc:0.818297\n",
      "Stopping. Best iteration:\n",
      "[662]\teval-auc:0.818299\n",
      "\n",
      "fold 3 - 0.818298812341\n",
      "[0]\teval-auc:0.776446\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.803283\n",
      "[200]\teval-auc:0.809169\n",
      "[300]\teval-auc:0.811983\n",
      "[400]\teval-auc:0.812998\n",
      "[500]\teval-auc:0.814013\n",
      "[600]\teval-auc:0.81442\n",
      "[700]\teval-auc:0.81452\n",
      "[800]\teval-auc:0.814551\n",
      "[900]\teval-auc:0.814575\n",
      "[1000]\teval-auc:0.814587\n",
      "[1100]\teval-auc:0.8146\n",
      "[1200]\teval-auc:0.814608\n",
      "Stopping. Best iteration:\n",
      "[1114]\teval-auc:0.814608\n",
      "\n",
      "fold 4 - 0.814607597253\n",
      "[0]\teval-auc:0.781795\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.812163\n",
      "[200]\teval-auc:0.815318\n",
      "[300]\teval-auc:0.817653\n",
      "[400]\teval-auc:0.819133\n",
      "[500]\teval-auc:0.820139\n",
      "[600]\teval-auc:0.820549\n",
      "[700]\teval-auc:0.820658\n",
      "Stopping. Best iteration:\n",
      "[644]\teval-auc:0.820659\n",
      "\n",
      "fold 5 - 0.820658751857\n",
      "[0]\teval-auc:0.781372\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.80936\n",
      "[200]\teval-auc:0.815262\n",
      "[300]\teval-auc:0.817305\n",
      "[400]\teval-auc:0.818487\n",
      "[500]\teval-auc:0.819328\n",
      "[600]\teval-auc:0.819501\n",
      "[700]\teval-auc:0.819519\n",
      "Stopping. Best iteration:\n",
      "[623]\teval-auc:0.819544\n",
      "\n",
      "fold 6 - 0.819543617684\n",
      "[0]\teval-auc:0.778395\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.807937\n",
      "[200]\teval-auc:0.811358\n",
      "[300]\teval-auc:0.813584\n",
      "[400]\teval-auc:0.814201\n",
      "[500]\teval-auc:0.814581\n",
      "[600]\teval-auc:0.814649\n",
      "Stopping. Best iteration:\n",
      "[549]\teval-auc:0.814657\n",
      "\n",
      "fold 7 - 0.814656755468\n",
      "[0]\teval-auc:0.770103\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.803812\n",
      "[200]\teval-auc:0.807057\n",
      "[300]\teval-auc:0.809362\n",
      "[400]\teval-auc:0.81077\n",
      "[500]\teval-auc:0.811646\n",
      "[600]\teval-auc:0.812003\n",
      "[700]\teval-auc:0.812113\n",
      "[800]\teval-auc:0.81212\n",
      "Stopping. Best iteration:\n",
      "[714]\teval-auc:0.81212\n",
      "\n",
      "fold 8 - 0.812120053404\n",
      "[0]\teval-auc:0.776442\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.807747\n",
      "[200]\teval-auc:0.812691\n",
      "[300]\teval-auc:0.814523\n",
      "[400]\teval-auc:0.816177\n",
      "[500]\teval-auc:0.816995\n",
      "[600]\teval-auc:0.81727\n",
      "[700]\teval-auc:0.817378\n",
      "[800]\teval-auc:0.817408\n",
      "[900]\teval-auc:0.817418\n",
      "Stopping. Best iteration:\n",
      "[879]\teval-auc:0.817418\n",
      "\n",
      "fold 9 - 0.817418239968\n",
      "cv score - on train:\n",
      "0.817026327910551\n",
      "('current score in fold:', 0.8171105855290536, 32)\n"
     ]
    }
   ],
   "source": [
    "final_cv_train_xgbst = np.zeros(len(labels_train))\n",
    "final_cv_pred_xgbst = np.zeros(len( test_ids ))\n",
    "\n",
    "NFOLDS = 10\n",
    "\n",
    "M = 32\n",
    "x_score_xgbst = []\n",
    "dtest = xgb.DMatrix( new_test )\n",
    "fold_scores_xgb = []\n",
    "for s in range( M ):\n",
    "    \n",
    "    params['seed'] = 2*s\n",
    "    \n",
    "    cv_train = np.zeros( len( labels_train ))\n",
    "    cv_pred = np.zeros( len( test_ids ) )\n",
    "    kfold = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=2*s)\n",
    "    kf  = kfold.split(  new_train , labels_train )\n",
    "    \n",
    "    for i, (train_fold, validate) in enumerate(kf):\n",
    "        \n",
    "        X_train, X_validate, label_train, label_validate = new_train[train_fold, :], new_train[validate, :], labels_train[train_fold], labels_train[validate]\n",
    "\n",
    "        dtrain = xgb.DMatrix( X_train , label=label_train )\n",
    "        dvalid = xgb.DMatrix( X_validate , label = label_validate )\n",
    "        evallist = [ (dvalid, 'eval') ]\n",
    "        bst = xgb.train(params, dtrain, num_boost_round, evals =  evallist , early_stopping_rounds=100 , verbose_eval=100 )\n",
    "        #bst = lgb.train(params, dtrain , num_boost_round , valid_sets=[dvalid ] , verbose_eval = 100 , early_stopping_rounds = 100 )\n",
    "    #best_trees.append(bst.best_iteration)    \n",
    "        #cv_pred +=  bst.predict(  new_test , num_iteration = bst.best_iteration )\n",
    "        \n",
    "        cv_pred += bst.predict( dtest, ntree_limit=bst.best_ntree_limit )\n",
    "    #cv_eval_total += bst.predict( x_val , num_iteration = bst.best_iteration )          \n",
    "        cv_train[validate] += bst.predict( dvalid , ntree_limit=bst.best_ntree_limit )\n",
    "        score = roc_auc_score( label_validate , cv_train[validate] )\n",
    "        fold_scores_xgb.append( score )\n",
    "        print( \"fold {} - {}\".format(i , score ))\n",
    "    \n",
    "    cv_pred /= NFOLDS\n",
    "    \n",
    "    final_cv_train_xgbst += cv_train\n",
    "    final_cv_pred_xgbst += cv_pred\n",
    "    \n",
    "    print(\"cv score - on train:\")\n",
    "    print( roc_auc_score(labels_train, cv_train))\n",
    "    print( \"current score in fold:\", roc_auc_score( labels_train , final_cv_train_xgbst / (s + 1.)), s+1)\n",
    "    \n",
    "    x_score_xgbst.append(roc_auc_score( labels_train , cv_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8169864005722789"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array( x_score_xgbst).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.968120993222278e-05"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array( x_score_xgbst)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist( x_score_xgbst )\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_xgb = final_cv_pred_xgbst/M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03161012, 0.11100603, 0.01604727, ..., 0.01432699, 0.03582011,\n",
       "       0.2561009 ])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final_cv_pred/M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train = final_cv_train_xgbst/M\n",
    "final_train_lgb = final_cv_train/M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pos = final_train[ labels_train == 1  ]\n",
    "final_neg = final_train[labels_train == 0 ]\n",
    "final_pos_lgb = final_train_lgb[ labels_train == 1  ]\n",
    "final_neg_lgb = final_train_lgb[labels_train == 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8177096477679208\n"
     ]
    }
   ],
   "source": [
    "print( np.array( x_score).mean() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8177907443613184"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score( labels_train , final_cv_train/M ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = len(final_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = len(final_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mean = ( final_xgb +  final_pred_lgb)/2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAFzNJREFUeJzt3Xt0VeWZx/HvE0CCiqKYUsrFxArKLYQhRVjIICIOyzpVCgh4GSwWdNA11Cmu0sJ0CraFzgitC9GBCoKtCCJSHW8zFO1YpgomFYkBGcHGGouYok5BKsPlmT9yCgFzODvnknPy5vdZ66zss8/e+zwvJ/z2m3dfjrk7IiLS9OVluwAREUkPBbqISCAU6CIigVCgi4gEQoEuIhIIBbqISCAU6CIigUgY6GaWb2abzex1M6s0s9mx+cvN7HdmtiX2KMl8uSIiEk/LCMscBC539/1m1grYaGbPxV67y90fz1x5IiISVcJA99pLSffHnraKPZK6vPS8887zwsLCZFYVEWm2ysvL/+juBYmWsyiX/ptZC6AcuBBY5O7fMrPlwCBqe/AbgBnufrCedacAUwC6du3a/5133mlIO0REmj0zK3f30kTLRToo6u5H3L0E6AwMMLPewLeBi4EvAecC34qz7hJ3L3X30oKChDsYERFJUoPOcnH3j4EXgZHuvttrHQQeAgZkokAREYkmylkuBWbWLjbdBhgBvGlmHWPzDLgWeCOThYqIyKlFOculI7AiNo6eBzzm7k+b2QtmVgAYsAW4LYN1ikgTcujQIaqrq/n000+zXUqTkp+fT+fOnWnVqlVS60c5y2Ur0K+e+Zcn9Y4iErzq6mratm1LYWEhtX/ESyLuzt69e6murqaoqCipbehKURFJu08//ZT27dsrzBvAzGjfvn1Kf9Uo0EUkIxTmDZfqv5kCXUQkEFEOioqIpKRwxjNp3V7VvC+ndXuhaDqBvnLc8enrV2evDhGRBli+fDllZWXcd999GX8vDbmIiARCgS4iQaqqquLiiy/mhhtuoEePHowZM4YDBw6wYcMG+vXrR58+fZg0aRIHD9begmrGjBn07NmT4uJipk+fHne711xzDQ8//DAAixcv5oYbbgDg1Vdfpbi4mJKSEu666y569+59bJ13332Xyy67jG7dujF79uyMtVmBLiLB2rFjB1OnTmX79u2cddZZLFiwgJtvvpnVq1dTUVHB4cOHeeCBB9i7dy/r1q2jsrKSrVu3MmvWrLjbXLJkCXPmzOHXv/418+fPZ+HChQB87WtfY/HixWzZsoUWLVqcsM7mzZtZu3YtW7duZc2aNZSVlWWkvQp0EQlWly5dGDx4MAA33ngjGzZsoKioiO7duwMwceJEXnrpJc4++2zy8/O55ZZbeOKJJzj99NPjbrNDhw7MmTOHYcOGMX/+fM4991w+/vhj9u3bx6BBgwC4/vrrT1hnxIgRtG/fnjZt2vDVr36VjRs3ZqS9CnQRCdbJ53W3a9eu3uVatmzJ5s2bGTNmDE8//TQjR4485XYrKipo3749f/jDH5KqI1Pn6Deds1xEpMnK1mmGv//973n55ZcZNGgQK1eupLS0lMWLF7Nz504uvPBCfvaznzF06FD279/PgQMHuOqqqxg8eDAXXHBB3G1u3ryZ5557jtdee42hQ4dy5ZVXUlRURNu2bdm0aROXXHIJq1atOmGd9evX8+GHH9KmTRt+8YtfsGzZsoy0Vz10EQnWRRddxKJFi+jRowcfffQRd955Jw899BBjx46lT58+5OXlcdttt7Fv3z6uvvpqiouLufTSS1mwYEG92zt48CCTJ09m2bJlfOELX2D+/PlMmjQJd2fp0qVMnjyZkpISPvnkE84+++xj6w0YMIDRo0dTXFzM6NGjKS1N+F0VSYn0jUXpUlpa6kkfDNB56CJNxvbt2+nRo0dWa6iqquLqq6/mjTca587e+/fv58wzzwRg3rx57N69m3vvvbfB26nv3y7qNxZpyEVEJA2eeeYZ5s6dy+HDhzn//PNZvnx5o9egQBeRIBUWFqbUO//BD37AmjVrTpg3duxYZs6cWe/y48aNY9y4cfW+1lgU6CIi9Zg5c2bc8M5VOigqIhIIBbqISCAU6CIigdAYuohk3so0HyzUqcv1Ug9dRKQR/OUc9UxSoIuIBCJhoJtZvpltNrPXzazSzGbH5heZ2SYz22lmq83stMyXKyISTVVVFT169GDy5Mn06tWLK6+8kj//+c/s2rWLkSNH0r9/f4YMGcKbb74JwK5duxg4cCB9+vRh1qxZp+xRr1u3juHDh+Pu7N69m+7du/P+++9z4MABrrvuOnr27MmoUaO45JJLTrhV7p133kmvXr0YPnw4NTU1aW9zlB76QeByd+8LlAAjzWwg8CPgx+5+IfARcEvaqxMRScFbb73F7bffTmVlJe3atWPt2rVMmTKFhQsXUl5ezj333MPUqVMBmDZtGtOmTaOiooLOnTufcrujRo2iY8eOLFq0iMmTJzN79mw+//nPc//993POOeewbds27r77bsrLy4+t88knn1BaWkplZSVDhw7NyBddJAx0r7U/9rRV7OHA5cDjsfkrgGvTXp2ISAqKioooKSkBoH///lRVVfGb3/yGsWPHUlJSwq233sru3bsBePnllxk7dizw2fuZ12fhwoXMnTuX1q1bM2HCBAA2btzI+PHjAejduzfFxcXHls/Lyzt2JemNN96YkXuiRzrLxcxaAOXAhcAiYBfwsbsfji1SDXSKs+4UYApA165dU61XRCSy1q1bH5tu0aIFe/bsoV27dmzZsiXlbVdXV5OXl8eePXs4evQoeXkNOySZiXuiRwp0dz8ClJhZO2AdcHHUN3D3JcASqL3bYjJFikgTlyOnGZ511lkUFRWxZs0axo4di7uzdetW+vbty8CBA1m7di3jxo37zP3MT3b48GEmTZrEo48+yooVK1iwYAHTp09n8ODBPPbYYwwbNoxt27ZRUVFxbJ2jR4/y+OOPM378eFauXMmll16a9vY1aJfi7h8DLwKDgHZm9pcdQmfgvTTXJiKSdo888ghLly6lb9++9OrViyeffBKAn/zkJyxYsIDi4mJ27tx5wv3MT/bDH/6QIUOGHLt3+oMPPsj27duZOnUqNTU19OzZk1mzZtGrV69j2znjjDPYvHkzvXv35oUXXuC73/1u2tuWsIduZgXAIXf/2MzaACOoPSD6IjAGWAVMBJ5Me3UiIkk6+W6L06dPPzb9/PPPf2b5Tp068corr2BmrFq1ih07dsTddt0wbtu27bEzZY4cOcLPf/5z8vPz2bVrF1dccQXnn38+UHu/9EyLMuTSEVgRG0fPAx5z96fNbBuwysy+D7wGLM1gnSIiGVVeXs4dd9yBu9OuXbukvibuwIEDDBs2jEOHDuHu3H///Zx2WuOd0Z0w0N19K9CvnvlvAwMyUZSISGMbMmQIr7/++gnzKioquOmmm06Y17p1azZt2lTvNtq2bUvS38qWBrqXi4hkhLtn7NvtG0ufPn3SckZMVKl+Jagu/ReRtMvPz2fv3r0pB1Rz4u7s3buX/Pz8pLehHrqIpF3nzp2prq7OyOXtIcvPz094leqpKNBFJO1atWpFUVFRtstodjTkIiISCAW6iEggFOgiIoFQoIuIBEKBLiISCAW6iEggFOgiIoFQoIuIBEKBLiISCAW6iEggFOgiIoFQoIuIBEKBLiISCAW6iEggFOgiIoFQoIuIBEKBLiISCAW6iEggEga6mXUxsxfNbJuZVZrZtNj875nZe2a2Jfa4KvPliohIPFG+U/Qw8E13/62ZtQXKzWx97LUfu/s9mStPRESiShjo7r4b2B2b3mdm24FOmS5MREQapkFj6GZWCPQDNsVm3WFmW81smZmdE2edKWZWZmZlNTU1KRUrIiLxRQ50MzsTWAt8w93/BDwAfBEoobYHP7++9dx9ibuXuntpQUFBGkoWEZH6RAp0M2tFbZg/4u5PALj7Hnc/4u5HgZ8CAzJXpoiIJBLlLBcDlgLb3X1Bnfkd6yw2Cngj/eWJiEhUUc5yGQzcBFSY2ZbYvO8AE8ysBHCgCrg1IxWKiEgkUc5y2QhYPS89m/5yREQkWbpSVEQkEAp0EZFAKNBFRAKhQBcRCYQCXUQkEAp0EZFAKNBFRAKhQBcRCYQCXUQkEAp0EZFAKNBFRAKhQBcRCYQCXUQkEAp0EZFAKNBFRAKhQBcRCYQCXUQkEAp0EZFAKNBFRAKhQBcRCYQCXUQkEAp0EZFAJAx0M+tiZi+a2TYzqzSzabH555rZejN7K/bznMyXKyIi8UTpoR8GvunuPYGBwO1m1hOYAWxw927AhthzERHJkoSB7u673f23sel9wHagE3ANsCK22Arg2kwVKSIiiTVoDN3MCoF+wCagg7vvjr30PtAhzjpTzKzMzMpqampSKFVERE4lcqCb2ZnAWuAb7v6nuq+5uwNe33ruvsTdS929tKCgIKViRUQkvkiBbmatqA3zR9z9idjsPWbWMfZ6R+CDzJQoIiJRRDnLxYClwHZ3X1DnpaeAibHpicCT6S9PRESiahlhmcHATUCFmW2JzfsOMA94zMxuAd4BrstMiSIiEkXCQHf3jYDFeXl4essREZFk6UpREZFAKNBFRAKhQBcRCYQCXUQkEAp0EZFAKNBFRAKhQBcRCYQCXUQkEAp0EZFAKNBFRAKhQBcRCYQCXUQkEAp0EZFAKNBFRAKhQBcRCYQCXUQkEAp0EZFAKNBFRAKhQBcRCYQCXUQkEAp0EZFAJAx0M1tmZh+Y2Rt15n3PzN4zsy2xx1WZLVNERBKJ0kNfDoysZ/6P3b0k9ng2vWWJiEhDJQx0d38J+LARahERkRS0TGHdO8zs74Ay4Jvu/lGaakps5bjj09evbrS3FRHJZckeFH0A+CJQAuwG5sdb0MymmFmZmZXV1NQk+XYiIpJIUoHu7nvc/Yi7HwV+Cgw4xbJL3L3U3UsLCgqSrVNERBJIKtDNrGOdp6OAN+ItKyIijSPhGLqZPQpcBpxnZtXAPwOXmVkJ4EAVcGsGaxQRkQgSBrq7T6hn9tIM1CIiIinQlaIiIoFQoIuIBEKBLiISCAW6iEggFOgiIoFQoIuIBEKBLiISCAW6iEggFOgiIoFQoIuIBCKV+6HnBt0bXUQEUA9dRCQYCnQRkUAo0EVEAqFAFxEJhAJdRCQQCnQRkUAo0EVEAqFAFxEJhAJdRCQQTf9K0bp01aiINGPqoYuIBCJhoJvZMjP7wMzeqDPvXDNbb2ZvxX6ek9kyRUQkkSg99OXAyJPmzQA2uHs3YEPsuYiIZFHCQHf3l4APT5p9DbAiNr0CuDbNdYmISAMlO4bewd13x6bfBzqkqR4REUlSygdF3d0Bj/e6mU0xszIzK6upqUn17UREJI5kA32PmXUEiP38IN6C7r7E3UvdvbSgoCDJtxMRkUSSDfSngImx6YnAk+kpR0REkhXltMVHgZeBi8ys2sxuAeYBI8zsLeCK2HMREcmihFeKuvuEOC8NT3MtIiKSAl0pKiISCAW6iEggFOgiIoFQoIuIBCKs2+fWpVvpikgzox66iEggFOgiIoFQoIuIBEKBLiISCAW6iEggFOgiIoFQoIuIBEKBLiISCAW6iEggwr1StC5dNSoizYB66CIigVCgi4gEQoEuIhIIBbqISCAU6CIigWgeZ7nUpTNeRCRQ6qGLiAQipR66mVUB+4AjwGF3L01HUSIi0nDpGHIZ5u5/TMN2Gl/d4RfQEIyINGkachERCUSqPXQH/tPMHFjs7kvSUFP26ICpiDRhqQb6pe7+npl9DlhvZm+6+0t1FzCzKcAUgK5du6b4do1I4S4iTUxKQy7u/l7s5wfAOmBAPcsscfdSdy8tKChI5e1EROQUku6hm9kZQJ6774tNXwnMSVtluUS9dRFpAlIZcukArDOzv2xnpbs/n5aqRESkwZIOdHd/G+ibxlpERCQFOm1RRCQQze9eLhH9cvueY9NX9Ohw/AWNp4tIjlKgRxA33EVEcogCvYFOCHf11kUkh2gMXUQkEM2+h163x53Kul+f8cyx6ap5X06pJhGRZAQV6PHCue64dyoBHlVhnHCPN19EJB2CCvR4GiPEH2z1r8emv37orqS3o9AXkWQ1i0DPproBHW9+vOCOt656/SJSH3P3Rnuz0tJSLysrS27lk7+MIqYxet+pSKW3ni7xdgDxljmZhpBEssvMyqN8I5x66M1AvBBv6DJR14/yF4d2ACLp1yR76LneK48nF3rruUjhLnJq6qHnoHQdOA1NMsNAIvJZCvQsUbiLSLo1mUBvqsMsUSjcRcJz8l+ejfEXZ5MJ9OZC4X6chmJEGkaBnsPqhns8zTH0dbaMSP0U6E1cvNBvLkGf67147XykMSnQA6WgT3xefToDNtXz+BNtUxd0SRQK9GZGwzjHZSKEk3nvKKEc5RYSdWkH0Dwp0OUzooT+yZrLTiAVDQ3lxnwvBX0YFOiSFur5i2RfSoFuZiOBe4EWwIPuPi8tVUmQGtrz1w6g8UQZr6/rVMs0595+NofxIIV7uZhZC+B/gBFANfAqMMHdt8VbJ5V7ufzyny5Laj0Jm0I/LKkcT8jETeGS2aHFk8qOLuq9XFIJ9EHA99z9b2LPvw3g7nPjraNAl6ZMOw9JRWMEeipDLp2Ad+s8rwYuSWF7IjktmYPFzZF2fLU++/sSwKX/ZjYFmBJ7ut/MdjRg9fOAP6a/qqxQW3JTKG3JoXb8V6obyKG2JG9E7Y/jbfm+pbK586MslEqgvwd0qfO8c2zeCdx9CbAkmTcws7Iof2Y0BWpLbgqlLaG0A9SWVOSlsO6rQDczKzKz04DxwFPpKUtERBoq6R66ux82szuA/6D2tMVl7l6ZtspERKRBUhpDd/dngWfTVEt9khqqyVFqS24KpS2htAPUlqQ16neKiohI5qQyhi4iIjkkJwLdzEaa2Q4z22lmM+p5vbWZrY69vsnMChu/ymgitOWvzey3ZnbYzMZko8YoIrTjH81sm5ltNbMNZhbptKpsiNCW28yswsy2mNlGM+uZjTqjSNSWOsuNNjM3s5w9WyTC53KzmdXEPpctZvb1bNQZRZTPxcyui/2fqTSzlRkpxN2z+qD2gOou4ALgNOB1oOdJy0wF/i02PR5Yne26U2hLIVAMPAyMyXbNKbRjGHB6bPrvm/hnclad6a8Az2e77mTbEluuLfAS8ApQmu26U/hcbgbuy3ataWpLN+A14JzY889lopZc6KEPAHa6+9vu/n/AKuCak5a5BlgRm34cGG5mKZ2lnyEJ2+LuVe6+FTiajQIjitKOF939QOzpK9Reh5CLorTlT3WengHk6oGlKP9XAO4GfgR82pjFNVDUtjQFUdoyGVjk7h8BuPsHmSgkFwK9vlsIdIq3jLsfBv4XaN8o1TVMlLY0BQ1txy3AcxmtKHmR2mJmt5vZLuBfgH9opNoaKmFbzOyvgC7unt3b/iUW9XdsdGxY73Ez61LP67kgSlu6A93N7L/N7JXYnWrTLhcCXZowM7sRKAWa9I1O3H2Ru38R+BYwK9v1JMPM8oAFwDezXUua/DtQ6O7FwHqO/5XeFLWkdtjlMmAC8FMza5fuN8mFQI9yC4Fjy5hZS+BsYG+jVNcwkW6H0AREaoeZXQHMBL7i7gcbqbaGauhnsgq4NqMVJS9RW9oCvYFfmVkVMBB4KkcPjCb8XNx9b53fqweB/o1UW0NF+R2rBp5y90Pu/jtqbz3eLe2V5MABhZbA20ARxw8o9Dppmds58aDoY9muO9m21Fl2Obl7UDTKZ9KP2gNB3bJdbxra0q3O9N8CZdmuO9Xfr9jyvyJ3D4pG+Vw61pkeBbyS7bpTaMtIYEVs+jxqh2jap72WbP9jxBp4FbV7rF3AzNi8OdT2/ADygTXATmAzcEG2a06hLV+idm/9CbV/ZVRmu+Yk2/FLYA+wJfZ4Kts1p9CWe4HKWDtePFVIZvuRqC0nLZuzgR7xc5kb+1xej30uF2e75hTaYtQOh20DKoDxmahDV4qKiAQiF8bQRUQkDRToIiKBUKCLiARCgS4iEggFuohIIBToIiKBUKCLiARCgS4iEoj/BxcD4OIXAg8SAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist( final_pos , density = True , bins = 100 , label = \"pos_xgb\" )\n",
    "plt.hist(  final_neg  , density = True , bins = 100 , alpha = 0.7 , label = \"neg_xgb\")\n",
    "#plt.hist( final_pos_lgb , density = True , bins = 100 , label = \"pos_lgb\" )\n",
    "#plt.hist(  final_neg_lgb , density = True , bins = 100 , alpha = 0.7 , label = \"neg_lgb\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAErJJREFUeJzt3W2MXudd5/Hvr3ZTutCStJmNsra7E1pLyK3Abb2pEQiVZkmcVKqDCFWCIKbKYtg6WtD2RV1ACts22mRXtCLaNLuBWHUQ4IQAiqEuxoSgqtLmYdq6SZ2QzTRNFVtpYuI8wFak6/DfF3O53Pia8dyeGc89M/l+pKM553+uc8516Z74N+fpTqoKSZIGvWbUHZAkLT2GgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqrR92BuTr33HNrfHx81N2QpGXlS1/60t9V1dhs7ZZtOIyPjzMxMTHqbkjSspLkm8O087KSJKljOEiSOoaDJKkzazgk+Z4kDyT5apJDSf5Lq1+Q5P4kk0nuSHJWq7+uLU+29eMD+/pYqz+W5JKB+pZWm0yyc+GHKUk6HcOcObwMvK+qfhjYCGxJshm4Efh0Vb0NeB64prW/Bni+1T/d2pFkA3Al8HZgC/CZJKuSrAJuBi4FNgBXtbaSpBGZNRxqyj+0xde2qYD3AXe1+m7g8ja/tS3T1l+UJK2+p6perqpvAJPAhW2arKonquo7wJ7WVpI0IkPdc2h/4R8EngUOAF8HXqiq463JYWBNm18DPAXQ1r8IvHmwftI2M9UlSSMyVDhU1StVtRFYy9Rf+j94Rns1gyTbk0wkmTh69OgouiBJrwqn9bRSVb0A3Av8CHB2khMv0a0FjrT5I8A6gLb++4HnBusnbTNTfbrj31pVm6pq09jYrC/4SZLmaNY3pJOMAf+vql5I8nrgJ5m6yXwvcAVT9wi2AXe3Tfa25f/d1v91VVWSvcAfJPkU8G+A9cADQID1SS5gKhSuBH524YbYG9/5uTO5+xk9ecP7R3JcSTpdw3x9xvnA7vZU0WuAO6vqz5M8AuxJ8kngK8Btrf1twO8lmQSOMfWPPVV1KMmdwCPAcWBHVb0CkORaYD+wCthVVYcWbISSpNM2azhU1UPAO6epP8HU/YeT6/8I/MwM+7oeuH6a+j5g3xD9lSQtAt+QliR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUmfWcEiyLsm9SR5JcijJr7T6byY5kuRgmy4b2OZjSSaTPJbkkoH6llabTLJzoH5Bkvtb/Y4kZy30QCVJwxvmzOE48JGq2gBsBnYk2dDWfbqqNrZpH0BbdyXwdmAL8Jkkq5KsAm4GLgU2AFcN7OfGtq+3Ac8D1yzQ+CRJczBrOFTV01X15Tb/98CjwJpTbLIV2FNVL1fVN4BJ4MI2TVbVE1X1HWAPsDVJgPcBd7XtdwOXz3VAkqT5O617DknGgXcC97fStUkeSrIryTmttgZ4amCzw602U/3NwAtVdfykuiRpRIYOhyTfB/wx8KtV9RJwC/BWYCPwNPBbZ6SH/7IP25NMJJk4evTomT6cJL1qDRUOSV7LVDD8flX9CUBVPVNVr1TVPwG/w9RlI4AjwLqBzde22kz154Czk6w+qd6pqluralNVbRobGxum65KkORjmaaUAtwGPVtWnBurnDzT7KeBrbX4vcGWS1yW5AFgPPAA8CKxvTyadxdRN671VVcC9wBVt+23A3fMbliRpPlbP3oQfBX4eeDjJwVb7NaaeNtoIFPAk8EsAVXUoyZ3AI0w96bSjql4BSHItsB9YBeyqqkNtfx8F9iT5JPAVpsJIkjQis4ZDVX0RyDSr9p1im+uB66ep75tuu6p6gn++LCVJGjHfkJYkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVJn1nBIsi7JvUkeSXIoya+0+puSHEjyePt5TqsnyU1JJpM8lORdA/va1to/nmTbQP3dSR5u29yUJGdisJKk4Qxz5nAc+EhVbQA2AzuSbAB2AvdU1XrgnrYMcCmwvk3bgVtgKkyA64D3ABcC150IlNbmFwe22zL/oUmS5mrWcKiqp6vqy23+74FHgTXAVmB3a7YbuLzNbwVuryn3AWcnOR+4BDhQVceq6nngALClrXtjVd1XVQXcPrAvSdIInNY9hyTjwDuB+4HzqurptupbwHltfg3w1MBmh1vtVPXD09SnO/72JBNJJo4ePXo6XZcknYahwyHJ9wF/DPxqVb00uK79xV8L3LdOVd1aVZuqatPY2NiZPpwkvWoNFQ5JXstUMPx+Vf1JKz/TLgnRfj7b6keAdQObr221U9XXTlOXJI3IME8rBbgNeLSqPjWwai9w4omjbcDdA/Wr21NLm4EX2+Wn/cDFSc5pN6IvBva3dS8l2dyOdfXAviRJI7B6iDY/Cvw88HCSg632a8ANwJ1JrgG+CXywrdsHXAZMAt8GPgRQVceSfAJ4sLX7eFUda/MfBj4LvB74fJskSSMyazhU1ReBmd47uGia9gXsmGFfu4Bd09QngHfM1hdJ0uLwDWlJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1Zg2HJLuSPJvkawO130xyJMnBNl02sO5jSSaTPJbkkoH6llabTLJzoH5Bkvtb/Y4kZy3kACVJp2+YM4fPAlumqX+6qja2aR9Akg3AlcDb2zafSbIqySrgZuBSYANwVWsLcGPb19uA54Fr5jMgSdL8zRoOVfUF4NiQ+9sK7Kmql6vqG8AkcGGbJqvqiar6DrAH2JokwPuAu9r2u4HLT3MMkqQFNp97Dtcmeahddjqn1dYATw20OdxqM9XfDLxQVcdPqk8ryfYkE0kmjh49Oo+uS5JOZa7hcAvwVmAj8DTwWwvWo1OoqluralNVbRobG1uMQ0rSq9LquWxUVc+cmE/yO8Cft8UjwLqBpmtbjRnqzwFnJ1ndzh4G20uSRmROZw5Jzh9Y/CngxJNMe4Erk7wuyQXAeuAB4EFgfXsy6SymblrvraoC7gWuaNtvA+6eS58kSQtn1jOHJH8IvBc4N8lh4DrgvUk2AgU8CfwSQFUdSnIn8AhwHNhRVa+0/VwL7AdWAbuq6lA7xEeBPUk+CXwFuG3BRidJmpNZw6GqrpqmPOM/4FV1PXD9NPV9wL5p6k8w9TSTJGmJ8A1pSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVJn1nBIsivJs0m+NlB7U5IDSR5vP89p9SS5KclkkoeSvGtgm22t/eNJtg3U353k4bbNTUmy0IOUJJ2eYc4cPgtsOam2E7inqtYD97RlgEuB9W3aDtwCU2ECXAe8B7gQuO5EoLQ2vziw3cnHkiQtslnDoaq+ABw7qbwV2N3mdwOXD9Rvryn3AWcnOR+4BDhQVceq6nngALClrXtjVd1XVQXcPrAvSdKIzPWew3lV9XSb/xZwXptfAzw10O5wq52qfniauiRphOZ9Q7r9xV8L0JdZJdmeZCLJxNGjRxfjkJL0qjTXcHimXRKi/Xy21Y8A6wbarW21U9XXTlOfVlXdWlWbqmrT2NjYHLsuSZrNXMNhL3DiiaNtwN0D9avbU0ubgRfb5af9wMVJzmk3oi8G9rd1LyXZ3J5SunpgX5KkEVk9W4Mkfwi8Fzg3yWGmnjq6AbgzyTXAN4EPtub7gMuASeDbwIcAqupYkk8AD7Z2H6+qEze5P8zUE1GvBz7fJknSCM0aDlV11QyrLpqmbQE7ZtjPLmDXNPUJ4B2z9UOStHh8Q1qS1DEcJEkdw0GS1DEcJEkdw0GS1Jn1aSUtnPGdnxvZsZ+84f0jO7ak5cczB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHXmFQ5JnkzycJKDSSZa7U1JDiR5vP08p9WT5KYkk0keSvKugf1sa+0fT7JtfkOSJM3XQpw5/ERVbayqTW15J3BPVa0H7mnLAJcC69u0HbgFpsIEuA54D3AhcN2JQJEkjcaZuKy0Fdjd5ncDlw/Ub68p9wFnJzkfuAQ4UFXHqup54ACw5Qz0S5I0pPmGQwF/meRLSba32nlV9XSb/xZwXptfAzw1sO3hVpupLkkakdXz3P7HqupIkn8NHEjyt4Mrq6qS1DyP8V0tgLYDvOUtb1mo3UqSTjKvM4eqOtJ+Pgv8KVP3DJ5pl4toP59tzY8A6wY2X9tqM9WnO96tVbWpqjaNjY3Np+uSpFOYczgk+d4kbzgxD1wMfA3YC5x44mgbcHeb3wtc3Z5a2gy82C4/7QcuTnJOuxF9catJkkZkPpeVzgP+NMmJ/fxBVf1FkgeBO5NcA3wT+GBrvw+4DJgEvg18CKCqjiX5BPBga/fxqjo2j35JkuZpzuFQVU8APzxN/TngomnqBeyYYV+7gF1z7YskaWH5hrQkqTPfp5W0TIzv/NxIjvvkDe8fyXElzY9nDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjm9I64wa1ZvZ4NvZ0nx45iBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6vieg1Ys/+930tx55iBJ6hgOkqSO4SBJ6hgOkqSON6SlBeaXDWol8MxBktRZMmcOSbYAvw2sAn63qm4YcZekZcfHd7VQlkQ4JFkF3Az8JHAYeDDJ3qp6ZLQ9kzQMQ2nlWRLhAFwITFbVEwBJ9gBbAcNB0oy8v3PmLJVwWAM8NbB8GHjPiPoiSbNa6WdLSyUchpJkO7C9Lf5DksdOY/Nzgb9b+F4tCSt1bCt1XODYlqMlMa7cOO9d/NthGi2VcDgCrBtYXttq/0JV3QrcOpcDJJmoqk1z697StlLHtlLHBY5tOVqp45rJUnmU9UFgfZILkpwFXAnsHXGfJOlVa0mcOVTV8STXAvuZepR1V1UdGnG3JOlVa0mEA0BV7QP2ncFDzOly1DKxUse2UscFjm05WqnjmlaqatR9kCQtMUvlnoMkaQlZceGQZEuSx5JMJtk5zfrXJbmjrb8/yfji93Juhhjbjyf5cpLjSa4YRR/nYohx/eckjyR5KMk9SYZ6FG8pGGJsv5zk4SQHk3wxyYZR9PN0zTaugXY/naSSLJunfIb4zH4hydH2mR1M8h9G0c8zrqpWzMTUzeyvAz8AnAV8FdhwUpsPA/+zzV8J3DHqfi/g2MaBHwJuB64YdZ8XcFw/AfyrNv8fV9hn9saB+Q8AfzHqfi/EuFq7NwBfAO4DNo263wv4mf0C8D9G3dczPa20M4fvfg1HVX0HOPE1HIO2Arvb/F3ARUmyiH2cq1nHVlVPVtVDwD+NooNzNMy47q2qb7fF+5h6D2Y5GGZsLw0sfi+wHG4CDvPfGcAngBuBf1zMzs3TsGNb8VZaOEz3NRxrZmpTVceBF4E3L0rv5meYsS1Hpzuua4DPn9EeLZyhxpZkR5KvA/8N+E+L1Lf5mHVcSd4FrKuq0X350dwM+/v40+0y511J1k2zftlbaeGgFSzJzwGbgP8+6r4spKq6uareCnwU+I1R92e+krwG+BTwkVH35Qz5M2C8qn4IOMA/X4lYUVZaOAzzNRzfbZNkNfD9wHOL0rv5GeorRpahocaV5N8Dvw58oKpeXqS+zdfpfmZ7gMvPaI8WxmzjegPwDuBvkjwJbAb2LpOb0rN+ZlX13MDv4O8C716kvi2qlRYOw3wNx15gW5u/AvjraneZlriV+hUjs44ryTuB/8VUMDw7gj7O1TBjWz+w+H7g8UXs31ydclxV9WJVnVtV41U1ztR9og9U1cRountahvnMzh9Y/ADw6CL2b/GM+o74Qk/AZcD/YeqJg19vtY8z9csJ8D3AHwGTwAPAD4y6zws4tn/H1DXS/8vU2dChUfd5gcb1V8AzwME27R11nxdwbL8NHGrjuhd4+6j7vBDjOqnt37BMnlYa8jP7r+0z+2r7zH5w1H0+E5NvSEuSOivtspIkaQEYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkzv8HTEVW0fESf9kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.hist( final_xgb)\n",
    "#plt.hist( final_mean )\n",
    "plt.hist( final_pred_lgb )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511,)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_logi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8169483052586347,\n",
       " 0.8190930615893933,\n",
       " 0.8182237024787657,\n",
       " 0.8180733051241529,\n",
       " 0.816361926066463,\n",
       " 0.8186181301271797,\n",
       " 0.8174379841161038,\n",
       " 0.8168223110545245,\n",
       " 0.816578728843284,\n",
       " 0.8182051318826529,\n",
       " 0.8168356163064975,\n",
       " 0.8175523110027269,\n",
       " 0.8172393537268681,\n",
       " 0.8182943858105127,\n",
       " 0.8162965355095738,\n",
       " 0.8186261278558308]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist( x_score_xgb )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001428089557675824"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array( x_score_xgb ).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0008594220828512764"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array( x_score ).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': final_mean }).to_csv('../data/pred_mean_oof.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot feature importances...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Plot feature importances...')\n",
    "ax = lgb.plot_importance( bst , max_num_features=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
