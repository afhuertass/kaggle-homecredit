{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from  sklearn.preprocessing import LabelEncoder\n",
    "from  sklearn.preprocessing import OneHotEncoder\n",
    "import scipy \n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "\n",
    "from __future__ import division\n",
    "from scipy.special import erfinv\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import xgboost as xgb\n",
    "from rgf.sklearn import RGFClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 269)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"../data/train_woe.csv\")\n",
    "df_test = pd.read_csv(\"../data/test_woe.csv\")\n",
    "#df_train = pd.read_csv(\"../data/sparse/train_good.csv\")\n",
    "#df_test = pd.read_csv(\"../data/sparse/test_good.csv\")\n",
    "df_labels = pd.read_csv(\"../data/labels_train.csv\" , header = None )[1]\n",
    "test_ids = pd.read_csv(\"../data/ids_test.csv\" , header = None)[1].values\n",
    "test_ids\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'NAME_INCOME_TYPE', u'EMERGENCYSTATE_MODE', u'OCCUPATION_TYPE',\n",
       "       u'NAME_TYPE_SUITE', u'FONDKAPREMONT_MODE', u'FLAG_OWN_CAR',\n",
       "       u'WEEKDAY_APPR_PROCESS_START', u'CODE_GENDER', u'FLAG_OWN_REALTY',\n",
       "       u'NAME_FAMILY_STATUS', u'NAME_CONTRACT_TYPE', u'NAME_HOUSING_TYPE',\n",
       "       u'NAME_EDUCATION_TYPE', u'WALLSMATERIAL_MODE', u'HOUSETYPE_MODE',\n",
       "       u'ORGANIZATION_TYPE', u'LAST(prev.NAME_YIELD_GROUP)',\n",
       "       u'LAST(prev.FLAG_LAST_APPL_PER_CONTRACT)',\n",
       "       u'LAST(pos.NAME_CONTRACT_STATUS)', u'LAST(prev.CODE_REJECT_REASON)',\n",
       "       u'LAST(prev.NAME_PRODUCT_TYPE)', u'LAST(prev.NAME_CLIENT_TYPE)',\n",
       "       u'LAST(prev.NAME_PORTFOLIO)', u'LAST(prev.NAME_CASH_LOAN_PURPOSE)',\n",
       "       u'LAST(prev.WEEKDAY_APPR_PROCESS_START)',\n",
       "       u'LAST(prev.NAME_CONTRACT_STATUS)', u'LAST(prev.NAME_GOODS_CATEGORY)',\n",
       "       u'LAST(bureau.CREDIT_CURRENCY)', u'LAST(prev.NAME_SELLER_INDUSTRY)',\n",
       "       u'LAST(bureau.CREDIT_ACTIVE)', u'LAST(prev.NAME_TYPE_SUITE)',\n",
       "       u'LAST(card.NAME_CONTRACT_STATUS)', u'LAST(bureau.CREDIT_TYPE)',\n",
       "       u'LAST(prev.NAME_PAYMENT_TYPE)', u'LAST(prev.CHANNEL_TYPE)',\n",
       "       u'LAST(prev.PRODUCT_COMBINATION)', u'LAST(prev.NAME_CONTRACT_TYPE)',\n",
       "       u'FLAG_PHONE', u'FLAG_WORK_PHONE', u'FLAG_EMP_PHONE', u'FLAG_EMAIL',\n",
       "       u'FLAG_CONT_MOBILE', u'FLAG_MOBIL'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns[:43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48744,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns = range( df_train.shape[1] )\n",
    "df_test.columns = range( df_test.shape[1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.752614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.564990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2626</td>\n",
       "      <td>2</td>\n",
       "      <td>0.525734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.202145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       43  44        45\n",
       "0  0.0000   2  0.752614\n",
       "1  0.0000   2  0.564990\n",
       "2  0.0000   2  0.000000\n",
       "3  0.2626   2  0.525734\n",
       "4  0.0000   2  0.202145"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.loc[ : , 43:45].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_data_indx = df_labels[ df_labels == 1 ]\n",
    "positive_data = df_train.iloc[ positive_data_indx.index ]\n",
    "#print( positive_data.shape )\n",
    "negative_data_indx = df_labels[  df_labels == 0 ]\n",
    "negative_data = df_train.iloc[  negative_data_indx.index ]\n",
    "#print( negative_data.shape )\n",
    "positive_ratio = float(len(positive_data)) / len(df_train)\n",
    "positive_ratio\n",
    "\n",
    "positive_data = None\n",
    "negative_data = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "num_leaves = 15\n",
    "min_data_in_leaf = 2000\n",
    "feature_fraction = 0.05\n",
    "num_boost_round = 10000\n",
    "ncat = 43\n",
    "params = {\"objective\": \"binary\",\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"learning_rate\": learning_rate,\n",
    "          \"metric\":[\"auc\" ,\"binary_logloss\"] , \n",
    "          \"num_leaves\": num_leaves,\n",
    "           \"max_bin\": 256,\n",
    "          \"feature_fraction\": feature_fraction,\n",
    "          \"verbosity\": 1,\n",
    "          \"drop_rate\": 0.1,\n",
    "          \"is_unbalance\": False,\n",
    "          \"max_drop\": 50,\n",
    "          \"min_child_samples\": 20,\n",
    "          \"min_child_weight\": 150,\n",
    "          \"min_split_gain\": 0.5,\n",
    "          \"max_depth\": -1,  \n",
    "          \"reg_alpha\" : 10 , \n",
    "          \"reg_lambda\": 10 , \n",
    "          \"min_gain_to_split\" : 0.5 ,\n",
    "          \"bagging_freq\" : 1 , \n",
    "          \"subsample\" : 0.9 , \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "num_leaves = 15\n",
    "min_data_in_leaf = 2000\n",
    "feature_fraction = 0.9\n",
    "num_boost_round = 10000\n",
    "params_xgb = {\"booster\": \"gbtree\",\n",
    "         \"eta\" : learning_rate , \n",
    "          \"max_depth\" : 5 , \n",
    "          \"colsample_bytree\" : feature_fraction , \n",
    "          \"lambda\" : 100 , \n",
    "            \"alpha\": 100 , \n",
    "           \"tree_method\" : \"hist\" , \n",
    "          \"max_bin\" : 256 , \n",
    "          \"rate_drop\": 0.01 , \n",
    "          'objective': 'binary:logistic' , \n",
    "          \"eval_metric\" : \"auc\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17485, 269)\n",
      "(17368, 269)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[300]\tvalid_0's binary_logloss: 0.634925\tvalid_0's auc: 0.733018\n",
      "[600]\tvalid_0's binary_logloss: 0.610037\tvalid_0's auc: 0.75066\n",
      "[900]\tvalid_0's binary_logloss: 0.597232\tvalid_0's auc: 0.75873\n",
      "[1200]\tvalid_0's binary_logloss: 0.590155\tvalid_0's auc: 0.763217\n",
      "[1500]\tvalid_0's binary_logloss: 0.584096\tvalid_0's auc: 0.767341\n",
      "[1800]\tvalid_0's binary_logloss: 0.579959\tvalid_0's auc: 0.769964\n",
      "[2100]\tvalid_0's binary_logloss: 0.577348\tvalid_0's auc: 0.771732\n",
      "[2400]\tvalid_0's binary_logloss: 0.575203\tvalid_0's auc: 0.773085\n",
      "[2700]\tvalid_0's binary_logloss: 0.573552\tvalid_0's auc: 0.774131\n",
      "[3000]\tvalid_0's binary_logloss: 0.572471\tvalid_0's auc: 0.774885\n",
      "[3300]\tvalid_0's binary_logloss: 0.571432\tvalid_0's auc: 0.77552\n",
      "[3600]\tvalid_0's binary_logloss: 0.570618\tvalid_0's auc: 0.776053\n",
      "[3900]\tvalid_0's binary_logloss: 0.569949\tvalid_0's auc: 0.776454\n",
      "[4200]\tvalid_0's binary_logloss: 0.569494\tvalid_0's auc: 0.776734\n",
      "[4500]\tvalid_0's binary_logloss: 0.569133\tvalid_0's auc: 0.776951\n",
      "[4800]\tvalid_0's binary_logloss: 0.568925\tvalid_0's auc: 0.777036\n",
      "Early stopping, best iteration is:\n",
      "[4745]\tvalid_0's binary_logloss: 0.568924\tvalid_0's auc: 0.777066\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[300]\tvalid_0's binary_logloss: 0.638177\tvalid_0's auc: 0.722022\n",
      "[600]\tvalid_0's binary_logloss: 0.615224\tvalid_0's auc: 0.738695\n",
      "[900]\tvalid_0's binary_logloss: 0.603714\tvalid_0's auc: 0.74652\n",
      "[1200]\tvalid_0's binary_logloss: 0.597544\tvalid_0's auc: 0.750588\n",
      "[1500]\tvalid_0's binary_logloss: 0.592739\tvalid_0's auc: 0.753629\n",
      "[1800]\tvalid_0's binary_logloss: 0.589472\tvalid_0's auc: 0.755732\n",
      "[2100]\tvalid_0's binary_logloss: 0.587557\tvalid_0's auc: 0.756978\n",
      "[2400]\tvalid_0's binary_logloss: 0.586051\tvalid_0's auc: 0.757982\n",
      "[2700]\tvalid_0's binary_logloss: 0.584902\tvalid_0's auc: 0.758693\n",
      "[3000]\tvalid_0's binary_logloss: 0.584315\tvalid_0's auc: 0.75907\n",
      "[3300]\tvalid_0's binary_logloss: 0.583607\tvalid_0's auc: 0.759592\n",
      "[3600]\tvalid_0's binary_logloss: 0.583172\tvalid_0's auc: 0.759895\n",
      "[3900]\tvalid_0's binary_logloss: 0.582776\tvalid_0's auc: 0.760177\n",
      "Early stopping, best iteration is:\n",
      "[4006]\tvalid_0's binary_logloss: 0.582642\tvalid_0's auc: 0.760285\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[300]\tvalid_0's binary_logloss: 0.63718\tvalid_0's auc: 0.724735\n",
      "[600]\tvalid_0's binary_logloss: 0.613645\tvalid_0's auc: 0.742504\n",
      "[900]\tvalid_0's binary_logloss: 0.601733\tvalid_0's auc: 0.75035\n",
      "[1200]\tvalid_0's binary_logloss: 0.595359\tvalid_0's auc: 0.754415\n",
      "[1500]\tvalid_0's binary_logloss: 0.590284\tvalid_0's auc: 0.757771\n",
      "[1800]\tvalid_0's binary_logloss: 0.586654\tvalid_0's auc: 0.760193\n",
      "[2100]\tvalid_0's binary_logloss: 0.584768\tvalid_0's auc: 0.761376\n",
      "[2400]\tvalid_0's binary_logloss: 0.583043\tvalid_0's auc: 0.762536\n",
      "[2700]\tvalid_0's binary_logloss: 0.581788\tvalid_0's auc: 0.763312\n",
      "[3000]\tvalid_0's binary_logloss: 0.581153\tvalid_0's auc: 0.763741\n",
      "[3300]\tvalid_0's binary_logloss: 0.580438\tvalid_0's auc: 0.764193\n",
      "[3600]\tvalid_0's binary_logloss: 0.580062\tvalid_0's auc: 0.764421\n",
      "[3900]\tvalid_0's binary_logloss: 0.579662\tvalid_0's auc: 0.764668\n",
      "[4200]\tvalid_0's binary_logloss: 0.579393\tvalid_0's auc: 0.764861\n",
      "[4500]\tvalid_0's binary_logloss: 0.579188\tvalid_0's auc: 0.765015\n",
      "Early stopping, best iteration is:\n",
      "[4696]\tvalid_0's binary_logloss: 0.579081\tvalid_0's auc: 0.765119\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[300]\tvalid_0's binary_logloss: 0.637097\tvalid_0's auc: 0.72485\n",
      "[600]\tvalid_0's binary_logloss: 0.612732\tvalid_0's auc: 0.743529\n",
      "[900]\tvalid_0's binary_logloss: 0.599571\tvalid_0's auc: 0.753239\n",
      "[1200]\tvalid_0's binary_logloss: 0.592519\tvalid_0's auc: 0.758107\n",
      "[1500]\tvalid_0's binary_logloss: 0.586524\tvalid_0's auc: 0.762464\n",
      "[1800]\tvalid_0's binary_logloss: 0.582688\tvalid_0's auc: 0.764885\n",
      "[2100]\tvalid_0's binary_logloss: 0.580209\tvalid_0's auc: 0.766729\n",
      "[2400]\tvalid_0's binary_logloss: 0.578062\tvalid_0's auc: 0.768268\n",
      "[2700]\tvalid_0's binary_logloss: 0.576508\tvalid_0's auc: 0.769286\n",
      "[3000]\tvalid_0's binary_logloss: 0.575604\tvalid_0's auc: 0.769858\n",
      "[3300]\tvalid_0's binary_logloss: 0.574638\tvalid_0's auc: 0.7705\n",
      "[3600]\tvalid_0's binary_logloss: 0.573966\tvalid_0's auc: 0.771012\n",
      "[3900]\tvalid_0's binary_logloss: 0.573407\tvalid_0's auc: 0.771378\n",
      "[4200]\tvalid_0's binary_logloss: 0.572867\tvalid_0's auc: 0.771781\n",
      "[4500]\tvalid_0's binary_logloss: 0.57253\tvalid_0's auc: 0.772052\n",
      "[4800]\tvalid_0's binary_logloss: 0.572202\tvalid_0's auc: 0.772334\n",
      "[5100]\tvalid_0's binary_logloss: 0.572024\tvalid_0's auc: 0.77249\n",
      "Early stopping, best iteration is:\n",
      "[5278]\tvalid_0's binary_logloss: 0.571913\tvalid_0's auc: 0.772565\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[300]\tvalid_0's binary_logloss: 0.635445\tvalid_0's auc: 0.732433\n",
      "[600]\tvalid_0's binary_logloss: 0.609832\tvalid_0's auc: 0.752098\n",
      "[900]\tvalid_0's binary_logloss: 0.595833\tvalid_0's auc: 0.76236\n",
      "[1200]\tvalid_0's binary_logloss: 0.588265\tvalid_0's auc: 0.767529\n",
      "[1500]\tvalid_0's binary_logloss: 0.582155\tvalid_0's auc: 0.771424\n",
      "[1800]\tvalid_0's binary_logloss: 0.577766\tvalid_0's auc: 0.774175\n",
      "[2100]\tvalid_0's binary_logloss: 0.575127\tvalid_0's auc: 0.775852\n",
      "[2400]\tvalid_0's binary_logloss: 0.57284\tvalid_0's auc: 0.777259\n",
      "[2700]\tvalid_0's binary_logloss: 0.571133\tvalid_0's auc: 0.77821\n",
      "[3000]\tvalid_0's binary_logloss: 0.570088\tvalid_0's auc: 0.77873\n",
      "[3300]\tvalid_0's binary_logloss: 0.569075\tvalid_0's auc: 0.779203\n",
      "[3600]\tvalid_0's binary_logloss: 0.568277\tvalid_0's auc: 0.77957\n",
      "Early stopping, best iteration is:\n",
      "[3740]\tvalid_0's binary_logloss: 0.567902\tvalid_0's auc: 0.779798\n",
      "[0]\teval-auc:0.689704\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[300]\teval-auc:0.743857\n",
      "[600]\teval-auc:0.755902\n",
      "[900]\teval-auc:0.761589\n",
      "[1200]\teval-auc:0.76511\n",
      "[1500]\teval-auc:0.767715\n",
      "Stopping. Best iteration:\n",
      "[1553]\teval-auc:0.768045\n",
      "\n",
      "[0]\teval-auc:0.682568\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[300]\teval-auc:0.72735\n",
      "[600]\teval-auc:0.740721\n",
      "[900]\teval-auc:0.746289\n",
      "[1200]\teval-auc:0.749285\n",
      "[1500]\teval-auc:0.750989\n",
      "Stopping. Best iteration:\n",
      "[1419]\teval-auc:0.750989\n",
      "\n",
      "[0]\teval-auc:0.683371\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[300]\teval-auc:0.735651\n",
      "[600]\teval-auc:0.748553\n",
      "[900]\teval-auc:0.75374\n",
      "[1200]\teval-auc:0.75641\n",
      "[1500]\teval-auc:0.758199\n",
      "Stopping. Best iteration:\n",
      "[1563]\teval-auc:0.758499\n",
      "\n",
      "[0]\teval-auc:0.68755\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[300]\teval-auc:0.740351\n",
      "[600]\teval-auc:0.75212\n",
      "[900]\teval-auc:0.758021\n",
      "[1200]\teval-auc:0.761187\n",
      "[1500]\teval-auc:0.763389\n",
      "Stopping. Best iteration:\n",
      "[1481]\teval-auc:0.763389\n",
      "\n",
      "[0]\teval-auc:0.68855\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[300]\teval-auc:0.739304\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f8be74af1115>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mdvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mX_validate\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_validate\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mevallist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'eval'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_xgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevallist\u001b[0m  \u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mcv_pred_xgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdtest\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mntree_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_ntree_limit\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/xgboost-0.7-py2.7.egg/xgboost/training.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/xgboost-0.7-py2.7.egg/xgboost/training.pyc\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# check evaluation result.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mbst_eval_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst_eval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTRING_TYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbst_eval_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/xgboost-0.7-py2.7.egg/xgboost/core.pyc\u001b[0m in \u001b[0;36meval_set\u001b[0;34m(self, evals, iteration, feval)\u001b[0m\n\u001b[1;32m    954\u001b[0m                                               \u001b[0mdmats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m                                               \u001b[0mc_bst_ulong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m                                               ctypes.byref(msg)))\n\u001b[0m\u001b[1;32m    957\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeval\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NFOLDS = 5\n",
    "ncat = 43\n",
    "#X = features_train_t.values\n",
    "X_test = df_test.values\n",
    "X_train_full = df_train.values\n",
    "# for xgb \n",
    "dtest = xgb.DMatrix( X_test )\n",
    "dtrain_full = xgb.DMatrix( df_train.values )\n",
    "\n",
    "labels_train = df_labels.values\n",
    "final_cv_train = np.zeros(len( labels_train ))\n",
    "\n",
    "final_cv_pred = np.zeros(len( test_ids ))\n",
    "\n",
    "x_score = []\n",
    "x_score_xgb = []\n",
    "\n",
    "best_trees = []\n",
    "fold_scores = []\n",
    "N = 16\n",
    "\n",
    "oof_train = []\n",
    "oof_test = [] \n",
    "\n",
    "oof_train_xgb = []\n",
    "oof_train_xgb = []\n",
    "\n",
    "oof_train_full = []\n",
    "oof_test_full = []\n",
    "for s in range(N):\n",
    "    \n",
    "    \n",
    "    params['seed'] = s\n",
    "    x_train , x_val , y_train , y_val = train_test_split( df_train , df_labels , test_size = 0.3 , random_state=s)\n",
    "    \n",
    "    positive_indx = y_train[ y_train == 1 ]\n",
    "    positive_data = x_train.loc[ positive_indx.index.values  ]\n",
    "\n",
    "    negative_indx = y_train[ y_train == 0 ]\n",
    "    negative_data = x_train.loc[  negative_indx.index.values  ]\n",
    "    negative_data = negative_data.sample( frac= positive_ratio / (1 - positive_ratio), random_state=s*5 )\n",
    "\n",
    "    print( positive_data.shape )\n",
    "    print( negative_data.shape )\n",
    "\n",
    "    labels = [ 0 for x in range( negative_data.shape[0]) ] + [ 1 for x in range( positive_data.shape[0]) ]\n",
    "\n",
    "    x_train_sampled = pd.concat( [ negative_data , positive_data] , axis = 0 )\n",
    "    x_train_sampled[\"y\"] = labels\n",
    "    x_train_sampled = x_train_sampled.sample(frac = 1 ,random_state = s )\n",
    "    labels_sampled = x_train_sampled[\"y\"].values\n",
    "    \n",
    "    x_train_sampled = x_train_sampled.drop( [\"y\"] , axis = 1 ).values\n",
    "    \n",
    "    kfold = KFold(n_splits=NFOLDS, shuffle=True, random_state=s)\n",
    "    kf = kfold.split( x_train_sampled , labels_sampled  )\n",
    "    best_trees = []\n",
    "    fold_scores = []\n",
    "    \n",
    "    cv_train = np.zeros( len( labels_sampled ))\n",
    "    cv_train_xgb = np.zeros( len(labels_sampled))\n",
    "    \n",
    "    #cv_eval_total = np.zeros( len( y_val ) )\n",
    "    \n",
    "    cv_pred = np.zeros( len( test_ids ) )\n",
    "    cv_pred_xgb = np.zeros( len(test_ids))\n",
    "    \n",
    "    oof_train = np.zeros((  len( labels_train ) , ))\n",
    "    oof_test = np.zeros((  len( test_ids )  , ))\n",
    "    \n",
    "    oof_train_xgb = np.zeros( (len(labels_train) , ) )\n",
    "    oof_test_xgb = np.zeros( (len(test_ids) , ))\n",
    "    \n",
    "    oof_test_skf = np.empty((NFOLDS, len( test_ids )  ))\n",
    "    oof_train_skf = np.empty((NFOLDS, len( labels_train )  ))\n",
    "    \n",
    "    oof_test_skf_xgb = np.empty((NFOLDS, len( test_ids )  ))\n",
    "    oof_train_skf_xgb = np.empty((NFOLDS, len( labels_train )  ))\n",
    "    \n",
    "    \n",
    "    cv_train_full = np.zeros( len( labels_train ))\n",
    "    cv_train_full_xgb = np.zeros( len( labels_train ))\n",
    "    \n",
    "    for i, (train_fold, validate) in enumerate(kf):\n",
    "        \n",
    "        X_train, X_validate, label_train, label_validate = x_train_sampled[train_fold, :], x_train_sampled[validate, :], labels_sampled[train_fold], labels_sampled[validate]\n",
    "        dtrain = lgb.Dataset( X_train , label_train  )\n",
    "        dvalid = lgb.Dataset(  X_validate  , label_validate , reference=dtrain  )\n",
    "        \n",
    "        bst = lgb.train(params, dtrain , num_boost_round , valid_sets=[dvalid ] , verbose_eval = 300 , early_stopping_rounds = 100 ) \n",
    "        cv_pred +=  bst.predict(  X_test , num_iteration = bst.best_iteration )\n",
    "        \n",
    "        cv_train[validate] += bst.predict( X_validate , num_iteration = bst.best_iteration )\n",
    "        \n",
    "        cv_train_full += bst.predict( X_train_full , num_iteration = bst.best_iteration )\n",
    "        \n",
    "        oof_train_skf[i, :] = bst.predict( X_train_full , num_iteration = bst.best_iteration  )\n",
    "        oof_test_skf[ i , : ] = bst.predict( X_test , num_iteration = bst.best_iteration )\n",
    "        \n",
    "        \n",
    "        \n",
    "    cv_train_full /= NFOLDS\n",
    "    \n",
    "    kfold = KFold(n_splits=NFOLDS, shuffle=True, random_state=2*s)\n",
    "    kf = kfold.split( x_train_sampled , labels_sampled  )\n",
    "    \n",
    "    params_xgb[\"seed\"] = 2*s\n",
    "    \n",
    "    for i , (train_fold,validate) in enumerate(kf):\n",
    "        \n",
    "        X_train, X_validate, label_train, label_validate = x_train_sampled[train_fold, :], x_train_sampled[validate, :], labels_sampled[train_fold], labels_sampled[validate]\n",
    "        \n",
    "        dtrain = xgb.DMatrix( X_train , label=label_train )\n",
    "        dvalid = xgb.DMatrix( X_validate , label = label_validate )\n",
    "        evallist = [ (dvalid, 'eval') ]\n",
    "        bst = xgb.train(params_xgb, dtrain, num_boost_round, evallist  , early_stopping_rounds=100 , verbose_eval=300 )\n",
    "        \n",
    "        cv_pred_xgb = bst.predict( dtest , ntree_limit=bst.best_ntree_limit )\n",
    "        cv_train_xgb[validate] += bst.predict( dvalid , ntree_limit=bst.best_ntree_limit  )\n",
    "        \n",
    "        oof_train_skf_xgb[ i , : ] = bst.predict( dtrain_full , ntree_limit=bst.best_ntree_limit )\n",
    "        oof_test_skf_xgb[i , :] = bst.predict( dtest , ntree_limit=bst.best_ntree_limit )\n",
    "        \n",
    "        cv_train_full_xgb += bst.predict( dtrain_full , ntree_limit=bst.best_ntree_limit )\n",
    "        \n",
    "        \n",
    "    cv_train_full_xgb /= NFOLDS  \n",
    "    \n",
    "    oof_test[:] = oof_test_skf.mean( axis = 0 )\n",
    "    oof_train[:] = oof_train_skf.mean( axis = 0 )\n",
    "    \n",
    "    oof_test_xgb[:] = oof_test_skf_xgb.mean( axis = 0 )\n",
    "    oof_train_xgb[:] = oof_train_skf_xgb.mean( axis = 0 )\n",
    "    \n",
    "    oof_train = oof_train.reshape(-1, 1)\n",
    "    oof_test = oof_test.reshape( -1 , 1 )\n",
    "    \n",
    "    oof_train_xgb = oof_train_xgb.reshape( -1 , 1 )\n",
    "    oof_test_xgb = oof_test_xgb.reshape( -1,1 )\n",
    "    \n",
    "    oof_train_full.append( oof_train ) \n",
    "    oof_train_full.append( oof_train_xgb )\n",
    "    \n",
    "    oof_test_full.append( oof_test )\n",
    "    oof_test_full.append( oof_test_xgb )\n",
    "    \n",
    "    score_lgb = roc_auc_score( labels_train , cv_train_full / (s + 1.))\n",
    "    score_xgb = roc_auc_score( labels_train , cv_train_full_xgb / (s + 1.))\n",
    "\n",
    "    x_score.append( score_lgb )\n",
    "    x_score_xgb.append( score_xgb )\n",
    "    \n",
    "    print( \"current score in fold - lgb :\", score_lgb , s+1)\n",
    "    print( \"current score in fold - xgb :\", score_xgb , s+1)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = np.hstack( oof_train_full )\n",
    "new_test = np.hstack( oof_test_full )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"SUCCES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "num_leaves = 16\n",
    "min_data_in_leaf = 2000\n",
    "feature_fraction = 0.9\n",
    "num_boost_round = 10000\n",
    "params = {\"objective\": \"binary\",\n",
    "          \"boosting_type\": \"dart\",\n",
    "          \"learning_rate\": learning_rate,\n",
    "          \"metric\":[\"auc\" ,\"binary_logloss\"] , \n",
    "          \"num_leaves\": num_leaves,\n",
    "           \"max_bin\": 256,\n",
    "          \"feature_fraction\": feature_fraction,\n",
    "          \"verbosity\": 1,\n",
    "          \"drop_rate\": 0.01,\n",
    "          \"is_unbalance\": False,\n",
    "          \"max_drop\": 50,\n",
    "          \"min_child_samples\": 20,\n",
    "          \"min_child_weight\": 150,\n",
    "          \"min_split_gain\": 0.5,\n",
    "          \"max_depth\": -1, \n",
    "          \"reg_alpha\" : 20 , \n",
    "          \"reg_lambda\": 20 , \n",
    "          \"min_gain_to_split\" : 0.5 ,\n",
    "          \"bagging_freq\" : 1 , \n",
    "          \"subsample\" : 0.9\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightgbm model with oof_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.379057\tvalid_0's auc: 0.783345\n",
      "[200]\tvalid_0's binary_logloss: 0.30656\tvalid_0's auc: 0.789976\n",
      "[300]\tvalid_0's binary_logloss: 0.282494\tvalid_0's auc: 0.790717\n",
      "[400]\tvalid_0's binary_logloss: 0.267422\tvalid_0's auc: 0.791098\n",
      "[500]\tvalid_0's binary_logloss: 0.255306\tvalid_0's auc: 0.791462\n",
      "[600]\tvalid_0's binary_logloss: 0.251526\tvalid_0's auc: 0.791692\n",
      "[700]\tvalid_0's binary_logloss: 0.244771\tvalid_0's auc: 0.792198\n",
      "[800]\tvalid_0's binary_logloss: 0.242743\tvalid_0's auc: 0.792368\n",
      "[900]\tvalid_0's binary_logloss: 0.240235\tvalid_0's auc: 0.792598\n",
      "[1000]\tvalid_0's binary_logloss: 0.238715\tvalid_0's auc: 0.792778\n",
      "[1100]\tvalid_0's binary_logloss: 0.2384\tvalid_0's auc: 0.792895\n",
      "[1200]\tvalid_0's binary_logloss: 0.238085\tvalid_0's auc: 0.793001\n",
      "[1300]\tvalid_0's binary_logloss: 0.238107\tvalid_0's auc: 0.793072\n",
      "Early stopping, best iteration is:\n",
      "[1220]\tvalid_0's binary_logloss: 0.237891\tvalid_0's auc: 0.793022\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.378949\tvalid_0's auc: 0.792999\n",
      "[200]\tvalid_0's binary_logloss: 0.306278\tvalid_0's auc: 0.793848\n",
      "[300]\tvalid_0's binary_logloss: 0.282085\tvalid_0's auc: 0.794598\n",
      "[400]\tvalid_0's binary_logloss: 0.266884\tvalid_0's auc: 0.794581\n",
      "[500]\tvalid_0's binary_logloss: 0.254634\tvalid_0's auc: 0.794931\n",
      "[600]\tvalid_0's binary_logloss: 0.250802\tvalid_0's auc: 0.795154\n",
      "[700]\tvalid_0's binary_logloss: 0.243926\tvalid_0's auc: 0.795466\n",
      "[800]\tvalid_0's binary_logloss: 0.24188\tvalid_0's auc: 0.795685\n",
      "[900]\tvalid_0's binary_logloss: 0.239334\tvalid_0's auc: 0.795856\n",
      "[1000]\tvalid_0's binary_logloss: 0.237782\tvalid_0's auc: 0.79602\n",
      "[1100]\tvalid_0's binary_logloss: 0.23747\tvalid_0's auc: 0.796155\n",
      "[1200]\tvalid_0's binary_logloss: 0.237156\tvalid_0's auc: 0.796218\n",
      "[1300]\tvalid_0's binary_logloss: 0.237196\tvalid_0's auc: 0.796297\n",
      "Early stopping, best iteration is:\n",
      "[1220]\tvalid_0's binary_logloss: 0.236952\tvalid_0's auc: 0.796265\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.3789\tvalid_0's auc: 0.789226\n",
      "[200]\tvalid_0's binary_logloss: 0.306285\tvalid_0's auc: 0.790235\n",
      "[300]\tvalid_0's binary_logloss: 0.282174\tvalid_0's auc: 0.790749\n",
      "[400]\tvalid_0's binary_logloss: 0.26704\tvalid_0's auc: 0.791009\n",
      "[500]\tvalid_0's binary_logloss: 0.254889\tvalid_0's auc: 0.791248\n",
      "[600]\tvalid_0's binary_logloss: 0.25109\tvalid_0's auc: 0.791814\n",
      "[700]\tvalid_0's binary_logloss: 0.244316\tvalid_0's auc: 0.792365\n",
      "[800]\tvalid_0's binary_logloss: 0.242295\tvalid_0's auc: 0.792604\n",
      "[900]\tvalid_0's binary_logloss: 0.239792\tvalid_0's auc: 0.792815\n",
      "[1000]\tvalid_0's binary_logloss: 0.238286\tvalid_0's auc: 0.792918\n",
      "[1100]\tvalid_0's binary_logloss: 0.238008\tvalid_0's auc: 0.793001\n",
      "[1200]\tvalid_0's binary_logloss: 0.237718\tvalid_0's auc: 0.793058\n",
      "[1300]\tvalid_0's binary_logloss: 0.237752\tvalid_0's auc: 0.793122\n",
      "Early stopping, best iteration is:\n",
      "[1220]\tvalid_0's binary_logloss: 0.237519\tvalid_0's auc: 0.793073\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.37822\tvalid_0's auc: 0.795627\n",
      "[200]\tvalid_0's binary_logloss: 0.305324\tvalid_0's auc: 0.797606\n",
      "[300]\tvalid_0's binary_logloss: 0.281016\tvalid_0's auc: 0.798183\n",
      "[400]\tvalid_0's binary_logloss: 0.265708\tvalid_0's auc: 0.798411\n",
      "[500]\tvalid_0's binary_logloss: 0.253352\tvalid_0's auc: 0.798743\n",
      "[600]\tvalid_0's binary_logloss: 0.249474\tvalid_0's auc: 0.799311\n",
      "[700]\tvalid_0's binary_logloss: 0.242525\tvalid_0's auc: 0.799781\n",
      "[800]\tvalid_0's binary_logloss: 0.240443\tvalid_0's auc: 0.799956\n",
      "[900]\tvalid_0's binary_logloss: 0.237837\tvalid_0's auc: 0.800169\n",
      "[1000]\tvalid_0's binary_logloss: 0.236235\tvalid_0's auc: 0.800332\n",
      "[1100]\tvalid_0's binary_logloss: 0.235909\tvalid_0's auc: 0.800464\n",
      "[1200]\tvalid_0's binary_logloss: 0.235578\tvalid_0's auc: 0.800561\n",
      "[1300]\tvalid_0's binary_logloss: 0.235605\tvalid_0's auc: 0.80061\n",
      "Early stopping, best iteration is:\n",
      "[1220]\tvalid_0's binary_logloss: 0.235362\tvalid_0's auc: 0.800584\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.378524\tvalid_0's auc: 0.791435\n",
      "[200]\tvalid_0's binary_logloss: 0.305852\tvalid_0's auc: 0.794022\n",
      "[300]\tvalid_0's binary_logloss: 0.281688\tvalid_0's auc: 0.795306\n",
      "[400]\tvalid_0's binary_logloss: 0.266525\tvalid_0's auc: 0.795636\n",
      "[500]\tvalid_0's binary_logloss: 0.254324\tvalid_0's auc: 0.796049\n",
      "[600]\tvalid_0's binary_logloss: 0.250466\tvalid_0's auc: 0.796425\n",
      "[700]\tvalid_0's binary_logloss: 0.243622\tvalid_0's auc: 0.796694\n",
      "[800]\tvalid_0's binary_logloss: 0.241542\tvalid_0's auc: 0.796984\n",
      "[900]\tvalid_0's binary_logloss: 0.238984\tvalid_0's auc: 0.797207\n",
      "[1000]\tvalid_0's binary_logloss: 0.237432\tvalid_0's auc: 0.797387\n",
      "[1100]\tvalid_0's binary_logloss: 0.237101\tvalid_0's auc: 0.797556\n",
      "[1200]\tvalid_0's binary_logloss: 0.236767\tvalid_0's auc: 0.797661\n",
      "[1300]\tvalid_0's binary_logloss: 0.236789\tvalid_0's auc: 0.797708\n",
      "Early stopping, best iteration is:\n",
      "[1220]\tvalid_0's binary_logloss: 0.236562\tvalid_0's auc: 0.797692\n",
      "cv score - on train:\n",
      "0.7959492113914372\n",
      "('current score in fold:', 0.7959492113914372, 1)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.37709\tvalid_0's auc: 0.786809\n",
      "[200]\tvalid_0's binary_logloss: 0.302451\tvalid_0's auc: 0.790322\n",
      "[300]\tvalid_0's binary_logloss: 0.272164\tvalid_0's auc: 0.790812\n",
      "[400]\tvalid_0's binary_logloss: 0.260651\tvalid_0's auc: 0.791432\n",
      "[500]\tvalid_0's binary_logloss: 0.253373\tvalid_0's auc: 0.791565\n",
      "[600]\tvalid_0's binary_logloss: 0.250097\tvalid_0's auc: 0.791814\n",
      "[700]\tvalid_0's binary_logloss: 0.247362\tvalid_0's auc: 0.791881\n",
      "[800]\tvalid_0's binary_logloss: 0.245042\tvalid_0's auc: 0.791922\n",
      "[900]\tvalid_0's binary_logloss: 0.242739\tvalid_0's auc: 0.791961\n",
      "[1000]\tvalid_0's binary_logloss: 0.242176\tvalid_0's auc: 0.792056\n",
      "[1100]\tvalid_0's binary_logloss: 0.2408\tvalid_0's auc: 0.792164\n",
      "[1200]\tvalid_0's binary_logloss: 0.239828\tvalid_0's auc: 0.792317\n",
      "Early stopping, best iteration is:\n",
      "[1197]\tvalid_0's binary_logloss: 0.239702\tvalid_0's auc: 0.792316\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.376693\tvalid_0's auc: 0.790672\n",
      "[200]\tvalid_0's binary_logloss: 0.30175\tvalid_0's auc: 0.793842\n",
      "[300]\tvalid_0's binary_logloss: 0.271235\tvalid_0's auc: 0.795372\n",
      "[400]\tvalid_0's binary_logloss: 0.259595\tvalid_0's auc: 0.79591\n",
      "[500]\tvalid_0's binary_logloss: 0.252196\tvalid_0's auc: 0.796236\n",
      "[600]\tvalid_0's binary_logloss: 0.248842\tvalid_0's auc: 0.796578\n",
      "[700]\tvalid_0's binary_logloss: 0.246033\tvalid_0's auc: 0.796807\n",
      "[800]\tvalid_0's binary_logloss: 0.243632\tvalid_0's auc: 0.796954\n",
      "[900]\tvalid_0's binary_logloss: 0.241222\tvalid_0's auc: 0.797101\n",
      "[1000]\tvalid_0's binary_logloss: 0.240641\tvalid_0's auc: 0.797192\n",
      "[1100]\tvalid_0's binary_logloss: 0.239196\tvalid_0's auc: 0.79726\n",
      "[1200]\tvalid_0's binary_logloss: 0.238186\tvalid_0's auc: 0.797343\n",
      "Early stopping, best iteration is:\n",
      "[1197]\tvalid_0's binary_logloss: 0.238052\tvalid_0's auc: 0.797345\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.376296\tvalid_0's auc: 0.791498\n",
      "[200]\tvalid_0's binary_logloss: 0.301276\tvalid_0's auc: 0.795373\n",
      "[300]\tvalid_0's binary_logloss: 0.270766\tvalid_0's auc: 0.795555\n",
      "[400]\tvalid_0's binary_logloss: 0.259123\tvalid_0's auc: 0.795956\n",
      "[500]\tvalid_0's binary_logloss: 0.251749\tvalid_0's auc: 0.796611\n",
      "[600]\tvalid_0's binary_logloss: 0.248404\tvalid_0's auc: 0.796997\n",
      "[700]\tvalid_0's binary_logloss: 0.245607\tvalid_0's auc: 0.797188\n",
      "[800]\tvalid_0's binary_logloss: 0.243195\tvalid_0's auc: 0.797388\n",
      "[900]\tvalid_0's binary_logloss: 0.240797\tvalid_0's auc: 0.79752\n",
      "[1000]\tvalid_0's binary_logloss: 0.240205\tvalid_0's auc: 0.797733\n",
      "[1100]\tvalid_0's binary_logloss: 0.238775\tvalid_0's auc: 0.797838\n",
      "[1200]\tvalid_0's binary_logloss: 0.23776\tvalid_0's auc: 0.797983\n",
      "Early stopping, best iteration is:\n",
      "[1197]\tvalid_0's binary_logloss: 0.237627\tvalid_0's auc: 0.797983\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.37679\tvalid_0's auc: 0.79174\n",
      "[200]\tvalid_0's binary_logloss: 0.301878\tvalid_0's auc: 0.792167\n",
      "[300]\tvalid_0's binary_logloss: 0.271396\tvalid_0's auc: 0.793736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\tvalid_0's binary_logloss: 0.25978\tvalid_0's auc: 0.794412\n",
      "[500]\tvalid_0's binary_logloss: 0.252442\tvalid_0's auc: 0.794713\n",
      "[600]\tvalid_0's binary_logloss: 0.249139\tvalid_0's auc: 0.794976\n",
      "[700]\tvalid_0's binary_logloss: 0.246381\tvalid_0's auc: 0.79509\n",
      "[800]\tvalid_0's binary_logloss: 0.244013\tvalid_0's auc: 0.795319\n",
      "[900]\tvalid_0's binary_logloss: 0.241648\tvalid_0's auc: 0.795445\n",
      "[1000]\tvalid_0's binary_logloss: 0.241094\tvalid_0's auc: 0.795568\n",
      "[1100]\tvalid_0's binary_logloss: 0.239679\tvalid_0's auc: 0.795637\n",
      "[1200]\tvalid_0's binary_logloss: 0.238689\tvalid_0's auc: 0.79577\n",
      "Early stopping, best iteration is:\n",
      "[1197]\tvalid_0's binary_logloss: 0.238556\tvalid_0's auc: 0.795769\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.376612\tvalid_0's auc: 0.790044\n",
      "[200]\tvalid_0's binary_logloss: 0.301798\tvalid_0's auc: 0.792493\n",
      "[300]\tvalid_0's binary_logloss: 0.271419\tvalid_0's auc: 0.793206\n",
      "[400]\tvalid_0's binary_logloss: 0.259837\tvalid_0's auc: 0.793604\n",
      "[500]\tvalid_0's binary_logloss: 0.252501\tvalid_0's auc: 0.794026\n",
      "[600]\tvalid_0's binary_logloss: 0.249184\tvalid_0's auc: 0.794449\n",
      "[700]\tvalid_0's binary_logloss: 0.246409\tvalid_0's auc: 0.794937\n",
      "[800]\tvalid_0's binary_logloss: 0.244053\tvalid_0's auc: 0.795039\n",
      "[900]\tvalid_0's binary_logloss: 0.241725\tvalid_0's auc: 0.795214\n",
      "[1000]\tvalid_0's binary_logloss: 0.241146\tvalid_0's auc: 0.795339\n",
      "[1100]\tvalid_0's binary_logloss: 0.239744\tvalid_0's auc: 0.795465\n",
      "[1200]\tvalid_0's binary_logloss: 0.238752\tvalid_0's auc: 0.795581\n",
      "Early stopping, best iteration is:\n",
      "[1197]\tvalid_0's binary_logloss: 0.238626\tvalid_0's auc: 0.79558\n",
      "cv score - on train:\n",
      "0.7956284018766059\n",
      "('current score in fold:', 0.7958668097994409, 2)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.377165\tvalid_0's auc: 0.784834\n",
      "[200]\tvalid_0's binary_logloss: 0.317007\tvalid_0's auc: 0.789158\n",
      "[300]\tvalid_0's binary_logloss: 0.283661\tvalid_0's auc: 0.789447\n",
      "[400]\tvalid_0's binary_logloss: 0.267957\tvalid_0's auc: 0.789507\n",
      "[500]\tvalid_0's binary_logloss: 0.259716\tvalid_0's auc: 0.789738\n",
      "[600]\tvalid_0's binary_logloss: 0.251475\tvalid_0's auc: 0.790169\n",
      "[700]\tvalid_0's binary_logloss: 0.249551\tvalid_0's auc: 0.79053\n",
      "[800]\tvalid_0's binary_logloss: 0.245681\tvalid_0's auc: 0.790648\n",
      "[900]\tvalid_0's binary_logloss: 0.243942\tvalid_0's auc: 0.790786\n",
      "[1000]\tvalid_0's binary_logloss: 0.242084\tvalid_0's auc: 0.790964\n",
      "[1100]\tvalid_0's binary_logloss: 0.240733\tvalid_0's auc: 0.791107\n",
      "[1200]\tvalid_0's binary_logloss: 0.239289\tvalid_0's auc: 0.791313\n",
      "[1300]\tvalid_0's binary_logloss: 0.238422\tvalid_0's auc: 0.791492\n",
      "[1400]\tvalid_0's binary_logloss: 0.23781\tvalid_0's auc: 0.791619\n",
      "[1500]\tvalid_0's binary_logloss: 0.237644\tvalid_0's auc: 0.791766\n",
      "[1600]\tvalid_0's binary_logloss: 0.237286\tvalid_0's auc: 0.79184\n",
      "[1700]\tvalid_0's binary_logloss: 0.237192\tvalid_0's auc: 0.791936\n",
      "[1800]\tvalid_0's binary_logloss: 0.236982\tvalid_0's auc: 0.792036\n",
      "[1900]\tvalid_0's binary_logloss: 0.236978\tvalid_0's auc: 0.792109\n",
      "[2000]\tvalid_0's binary_logloss: 0.236674\tvalid_0's auc: 0.792198\n",
      "Early stopping, best iteration is:\n",
      "[1998]\tvalid_0's binary_logloss: 0.236651\tvalid_0's auc: 0.792197\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.376839\tvalid_0's auc: 0.788039\n",
      "[200]\tvalid_0's binary_logloss: 0.316602\tvalid_0's auc: 0.792253\n",
      "[300]\tvalid_0's binary_logloss: 0.283175\tvalid_0's auc: 0.792624\n",
      "[400]\tvalid_0's binary_logloss: 0.267377\tvalid_0's auc: 0.793046\n",
      "[500]\tvalid_0's binary_logloss: 0.259068\tvalid_0's auc: 0.793364\n",
      "[600]\tvalid_0's binary_logloss: 0.250776\tvalid_0's auc: 0.793756\n",
      "[700]\tvalid_0's binary_logloss: 0.248829\tvalid_0's auc: 0.793834\n",
      "[800]\tvalid_0's binary_logloss: 0.244943\tvalid_0's auc: 0.79399\n",
      "[900]\tvalid_0's binary_logloss: 0.243189\tvalid_0's auc: 0.794211\n",
      "[1000]\tvalid_0's binary_logloss: 0.241313\tvalid_0's auc: 0.794395\n",
      "[1100]\tvalid_0's binary_logloss: 0.239942\tvalid_0's auc: 0.794542\n",
      "[1200]\tvalid_0's binary_logloss: 0.238493\tvalid_0's auc: 0.794697\n",
      "[1300]\tvalid_0's binary_logloss: 0.237606\tvalid_0's auc: 0.794917\n",
      "[1400]\tvalid_0's binary_logloss: 0.236988\tvalid_0's auc: 0.794981\n",
      "[1500]\tvalid_0's binary_logloss: 0.236817\tvalid_0's auc: 0.795148\n",
      "[1600]\tvalid_0's binary_logloss: 0.236465\tvalid_0's auc: 0.795203\n",
      "[1700]\tvalid_0's binary_logloss: 0.236365\tvalid_0's auc: 0.795291\n",
      "[1800]\tvalid_0's binary_logloss: 0.236166\tvalid_0's auc: 0.795361\n",
      "[1900]\tvalid_0's binary_logloss: 0.236162\tvalid_0's auc: 0.795433\n",
      "[2000]\tvalid_0's binary_logloss: 0.235872\tvalid_0's auc: 0.795507\n",
      "Early stopping, best iteration is:\n",
      "[1998]\tvalid_0's binary_logloss: 0.235849\tvalid_0's auc: 0.795508\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.37661\tvalid_0's auc: 0.791427\n",
      "[200]\tvalid_0's binary_logloss: 0.316148\tvalid_0's auc: 0.794431\n",
      "[300]\tvalid_0's binary_logloss: 0.282562\tvalid_0's auc: 0.794825\n",
      "[400]\tvalid_0's binary_logloss: 0.266696\tvalid_0's auc: 0.795529\n",
      "[500]\tvalid_0's binary_logloss: 0.258348\tvalid_0's auc: 0.795949\n",
      "[600]\tvalid_0's binary_logloss: 0.249978\tvalid_0's auc: 0.796625\n",
      "[700]\tvalid_0's binary_logloss: 0.248022\tvalid_0's auc: 0.796817\n",
      "[800]\tvalid_0's binary_logloss: 0.244045\tvalid_0's auc: 0.796943\n",
      "[900]\tvalid_0's binary_logloss: 0.24228\tvalid_0's auc: 0.797048\n",
      "[1000]\tvalid_0's binary_logloss: 0.240362\tvalid_0's auc: 0.797176\n",
      "[1100]\tvalid_0's binary_logloss: 0.238951\tvalid_0's auc: 0.797281\n",
      "[1200]\tvalid_0's binary_logloss: 0.237437\tvalid_0's auc: 0.797441\n",
      "[1300]\tvalid_0's binary_logloss: 0.236516\tvalid_0's auc: 0.797573\n",
      "[1400]\tvalid_0's binary_logloss: 0.235854\tvalid_0's auc: 0.797641\n",
      "[1500]\tvalid_0's binary_logloss: 0.235683\tvalid_0's auc: 0.797817\n",
      "[1600]\tvalid_0's binary_logloss: 0.235289\tvalid_0's auc: 0.797886\n",
      "[1700]\tvalid_0's binary_logloss: 0.235188\tvalid_0's auc: 0.797945\n",
      "[1800]\tvalid_0's binary_logloss: 0.234966\tvalid_0's auc: 0.797998\n",
      "[1900]\tvalid_0's binary_logloss: 0.234962\tvalid_0's auc: 0.798047\n",
      "[2000]\tvalid_0's binary_logloss: 0.234624\tvalid_0's auc: 0.798109\n",
      "Early stopping, best iteration is:\n",
      "[1998]\tvalid_0's binary_logloss: 0.234597\tvalid_0's auc: 0.798108\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.376057\tvalid_0's auc: 0.796472\n",
      "[200]\tvalid_0's binary_logloss: 0.315475\tvalid_0's auc: 0.797445\n",
      "[300]\tvalid_0's binary_logloss: 0.281779\tvalid_0's auc: 0.797695\n",
      "[400]\tvalid_0's binary_logloss: 0.265839\tvalid_0's auc: 0.797838\n",
      "[500]\tvalid_0's binary_logloss: 0.257458\tvalid_0's auc: 0.798004\n",
      "[600]\tvalid_0's binary_logloss: 0.249014\tvalid_0's auc: 0.798788\n",
      "[700]\tvalid_0's binary_logloss: 0.247032\tvalid_0's auc: 0.799132\n",
      "[800]\tvalid_0's binary_logloss: 0.243032\tvalid_0's auc: 0.799465\n",
      "[900]\tvalid_0's binary_logloss: 0.241242\tvalid_0's auc: 0.799647\n",
      "[1000]\tvalid_0's binary_logloss: 0.239299\tvalid_0's auc: 0.799882\n",
      "[1100]\tvalid_0's binary_logloss: 0.237865\tvalid_0's auc: 0.800037\n",
      "[1200]\tvalid_0's binary_logloss: 0.236327\tvalid_0's auc: 0.800265\n",
      "[1300]\tvalid_0's binary_logloss: 0.235384\tvalid_0's auc: 0.800458\n",
      "[1400]\tvalid_0's binary_logloss: 0.234712\tvalid_0's auc: 0.800554\n",
      "[1500]\tvalid_0's binary_logloss: 0.23454\tvalid_0's auc: 0.800616\n",
      "[1600]\tvalid_0's binary_logloss: 0.234141\tvalid_0's auc: 0.800731\n",
      "[1700]\tvalid_0's binary_logloss: 0.23404\tvalid_0's auc: 0.800749\n",
      "[1800]\tvalid_0's binary_logloss: 0.233813\tvalid_0's auc: 0.800822\n",
      "[1900]\tvalid_0's binary_logloss: 0.233817\tvalid_0's auc: 0.800858\n",
      "[2000]\tvalid_0's binary_logloss: 0.233459\tvalid_0's auc: 0.80097\n",
      "Early stopping, best iteration is:\n",
      "[1998]\tvalid_0's binary_logloss: 0.233432\tvalid_0's auc: 0.800969\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.376786\tvalid_0's auc: 0.790935\n",
      "[200]\tvalid_0's binary_logloss: 0.316493\tvalid_0's auc: 0.791446\n",
      "[300]\tvalid_0's binary_logloss: 0.283048\tvalid_0's auc: 0.793222\n",
      "[400]\tvalid_0's binary_logloss: 0.267245\tvalid_0's auc: 0.793475\n",
      "[500]\tvalid_0's binary_logloss: 0.258922\tvalid_0's auc: 0.793965\n",
      "[600]\tvalid_0's binary_logloss: 0.250572\tvalid_0's auc: 0.794649\n",
      "[700]\tvalid_0's binary_logloss: 0.248616\tvalid_0's auc: 0.794827\n",
      "[800]\tvalid_0's binary_logloss: 0.24468\tvalid_0's auc: 0.795008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[900]\tvalid_0's binary_logloss: 0.242928\tvalid_0's auc: 0.795194\n",
      "[1000]\tvalid_0's binary_logloss: 0.24105\tvalid_0's auc: 0.795275\n",
      "[1100]\tvalid_0's binary_logloss: 0.239675\tvalid_0's auc: 0.795515\n",
      "[1200]\tvalid_0's binary_logloss: 0.238209\tvalid_0's auc: 0.795675\n",
      "[1300]\tvalid_0's binary_logloss: 0.237314\tvalid_0's auc: 0.795839\n",
      "[1400]\tvalid_0's binary_logloss: 0.236686\tvalid_0's auc: 0.795912\n",
      "[1500]\tvalid_0's binary_logloss: 0.236544\tvalid_0's auc: 0.795954\n",
      "[1600]\tvalid_0's binary_logloss: 0.236196\tvalid_0's auc: 0.795994\n",
      "[1700]\tvalid_0's binary_logloss: 0.236112\tvalid_0's auc: 0.796047\n",
      "[1800]\tvalid_0's binary_logloss: 0.235915\tvalid_0's auc: 0.796068\n",
      "[1900]\tvalid_0's binary_logloss: 0.235914\tvalid_0's auc: 0.7961\n",
      "[2000]\tvalid_0's binary_logloss: 0.235601\tvalid_0's auc: 0.796155\n",
      "Early stopping, best iteration is:\n",
      "[1998]\tvalid_0's binary_logloss: 0.235576\tvalid_0's auc: 0.796154\n",
      "cv score - on train:\n",
      "0.7964433132918807\n",
      "('current score in fold:', 0.7961671469500401, 3)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.382126\tvalid_0's auc: 0.786591\n",
      "[200]\tvalid_0's binary_logloss: 0.311138\tvalid_0's auc: 0.788316\n",
      "[300]\tvalid_0's binary_logloss: 0.281221\tvalid_0's auc: 0.789838\n",
      "[400]\tvalid_0's binary_logloss: 0.259945\tvalid_0's auc: 0.790825\n",
      "[500]\tvalid_0's binary_logloss: 0.251015\tvalid_0's auc: 0.791289\n",
      "[600]\tvalid_0's binary_logloss: 0.24744\tvalid_0's auc: 0.791821\n",
      "[700]\tvalid_0's binary_logloss: 0.243863\tvalid_0's auc: 0.792195\n",
      "[800]\tvalid_0's binary_logloss: 0.242186\tvalid_0's auc: 0.792321\n",
      "[900]\tvalid_0's binary_logloss: 0.240915\tvalid_0's auc: 0.792577\n",
      "[1000]\tvalid_0's binary_logloss: 0.239397\tvalid_0's auc: 0.792772\n",
      "[1100]\tvalid_0's binary_logloss: 0.238687\tvalid_0's auc: 0.792908\n",
      "[1200]\tvalid_0's binary_logloss: 0.238068\tvalid_0's auc: 0.793034\n",
      "[1300]\tvalid_0's binary_logloss: 0.237866\tvalid_0's auc: 0.793104\n",
      "[1400]\tvalid_0's binary_logloss: 0.237344\tvalid_0's auc: 0.793169\n",
      "[1500]\tvalid_0's binary_logloss: 0.236973\tvalid_0's auc: 0.793184\n",
      "[1600]\tvalid_0's binary_logloss: 0.236839\tvalid_0's auc: 0.793245\n",
      "[1700]\tvalid_0's binary_logloss: 0.23689\tvalid_0's auc: 0.793287\n",
      "[1800]\tvalid_0's binary_logloss: 0.236854\tvalid_0's auc: 0.793306\n",
      "Early stopping, best iteration is:\n",
      "[1735]\tvalid_0's binary_logloss: 0.236563\tvalid_0's auc: 0.793288\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.38187\tvalid_0's auc: 0.788252\n",
      "[200]\tvalid_0's binary_logloss: 0.310684\tvalid_0's auc: 0.793685\n",
      "[300]\tvalid_0's binary_logloss: 0.280609\tvalid_0's auc: 0.794064\n",
      "[400]\tvalid_0's binary_logloss: 0.259189\tvalid_0's auc: 0.794543\n",
      "[500]\tvalid_0's binary_logloss: 0.250202\tvalid_0's auc: 0.794816\n",
      "[600]\tvalid_0's binary_logloss: 0.246619\tvalid_0's auc: 0.795042\n",
      "[700]\tvalid_0's binary_logloss: 0.243041\tvalid_0's auc: 0.795386\n",
      "[800]\tvalid_0's binary_logloss: 0.24134\tvalid_0's auc: 0.795523\n",
      "[900]\tvalid_0's binary_logloss: 0.240064\tvalid_0's auc: 0.795603\n",
      "[1000]\tvalid_0's binary_logloss: 0.23853\tvalid_0's auc: 0.795707\n",
      "[1100]\tvalid_0's binary_logloss: 0.23782\tvalid_0's auc: 0.795829\n",
      "[1200]\tvalid_0's binary_logloss: 0.23718\tvalid_0's auc: 0.795948\n",
      "[1300]\tvalid_0's binary_logloss: 0.236966\tvalid_0's auc: 0.796005\n",
      "[1400]\tvalid_0's binary_logloss: 0.236419\tvalid_0's auc: 0.796054\n",
      "[1500]\tvalid_0's binary_logloss: 0.236039\tvalid_0's auc: 0.796104\n",
      "[1600]\tvalid_0's binary_logloss: 0.235896\tvalid_0's auc: 0.796194\n",
      "[1700]\tvalid_0's binary_logloss: 0.235951\tvalid_0's auc: 0.796262\n",
      "[1800]\tvalid_0's binary_logloss: 0.235906\tvalid_0's auc: 0.796297\n",
      "Early stopping, best iteration is:\n",
      "[1735]\tvalid_0's binary_logloss: 0.235602\tvalid_0's auc: 0.796263\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.381574\tvalid_0's auc: 0.793932\n",
      "[200]\tvalid_0's binary_logloss: 0.310331\tvalid_0's auc: 0.794589\n",
      "[300]\tvalid_0's binary_logloss: 0.280241\tvalid_0's auc: 0.796289\n",
      "[400]\tvalid_0's binary_logloss: 0.258796\tvalid_0's auc: 0.796902\n",
      "[500]\tvalid_0's binary_logloss: 0.249768\tvalid_0's auc: 0.797407\n",
      "[600]\tvalid_0's binary_logloss: 0.246157\tvalid_0's auc: 0.797653\n",
      "[700]\tvalid_0's binary_logloss: 0.242551\tvalid_0's auc: 0.79786\n",
      "[800]\tvalid_0's binary_logloss: 0.240854\tvalid_0's auc: 0.79792\n",
      "[900]\tvalid_0's binary_logloss: 0.239568\tvalid_0's auc: 0.798033\n",
      "[1000]\tvalid_0's binary_logloss: 0.238045\tvalid_0's auc: 0.798123\n",
      "[1100]\tvalid_0's binary_logloss: 0.237327\tvalid_0's auc: 0.798263\n",
      "[1200]\tvalid_0's binary_logloss: 0.236708\tvalid_0's auc: 0.798312\n",
      "[1300]\tvalid_0's binary_logloss: 0.236504\tvalid_0's auc: 0.798381\n",
      "[1400]\tvalid_0's binary_logloss: 0.235972\tvalid_0's auc: 0.798414\n",
      "[1500]\tvalid_0's binary_logloss: 0.235604\tvalid_0's auc: 0.798426\n",
      "[1600]\tvalid_0's binary_logloss: 0.235475\tvalid_0's auc: 0.798497\n",
      "[1700]\tvalid_0's binary_logloss: 0.235528\tvalid_0's auc: 0.798509\n",
      "[1800]\tvalid_0's binary_logloss: 0.235504\tvalid_0's auc: 0.798519\n",
      "Early stopping, best iteration is:\n",
      "[1735]\tvalid_0's binary_logloss: 0.235199\tvalid_0's auc: 0.798519\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.382165\tvalid_0's auc: 0.7866\n",
      "[200]\tvalid_0's binary_logloss: 0.311184\tvalid_0's auc: 0.789419\n",
      "[300]\tvalid_0's binary_logloss: 0.28127\tvalid_0's auc: 0.790006\n",
      "[400]\tvalid_0's binary_logloss: 0.260041\tvalid_0's auc: 0.790298\n",
      "[500]\tvalid_0's binary_logloss: 0.251178\tvalid_0's auc: 0.790866\n",
      "[600]\tvalid_0's binary_logloss: 0.247635\tvalid_0's auc: 0.791364\n",
      "[700]\tvalid_0's binary_logloss: 0.244132\tvalid_0's auc: 0.791621\n",
      "[800]\tvalid_0's binary_logloss: 0.242477\tvalid_0's auc: 0.791729\n",
      "[900]\tvalid_0's binary_logloss: 0.241231\tvalid_0's auc: 0.791826\n",
      "[1000]\tvalid_0's binary_logloss: 0.239767\tvalid_0's auc: 0.79192\n",
      "[1100]\tvalid_0's binary_logloss: 0.239101\tvalid_0's auc: 0.791988\n",
      "[1200]\tvalid_0's binary_logloss: 0.238502\tvalid_0's auc: 0.792122\n",
      "[1300]\tvalid_0's binary_logloss: 0.238313\tvalid_0's auc: 0.792167\n",
      "[1400]\tvalid_0's binary_logloss: 0.237816\tvalid_0's auc: 0.792185\n",
      "Early stopping, best iteration is:\n",
      "[1335]\tvalid_0's binary_logloss: 0.238057\tvalid_0's auc: 0.792196\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.381123\tvalid_0's auc: 0.79523\n",
      "[200]\tvalid_0's binary_logloss: 0.309727\tvalid_0's auc: 0.797379\n",
      "[300]\tvalid_0's binary_logloss: 0.279526\tvalid_0's auc: 0.797589\n",
      "[400]\tvalid_0's binary_logloss: 0.258\tvalid_0's auc: 0.797744\n",
      "[500]\tvalid_0's binary_logloss: 0.248937\tvalid_0's auc: 0.798374\n",
      "[600]\tvalid_0's binary_logloss: 0.245307\tvalid_0's auc: 0.79888\n",
      "[700]\tvalid_0's binary_logloss: 0.241664\tvalid_0's auc: 0.799273\n",
      "[800]\tvalid_0's binary_logloss: 0.239961\tvalid_0's auc: 0.799684\n",
      "[900]\tvalid_0's binary_logloss: 0.238654\tvalid_0's auc: 0.799857\n",
      "[1000]\tvalid_0's binary_logloss: 0.237103\tvalid_0's auc: 0.799961\n",
      "[1100]\tvalid_0's binary_logloss: 0.236375\tvalid_0's auc: 0.800077\n",
      "[1200]\tvalid_0's binary_logloss: 0.235743\tvalid_0's auc: 0.800212\n",
      "[1300]\tvalid_0's binary_logloss: 0.235529\tvalid_0's auc: 0.800302\n",
      "[1400]\tvalid_0's binary_logloss: 0.234972\tvalid_0's auc: 0.80039\n",
      "[1500]\tvalid_0's binary_logloss: 0.234574\tvalid_0's auc: 0.800458\n",
      "[1600]\tvalid_0's binary_logloss: 0.234432\tvalid_0's auc: 0.800584\n",
      "[1700]\tvalid_0's binary_logloss: 0.234492\tvalid_0's auc: 0.800604\n",
      "[1800]\tvalid_0's binary_logloss: 0.234446\tvalid_0's auc: 0.800663\n",
      "Early stopping, best iteration is:\n",
      "[1735]\tvalid_0's binary_logloss: 0.234141\tvalid_0's auc: 0.800624\n",
      "cv score - on train:\n",
      "0.7959953313345389\n",
      "('current score in fold:', 0.7961844830213438, 4)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.387292\tvalid_0's auc: 0.791713\n",
      "[200]\tvalid_0's binary_logloss: 0.313381\tvalid_0's auc: 0.792425\n",
      "[300]\tvalid_0's binary_logloss: 0.274429\tvalid_0's auc: 0.79328\n",
      "[400]\tvalid_0's binary_logloss: 0.262257\tvalid_0's auc: 0.793287\n",
      "[500]\tvalid_0's binary_logloss: 0.254841\tvalid_0's auc: 0.793689\n",
      "[600]\tvalid_0's binary_logloss: 0.249078\tvalid_0's auc: 0.794172\n",
      "[700]\tvalid_0's binary_logloss: 0.244392\tvalid_0's auc: 0.794438\n",
      "[800]\tvalid_0's binary_logloss: 0.243074\tvalid_0's auc: 0.794562\n",
      "[900]\tvalid_0's binary_logloss: 0.241491\tvalid_0's auc: 0.794641\n",
      "[1000]\tvalid_0's binary_logloss: 0.23912\tvalid_0's auc: 0.794764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1100]\tvalid_0's binary_logloss: 0.237837\tvalid_0's auc: 0.7949\n",
      "[1200]\tvalid_0's binary_logloss: 0.237739\tvalid_0's auc: 0.795036\n",
      "Early stopping, best iteration is:\n",
      "[1161]\tvalid_0's binary_logloss: 0.237092\tvalid_0's auc: 0.795031\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.387381\tvalid_0's auc: 0.790289\n",
      "[200]\tvalid_0's binary_logloss: 0.313484\tvalid_0's auc: 0.793877\n",
      "[300]\tvalid_0's binary_logloss: 0.274458\tvalid_0's auc: 0.795131\n",
      "[400]\tvalid_0's binary_logloss: 0.26223\tvalid_0's auc: 0.795397\n",
      "[500]\tvalid_0's binary_logloss: 0.25474\tvalid_0's auc: 0.795775\n",
      "[600]\tvalid_0's binary_logloss: 0.248925\tvalid_0's auc: 0.79608\n",
      "[700]\tvalid_0's binary_logloss: 0.244191\tvalid_0's auc: 0.796274\n",
      "[800]\tvalid_0's binary_logloss: 0.242863\tvalid_0's auc: 0.796567\n",
      "[900]\tvalid_0's binary_logloss: 0.241245\tvalid_0's auc: 0.796675\n",
      "[1000]\tvalid_0's binary_logloss: 0.238828\tvalid_0's auc: 0.796754\n",
      "[1100]\tvalid_0's binary_logloss: 0.237507\tvalid_0's auc: 0.796855\n",
      "[1200]\tvalid_0's binary_logloss: 0.237413\tvalid_0's auc: 0.796947\n",
      "Early stopping, best iteration is:\n",
      "[1161]\tvalid_0's binary_logloss: 0.236752\tvalid_0's auc: 0.796957\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.387559\tvalid_0's auc: 0.786437\n",
      "[200]\tvalid_0's binary_logloss: 0.313847\tvalid_0's auc: 0.78883\n",
      "[300]\tvalid_0's binary_logloss: 0.275026\tvalid_0's auc: 0.789769\n",
      "[400]\tvalid_0's binary_logloss: 0.262928\tvalid_0's auc: 0.790121\n",
      "[500]\tvalid_0's binary_logloss: 0.255546\tvalid_0's auc: 0.790327\n",
      "[600]\tvalid_0's binary_logloss: 0.249816\tvalid_0's auc: 0.790805\n",
      "[700]\tvalid_0's binary_logloss: 0.245157\tvalid_0's auc: 0.791271\n",
      "[800]\tvalid_0's binary_logloss: 0.243856\tvalid_0's auc: 0.79143\n",
      "[900]\tvalid_0's binary_logloss: 0.242269\tvalid_0's auc: 0.791578\n",
      "[1000]\tvalid_0's binary_logloss: 0.23988\tvalid_0's auc: 0.791873\n",
      "[1100]\tvalid_0's binary_logloss: 0.238579\tvalid_0's auc: 0.792158\n",
      "[1200]\tvalid_0's binary_logloss: 0.238481\tvalid_0's auc: 0.792257\n",
      "Early stopping, best iteration is:\n",
      "[1161]\tvalid_0's binary_logloss: 0.237838\tvalid_0's auc: 0.792259\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.387296\tvalid_0's auc: 0.78962\n",
      "[200]\tvalid_0's binary_logloss: 0.313364\tvalid_0's auc: 0.793924\n",
      "[300]\tvalid_0's binary_logloss: 0.27437\tvalid_0's auc: 0.793888\n",
      "[400]\tvalid_0's binary_logloss: 0.262158\tvalid_0's auc: 0.794314\n",
      "[500]\tvalid_0's binary_logloss: 0.254697\tvalid_0's auc: 0.79481\n",
      "[600]\tvalid_0's binary_logloss: 0.248895\tvalid_0's auc: 0.795416\n",
      "[700]\tvalid_0's binary_logloss: 0.244223\tvalid_0's auc: 0.795794\n",
      "[800]\tvalid_0's binary_logloss: 0.242904\tvalid_0's auc: 0.795903\n",
      "[900]\tvalid_0's binary_logloss: 0.241302\tvalid_0's auc: 0.796079\n",
      "[1000]\tvalid_0's binary_logloss: 0.238925\tvalid_0's auc: 0.796258\n",
      "[1100]\tvalid_0's binary_logloss: 0.237621\tvalid_0's auc: 0.796449\n",
      "[1200]\tvalid_0's binary_logloss: 0.237518\tvalid_0's auc: 0.796577\n",
      "Early stopping, best iteration is:\n",
      "[1161]\tvalid_0's binary_logloss: 0.236887\tvalid_0's auc: 0.796531\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.387191\tvalid_0's auc: 0.794693\n",
      "[200]\tvalid_0's binary_logloss: 0.31324\tvalid_0's auc: 0.796153\n",
      "[300]\tvalid_0's binary_logloss: 0.274154\tvalid_0's auc: 0.796598\n",
      "[400]\tvalid_0's binary_logloss: 0.261908\tvalid_0's auc: 0.797026\n",
      "[500]\tvalid_0's binary_logloss: 0.254392\tvalid_0's auc: 0.797443\n",
      "[600]\tvalid_0's binary_logloss: 0.248568\tvalid_0's auc: 0.798058\n",
      "[700]\tvalid_0's binary_logloss: 0.24382\tvalid_0's auc: 0.798311\n",
      "[800]\tvalid_0's binary_logloss: 0.242488\tvalid_0's auc: 0.798448\n",
      "[900]\tvalid_0's binary_logloss: 0.240877\tvalid_0's auc: 0.798527\n",
      "[1000]\tvalid_0's binary_logloss: 0.238421\tvalid_0's auc: 0.798779\n",
      "[1100]\tvalid_0's binary_logloss: 0.237065\tvalid_0's auc: 0.798954\n",
      "[1200]\tvalid_0's binary_logloss: 0.236955\tvalid_0's auc: 0.799045\n",
      "Early stopping, best iteration is:\n",
      "[1161]\tvalid_0's binary_logloss: 0.236292\tvalid_0's auc: 0.799033\n",
      "cv score - on train:\n",
      "0.7957973358417406\n",
      "('current score in fold:', 0.79615019020638, 5)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.379457\tvalid_0's auc: 0.790883\n",
      "[200]\tvalid_0's binary_logloss: 0.302423\tvalid_0's auc: 0.793003\n",
      "[300]\tvalid_0's binary_logloss: 0.274422\tvalid_0's auc: 0.793094\n",
      "[400]\tvalid_0's binary_logloss: 0.259423\tvalid_0's auc: 0.793572\n",
      "[500]\tvalid_0's binary_logloss: 0.25731\tvalid_0's auc: 0.793764\n",
      "[600]\tvalid_0's binary_logloss: 0.249757\tvalid_0's auc: 0.794239\n",
      "[700]\tvalid_0's binary_logloss: 0.247089\tvalid_0's auc: 0.794494\n",
      "[800]\tvalid_0's binary_logloss: 0.244239\tvalid_0's auc: 0.794877\n",
      "[900]\tvalid_0's binary_logloss: 0.242289\tvalid_0's auc: 0.79508\n",
      "[1000]\tvalid_0's binary_logloss: 0.240495\tvalid_0's auc: 0.795267\n",
      "[1100]\tvalid_0's binary_logloss: 0.239666\tvalid_0's auc: 0.795405\n",
      "[1200]\tvalid_0's binary_logloss: 0.238994\tvalid_0's auc: 0.795524\n",
      "[1300]\tvalid_0's binary_logloss: 0.237832\tvalid_0's auc: 0.795701\n",
      "[1400]\tvalid_0's binary_logloss: 0.237871\tvalid_0's auc: 0.795799\n",
      "Early stopping, best iteration is:\n",
      "[1310]\tvalid_0's binary_logloss: 0.237688\tvalid_0's auc: 0.795702\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.378954\tvalid_0's auc: 0.792331\n",
      "[200]\tvalid_0's binary_logloss: 0.301738\tvalid_0's auc: 0.795066\n",
      "[300]\tvalid_0's binary_logloss: 0.273595\tvalid_0's auc: 0.796354\n",
      "[400]\tvalid_0's binary_logloss: 0.258493\tvalid_0's auc: 0.79679\n",
      "[500]\tvalid_0's binary_logloss: 0.25635\tvalid_0's auc: 0.796941\n",
      "[600]\tvalid_0's binary_logloss: 0.248746\tvalid_0's auc: 0.797174\n",
      "[700]\tvalid_0's binary_logloss: 0.246066\tvalid_0's auc: 0.79738\n",
      "[800]\tvalid_0's binary_logloss: 0.243212\tvalid_0's auc: 0.797584\n",
      "[900]\tvalid_0's binary_logloss: 0.241267\tvalid_0's auc: 0.797652\n",
      "[1000]\tvalid_0's binary_logloss: 0.239478\tvalid_0's auc: 0.797755\n",
      "[1100]\tvalid_0's binary_logloss: 0.238662\tvalid_0's auc: 0.797879\n",
      "[1200]\tvalid_0's binary_logloss: 0.237996\tvalid_0's auc: 0.797988\n",
      "[1300]\tvalid_0's binary_logloss: 0.236841\tvalid_0's auc: 0.798064\n",
      "[1400]\tvalid_0's binary_logloss: 0.236909\tvalid_0's auc: 0.798106\n",
      "Early stopping, best iteration is:\n",
      "[1310]\tvalid_0's binary_logloss: 0.236699\tvalid_0's auc: 0.798065\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.37921\tvalid_0's auc: 0.790077\n",
      "[200]\tvalid_0's binary_logloss: 0.302245\tvalid_0's auc: 0.791135\n",
      "[300]\tvalid_0's binary_logloss: 0.274273\tvalid_0's auc: 0.791443\n",
      "[400]\tvalid_0's binary_logloss: 0.259325\tvalid_0's auc: 0.791949\n",
      "[500]\tvalid_0's binary_logloss: 0.257198\tvalid_0's auc: 0.792585\n",
      "[600]\tvalid_0's binary_logloss: 0.249712\tvalid_0's auc: 0.792828\n",
      "[700]\tvalid_0's binary_logloss: 0.247083\tvalid_0's auc: 0.793062\n",
      "[800]\tvalid_0's binary_logloss: 0.244299\tvalid_0's auc: 0.793186\n",
      "[900]\tvalid_0's binary_logloss: 0.242412\tvalid_0's auc: 0.793289\n",
      "[1000]\tvalid_0's binary_logloss: 0.240667\tvalid_0's auc: 0.793371\n",
      "[1100]\tvalid_0's binary_logloss: 0.239871\tvalid_0's auc: 0.793452\n",
      "[1200]\tvalid_0's binary_logloss: 0.239233\tvalid_0's auc: 0.793534\n",
      "[1300]\tvalid_0's binary_logloss: 0.238119\tvalid_0's auc: 0.793636\n",
      "[1400]\tvalid_0's binary_logloss: 0.238167\tvalid_0's auc: 0.793686\n",
      "Early stopping, best iteration is:\n",
      "[1310]\tvalid_0's binary_logloss: 0.237982\tvalid_0's auc: 0.793642\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.378823\tvalid_0's auc: 0.791513\n",
      "[200]\tvalid_0's binary_logloss: 0.301604\tvalid_0's auc: 0.794322\n",
      "[300]\tvalid_0's binary_logloss: 0.273486\tvalid_0's auc: 0.794989\n",
      "[400]\tvalid_0's binary_logloss: 0.258448\tvalid_0's auc: 0.795333\n",
      "[500]\tvalid_0's binary_logloss: 0.256306\tvalid_0's auc: 0.795511\n",
      "[600]\tvalid_0's binary_logloss: 0.248739\tvalid_0's auc: 0.795864\n",
      "[700]\tvalid_0's binary_logloss: 0.246083\tvalid_0's auc: 0.796085\n",
      "[800]\tvalid_0's binary_logloss: 0.243281\tvalid_0's auc: 0.796302\n",
      "[900]\tvalid_0's binary_logloss: 0.241353\tvalid_0's auc: 0.796499\n",
      "[1000]\tvalid_0's binary_logloss: 0.239585\tvalid_0's auc: 0.79662\n",
      "[1100]\tvalid_0's binary_logloss: 0.238778\tvalid_0's auc: 0.796725\n",
      "[1200]\tvalid_0's binary_logloss: 0.238136\tvalid_0's auc: 0.79685\n",
      "[1300]\tvalid_0's binary_logloss: 0.237002\tvalid_0's auc: 0.796936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1400]\tvalid_0's binary_logloss: 0.23706\tvalid_0's auc: 0.796945\n",
      "Early stopping, best iteration is:\n",
      "[1310]\tvalid_0's binary_logloss: 0.236859\tvalid_0's auc: 0.796944\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.379334\tvalid_0's auc: 0.790085\n",
      "[200]\tvalid_0's binary_logloss: 0.302245\tvalid_0's auc: 0.792733\n",
      "[300]\tvalid_0's binary_logloss: 0.274187\tvalid_0's auc: 0.793341\n",
      "[400]\tvalid_0's binary_logloss: 0.2592\tvalid_0's auc: 0.79345\n",
      "[500]\tvalid_0's binary_logloss: 0.257108\tvalid_0's auc: 0.793823\n",
      "[600]\tvalid_0's binary_logloss: 0.249558\tvalid_0's auc: 0.794034\n",
      "[700]\tvalid_0's binary_logloss: 0.24692\tvalid_0's auc: 0.79432\n",
      "[800]\tvalid_0's binary_logloss: 0.244107\tvalid_0's auc: 0.794524\n",
      "[900]\tvalid_0's binary_logloss: 0.242191\tvalid_0's auc: 0.794786\n",
      "[1000]\tvalid_0's binary_logloss: 0.240399\tvalid_0's auc: 0.794889\n",
      "[1100]\tvalid_0's binary_logloss: 0.239565\tvalid_0's auc: 0.795073\n",
      "[1200]\tvalid_0's binary_logloss: 0.238906\tvalid_0's auc: 0.795166\n",
      "[1300]\tvalid_0's binary_logloss: 0.237751\tvalid_0's auc: 0.79528\n",
      "[1400]\tvalid_0's binary_logloss: 0.237817\tvalid_0's auc: 0.795324\n",
      "Early stopping, best iteration is:\n",
      "[1310]\tvalid_0's binary_logloss: 0.237608\tvalid_0's auc: 0.795286\n",
      "cv score - on train:\n",
      "0.7957921775130257\n",
      "('current score in fold:', 0.7961244983108697, 6)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.386157\tvalid_0's auc: 0.793915\n",
      "[200]\tvalid_0's binary_logloss: 0.313733\tvalid_0's auc: 0.794479\n",
      "[300]\tvalid_0's binary_logloss: 0.279467\tvalid_0's auc: 0.794845\n",
      "[400]\tvalid_0's binary_logloss: 0.267529\tvalid_0's auc: 0.794885\n",
      "[500]\tvalid_0's binary_logloss: 0.253685\tvalid_0's auc: 0.795524\n",
      "[600]\tvalid_0's binary_logloss: 0.247813\tvalid_0's auc: 0.795847\n",
      "[700]\tvalid_0's binary_logloss: 0.244974\tvalid_0's auc: 0.796118\n",
      "[800]\tvalid_0's binary_logloss: 0.243848\tvalid_0's auc: 0.79615\n",
      "[900]\tvalid_0's binary_logloss: 0.240361\tvalid_0's auc: 0.796356\n",
      "[1000]\tvalid_0's binary_logloss: 0.239923\tvalid_0's auc: 0.796481\n",
      "[1100]\tvalid_0's binary_logloss: 0.238038\tvalid_0's auc: 0.796623\n",
      "[1200]\tvalid_0's binary_logloss: 0.236755\tvalid_0's auc: 0.796769\n",
      "[1300]\tvalid_0's binary_logloss: 0.236003\tvalid_0's auc: 0.797009\n",
      "[1400]\tvalid_0's binary_logloss: 0.235754\tvalid_0's auc: 0.797127\n",
      "[1500]\tvalid_0's binary_logloss: 0.235831\tvalid_0's auc: 0.797192\n",
      "Early stopping, best iteration is:\n",
      "[1404]\tvalid_0's binary_logloss: 0.235651\tvalid_0's auc: 0.797144\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.386548\tvalid_0's auc: 0.78409\n",
      "[200]\tvalid_0's binary_logloss: 0.314367\tvalid_0's auc: 0.787557\n",
      "[300]\tvalid_0's binary_logloss: 0.280247\tvalid_0's auc: 0.78955\n",
      "[400]\tvalid_0's binary_logloss: 0.268366\tvalid_0's auc: 0.790225\n",
      "[500]\tvalid_0's binary_logloss: 0.254613\tvalid_0's auc: 0.790506\n",
      "[600]\tvalid_0's binary_logloss: 0.248793\tvalid_0's auc: 0.790881\n",
      "[700]\tvalid_0's binary_logloss: 0.245973\tvalid_0's auc: 0.791401\n",
      "[800]\tvalid_0's binary_logloss: 0.244848\tvalid_0's auc: 0.791513\n",
      "[900]\tvalid_0's binary_logloss: 0.241415\tvalid_0's auc: 0.79174\n",
      "[1000]\tvalid_0's binary_logloss: 0.240995\tvalid_0's auc: 0.791899\n",
      "[1100]\tvalid_0's binary_logloss: 0.239172\tvalid_0's auc: 0.792048\n",
      "[1200]\tvalid_0's binary_logloss: 0.237935\tvalid_0's auc: 0.792225\n",
      "[1300]\tvalid_0's binary_logloss: 0.237252\tvalid_0's auc: 0.792337\n",
      "[1400]\tvalid_0's binary_logloss: 0.237042\tvalid_0's auc: 0.792384\n",
      "[1500]\tvalid_0's binary_logloss: 0.237132\tvalid_0's auc: 0.792416\n",
      "Early stopping, best iteration is:\n",
      "[1404]\tvalid_0's binary_logloss: 0.236948\tvalid_0's auc: 0.792391\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.386247\tvalid_0's auc: 0.791479\n",
      "[200]\tvalid_0's binary_logloss: 0.313875\tvalid_0's auc: 0.793183\n",
      "[300]\tvalid_0's binary_logloss: 0.279667\tvalid_0's auc: 0.793671\n",
      "[400]\tvalid_0's binary_logloss: 0.267738\tvalid_0's auc: 0.793731\n",
      "[500]\tvalid_0's binary_logloss: 0.25392\tvalid_0's auc: 0.794088\n",
      "[600]\tvalid_0's binary_logloss: 0.248061\tvalid_0's auc: 0.794414\n",
      "[700]\tvalid_0's binary_logloss: 0.245227\tvalid_0's auc: 0.794739\n",
      "[800]\tvalid_0's binary_logloss: 0.244098\tvalid_0's auc: 0.794915\n",
      "[900]\tvalid_0's binary_logloss: 0.240616\tvalid_0's auc: 0.795013\n",
      "[1000]\tvalid_0's binary_logloss: 0.240195\tvalid_0's auc: 0.795081\n",
      "[1100]\tvalid_0's binary_logloss: 0.238321\tvalid_0's auc: 0.795261\n",
      "[1200]\tvalid_0's binary_logloss: 0.237043\tvalid_0's auc: 0.795415\n",
      "[1300]\tvalid_0's binary_logloss: 0.236309\tvalid_0's auc: 0.795553\n",
      "[1400]\tvalid_0's binary_logloss: 0.236064\tvalid_0's auc: 0.795674\n",
      "[1500]\tvalid_0's binary_logloss: 0.236149\tvalid_0's auc: 0.795712\n",
      "Early stopping, best iteration is:\n",
      "[1404]\tvalid_0's binary_logloss: 0.235964\tvalid_0's auc: 0.795685\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.386071\tvalid_0's auc: 0.792637\n",
      "[200]\tvalid_0's binary_logloss: 0.313688\tvalid_0's auc: 0.794089\n",
      "[300]\tvalid_0's binary_logloss: 0.279444\tvalid_0's auc: 0.79485\n",
      "[400]\tvalid_0's binary_logloss: 0.267475\tvalid_0's auc: 0.795229\n",
      "[500]\tvalid_0's binary_logloss: 0.253621\tvalid_0's auc: 0.795559\n",
      "[600]\tvalid_0's binary_logloss: 0.247735\tvalid_0's auc: 0.79639\n",
      "[700]\tvalid_0's binary_logloss: 0.244867\tvalid_0's auc: 0.796586\n",
      "[800]\tvalid_0's binary_logloss: 0.243744\tvalid_0's auc: 0.796624\n",
      "[900]\tvalid_0's binary_logloss: 0.240261\tvalid_0's auc: 0.796873\n",
      "[1000]\tvalid_0's binary_logloss: 0.239831\tvalid_0's auc: 0.796999\n",
      "[1100]\tvalid_0's binary_logloss: 0.237952\tvalid_0's auc: 0.797158\n",
      "[1200]\tvalid_0's binary_logloss: 0.236673\tvalid_0's auc: 0.797329\n",
      "[1300]\tvalid_0's binary_logloss: 0.23595\tvalid_0's auc: 0.797386\n",
      "[1400]\tvalid_0's binary_logloss: 0.235723\tvalid_0's auc: 0.797423\n",
      "[1500]\tvalid_0's binary_logloss: 0.235815\tvalid_0's auc: 0.797421\n",
      "Early stopping, best iteration is:\n",
      "[1404]\tvalid_0's binary_logloss: 0.235624\tvalid_0's auc: 0.797427\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.385953\tvalid_0's auc: 0.793326\n",
      "[200]\tvalid_0's binary_logloss: 0.313469\tvalid_0's auc: 0.795341\n",
      "[300]\tvalid_0's binary_logloss: 0.279206\tvalid_0's auc: 0.795456\n",
      "[400]\tvalid_0's binary_logloss: 0.267237\tvalid_0's auc: 0.795777\n",
      "[500]\tvalid_0's binary_logloss: 0.253354\tvalid_0's auc: 0.796325\n",
      "[600]\tvalid_0's binary_logloss: 0.247436\tvalid_0's auc: 0.79703\n",
      "[700]\tvalid_0's binary_logloss: 0.244555\tvalid_0's auc: 0.797262\n",
      "[800]\tvalid_0's binary_logloss: 0.243414\tvalid_0's auc: 0.797665\n",
      "[900]\tvalid_0's binary_logloss: 0.239896\tvalid_0's auc: 0.797944\n",
      "[1000]\tvalid_0's binary_logloss: 0.239448\tvalid_0's auc: 0.798076\n",
      "[1100]\tvalid_0's binary_logloss: 0.237556\tvalid_0's auc: 0.798242\n",
      "[1200]\tvalid_0's binary_logloss: 0.236261\tvalid_0's auc: 0.79839\n",
      "[1300]\tvalid_0's binary_logloss: 0.235514\tvalid_0's auc: 0.798532\n",
      "[1400]\tvalid_0's binary_logloss: 0.235275\tvalid_0's auc: 0.798601\n",
      "[1500]\tvalid_0's binary_logloss: 0.235359\tvalid_0's auc: 0.798653\n",
      "Early stopping, best iteration is:\n",
      "[1404]\tvalid_0's binary_logloss: 0.235176\tvalid_0's auc: 0.798601\n",
      "cv score - on train:\n",
      "0.796096528027044\n",
      "('current score in fold:', 0.7961440994469975, 7)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.38051\tvalid_0's auc: 0.787715\n",
      "[200]\tvalid_0's binary_logloss: 0.304518\tvalid_0's auc: 0.790975\n",
      "[300]\tvalid_0's binary_logloss: 0.272622\tvalid_0's auc: 0.791669\n",
      "[400]\tvalid_0's binary_logloss: 0.262998\tvalid_0's auc: 0.791965\n",
      "[500]\tvalid_0's binary_logloss: 0.252262\tvalid_0's auc: 0.792773\n",
      "[600]\tvalid_0's binary_logloss: 0.247105\tvalid_0's auc: 0.792959\n",
      "[700]\tvalid_0's binary_logloss: 0.244969\tvalid_0's auc: 0.793082\n",
      "[800]\tvalid_0's binary_logloss: 0.240908\tvalid_0's auc: 0.793302\n",
      "[900]\tvalid_0's binary_logloss: 0.239794\tvalid_0's auc: 0.793577\n",
      "[1000]\tvalid_0's binary_logloss: 0.239581\tvalid_0's auc: 0.79371\n",
      "[1100]\tvalid_0's binary_logloss: 0.238128\tvalid_0's auc: 0.793834\n",
      "[1200]\tvalid_0's binary_logloss: 0.237816\tvalid_0's auc: 0.793993\n",
      "[1300]\tvalid_0's binary_logloss: 0.237847\tvalid_0's auc: 0.794065\n",
      "Early stopping, best iteration is:\n",
      "[1212]\tvalid_0's binary_logloss: 0.237613\tvalid_0's auc: 0.794013\n",
      "Training until validation scores don't improve for 100 rounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.380264\tvalid_0's auc: 0.790267\n",
      "[200]\tvalid_0's binary_logloss: 0.304141\tvalid_0's auc: 0.791513\n",
      "[300]\tvalid_0's binary_logloss: 0.272207\tvalid_0's auc: 0.792948\n",
      "[400]\tvalid_0's binary_logloss: 0.262541\tvalid_0's auc: 0.793249\n",
      "[500]\tvalid_0's binary_logloss: 0.251778\tvalid_0's auc: 0.793774\n",
      "[600]\tvalid_0's binary_logloss: 0.246611\tvalid_0's auc: 0.794076\n",
      "[700]\tvalid_0's binary_logloss: 0.244477\tvalid_0's auc: 0.79442\n",
      "[800]\tvalid_0's binary_logloss: 0.240432\tvalid_0's auc: 0.794702\n",
      "[900]\tvalid_0's binary_logloss: 0.239316\tvalid_0's auc: 0.79488\n",
      "[1000]\tvalid_0's binary_logloss: 0.239114\tvalid_0's auc: 0.794962\n",
      "[1100]\tvalid_0's binary_logloss: 0.237691\tvalid_0's auc: 0.795017\n",
      "[1200]\tvalid_0's binary_logloss: 0.237386\tvalid_0's auc: 0.795121\n",
      "[1300]\tvalid_0's binary_logloss: 0.237432\tvalid_0's auc: 0.795158\n",
      "Early stopping, best iteration is:\n",
      "[1212]\tvalid_0's binary_logloss: 0.237188\tvalid_0's auc: 0.795132\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.380594\tvalid_0's auc: 0.784921\n",
      "[200]\tvalid_0's binary_logloss: 0.304702\tvalid_0's auc: 0.788334\n",
      "[300]\tvalid_0's binary_logloss: 0.272908\tvalid_0's auc: 0.789287\n",
      "[400]\tvalid_0's binary_logloss: 0.26333\tvalid_0's auc: 0.79017\n",
      "[500]\tvalid_0's binary_logloss: 0.252715\tvalid_0's auc: 0.790477\n",
      "[600]\tvalid_0's binary_logloss: 0.247624\tvalid_0's auc: 0.790769\n",
      "[700]\tvalid_0's binary_logloss: 0.245521\tvalid_0's auc: 0.790962\n",
      "[800]\tvalid_0's binary_logloss: 0.241567\tvalid_0's auc: 0.791198\n",
      "[900]\tvalid_0's binary_logloss: 0.24049\tvalid_0's auc: 0.791462\n",
      "[1000]\tvalid_0's binary_logloss: 0.240292\tvalid_0's auc: 0.791539\n",
      "[1100]\tvalid_0's binary_logloss: 0.238921\tvalid_0's auc: 0.79163\n",
      "[1200]\tvalid_0's binary_logloss: 0.238629\tvalid_0's auc: 0.791698\n",
      "[1300]\tvalid_0's binary_logloss: 0.238669\tvalid_0's auc: 0.791729\n",
      "Early stopping, best iteration is:\n",
      "[1212]\tvalid_0's binary_logloss: 0.238441\tvalid_0's auc: 0.791713\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.38013\tvalid_0's auc: 0.792025\n",
      "[200]\tvalid_0's binary_logloss: 0.303908\tvalid_0's auc: 0.796532\n",
      "[300]\tvalid_0's binary_logloss: 0.271797\tvalid_0's auc: 0.797295\n",
      "[400]\tvalid_0's binary_logloss: 0.26207\tvalid_0's auc: 0.797804\n",
      "[500]\tvalid_0's binary_logloss: 0.251245\tvalid_0's auc: 0.797988\n",
      "[600]\tvalid_0's binary_logloss: 0.24605\tvalid_0's auc: 0.798227\n",
      "[700]\tvalid_0's binary_logloss: 0.243886\tvalid_0's auc: 0.798391\n",
      "[800]\tvalid_0's binary_logloss: 0.23977\tvalid_0's auc: 0.798613\n",
      "[900]\tvalid_0's binary_logloss: 0.238627\tvalid_0's auc: 0.798716\n",
      "[1000]\tvalid_0's binary_logloss: 0.238405\tvalid_0's auc: 0.798858\n",
      "[1100]\tvalid_0's binary_logloss: 0.236934\tvalid_0's auc: 0.798978\n",
      "[1200]\tvalid_0's binary_logloss: 0.236616\tvalid_0's auc: 0.799029\n"
     ]
    }
   ],
   "source": [
    "final_cv_train = np.zeros(len(labels_train))\n",
    "final_cv_pred = np.zeros(len( test_ids ))\n",
    "\n",
    "NFOLDS = 5 \n",
    "\n",
    "M = 16 \n",
    "x_score = []\n",
    "for s in range( M ):\n",
    "    \n",
    "    params['seed'] = s\n",
    "    \n",
    "    cv_train = np.zeros( len( labels_train ))\n",
    "    cv_pred = np.zeros( len( test_ids ) )\n",
    "    kfold = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=s)\n",
    "    kf  = kfold.split(  new_train , labels_train )\n",
    "    \n",
    "    for i, (train_fold, validate) in enumerate(kf):\n",
    "        \n",
    "        X_train, X_validate, label_train, label_validate = new_train[train_fold, :], new_train[validate, :], labels_train[train_fold], labels_train[validate]\n",
    "    \n",
    "    #X_train, X_validate, label_train, label_validate = X[train_fold, :], X[validate, :], labels_train[train_fold], labels_train[validate]\n",
    "        dtrain = lgb.Dataset( X_train , label_train  )\n",
    "    \n",
    "        dvalid = lgb.Dataset(  X_validate  , label_validate , reference=dtrain )\n",
    "        bst = lgb.train(params, dtrain , num_boost_round , valid_sets=[dvalid ] , verbose_eval = 100 , early_stopping_rounds = 100 )\n",
    "    #best_trees.append(bst.best_iteration)    \n",
    "        cv_pred +=  bst.predict(  new_test , num_iteration = bst.best_iteration )\n",
    "    #cv_eval_total += bst.predict( x_val , num_iteration = bst.best_iteration )          \n",
    "        cv_train[validate] += bst.predict( X_validate )\n",
    "        \n",
    "        \n",
    "    cv_pred /= NFOLDS\n",
    "    \n",
    "    final_cv_train += cv_train\n",
    "    final_cv_pred += cv_pred\n",
    "    \n",
    "    print(\"cv score - on train:\")\n",
    "    print( roc_auc_score(labels_train, cv_train))\n",
    "    print( \"current score in fold:\", roc_auc_score( labels_train , final_cv_train / (s + 1.)), s+1)\n",
    "    \n",
    "    x_score.append(roc_auc_score( labels_train , cv_train))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7809469043300058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7374227103360562,\n",
       " 0.8012891254039022,\n",
       " 0.7656663300098203,\n",
       " 0.7558432037072309,\n",
       " 0.790449433006702,\n",
       " 0.801253998125121,\n",
       " 0.801639766928955,\n",
       " 0.80134402196555,\n",
       " 0.757062446542607,\n",
       " 0.7471681182183294,\n",
       " 0.8013086862845605,\n",
       " 0.8009824354415024,\n",
       " 0.8012619285950764,\n",
       " 0.8007582549415067,\n",
       " 0.7739928274300968,\n",
       " 0.7577071823430762]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( np.array(x_score).mean())\n",
    "x_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred_lgb = final_cv_pred/M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist( final_pred_lgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': final_pred_lgb }).to_csv('../data/pred_lgb_oof-16.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGboost model with oof_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "num_leaves = 30\n",
    "min_data_in_leaf = 2000\n",
    "feature_fraction = 0.9\n",
    "num_boost_round = 5000\n",
    "params = {\"booster\": \"gbtree\",\n",
    "         \"eta\" : learning_rate , \n",
    "          \"max_depth\" : 5 , \n",
    "          \"colsample_bytree\" : feature_fraction , \n",
    "          \"lambda\" : 100 , \n",
    "           \"tree_method\" : \"hist\" , \n",
    "          \"max_bin\" : 256 , \n",
    "          \"rate_drop\": 0.01 , \n",
    "          'objective': 'binary:logistic' , \n",
    "          \"eval_metric\" : \"auc\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.758766\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.79067\n",
      "[200]\teval-auc:0.796796\n",
      "[300]\teval-auc:0.798211\n",
      "[400]\teval-auc:0.799542\n",
      "[500]\teval-auc:0.80033\n",
      "[600]\teval-auc:0.8007\n",
      "[700]\teval-auc:0.800779\n",
      "[800]\teval-auc:0.800827\n",
      "[900]\teval-auc:0.800872\n",
      "[1000]\teval-auc:0.800916\n",
      "[1100]\teval-auc:0.80097\n",
      "[1200]\teval-auc:0.800968\n",
      "[1300]\teval-auc:0.80102\n",
      "[1400]\teval-auc:0.801025\n",
      "Stopping. Best iteration:\n",
      "[1337]\teval-auc:0.801037\n",
      "\n",
      "[0]\teval-auc:0.766473\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.796686\n",
      "[200]\teval-auc:0.799213\n",
      "[300]\teval-auc:0.80033\n",
      "[400]\teval-auc:0.801508\n",
      "[500]\teval-auc:0.802192\n",
      "[600]\teval-auc:0.802377\n",
      "[700]\teval-auc:0.802405\n",
      "Stopping. Best iteration:\n",
      "[636]\teval-auc:0.80242\n",
      "\n",
      "[0]\teval-auc:0.770039\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.793108\n",
      "[200]\teval-auc:0.796828\n",
      "[300]\teval-auc:0.798536\n",
      "[400]\teval-auc:0.799844\n",
      "[500]\teval-auc:0.800461\n",
      "[600]\teval-auc:0.800584\n",
      "[700]\teval-auc:0.80071\n",
      "Stopping. Best iteration:\n",
      "[690]\teval-auc:0.800713\n",
      "\n",
      "[0]\teval-auc:0.776121\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.800158\n",
      "[200]\teval-auc:0.803024\n",
      "[300]\teval-auc:0.804796\n",
      "[400]\teval-auc:0.806025\n",
      "[500]\teval-auc:0.806369\n",
      "[600]\teval-auc:0.806584\n",
      "[700]\teval-auc:0.806698\n",
      "[800]\teval-auc:0.80668\n",
      "Stopping. Best iteration:\n",
      "[702]\teval-auc:0.8067\n",
      "\n",
      "[0]\teval-auc:0.764768\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.796462\n",
      "[200]\teval-auc:0.800452\n",
      "[300]\teval-auc:0.802007\n",
      "[400]\teval-auc:0.803805\n",
      "[500]\teval-auc:0.804718\n",
      "[600]\teval-auc:0.805137\n",
      "[700]\teval-auc:0.805208\n",
      "[800]\teval-auc:0.805266\n",
      "[900]\teval-auc:0.805324\n",
      "[1000]\teval-auc:0.805427\n",
      "[1100]\teval-auc:0.805507\n",
      "[1200]\teval-auc:0.805549\n",
      "[1300]\teval-auc:0.805542\n",
      "Stopping. Best iteration:\n",
      "[1251]\teval-auc:0.805561\n",
      "\n",
      "cv score - on train:\n",
      "0.8031961184693241\n",
      "('current score in fold:', 0.8031961184693241, 1)\n",
      "[0]\teval-auc:0.768604\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.792946\n",
      "[200]\teval-auc:0.797129\n",
      "[300]\teval-auc:0.79846\n",
      "[400]\teval-auc:0.799336\n",
      "[500]\teval-auc:0.799922\n",
      "[600]\teval-auc:0.80015\n",
      "[700]\teval-auc:0.800171\n",
      "[800]\teval-auc:0.800244\n",
      "[900]\teval-auc:0.800314\n",
      "[1000]\teval-auc:0.800381\n",
      "[1100]\teval-auc:0.800438\n",
      "[1200]\teval-auc:0.800451\n",
      "Stopping. Best iteration:\n",
      "[1189]\teval-auc:0.800457\n",
      "\n",
      "[0]\teval-auc:0.765096\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.796888\n",
      "[200]\teval-auc:0.800537\n",
      "[300]\teval-auc:0.802123\n",
      "[400]\teval-auc:0.803541\n",
      "[500]\teval-auc:0.804398\n",
      "[600]\teval-auc:0.804724\n",
      "[700]\teval-auc:0.804833\n",
      "[800]\teval-auc:0.804833\n",
      "Stopping. Best iteration:\n",
      "[729]\teval-auc:0.804837\n",
      "\n",
      "[0]\teval-auc:0.765903\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.797521\n",
      "[200]\teval-auc:0.800543\n",
      "[300]\teval-auc:0.803314\n",
      "[400]\teval-auc:0.804852\n",
      "[500]\teval-auc:0.805767\n",
      "[600]\teval-auc:0.806216\n",
      "[700]\teval-auc:0.806336\n",
      "[800]\teval-auc:0.80641\n",
      "[900]\teval-auc:0.806431\n",
      "[1000]\teval-auc:0.806493\n",
      "[1100]\teval-auc:0.806519\n",
      "Stopping. Best iteration:\n",
      "[1066]\teval-auc:0.806522\n",
      "\n",
      "[0]\teval-auc:0.772787\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.795359\n",
      "[200]\teval-auc:0.798789\n",
      "[300]\teval-auc:0.800364\n",
      "[400]\teval-auc:0.801397\n",
      "[500]\teval-auc:0.801881\n",
      "[600]\teval-auc:0.802126\n",
      "[700]\teval-auc:0.80226\n",
      "[800]\teval-auc:0.802325\n",
      "[900]\teval-auc:0.802366\n",
      "[1000]\teval-auc:0.802394\n",
      "[1100]\teval-auc:0.802405\n",
      "Stopping. Best iteration:\n",
      "[1033]\teval-auc:0.802409\n",
      "\n",
      "[0]\teval-auc:0.761813\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.796551\n",
      "[200]\teval-auc:0.799424\n",
      "[300]\teval-auc:0.800981\n",
      "[400]\teval-auc:0.802249\n",
      "[500]\teval-auc:0.802733\n",
      "[600]\teval-auc:0.80305\n",
      "[700]\teval-auc:0.803242\n",
      "[800]\teval-auc:0.803277\n",
      "Stopping. Best iteration:\n",
      "[780]\teval-auc:0.803281\n",
      "\n",
      "cv score - on train:\n",
      "0.8034262938280621\n",
      "('current score in fold:', 0.8035018822709348, 2)\n",
      "[0]\teval-auc:0.761327\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.791217\n",
      "[200]\teval-auc:0.794188\n",
      "[300]\teval-auc:0.795979\n",
      "[400]\teval-auc:0.797436\n",
      "[500]\teval-auc:0.798098\n",
      "[600]\teval-auc:0.798432\n",
      "[700]\teval-auc:0.798531\n",
      "[800]\teval-auc:0.798546\n",
      "[900]\teval-auc:0.798584\n",
      "[1000]\teval-auc:0.798669\n",
      "[1100]\teval-auc:0.798672\n",
      "Stopping. Best iteration:\n",
      "[1006]\teval-auc:0.79868\n",
      "\n",
      "[0]\teval-auc:0.762755\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.79328\n",
      "[200]\teval-auc:0.798094\n",
      "[300]\teval-auc:0.799446\n",
      "[400]\teval-auc:0.800544\n",
      "[500]\teval-auc:0.800945\n",
      "[600]\teval-auc:0.801228\n",
      "[700]\teval-auc:0.801272\n",
      "[800]\teval-auc:0.80129\n",
      "[900]\teval-auc:0.801314\n",
      "[1000]\teval-auc:0.801333\n",
      "[1100]\teval-auc:0.801343\n",
      "[1200]\teval-auc:0.801356\n",
      "[1300]\teval-auc:0.801383\n",
      "[1400]\teval-auc:0.80137\n",
      "Stopping. Best iteration:\n",
      "[1305]\teval-auc:0.801386\n",
      "\n",
      "[0]\teval-auc:0.773506\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.797787\n",
      "[200]\teval-auc:0.80122\n",
      "[300]\teval-auc:0.802816\n",
      "[400]\teval-auc:0.804126\n",
      "[500]\teval-auc:0.804627\n",
      "[600]\teval-auc:0.804848\n",
      "[700]\teval-auc:0.804988\n",
      "[800]\teval-auc:0.805026\n",
      "[900]\teval-auc:0.805119\n",
      "[1000]\teval-auc:0.805193\n",
      "[1100]\teval-auc:0.805194\n",
      "[1200]\teval-auc:0.805213\n",
      "[1300]\teval-auc:0.805194\n",
      "Stopping. Best iteration:\n",
      "[1202]\teval-auc:0.805215\n",
      "\n",
      "[0]\teval-auc:0.776792\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.80118\n",
      "[200]\teval-auc:0.80395\n",
      "[300]\teval-auc:0.805762\n",
      "[400]\teval-auc:0.807504\n",
      "[500]\teval-auc:0.808073\n",
      "[600]\teval-auc:0.808473\n",
      "[700]\teval-auc:0.808556\n",
      "[800]\teval-auc:0.808615\n",
      "[900]\teval-auc:0.80867\n",
      "[1000]\teval-auc:0.808745\n",
      "[1100]\teval-auc:0.808811\n",
      "[1200]\teval-auc:0.808835\n",
      "[1300]\teval-auc:0.808864\n",
      "[1400]\teval-auc:0.808884\n",
      "[1500]\teval-auc:0.808878\n",
      "Stopping. Best iteration:\n",
      "[1458]\teval-auc:0.808901\n",
      "\n",
      "[0]\teval-auc:0.77318\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.795847\n",
      "[200]\teval-auc:0.799564\n",
      "[300]\teval-auc:0.800905\n",
      "[400]\teval-auc:0.802067\n",
      "[500]\teval-auc:0.802545\n",
      "[600]\teval-auc:0.802889\n",
      "[700]\teval-auc:0.802965\n",
      "[800]\teval-auc:0.803005\n",
      "[900]\teval-auc:0.803044\n",
      "[1000]\teval-auc:0.803051\n",
      "[1100]\teval-auc:0.803095\n",
      "[1200]\teval-auc:0.803101\n",
      "[1300]\teval-auc:0.803125\n",
      "[1400]\teval-auc:0.803125\n",
      "Stopping. Best iteration:\n",
      "[1309]\teval-auc:0.803128\n",
      "\n",
      "cv score - on train:\n",
      "0.803396106358484\n",
      "('current score in fold:', 0.8036041273868582, 3)\n",
      "[0]\teval-auc:0.761183\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.791789\n",
      "[200]\teval-auc:0.795887\n",
      "[300]\teval-auc:0.797537\n",
      "[400]\teval-auc:0.798836\n",
      "[500]\teval-auc:0.799828\n",
      "[600]\teval-auc:0.80022\n",
      "[700]\teval-auc:0.800365\n",
      "[800]\teval-auc:0.800444\n",
      "[900]\teval-auc:0.800499\n",
      "[1000]\teval-auc:0.800626\n",
      "[1100]\teval-auc:0.800688\n",
      "[1200]\teval-auc:0.800719\n",
      "[1300]\teval-auc:0.800763\n",
      "[1400]\teval-auc:0.800841\n",
      "[1500]\teval-auc:0.800877\n",
      "Stopping. Best iteration:\n",
      "[1475]\teval-auc:0.800889\n",
      "\n",
      "[0]\teval-auc:0.770353\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.795274\n",
      "[200]\teval-auc:0.799444\n",
      "[300]\teval-auc:0.801077\n",
      "[400]\teval-auc:0.802468\n",
      "[500]\teval-auc:0.80288\n",
      "[600]\teval-auc:0.803052\n",
      "[700]\teval-auc:0.803098\n",
      "[800]\teval-auc:0.803117\n",
      "Stopping. Best iteration:\n",
      "[774]\teval-auc:0.803126\n",
      "\n",
      "[0]\teval-auc:0.762434\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.798372\n",
      "[200]\teval-auc:0.802289\n",
      "[300]\teval-auc:0.803514\n",
      "[400]\teval-auc:0.804135\n",
      "[500]\teval-auc:0.804558\n",
      "[600]\teval-auc:0.804669\n",
      "[700]\teval-auc:0.804732\n",
      "[800]\teval-auc:0.804777\n",
      "[900]\teval-auc:0.80479\n",
      "[1000]\teval-auc:0.804782\n",
      "Stopping. Best iteration:\n",
      "[905]\teval-auc:0.804794\n",
      "\n",
      "[0]\teval-auc:0.75995\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.792343\n",
      "[200]\teval-auc:0.795525\n",
      "[300]\teval-auc:0.797006\n",
      "[400]\teval-auc:0.79837\n",
      "[500]\teval-auc:0.798964\n",
      "[600]\teval-auc:0.799419\n",
      "[700]\teval-auc:0.799558\n",
      "[800]\teval-auc:0.799652\n",
      "[900]\teval-auc:0.799745\n",
      "[1000]\teval-auc:0.799802\n",
      "[1100]\teval-auc:0.799846\n",
      "[1200]\teval-auc:0.799902\n",
      "[1300]\teval-auc:0.799918\n",
      "[1400]\teval-auc:0.799919\n",
      "Stopping. Best iteration:\n",
      "[1332]\teval-auc:0.799933\n",
      "\n",
      "[0]\teval-auc:0.768778\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.800526\n",
      "[200]\teval-auc:0.803209\n",
      "[300]\teval-auc:0.804845\n",
      "[400]\teval-auc:0.806166\n",
      "[500]\teval-auc:0.806878\n",
      "[600]\teval-auc:0.807216\n",
      "[700]\teval-auc:0.807325\n",
      "[800]\teval-auc:0.807419\n",
      "[900]\teval-auc:0.807524\n",
      "[1000]\teval-auc:0.807555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1100]\teval-auc:0.807589\n",
      "[1200]\teval-auc:0.807598\n",
      "Stopping. Best iteration:\n",
      "[1168]\teval-auc:0.807605\n",
      "\n",
      "cv score - on train:\n",
      "0.8031954824329086\n",
      "('current score in fold:', 0.8036075622114969, 4)\n",
      "[0]\teval-auc:0.768604\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.794718\n",
      "[200]\teval-auc:0.798586\n",
      "[300]\teval-auc:0.799743\n",
      "[400]\teval-auc:0.801255\n",
      "[500]\teval-auc:0.80183\n",
      "[600]\teval-auc:0.80204\n",
      "[700]\teval-auc:0.802091\n",
      "[800]\teval-auc:0.80214\n",
      "[900]\teval-auc:0.802157\n",
      "[1000]\teval-auc:0.802233\n",
      "[1100]\teval-auc:0.802337\n",
      "[1200]\teval-auc:0.802434\n",
      "[1300]\teval-auc:0.802476\n",
      "Stopping. Best iteration:\n",
      "[1293]\teval-auc:0.802478\n",
      "\n",
      "[0]\teval-auc:0.766094\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.796847\n",
      "[200]\teval-auc:0.800783\n",
      "[300]\teval-auc:0.80196\n",
      "[400]\teval-auc:0.803055\n",
      "[500]\teval-auc:0.803348\n",
      "[600]\teval-auc:0.803554\n",
      "[700]\teval-auc:0.803571\n",
      "Stopping. Best iteration:\n",
      "[660]\teval-auc:0.803587\n",
      "\n",
      "[0]\teval-auc:0.76057\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.79189\n",
      "[200]\teval-auc:0.796064\n",
      "[300]\teval-auc:0.797322\n",
      "[400]\teval-auc:0.798626\n",
      "[500]\teval-auc:0.799253\n",
      "[600]\teval-auc:0.799607\n",
      "[700]\teval-auc:0.799724\n",
      "[800]\teval-auc:0.79978\n",
      "[900]\teval-auc:0.799843\n",
      "[1000]\teval-auc:0.799879\n",
      "[1100]\teval-auc:0.799908\n",
      "[1200]\teval-auc:0.799942\n",
      "Stopping. Best iteration:\n",
      "[1169]\teval-auc:0.799949\n",
      "\n",
      "[0]\teval-auc:0.771419\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.796921\n",
      "[200]\teval-auc:0.799933\n",
      "[300]\teval-auc:0.802146\n",
      "[400]\teval-auc:0.803301\n",
      "[500]\teval-auc:0.804088\n",
      "[600]\teval-auc:0.804417\n",
      "[700]\teval-auc:0.804497\n",
      "[800]\teval-auc:0.804561\n",
      "[900]\teval-auc:0.804647\n",
      "[1000]\teval-auc:0.804688\n",
      "[1100]\teval-auc:0.804732\n",
      "[1200]\teval-auc:0.804746\n",
      "Stopping. Best iteration:\n",
      "[1142]\teval-auc:0.804752\n",
      "\n",
      "[0]\teval-auc:0.765549\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.799691\n",
      "[200]\teval-auc:0.801933\n",
      "[300]\teval-auc:0.803495\n",
      "[400]\teval-auc:0.804998\n",
      "[500]\teval-auc:0.80549\n",
      "[600]\teval-auc:0.805686\n",
      "[700]\teval-auc:0.805796\n",
      "[800]\teval-auc:0.805784\n",
      "Stopping. Best iteration:\n",
      "[727]\teval-auc:0.805801\n",
      "\n",
      "cv score - on train:\n",
      "0.8032153632911117\n",
      "('current score in fold:', 0.8036082357246856, 5)\n",
      "[0]\teval-auc:0.770193\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.795297\n",
      "[200]\teval-auc:0.797876\n",
      "[300]\teval-auc:0.800256\n",
      "[400]\teval-auc:0.801693\n",
      "[500]\teval-auc:0.802506\n",
      "[600]\teval-auc:0.802945\n",
      "[700]\teval-auc:0.803028\n",
      "[800]\teval-auc:0.803114\n",
      "[900]\teval-auc:0.803216\n",
      "[1000]\teval-auc:0.803313\n",
      "[1100]\teval-auc:0.803387\n",
      "[1200]\teval-auc:0.803406\n",
      "[1300]\teval-auc:0.803466\n",
      "[1400]\teval-auc:0.803517\n",
      "[1500]\teval-auc:0.803558\n",
      "[1600]\teval-auc:0.803565\n",
      "Stopping. Best iteration:\n",
      "[1544]\teval-auc:0.803577\n",
      "\n",
      "[0]\teval-auc:0.767708\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.798751\n",
      "[200]\teval-auc:0.801431\n",
      "[300]\teval-auc:0.803067\n",
      "[400]\teval-auc:0.80439\n",
      "[500]\teval-auc:0.805122\n",
      "[600]\teval-auc:0.805354\n",
      "[700]\teval-auc:0.805469\n",
      "[800]\teval-auc:0.80553\n",
      "[900]\teval-auc:0.805542\n",
      "[1000]\teval-auc:0.805588\n",
      "[1100]\teval-auc:0.805618\n",
      "[1200]\teval-auc:0.805646\n",
      "[1300]\teval-auc:0.805656\n",
      "[1400]\teval-auc:0.805668\n",
      "[1500]\teval-auc:0.805667\n",
      "Stopping. Best iteration:\n",
      "[1403]\teval-auc:0.805673\n",
      "\n",
      "[0]\teval-auc:0.767519\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.79457\n",
      "[200]\teval-auc:0.797445\n",
      "[300]\teval-auc:0.799204\n",
      "[400]\teval-auc:0.800574\n",
      "[500]\teval-auc:0.800899\n",
      "[600]\teval-auc:0.801167\n",
      "[700]\teval-auc:0.801211\n",
      "[800]\teval-auc:0.801259\n",
      "[900]\teval-auc:0.801292\n",
      "[1000]\teval-auc:0.80132\n",
      "[1100]\teval-auc:0.801379\n",
      "[1200]\teval-auc:0.801408\n",
      "[1300]\teval-auc:0.801444\n",
      "[1400]\teval-auc:0.801419\n",
      "Stopping. Best iteration:\n",
      "[1301]\teval-auc:0.801445\n",
      "\n",
      "[0]\teval-auc:0.765475\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.796504\n",
      "[200]\teval-auc:0.80033\n",
      "[300]\teval-auc:0.80162\n",
      "[400]\teval-auc:0.803185\n",
      "[500]\teval-auc:0.80363\n",
      "[600]\teval-auc:0.803864\n",
      "[700]\teval-auc:0.803885\n",
      "[800]\teval-auc:0.803967\n",
      "[900]\teval-auc:0.803993\n",
      "[1000]\teval-auc:0.80405\n",
      "[1100]\teval-auc:0.804044\n",
      "Stopping. Best iteration:\n",
      "[1024]\teval-auc:0.804057\n",
      "\n",
      "[0]\teval-auc:0.766654\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.793639\n",
      "[200]\teval-auc:0.798314\n",
      "[300]\teval-auc:0.799273\n",
      "[400]\teval-auc:0.800631\n",
      "[500]\teval-auc:0.801344\n",
      "[600]\teval-auc:0.801556\n",
      "[700]\teval-auc:0.801634\n",
      "[800]\teval-auc:0.801655\n",
      "[900]\teval-auc:0.801619\n",
      "Stopping. Best iteration:\n",
      "[800]\teval-auc:0.801655\n",
      "\n",
      "cv score - on train:\n",
      "0.8032032007957274\n",
      "('current score in fold:', 0.8036150616985605, 6)\n",
      "[0]\teval-auc:0.772489\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.797005\n",
      "[200]\teval-auc:0.800334\n",
      "[300]\teval-auc:0.801512\n",
      "[400]\teval-auc:0.802849\n",
      "[500]\teval-auc:0.803371\n",
      "[600]\teval-auc:0.803537\n",
      "[700]\teval-auc:0.80363\n",
      "[800]\teval-auc:0.803682\n",
      "[900]\teval-auc:0.803692\n",
      "[1000]\teval-auc:0.803721\n",
      "[1100]\teval-auc:0.803757\n",
      "[1200]\teval-auc:0.8038\n",
      "[1300]\teval-auc:0.80382\n",
      "[1400]\teval-auc:0.803867\n",
      "[1500]\teval-auc:0.803918\n",
      "[1600]\teval-auc:0.803953\n",
      "[1700]\teval-auc:0.803993\n",
      "[1800]\teval-auc:0.803991\n",
      "Stopping. Best iteration:\n",
      "[1729]\teval-auc:0.804004\n",
      "\n",
      "[0]\teval-auc:0.762579\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.792108\n",
      "[200]\teval-auc:0.795402\n",
      "[300]\teval-auc:0.796869\n",
      "[400]\teval-auc:0.798167\n",
      "[500]\teval-auc:0.798753\n",
      "[600]\teval-auc:0.798849\n",
      "[700]\teval-auc:0.798854\n",
      "Stopping. Best iteration:\n",
      "[682]\teval-auc:0.79887\n",
      "\n",
      "[0]\teval-auc:0.765593\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.79415\n",
      "[200]\teval-auc:0.799295\n",
      "[300]\teval-auc:0.800826\n",
      "[400]\teval-auc:0.802327\n",
      "[500]\teval-auc:0.802912\n",
      "[600]\teval-auc:0.803097\n",
      "[700]\teval-auc:0.803129\n",
      "[800]\teval-auc:0.803136\n",
      "[900]\teval-auc:0.803158\n",
      "[1000]\teval-auc:0.80316\n",
      "[1100]\teval-auc:0.803169\n",
      "Stopping. Best iteration:\n",
      "[1083]\teval-auc:0.803174\n",
      "\n",
      "[0]\teval-auc:0.765722\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.797531\n",
      "[200]\teval-auc:0.800289\n",
      "[300]\teval-auc:0.801672\n",
      "[400]\teval-auc:0.802808\n",
      "[500]\teval-auc:0.803242\n",
      "[600]\teval-auc:0.803581\n",
      "[700]\teval-auc:0.803639\n",
      "[800]\teval-auc:0.803684\n",
      "[900]\teval-auc:0.803718\n",
      "[1000]\teval-auc:0.803745\n",
      "[1100]\teval-auc:0.80376\n",
      "[1200]\teval-auc:0.803771\n",
      "[1300]\teval-auc:0.803765\n",
      "Stopping. Best iteration:\n",
      "[1249]\teval-auc:0.803777\n",
      "\n",
      "[0]\teval-auc:0.772235\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.798691\n",
      "[200]\teval-auc:0.800937\n",
      "[300]\teval-auc:0.803177\n",
      "[400]\teval-auc:0.804629\n",
      "[500]\teval-auc:0.805387\n",
      "[600]\teval-auc:0.805813\n",
      "[700]\teval-auc:0.805996\n",
      "[800]\teval-auc:0.806038\n",
      "[900]\teval-auc:0.806134\n",
      "[1000]\teval-auc:0.80631\n",
      "[1100]\teval-auc:0.806409\n",
      "[1200]\teval-auc:0.806509\n",
      "[1300]\teval-auc:0.806544\n",
      "[1400]\teval-auc:0.806555\n",
      "Stopping. Best iteration:\n",
      "[1382]\teval-auc:0.806557\n",
      "\n",
      "cv score - on train:\n",
      "0.8032416509675679\n",
      "('current score in fold:', 0.8036209065077127, 7)\n",
      "[0]\teval-auc:0.762703\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.792976\n",
      "[200]\teval-auc:0.796431\n",
      "[300]\teval-auc:0.79776\n",
      "[400]\teval-auc:0.799326\n",
      "[500]\teval-auc:0.799891\n",
      "[600]\teval-auc:0.800257\n",
      "[700]\teval-auc:0.800437\n",
      "[800]\teval-auc:0.800456\n",
      "[900]\teval-auc:0.80049\n",
      "[1000]\teval-auc:0.80057\n",
      "[1100]\teval-auc:0.800609\n",
      "[1200]\teval-auc:0.800633\n",
      "[1300]\teval-auc:0.800663\n",
      "Stopping. Best iteration:\n",
      "[1295]\teval-auc:0.800663\n",
      "\n",
      "[0]\teval-auc:0.76732\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.7948\n",
      "[200]\teval-auc:0.79866\n",
      "[300]\teval-auc:0.800511\n",
      "[400]\teval-auc:0.801629\n",
      "[500]\teval-auc:0.802141\n",
      "[600]\teval-auc:0.802377\n",
      "[700]\teval-auc:0.802529\n",
      "[800]\teval-auc:0.802601\n",
      "[900]\teval-auc:0.802667\n",
      "[1000]\teval-auc:0.802673\n",
      "[1100]\teval-auc:0.802702\n",
      "[1200]\teval-auc:0.802726\n",
      "[1300]\teval-auc:0.802761\n",
      "[1400]\teval-auc:0.802815\n",
      "[1500]\teval-auc:0.802856\n",
      "[1600]\teval-auc:0.802871\n",
      "[1700]\teval-auc:0.802872\n",
      "Stopping. Best iteration:\n",
      "[1617]\teval-auc:0.802881\n",
      "\n",
      "[0]\teval-auc:0.759189\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.791702\n",
      "[200]\teval-auc:0.795786\n",
      "[300]\teval-auc:0.797057\n",
      "[400]\teval-auc:0.798822\n",
      "[500]\teval-auc:0.799583\n",
      "[600]\teval-auc:0.799858\n",
      "[700]\teval-auc:0.800061\n",
      "[800]\teval-auc:0.800092\n",
      "[900]\teval-auc:0.800155\n",
      "[1000]\teval-auc:0.800258\n",
      "[1100]\teval-auc:0.80032\n",
      "[1200]\teval-auc:0.800349\n",
      "[1300]\teval-auc:0.800376\n",
      "Stopping. Best iteration:\n",
      "[1299]\teval-auc:0.800379\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.769141\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.799663\n",
      "[200]\teval-auc:0.801977\n",
      "[300]\teval-auc:0.803258\n",
      "[400]\teval-auc:0.80447\n",
      "[500]\teval-auc:0.805219\n",
      "[600]\teval-auc:0.805482\n",
      "[700]\teval-auc:0.805532\n",
      "[800]\teval-auc:0.805584\n",
      "[900]\teval-auc:0.805612\n",
      "[1000]\teval-auc:0.805635\n",
      "[1100]\teval-auc:0.805642\n",
      "[1200]\teval-auc:0.805687\n",
      "[1300]\teval-auc:0.805706\n",
      "[1400]\teval-auc:0.805725\n",
      "Stopping. Best iteration:\n",
      "[1376]\teval-auc:0.805734\n",
      "\n",
      "[0]\teval-auc:0.771385\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.801648\n",
      "[200]\teval-auc:0.804253\n",
      "[300]\teval-auc:0.805479\n",
      "[400]\teval-auc:0.806651\n",
      "[500]\teval-auc:0.807078\n",
      "[600]\teval-auc:0.807095\n",
      "Stopping. Best iteration:\n",
      "[586]\teval-auc:0.807108\n",
      "\n",
      "cv score - on train:\n",
      "0.8032214537654998\n",
      "('current score in fold:', 0.8036319431324308, 8)\n",
      "[0]\teval-auc:0.770312\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.798476\n",
      "[200]\teval-auc:0.80138\n",
      "[300]\teval-auc:0.803928\n",
      "[400]\teval-auc:0.805779\n",
      "[500]\teval-auc:0.806568\n",
      "[600]\teval-auc:0.806754\n",
      "Stopping. Best iteration:\n",
      "[581]\teval-auc:0.806772\n",
      "\n",
      "[0]\teval-auc:0.768648\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.799659\n",
      "[200]\teval-auc:0.803324\n",
      "[300]\teval-auc:0.804633\n",
      "[400]\teval-auc:0.80589\n",
      "[500]\teval-auc:0.806354\n",
      "[600]\teval-auc:0.80658\n",
      "[700]\teval-auc:0.806669\n",
      "[800]\teval-auc:0.806691\n",
      "Stopping. Best iteration:\n",
      "[754]\teval-auc:0.806701\n",
      "\n",
      "[0]\teval-auc:0.768457\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.796217\n",
      "[200]\teval-auc:0.798839\n",
      "[300]\teval-auc:0.800776\n",
      "[400]\teval-auc:0.802054\n",
      "[500]\teval-auc:0.802607\n",
      "[600]\teval-auc:0.802912\n",
      "[700]\teval-auc:0.803035\n",
      "[800]\teval-auc:0.803094\n",
      "[900]\teval-auc:0.803155\n",
      "[1000]\teval-auc:0.803234\n",
      "[1100]\teval-auc:0.803292\n",
      "[1200]\teval-auc:0.803341\n",
      "[1300]\teval-auc:0.803385\n",
      "[1400]\teval-auc:0.803417\n",
      "[1500]\teval-auc:0.803455\n",
      "[1600]\teval-auc:0.803506\n",
      "[1700]\teval-auc:0.803557\n",
      "[1800]\teval-auc:0.80356\n",
      "[1900]\teval-auc:0.803579\n",
      "[2000]\teval-auc:0.803566\n",
      "Stopping. Best iteration:\n",
      "[1945]\teval-auc:0.803583\n",
      "\n",
      "[0]\teval-auc:0.764651\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.792719\n",
      "[200]\teval-auc:0.79605\n",
      "[300]\teval-auc:0.797292\n",
      "[400]\teval-auc:0.798333\n",
      "[500]\teval-auc:0.798717\n",
      "[600]\teval-auc:0.798832\n",
      "[700]\teval-auc:0.798954\n",
      "[800]\teval-auc:0.799001\n",
      "[900]\teval-auc:0.799038\n",
      "Stopping. Best iteration:\n",
      "[893]\teval-auc:0.799041\n",
      "\n",
      "[0]\teval-auc:0.759025\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.792365\n",
      "[200]\teval-auc:0.795806\n",
      "[300]\teval-auc:0.797527\n",
      "[400]\teval-auc:0.798698\n",
      "[500]\teval-auc:0.799506\n",
      "[600]\teval-auc:0.799927\n",
      "[700]\teval-auc:0.800128\n",
      "[800]\teval-auc:0.800209\n",
      "[900]\teval-auc:0.800279\n",
      "[1000]\teval-auc:0.800378\n",
      "[1100]\teval-auc:0.800506\n",
      "[1200]\teval-auc:0.800565\n",
      "[1300]\teval-auc:0.800596\n",
      "[1400]\teval-auc:0.800601\n",
      "Stopping. Best iteration:\n",
      "[1316]\teval-auc:0.800606\n",
      "\n",
      "cv score - on train:\n",
      "0.8031856946539719\n",
      "('current score in fold:', 0.8036370087666935, 9)\n",
      "[0]\teval-auc:0.757619\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.792103\n",
      "[200]\teval-auc:0.795748\n",
      "[300]\teval-auc:0.797132\n",
      "[400]\teval-auc:0.798847\n",
      "[500]\teval-auc:0.799578\n",
      "[600]\teval-auc:0.799821\n",
      "[700]\teval-auc:0.799922\n",
      "[800]\teval-auc:0.80002\n",
      "[900]\teval-auc:0.800089\n",
      "[1000]\teval-auc:0.800183\n",
      "[1100]\teval-auc:0.800252\n",
      "[1200]\teval-auc:0.800267\n",
      "[1300]\teval-auc:0.800258\n",
      "Stopping. Best iteration:\n",
      "[1225]\teval-auc:0.800274\n",
      "\n",
      "[0]\teval-auc:0.758513\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.792977\n",
      "[200]\teval-auc:0.797853\n",
      "[300]\teval-auc:0.798971\n",
      "[400]\teval-auc:0.800381\n",
      "[500]\teval-auc:0.800935\n",
      "[600]\teval-auc:0.801267\n",
      "[700]\teval-auc:0.801455\n",
      "[800]\teval-auc:0.801497\n",
      "[900]\teval-auc:0.801526\n",
      "[1000]\teval-auc:0.801575\n",
      "[1100]\teval-auc:0.801621\n",
      "[1200]\teval-auc:0.801704\n",
      "[1300]\teval-auc:0.801738\n",
      "[1400]\teval-auc:0.801755\n",
      "[1500]\teval-auc:0.80177\n",
      "[1600]\teval-auc:0.801782\n",
      "[1700]\teval-auc:0.80177\n",
      "Stopping. Best iteration:\n",
      "[1606]\teval-auc:0.801787\n",
      "\n",
      "[0]\teval-auc:0.760608\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.796743\n",
      "[200]\teval-auc:0.800016\n",
      "[300]\teval-auc:0.801272\n",
      "[400]\teval-auc:0.802558\n",
      "[500]\teval-auc:0.803219\n",
      "[600]\teval-auc:0.803502\n",
      "[700]\teval-auc:0.80357\n",
      "[800]\teval-auc:0.803589\n",
      "[900]\teval-auc:0.803659\n",
      "[1000]\teval-auc:0.803674\n",
      "[1100]\teval-auc:0.803703\n",
      "[1200]\teval-auc:0.803734\n",
      "[1300]\teval-auc:0.803761\n",
      "Stopping. Best iteration:\n",
      "[1297]\teval-auc:0.803764\n",
      "\n",
      "[0]\teval-auc:0.768569\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.800708\n",
      "[200]\teval-auc:0.803109\n",
      "[300]\teval-auc:0.805026\n",
      "[400]\teval-auc:0.806161\n",
      "[500]\teval-auc:0.806708\n",
      "[600]\teval-auc:0.807014\n",
      "[700]\teval-auc:0.807062\n",
      "[800]\teval-auc:0.807123\n",
      "[900]\teval-auc:0.807166\n",
      "[1000]\teval-auc:0.807177\n",
      "[1100]\teval-auc:0.807239\n",
      "[1200]\teval-auc:0.807266\n",
      "Stopping. Best iteration:\n",
      "[1153]\teval-auc:0.807272\n",
      "\n",
      "[0]\teval-auc:0.767074\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.79692\n",
      "[200]\teval-auc:0.800257\n",
      "[300]\teval-auc:0.801527\n",
      "[400]\teval-auc:0.802869\n",
      "[500]\teval-auc:0.803532\n",
      "[600]\teval-auc:0.803886\n",
      "[700]\teval-auc:0.804004\n",
      "[800]\teval-auc:0.804004\n",
      "Stopping. Best iteration:\n",
      "[717]\teval-auc:0.804019\n",
      "\n",
      "cv score - on train:\n",
      "0.8033642364952822\n",
      "('current score in fold:', 0.8036514924708129, 10)\n",
      "[0]\teval-auc:0.76332\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.796806\n",
      "[200]\teval-auc:0.801341\n",
      "[300]\teval-auc:0.802527\n",
      "[400]\teval-auc:0.803652\n",
      "[500]\teval-auc:0.804391\n",
      "[600]\teval-auc:0.804642\n",
      "[700]\teval-auc:0.804779\n",
      "[800]\teval-auc:0.804837\n",
      "[900]\teval-auc:0.804852\n",
      "[1000]\teval-auc:0.804953\n",
      "[1100]\teval-auc:0.804987\n",
      "[1200]\teval-auc:0.804998\n",
      "[1300]\teval-auc:0.805\n",
      "Stopping. Best iteration:\n",
      "[1248]\teval-auc:0.805007\n",
      "\n",
      "[0]\teval-auc:0.774044\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.800518\n",
      "[200]\teval-auc:0.802909\n",
      "[300]\teval-auc:0.804202\n",
      "[400]\teval-auc:0.806072\n",
      "[500]\teval-auc:0.806664\n",
      "[600]\teval-auc:0.806944\n",
      "[700]\teval-auc:0.806998\n",
      "Stopping. Best iteration:\n",
      "[655]\teval-auc:0.807018\n",
      "\n",
      "[0]\teval-auc:0.769262\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.79245\n",
      "[200]\teval-auc:0.796309\n",
      "[300]\teval-auc:0.79788\n",
      "[400]\teval-auc:0.799309\n",
      "[500]\teval-auc:0.799739\n",
      "[600]\teval-auc:0.800147\n",
      "[700]\teval-auc:0.800264\n",
      "Stopping. Best iteration:\n",
      "[683]\teval-auc:0.800266\n",
      "\n",
      "[0]\teval-auc:0.762874\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.793444\n",
      "[200]\teval-auc:0.797422\n",
      "[300]\teval-auc:0.799397\n",
      "[400]\teval-auc:0.800431\n",
      "[500]\teval-auc:0.80091\n",
      "[600]\teval-auc:0.80112\n",
      "[700]\teval-auc:0.801177\n",
      "[800]\teval-auc:0.801202\n",
      "[900]\teval-auc:0.801255\n",
      "[1000]\teval-auc:0.80127\n",
      "[1100]\teval-auc:0.801321\n",
      "[1200]\teval-auc:0.801355\n",
      "[1300]\teval-auc:0.801364\n",
      "Stopping. Best iteration:\n",
      "[1242]\teval-auc:0.801379\n",
      "\n",
      "[0]\teval-auc:0.766109\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.794938\n",
      "[200]\teval-auc:0.798122\n",
      "[300]\teval-auc:0.799802\n",
      "[400]\teval-auc:0.80121\n",
      "[500]\teval-auc:0.801703\n",
      "[600]\teval-auc:0.802158\n",
      "[700]\teval-auc:0.802364\n",
      "[800]\teval-auc:0.802454\n",
      "[900]\teval-auc:0.802481\n",
      "[1000]\teval-auc:0.802486\n",
      "[1100]\teval-auc:0.802533\n",
      "[1200]\teval-auc:0.802533\n",
      "[1300]\teval-auc:0.802547\n",
      "[1400]\teval-auc:0.802533\n",
      "Stopping. Best iteration:\n",
      "[1323]\teval-auc:0.802553\n",
      "\n",
      "cv score - on train:\n",
      "0.8031323653481803\n",
      "('current score in fold:', 0.8036455632320479, 11)\n",
      "[0]\teval-auc:0.768036\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.795687\n",
      "[200]\teval-auc:0.798393\n",
      "[300]\teval-auc:0.800387\n",
      "[400]\teval-auc:0.80151\n",
      "[500]\teval-auc:0.802464\n",
      "[600]\teval-auc:0.802746\n",
      "[700]\teval-auc:0.802851\n",
      "[800]\teval-auc:0.802932\n",
      "[900]\teval-auc:0.802959\n",
      "[1000]\teval-auc:0.803063\n",
      "[1100]\teval-auc:0.803139\n",
      "[1200]\teval-auc:0.803192\n",
      "[1300]\teval-auc:0.803236\n",
      "[1400]\teval-auc:0.803287\n",
      "[1500]\teval-auc:0.803304\n",
      "[1600]\teval-auc:0.803297\n",
      "Stopping. Best iteration:\n",
      "[1543]\teval-auc:0.803311\n",
      "\n",
      "[0]\teval-auc:0.764654\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.795393\n",
      "[200]\teval-auc:0.799735\n",
      "[300]\teval-auc:0.801039\n",
      "[400]\teval-auc:0.802441\n",
      "[500]\teval-auc:0.803254\n",
      "[600]\teval-auc:0.803456\n",
      "[700]\teval-auc:0.803632\n",
      "[800]\teval-auc:0.803677\n",
      "[900]\teval-auc:0.803722\n",
      "[1000]\teval-auc:0.803766\n",
      "[1100]\teval-auc:0.803793\n",
      "[1200]\teval-auc:0.803814\n",
      "[1300]\teval-auc:0.803819\n",
      "[1400]\teval-auc:0.803851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1500]\teval-auc:0.803864\n",
      "Stopping. Best iteration:\n",
      "[1485]\teval-auc:0.803869\n",
      "\n",
      "[0]\teval-auc:0.762856\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.795951\n",
      "[200]\teval-auc:0.798383\n",
      "[300]\teval-auc:0.799838\n",
      "[400]\teval-auc:0.801178\n",
      "[500]\teval-auc:0.801818\n",
      "[600]\teval-auc:0.802295\n",
      "[700]\teval-auc:0.802454\n",
      "[800]\teval-auc:0.802531\n",
      "[900]\teval-auc:0.802608\n",
      "[1000]\teval-auc:0.802725\n",
      "[1100]\teval-auc:0.802798\n",
      "[1200]\teval-auc:0.802881\n",
      "[1300]\teval-auc:0.802945\n",
      "[1400]\teval-auc:0.802962\n",
      "[1500]\teval-auc:0.802989\n",
      "[1600]\teval-auc:0.802988\n",
      "[1700]\teval-auc:0.80304\n",
      "[1800]\teval-auc:0.803046\n",
      "[1900]\teval-auc:0.80302\n",
      "Stopping. Best iteration:\n",
      "[1844]\teval-auc:0.803054\n",
      "\n",
      "[0]\teval-auc:0.770916\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.796959\n",
      "[200]\teval-auc:0.799759\n",
      "[300]\teval-auc:0.801973\n",
      "[400]\teval-auc:0.80337\n",
      "[500]\teval-auc:0.803991\n",
      "[600]\teval-auc:0.804324\n",
      "[700]\teval-auc:0.804396\n",
      "[800]\teval-auc:0.804422\n",
      "[900]\teval-auc:0.804472\n",
      "[1000]\teval-auc:0.804597\n",
      "[1100]\teval-auc:0.804633\n",
      "[1200]\teval-auc:0.804645\n",
      "Stopping. Best iteration:\n",
      "[1135]\teval-auc:0.804649\n",
      "\n",
      "[0]\teval-auc:0.764364\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.796343\n",
      "[200]\teval-auc:0.799771\n",
      "[300]\teval-auc:0.800975\n",
      "[400]\teval-auc:0.802085\n",
      "[500]\teval-auc:0.80254\n",
      "[600]\teval-auc:0.802674\n",
      "[700]\teval-auc:0.802727\n",
      "[800]\teval-auc:0.802765\n",
      "[900]\teval-auc:0.802756\n",
      "Stopping. Best iteration:\n",
      "[859]\teval-auc:0.802774\n",
      "\n",
      "cv score - on train:\n",
      "0.8034497486594554\n",
      "('current score in fold:', 0.8036675698640262, 12)\n",
      "[0]\teval-auc:0.76327\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.793599\n",
      "[200]\teval-auc:0.796082\n",
      "[300]\teval-auc:0.797158\n",
      "[400]\teval-auc:0.798867\n",
      "[500]\teval-auc:0.799592\n",
      "[600]\teval-auc:0.799905\n",
      "[700]\teval-auc:0.800043\n",
      "[800]\teval-auc:0.800159\n",
      "[900]\teval-auc:0.800243\n",
      "[1000]\teval-auc:0.80034\n",
      "[1100]\teval-auc:0.800393\n",
      "[1200]\teval-auc:0.80042\n",
      "[1300]\teval-auc:0.800425\n",
      "[1400]\teval-auc:0.800447\n",
      "[1500]\teval-auc:0.800436\n",
      "Stopping. Best iteration:\n",
      "[1406]\teval-auc:0.800453\n",
      "\n",
      "[0]\teval-auc:0.759063\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.791314\n",
      "[200]\teval-auc:0.795878\n",
      "[300]\teval-auc:0.797547\n",
      "[400]\teval-auc:0.7987\n",
      "[500]\teval-auc:0.79937\n",
      "[600]\teval-auc:0.799661\n",
      "[700]\teval-auc:0.799673\n",
      "[800]\teval-auc:0.799683\n",
      "Stopping. Best iteration:\n",
      "[757]\teval-auc:0.799698\n",
      "\n",
      "[0]\teval-auc:0.777507\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.801004\n",
      "[200]\teval-auc:0.805232\n",
      "[300]\teval-auc:0.806767\n",
      "[400]\teval-auc:0.808218\n",
      "[500]\teval-auc:0.808941\n",
      "[600]\teval-auc:0.809126\n",
      "[700]\teval-auc:0.809222\n",
      "[800]\teval-auc:0.809278\n",
      "[900]\teval-auc:0.80936\n",
      "[1000]\teval-auc:0.809432\n",
      "[1100]\teval-auc:0.809476\n",
      "[1200]\teval-auc:0.809509\n",
      "[1300]\teval-auc:0.809532\n",
      "[1400]\teval-auc:0.809548\n",
      "[1500]\teval-auc:0.809562\n",
      "[1600]\teval-auc:0.809568\n",
      "Stopping. Best iteration:\n",
      "[1544]\teval-auc:0.809579\n",
      "\n",
      "[0]\teval-auc:0.763135\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.792669\n",
      "[200]\teval-auc:0.796904\n",
      "[300]\teval-auc:0.798315\n",
      "[400]\teval-auc:0.799404\n",
      "[500]\teval-auc:0.799717\n",
      "[600]\teval-auc:0.799896\n",
      "[700]\teval-auc:0.799929\n",
      "[800]\teval-auc:0.799927\n",
      "[900]\teval-auc:0.799946\n",
      "Stopping. Best iteration:\n",
      "[872]\teval-auc:0.79995\n",
      "\n",
      "[0]\teval-auc:0.769282\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.799705\n",
      "[200]\teval-auc:0.801849\n",
      "[300]\teval-auc:0.804465\n",
      "[400]\teval-auc:0.805881\n",
      "[500]\teval-auc:0.806576\n",
      "[600]\teval-auc:0.806931\n",
      "[700]\teval-auc:0.807105\n",
      "[800]\teval-auc:0.807173\n",
      "[900]\teval-auc:0.807251\n",
      "[1000]\teval-auc:0.807339\n",
      "[1100]\teval-auc:0.807361\n",
      "[1200]\teval-auc:0.807375\n",
      "[1300]\teval-auc:0.807381\n",
      "Stopping. Best iteration:\n",
      "[1213]\teval-auc:0.807387\n",
      "\n",
      "cv score - on train:\n",
      "0.8033310014373055\n",
      "('current score in fold:', 0.8036741310780352, 13)\n",
      "[0]\teval-auc:0.770857\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.795216\n",
      "[200]\teval-auc:0.798347\n",
      "[300]\teval-auc:0.799876\n",
      "[400]\teval-auc:0.801347\n",
      "[500]\teval-auc:0.802129\n",
      "[600]\teval-auc:0.802328\n",
      "[700]\teval-auc:0.802322\n",
      "Stopping. Best iteration:\n",
      "[611]\teval-auc:0.802336\n",
      "\n",
      "[0]\teval-auc:0.767976\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.799167\n",
      "[200]\teval-auc:0.802108\n",
      "[300]\teval-auc:0.803994\n",
      "[400]\teval-auc:0.805072\n",
      "[500]\teval-auc:0.805711\n",
      "[600]\teval-auc:0.806032\n",
      "[700]\teval-auc:0.806265\n",
      "[800]\teval-auc:0.80635\n",
      "[900]\teval-auc:0.806449\n",
      "[1000]\teval-auc:0.806552\n",
      "[1100]\teval-auc:0.806624\n",
      "[1200]\teval-auc:0.806678\n",
      "[1300]\teval-auc:0.806727\n",
      "[1400]\teval-auc:0.806763\n",
      "[1500]\teval-auc:0.806805\n",
      "[1600]\teval-auc:0.806829\n",
      "[1700]\teval-auc:0.806832\n",
      "[1800]\teval-auc:0.806848\n",
      "[1900]\teval-auc:0.806882\n",
      "[2000]\teval-auc:0.806908\n",
      "[2100]\teval-auc:0.806947\n",
      "[2200]\teval-auc:0.806974\n",
      "[2300]\teval-auc:0.80698\n",
      "[2400]\teval-auc:0.806981\n",
      "Stopping. Best iteration:\n",
      "[2352]\teval-auc:0.806987\n",
      "\n",
      "[0]\teval-auc:0.759963\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.792361\n",
      "[200]\teval-auc:0.796121\n",
      "[300]\teval-auc:0.798335\n",
      "[400]\teval-auc:0.799565\n",
      "[500]\teval-auc:0.800282\n",
      "[600]\teval-auc:0.800504\n",
      "[700]\teval-auc:0.800568\n",
      "Stopping. Best iteration:\n",
      "[675]\teval-auc:0.800573\n",
      "\n",
      "[0]\teval-auc:0.769101\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.795248\n",
      "[200]\teval-auc:0.797133\n",
      "[300]\teval-auc:0.799238\n",
      "[400]\teval-auc:0.800662\n",
      "[500]\teval-auc:0.8012\n",
      "[600]\teval-auc:0.801525\n",
      "[700]\teval-auc:0.801591\n",
      "[800]\teval-auc:0.801631\n",
      "Stopping. Best iteration:\n",
      "[784]\teval-auc:0.801638\n",
      "\n",
      "[0]\teval-auc:0.766281\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.797523\n",
      "[200]\teval-auc:0.800784\n",
      "[300]\teval-auc:0.802197\n",
      "[400]\teval-auc:0.80354\n",
      "[500]\teval-auc:0.804211\n",
      "[600]\teval-auc:0.804533\n",
      "[700]\teval-auc:0.804736\n",
      "[800]\teval-auc:0.804864\n",
      "[900]\teval-auc:0.804911\n",
      "[1000]\teval-auc:0.804995\n",
      "[1100]\teval-auc:0.805052\n",
      "[1200]\teval-auc:0.805102\n",
      "[1300]\teval-auc:0.805157\n",
      "[1400]\teval-auc:0.805195\n",
      "[1500]\teval-auc:0.805235\n",
      "Stopping. Best iteration:\n",
      "[1462]\teval-auc:0.805237\n",
      "\n",
      "cv score - on train:\n",
      "0.8032564263635307\n",
      "('current score in fold:', 0.8036838866525966, 14)\n",
      "[0]\teval-auc:0.766912\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.798653\n",
      "[200]\teval-auc:0.803266\n",
      "[300]\teval-auc:0.804518\n",
      "[400]\teval-auc:0.805753\n",
      "[500]\teval-auc:0.806563\n",
      "[600]\teval-auc:0.806871\n",
      "[700]\teval-auc:0.806848\n",
      "Stopping. Best iteration:\n",
      "[618]\teval-auc:0.806901\n",
      "\n",
      "[0]\teval-auc:0.770018\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.800019\n",
      "[200]\teval-auc:0.803108\n",
      "[300]\teval-auc:0.804971\n",
      "[400]\teval-auc:0.806135\n",
      "[500]\teval-auc:0.806791\n",
      "[600]\teval-auc:0.8069\n",
      "[700]\teval-auc:0.80694\n",
      "[800]\teval-auc:0.806919\n",
      "Stopping. Best iteration:\n",
      "[736]\teval-auc:0.806942\n",
      "\n",
      "[0]\teval-auc:0.762658\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.790243\n",
      "[200]\teval-auc:0.792664\n",
      "[300]\teval-auc:0.794585\n",
      "[400]\teval-auc:0.795741\n",
      "[500]\teval-auc:0.796453\n",
      "[600]\teval-auc:0.796743\n",
      "[700]\teval-auc:0.796893\n",
      "[800]\teval-auc:0.797018\n",
      "[900]\teval-auc:0.79709\n",
      "[1000]\teval-auc:0.797128\n",
      "[1100]\teval-auc:0.797237\n",
      "[1200]\teval-auc:0.79731\n",
      "[1300]\teval-auc:0.797358\n",
      "[1400]\teval-auc:0.797407\n",
      "[1500]\teval-auc:0.797483\n",
      "[1600]\teval-auc:0.797509\n",
      "[1700]\teval-auc:0.797546\n",
      "[1800]\teval-auc:0.797633\n",
      "[1900]\teval-auc:0.797656\n",
      "[2000]\teval-auc:0.797671\n",
      "[2100]\teval-auc:0.797671\n",
      "Stopping. Best iteration:\n",
      "[2065]\teval-auc:0.797685\n",
      "\n",
      "[0]\teval-auc:0.769862\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.796402\n",
      "[200]\teval-auc:0.799946\n",
      "[300]\teval-auc:0.801274\n",
      "[400]\teval-auc:0.803031\n",
      "[500]\teval-auc:0.80383\n",
      "[600]\teval-auc:0.804297\n",
      "[700]\teval-auc:0.804462\n",
      "[800]\teval-auc:0.804531\n",
      "[900]\teval-auc:0.804571\n",
      "[1000]\teval-auc:0.804646\n",
      "[1100]\teval-auc:0.804695\n",
      "[1200]\teval-auc:0.804714\n",
      "[1300]\teval-auc:0.804761\n",
      "[1400]\teval-auc:0.80478\n",
      "[1500]\teval-auc:0.804798\n",
      "[1600]\teval-auc:0.804828\n",
      "[1700]\teval-auc:0.804847\n",
      "[1800]\teval-auc:0.804848\n",
      "[1900]\teval-auc:0.804841\n",
      "Stopping. Best iteration:\n",
      "[1887]\teval-auc:0.804867\n",
      "\n",
      "[0]\teval-auc:0.768633\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.794018\n",
      "[200]\teval-auc:0.797404\n",
      "[300]\teval-auc:0.799327\n",
      "[400]\teval-auc:0.800332\n",
      "[500]\teval-auc:0.800935\n",
      "[600]\teval-auc:0.801332\n",
      "[700]\teval-auc:0.801458\n",
      "[800]\teval-auc:0.801457\n",
      "[900]\teval-auc:0.801502\n",
      "[1000]\teval-auc:0.80159\n",
      "[1100]\teval-auc:0.801608\n",
      "Stopping. Best iteration:\n",
      "[1090]\teval-auc:0.801613\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score - on train:\n",
      "0.8034483845334098\n",
      "('current score in fold:', 0.8037032557319745, 15)\n",
      "[0]\teval-auc:0.769643\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.800739\n",
      "[200]\teval-auc:0.804278\n",
      "[300]\teval-auc:0.806157\n",
      "[400]\teval-auc:0.807579\n",
      "[500]\teval-auc:0.808284\n",
      "[600]\teval-auc:0.808584\n",
      "[700]\teval-auc:0.808692\n",
      "[800]\teval-auc:0.808714\n",
      "[900]\teval-auc:0.808757\n",
      "[1000]\teval-auc:0.808757\n",
      "Stopping. Best iteration:\n",
      "[919]\teval-auc:0.808769\n",
      "\n",
      "[0]\teval-auc:0.755442\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.795811\n",
      "[200]\teval-auc:0.800364\n",
      "[300]\teval-auc:0.802278\n",
      "[400]\teval-auc:0.803463\n",
      "[500]\teval-auc:0.804158\n",
      "[600]\teval-auc:0.804583\n",
      "[700]\teval-auc:0.80467\n",
      "[800]\teval-auc:0.804696\n",
      "[900]\teval-auc:0.804739\n",
      "[1000]\teval-auc:0.804803\n",
      "[1100]\teval-auc:0.804862\n",
      "[1200]\teval-auc:0.804898\n",
      "[1300]\teval-auc:0.804924\n",
      "[1400]\teval-auc:0.804965\n",
      "[1500]\teval-auc:0.804929\n",
      "Stopping. Best iteration:\n",
      "[1449]\teval-auc:0.804983\n",
      "\n",
      "[0]\teval-auc:0.758468\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.794179\n",
      "[200]\teval-auc:0.797334\n",
      "[300]\teval-auc:0.79898\n",
      "[400]\teval-auc:0.799991\n",
      "[500]\teval-auc:0.800479\n",
      "[600]\teval-auc:0.800691\n",
      "[700]\teval-auc:0.800835\n",
      "[800]\teval-auc:0.800948\n",
      "[900]\teval-auc:0.801004\n",
      "[1000]\teval-auc:0.801068\n",
      "[1100]\teval-auc:0.801097\n",
      "[1200]\teval-auc:0.801105\n",
      "Stopping. Best iteration:\n",
      "[1116]\teval-auc:0.801121\n",
      "\n",
      "[0]\teval-auc:0.758325\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.79217\n",
      "[200]\teval-auc:0.794914\n",
      "[300]\teval-auc:0.796637\n",
      "[400]\teval-auc:0.797987\n",
      "[500]\teval-auc:0.798658\n",
      "[600]\teval-auc:0.798974\n",
      "[700]\teval-auc:0.799125\n",
      "[800]\teval-auc:0.799197\n",
      "[900]\teval-auc:0.7993\n",
      "[1000]\teval-auc:0.799372\n",
      "[1100]\teval-auc:0.79942\n",
      "[1200]\teval-auc:0.799459\n",
      "[1300]\teval-auc:0.799471\n",
      "[1400]\teval-auc:0.799471\n",
      "[1500]\teval-auc:0.799486\n",
      "[1600]\teval-auc:0.799495\n",
      "[1700]\teval-auc:0.799509\n",
      "[1800]\teval-auc:0.7995\n",
      "Stopping. Best iteration:\n",
      "[1729]\teval-auc:0.799524\n",
      "\n",
      "[0]\teval-auc:0.765843\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.797621\n",
      "[200]\teval-auc:0.799212\n",
      "[300]\teval-auc:0.800453\n",
      "[400]\teval-auc:0.801719\n",
      "[500]\teval-auc:0.802312\n",
      "[600]\teval-auc:0.802555\n",
      "[700]\teval-auc:0.80263\n",
      "[800]\teval-auc:0.802701\n",
      "[900]\teval-auc:0.802723\n",
      "[1000]\teval-auc:0.80277\n",
      "[1100]\teval-auc:0.802805\n",
      "[1200]\teval-auc:0.802842\n",
      "[1300]\teval-auc:0.802922\n",
      "[1400]\teval-auc:0.802937\n",
      "[1500]\teval-auc:0.802935\n",
      "Stopping. Best iteration:\n",
      "[1449]\teval-auc:0.802944\n",
      "\n",
      "cv score - on train:\n",
      "0.803357231046138\n",
      "('current score in fold:', 0.803709251303203, 16)\n",
      "[0]\teval-auc:0.754937\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.796608\n",
      "[200]\teval-auc:0.800292\n",
      "[300]\teval-auc:0.801888\n",
      "[400]\teval-auc:0.803228\n",
      "[500]\teval-auc:0.803945\n",
      "[600]\teval-auc:0.804173\n",
      "[700]\teval-auc:0.804227\n",
      "Stopping. Best iteration:\n",
      "[637]\teval-auc:0.80425\n",
      "\n",
      "[0]\teval-auc:0.765211\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.792116\n",
      "[200]\teval-auc:0.797259\n",
      "[300]\teval-auc:0.798759\n",
      "[400]\teval-auc:0.799888\n",
      "[500]\teval-auc:0.800295\n",
      "[600]\teval-auc:0.80049\n",
      "[700]\teval-auc:0.800541\n",
      "[800]\teval-auc:0.80052\n",
      "Stopping. Best iteration:\n",
      "[730]\teval-auc:0.80055\n",
      "\n",
      "[0]\teval-auc:0.768861\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.797873\n",
      "[200]\teval-auc:0.803392\n",
      "[300]\teval-auc:0.804555\n",
      "[400]\teval-auc:0.805862\n",
      "[500]\teval-auc:0.806409\n",
      "[600]\teval-auc:0.806689\n",
      "[700]\teval-auc:0.806764\n",
      "[800]\teval-auc:0.806817\n",
      "[900]\teval-auc:0.806905\n",
      "[1000]\teval-auc:0.806983\n",
      "[1100]\teval-auc:0.807055\n",
      "[1200]\teval-auc:0.807048\n",
      "Stopping. Best iteration:\n",
      "[1148]\teval-auc:0.807067\n",
      "\n",
      "[0]\teval-auc:0.766427\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.793846\n",
      "[200]\teval-auc:0.796073\n",
      "[300]\teval-auc:0.799079\n",
      "[400]\teval-auc:0.800124\n",
      "[500]\teval-auc:0.800793\n",
      "[600]\teval-auc:0.801089\n",
      "[700]\teval-auc:0.80126\n",
      "[800]\teval-auc:0.801288\n",
      "[900]\teval-auc:0.801374\n",
      "[1000]\teval-auc:0.801442\n",
      "[1100]\teval-auc:0.80149\n",
      "[1200]\teval-auc:0.801526\n",
      "[1300]\teval-auc:0.801522\n",
      "Stopping. Best iteration:\n",
      "[1231]\teval-auc:0.801538\n",
      "\n",
      "[0]\teval-auc:0.7616\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.795132\n",
      "[200]\teval-auc:0.797289\n",
      "[300]\teval-auc:0.79939\n",
      "[400]\teval-auc:0.801457\n",
      "[500]\teval-auc:0.802217\n",
      "[600]\teval-auc:0.802625\n",
      "[700]\teval-auc:0.802773\n",
      "[800]\teval-auc:0.802779\n",
      "[900]\teval-auc:0.802818\n",
      "[1000]\teval-auc:0.80289\n",
      "[1100]\teval-auc:0.802939\n",
      "[1200]\teval-auc:0.802958\n",
      "[1300]\teval-auc:0.802982\n",
      "[1400]\teval-auc:0.803018\n",
      "[1500]\teval-auc:0.803044\n",
      "[1600]\teval-auc:0.803077\n",
      "[1700]\teval-auc:0.8031\n",
      "[1800]\teval-auc:0.803137\n",
      "[1900]\teval-auc:0.80315\n",
      "[2000]\teval-auc:0.803137\n",
      "Stopping. Best iteration:\n",
      "[1903]\teval-auc:0.803155\n",
      "\n",
      "cv score - on train:\n",
      "0.8032122513652108\n",
      "('current score in fold:', 0.8037072606168083, 17)\n",
      "[0]\teval-auc:0.770863\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.797425\n",
      "[200]\teval-auc:0.800577\n",
      "[300]\teval-auc:0.80233\n",
      "[400]\teval-auc:0.803374\n",
      "[500]\teval-auc:0.804147\n",
      "[600]\teval-auc:0.804538\n",
      "[700]\teval-auc:0.804697\n",
      "[800]\teval-auc:0.804723\n",
      "[900]\teval-auc:0.804782\n",
      "[1000]\teval-auc:0.804845\n",
      "[1100]\teval-auc:0.804859\n",
      "[1200]\teval-auc:0.80487\n",
      "[1300]\teval-auc:0.804872\n",
      "Stopping. Best iteration:\n",
      "[1270]\teval-auc:0.804888\n",
      "\n",
      "[0]\teval-auc:0.765722\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.796108\n",
      "[200]\teval-auc:0.798615\n",
      "[300]\teval-auc:0.79989\n",
      "[400]\teval-auc:0.801273\n",
      "[500]\teval-auc:0.801861\n",
      "[600]\teval-auc:0.802021\n",
      "[700]\teval-auc:0.80212\n",
      "[800]\teval-auc:0.802184\n",
      "[900]\teval-auc:0.802241\n",
      "[1000]\teval-auc:0.802323\n",
      "[1100]\teval-auc:0.802337\n",
      "Stopping. Best iteration:\n",
      "[1089]\teval-auc:0.802344\n",
      "\n",
      "[0]\teval-auc:0.762623\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.795098\n",
      "[200]\teval-auc:0.799101\n",
      "[300]\teval-auc:0.801256\n",
      "[400]\teval-auc:0.802723\n",
      "[500]\teval-auc:0.803358\n",
      "[600]\teval-auc:0.803661\n",
      "[700]\teval-auc:0.803772\n",
      "[800]\teval-auc:0.80379\n",
      "[900]\teval-auc:0.803782\n",
      "Stopping. Best iteration:\n",
      "[853]\teval-auc:0.803808\n",
      "\n",
      "[0]\teval-auc:0.753756\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.79391\n",
      "[200]\teval-auc:0.796322\n",
      "[300]\teval-auc:0.798826\n",
      "[400]\teval-auc:0.799983\n",
      "[500]\teval-auc:0.800647\n",
      "[600]\teval-auc:0.800986\n",
      "[700]\teval-auc:0.801068\n",
      "[800]\teval-auc:0.801147\n",
      "[900]\teval-auc:0.8012\n",
      "[1000]\teval-auc:0.801269\n",
      "[1100]\teval-auc:0.801372\n",
      "[1200]\teval-auc:0.801425\n",
      "[1300]\teval-auc:0.801463\n",
      "[1400]\teval-auc:0.801483\n",
      "[1500]\teval-auc:0.801503\n",
      "[1600]\teval-auc:0.801516\n",
      "Stopping. Best iteration:\n",
      "[1594]\teval-auc:0.801523\n",
      "\n",
      "[0]\teval-auc:0.766782\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.796928\n",
      "[200]\teval-auc:0.800308\n",
      "[300]\teval-auc:0.801892\n",
      "[400]\teval-auc:0.803263\n",
      "[500]\teval-auc:0.803538\n",
      "[600]\teval-auc:0.803712\n",
      "[700]\teval-auc:0.803822\n",
      "[800]\teval-auc:0.803911\n",
      "[900]\teval-auc:0.803954\n",
      "Stopping. Best iteration:\n",
      "[879]\teval-auc:0.803973\n",
      "\n",
      "cv score - on train:\n",
      "0.8032281199287238\n",
      "('current score in fold:', 0.803704144487239, 18)\n",
      "[0]\teval-auc:0.762246\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.792122\n",
      "[200]\teval-auc:0.795511\n",
      "[300]\teval-auc:0.797151\n",
      "[400]\teval-auc:0.798841\n",
      "[500]\teval-auc:0.799525\n",
      "[600]\teval-auc:0.7998\n",
      "[700]\teval-auc:0.799886\n",
      "[800]\teval-auc:0.799961\n",
      "[900]\teval-auc:0.800088\n",
      "[1000]\teval-auc:0.800245\n",
      "[1100]\teval-auc:0.800335\n",
      "[1200]\teval-auc:0.800399\n",
      "[1300]\teval-auc:0.800423\n",
      "[1400]\teval-auc:0.800467\n",
      "[1500]\teval-auc:0.800471\n",
      "[1600]\teval-auc:0.800484\n",
      "[1700]\teval-auc:0.800507\n",
      "[1800]\teval-auc:0.800535\n",
      "[1900]\teval-auc:0.80056\n",
      "[2000]\teval-auc:0.80056\n",
      "[2100]\teval-auc:0.800595\n",
      "[2200]\teval-auc:0.800603\n",
      "[2300]\teval-auc:0.800607\n",
      "Stopping. Best iteration:\n",
      "[2234]\teval-auc:0.800616\n",
      "\n",
      "[0]\teval-auc:0.768311\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.797356\n",
      "[200]\teval-auc:0.800892\n",
      "[300]\teval-auc:0.802298\n",
      "[400]\teval-auc:0.803578\n",
      "[500]\teval-auc:0.804316\n",
      "[600]\teval-auc:0.804599\n",
      "[700]\teval-auc:0.804733\n",
      "[800]\teval-auc:0.804758\n",
      "[900]\teval-auc:0.804821\n",
      "[1000]\teval-auc:0.804842\n",
      "[1100]\teval-auc:0.804855\n",
      "[1200]\teval-auc:0.804879\n",
      "Stopping. Best iteration:\n",
      "[1184]\teval-auc:0.804887\n",
      "\n",
      "[0]\teval-auc:0.76714\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.796594\n",
      "[200]\teval-auc:0.800171\n",
      "[300]\teval-auc:0.801722\n",
      "[400]\teval-auc:0.80294\n",
      "[500]\teval-auc:0.803569\n",
      "[600]\teval-auc:0.803934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[700]\teval-auc:0.804046\n",
      "[800]\teval-auc:0.804079\n",
      "[900]\teval-auc:0.804126\n",
      "[1000]\teval-auc:0.804159\n",
      "[1100]\teval-auc:0.804129\n",
      "Stopping. Best iteration:\n",
      "[1002]\teval-auc:0.804161\n",
      "\n",
      "[0]\teval-auc:0.760548\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.792579\n",
      "[200]\teval-auc:0.796815\n",
      "[300]\teval-auc:0.798253\n",
      "[400]\teval-auc:0.799342\n",
      "[500]\teval-auc:0.799892\n",
      "[600]\teval-auc:0.800156\n",
      "Stopping. Best iteration:\n",
      "[597]\teval-auc:0.800158\n",
      "\n",
      "[0]\teval-auc:0.774553\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.800726\n",
      "[200]\teval-auc:0.80394\n",
      "[300]\teval-auc:0.805387\n",
      "[400]\teval-auc:0.806292\n",
      "[500]\teval-auc:0.806829\n",
      "[600]\teval-auc:0.80703\n",
      "[700]\teval-auc:0.807131\n",
      "[800]\teval-auc:0.8072\n",
      "[900]\teval-auc:0.807274\n",
      "[1000]\teval-auc:0.807319\n",
      "Stopping. Best iteration:\n",
      "[994]\teval-auc:0.807325\n",
      "\n",
      "cv score - on train:\n",
      "0.8033449090250974\n",
      "('current score in fold:', 0.803711048050859, 19)\n",
      "[0]\teval-auc:0.766271\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.790078\n",
      "[200]\teval-auc:0.793945\n",
      "[300]\teval-auc:0.795185\n",
      "[400]\teval-auc:0.79679\n",
      "[500]\teval-auc:0.797396\n",
      "[600]\teval-auc:0.797666\n",
      "[700]\teval-auc:0.797756\n",
      "[800]\teval-auc:0.797765\n",
      "[900]\teval-auc:0.797821\n",
      "[1000]\teval-auc:0.797925\n",
      "[1100]\teval-auc:0.79801\n",
      "[1200]\teval-auc:0.798055\n",
      "[1300]\teval-auc:0.798082\n",
      "[1400]\teval-auc:0.798086\n",
      "[1500]\teval-auc:0.798104\n",
      "[1600]\teval-auc:0.798122\n",
      "Stopping. Best iteration:\n",
      "[1593]\teval-auc:0.798122\n",
      "\n",
      "[0]\teval-auc:0.770412\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.802372\n",
      "[200]\teval-auc:0.80639\n",
      "[300]\teval-auc:0.808396\n",
      "[400]\teval-auc:0.809774\n",
      "[500]\teval-auc:0.810453\n",
      "[600]\teval-auc:0.810862\n",
      "[700]\teval-auc:0.810896\n",
      "[800]\teval-auc:0.810889\n",
      "Stopping. Best iteration:\n",
      "[702]\teval-auc:0.810897\n",
      "\n",
      "[0]\teval-auc:0.773493\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.799512\n",
      "[200]\teval-auc:0.8027\n",
      "[300]\teval-auc:0.803829\n",
      "[400]\teval-auc:0.804883\n",
      "[500]\teval-auc:0.805307\n",
      "[600]\teval-auc:0.805692\n",
      "[700]\teval-auc:0.805909\n",
      "[800]\teval-auc:0.805956\n",
      "[900]\teval-auc:0.806038\n",
      "[1000]\teval-auc:0.80611\n",
      "[1100]\teval-auc:0.806141\n",
      "[1200]\teval-auc:0.806192\n",
      "[1300]\teval-auc:0.806209\n",
      "[1400]\teval-auc:0.806211\n",
      "Stopping. Best iteration:\n",
      "[1325]\teval-auc:0.806221\n",
      "\n",
      "[0]\teval-auc:0.768199\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.796229\n",
      "[200]\teval-auc:0.800045\n",
      "[300]\teval-auc:0.801248\n",
      "[400]\teval-auc:0.802903\n",
      "[500]\teval-auc:0.803423\n",
      "[600]\teval-auc:0.803711\n",
      "[700]\teval-auc:0.803681\n",
      "Stopping. Best iteration:\n",
      "[634]\teval-auc:0.803719\n",
      "\n",
      "[0]\teval-auc:0.756509\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.79015\n",
      "[200]\teval-auc:0.793659\n",
      "[300]\teval-auc:0.795098\n",
      "[400]\teval-auc:0.796814\n",
      "[500]\teval-auc:0.797363\n",
      "[600]\teval-auc:0.797686\n",
      "[700]\teval-auc:0.7978\n",
      "[800]\teval-auc:0.797856\n",
      "[900]\teval-auc:0.79792\n",
      "[1000]\teval-auc:0.797971\n",
      "[1100]\teval-auc:0.79806\n",
      "[1200]\teval-auc:0.79811\n",
      "[1300]\teval-auc:0.798143\n",
      "[1400]\teval-auc:0.798208\n",
      "[1500]\teval-auc:0.798282\n",
      "[1600]\teval-auc:0.798339\n",
      "[1700]\teval-auc:0.798356\n",
      "[1800]\teval-auc:0.798385\n",
      "[1900]\teval-auc:0.798385\n",
      "[2000]\teval-auc:0.798402\n",
      "Stopping. Best iteration:\n",
      "[1994]\teval-auc:0.798404\n",
      "\n",
      "cv score - on train:\n",
      "0.8033366899982379\n",
      "('current score in fold:', 0.8037174374844495, 20)\n",
      "[0]\teval-auc:0.760017\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.792534\n",
      "[200]\teval-auc:0.795047\n",
      "[300]\teval-auc:0.797014\n",
      "[400]\teval-auc:0.798342\n",
      "[500]\teval-auc:0.799068\n",
      "[600]\teval-auc:0.799348\n",
      "[700]\teval-auc:0.799344\n",
      "Stopping. Best iteration:\n",
      "[622]\teval-auc:0.799367\n",
      "\n",
      "[0]\teval-auc:0.767092\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.796631\n",
      "[200]\teval-auc:0.800103\n",
      "[300]\teval-auc:0.802109\n",
      "[400]\teval-auc:0.803476\n",
      "[500]\teval-auc:0.804057\n",
      "[600]\teval-auc:0.804385\n",
      "[700]\teval-auc:0.804522\n",
      "[800]\teval-auc:0.804595\n",
      "[900]\teval-auc:0.804639\n",
      "[1000]\teval-auc:0.804668\n",
      "[1100]\teval-auc:0.804694\n",
      "[1200]\teval-auc:0.804709\n",
      "[1300]\teval-auc:0.804725\n",
      "Stopping. Best iteration:\n",
      "[1286]\teval-auc:0.804729\n",
      "\n",
      "[0]\teval-auc:0.765873\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.798534\n",
      "[200]\teval-auc:0.802228\n",
      "[300]\teval-auc:0.803929\n",
      "[400]\teval-auc:0.805128\n",
      "[500]\teval-auc:0.805667\n",
      "[600]\teval-auc:0.80594\n",
      "[700]\teval-auc:0.806098\n",
      "[800]\teval-auc:0.806123\n",
      "[900]\teval-auc:0.806231\n",
      "[1000]\teval-auc:0.806311\n",
      "[1100]\teval-auc:0.80633\n",
      "[1200]\teval-auc:0.806351\n",
      "[1300]\teval-auc:0.806372\n",
      "Stopping. Best iteration:\n",
      "[1254]\teval-auc:0.806389\n",
      "\n",
      "[0]\teval-auc:0.771082\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.795153\n",
      "[200]\teval-auc:0.798398\n",
      "[300]\teval-auc:0.799438\n",
      "[400]\teval-auc:0.800846\n",
      "[500]\teval-auc:0.801372\n",
      "[600]\teval-auc:0.801553\n",
      "[700]\teval-auc:0.801547\n",
      "Stopping. Best iteration:\n",
      "[623]\teval-auc:0.801569\n",
      "\n",
      "[0]\teval-auc:0.773851\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.798123\n",
      "[200]\teval-auc:0.799699\n",
      "[300]\teval-auc:0.801641\n",
      "[400]\teval-auc:0.803071\n",
      "[500]\teval-auc:0.803726\n",
      "[600]\teval-auc:0.804029\n",
      "[700]\teval-auc:0.804156\n",
      "[800]\teval-auc:0.804192\n",
      "[900]\teval-auc:0.804259\n",
      "[1000]\teval-auc:0.804335\n",
      "[1100]\teval-auc:0.80441\n",
      "[1200]\teval-auc:0.804466\n",
      "[1300]\teval-auc:0.804491\n",
      "[1400]\teval-auc:0.804516\n",
      "[1500]\teval-auc:0.804562\n",
      "[1600]\teval-auc:0.804575\n",
      "[1700]\teval-auc:0.804613\n",
      "[1800]\teval-auc:0.804665\n",
      "[1900]\teval-auc:0.804685\n",
      "[2000]\teval-auc:0.804674\n",
      "Stopping. Best iteration:\n",
      "[1921]\teval-auc:0.804693\n",
      "\n",
      "cv score - on train:\n",
      "0.8032755313242804\n",
      "('current score in fold:', 0.8037201123000772, 21)\n",
      "[0]\teval-auc:0.774393\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.796883\n",
      "[200]\teval-auc:0.801355\n",
      "[300]\teval-auc:0.802509\n",
      "[400]\teval-auc:0.80374\n",
      "[500]\teval-auc:0.804389\n",
      "[600]\teval-auc:0.80459\n",
      "[700]\teval-auc:0.804666\n",
      "[800]\teval-auc:0.804723\n",
      "[900]\teval-auc:0.804769\n",
      "[1000]\teval-auc:0.80481\n",
      "[1100]\teval-auc:0.804848\n",
      "[1200]\teval-auc:0.804847\n",
      "[1300]\teval-auc:0.804839\n",
      "Stopping. Best iteration:\n",
      "[1202]\teval-auc:0.804852\n",
      "\n",
      "[0]\teval-auc:0.767032\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.797351\n",
      "[200]\teval-auc:0.800252\n",
      "[300]\teval-auc:0.802633\n",
      "[400]\teval-auc:0.803973\n",
      "[500]\teval-auc:0.804722\n",
      "[600]\teval-auc:0.805019\n",
      "[700]\teval-auc:0.80517\n",
      "[800]\teval-auc:0.80523\n",
      "[900]\teval-auc:0.80529\n",
      "[1000]\teval-auc:0.805358\n",
      "[1100]\teval-auc:0.805408\n",
      "[1200]\teval-auc:0.805443\n",
      "[1300]\teval-auc:0.805495\n",
      "[1400]\teval-auc:0.8055\n",
      "Stopping. Best iteration:\n",
      "[1364]\teval-auc:0.80551\n",
      "\n",
      "[0]\teval-auc:0.767297\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.798438\n",
      "[200]\teval-auc:0.801781\n",
      "[300]\teval-auc:0.803197\n",
      "[400]\teval-auc:0.804244\n",
      "[500]\teval-auc:0.804591\n",
      "[600]\teval-auc:0.804776\n",
      "[700]\teval-auc:0.804802\n",
      "[800]\teval-auc:0.804844\n",
      "[900]\teval-auc:0.80489\n",
      "[1000]\teval-auc:0.804917\n",
      "Stopping. Best iteration:\n",
      "[998]\teval-auc:0.804922\n",
      "\n",
      "[0]\teval-auc:0.762469\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.793696\n",
      "[200]\teval-auc:0.798113\n",
      "[300]\teval-auc:0.800063\n",
      "[400]\teval-auc:0.801675\n",
      "[500]\teval-auc:0.802392\n",
      "[600]\teval-auc:0.802739\n",
      "[700]\teval-auc:0.802795\n",
      "[800]\teval-auc:0.802773\n",
      "Stopping. Best iteration:\n",
      "[706]\teval-auc:0.8028\n",
      "\n",
      "[0]\teval-auc:0.765749\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.79189\n",
      "[200]\teval-auc:0.795049\n",
      "[300]\teval-auc:0.796775\n",
      "[400]\teval-auc:0.798259\n",
      "[500]\teval-auc:0.798848\n",
      "[600]\teval-auc:0.799378\n",
      "[700]\teval-auc:0.799466\n",
      "[800]\teval-auc:0.799493\n",
      "[900]\teval-auc:0.799558\n",
      "[1000]\teval-auc:0.799647\n",
      "[1100]\teval-auc:0.799705\n",
      "[1200]\teval-auc:0.799764\n",
      "[1300]\teval-auc:0.799812\n",
      "[1400]\teval-auc:0.799859\n",
      "[1500]\teval-auc:0.79986\n",
      "[1600]\teval-auc:0.799886\n",
      "[1700]\teval-auc:0.799904\n",
      "[1800]\teval-auc:0.799971\n",
      "[1900]\teval-auc:0.799986\n",
      "[2000]\teval-auc:0.800007\n",
      "[2100]\teval-auc:0.800049\n",
      "[2200]\teval-auc:0.800067\n",
      "[2300]\teval-auc:0.800082\n",
      "[2400]\teval-auc:0.800052\n",
      "Stopping. Best iteration:\n",
      "[2321]\teval-auc:0.800089\n",
      "\n",
      "cv score - on train:\n",
      "0.8035467731753712\n",
      "('current score in fold:', 0.8037332140659963, 22)\n",
      "[0]\teval-auc:0.76391\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.793078\n",
      "[200]\teval-auc:0.797597\n",
      "[300]\teval-auc:0.799048\n",
      "[400]\teval-auc:0.800256\n",
      "[500]\teval-auc:0.800908\n",
      "[600]\teval-auc:0.801255\n",
      "[700]\teval-auc:0.801377\n",
      "[800]\teval-auc:0.801405\n",
      "[900]\teval-auc:0.801448\n",
      "[1000]\teval-auc:0.801476\n",
      "[1100]\teval-auc:0.801493\n",
      "[1200]\teval-auc:0.801533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1300]\teval-auc:0.801547\n",
      "[1400]\teval-auc:0.80155\n",
      "[1500]\teval-auc:0.801546\n",
      "Stopping. Best iteration:\n",
      "[1452]\teval-auc:0.801557\n",
      "\n",
      "[0]\teval-auc:0.767805\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.795345\n",
      "[200]\teval-auc:0.7989\n",
      "[300]\teval-auc:0.801227\n",
      "[400]\teval-auc:0.802652\n",
      "[500]\teval-auc:0.803223\n",
      "[600]\teval-auc:0.80359\n",
      "[700]\teval-auc:0.803611\n",
      "[800]\teval-auc:0.803606\n",
      "Stopping. Best iteration:\n",
      "[730]\teval-auc:0.803619\n",
      "\n",
      "[0]\teval-auc:0.766566\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.797066\n",
      "[200]\teval-auc:0.800042\n",
      "[300]\teval-auc:0.801453\n",
      "[400]\teval-auc:0.802388\n",
      "[500]\teval-auc:0.803092\n",
      "[600]\teval-auc:0.803298\n",
      "[700]\teval-auc:0.803299\n",
      "Stopping. Best iteration:\n",
      "[670]\teval-auc:0.80332\n",
      "\n",
      "[0]\teval-auc:0.765722\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.795159\n",
      "[200]\teval-auc:0.799734\n",
      "[300]\teval-auc:0.801344\n",
      "[400]\teval-auc:0.80253\n",
      "[500]\teval-auc:0.802956\n",
      "[600]\teval-auc:0.803248\n",
      "[700]\teval-auc:0.80334\n",
      "[800]\teval-auc:0.803391\n",
      "[900]\teval-auc:0.80345\n",
      "[1000]\teval-auc:0.803546\n",
      "[1100]\teval-auc:0.803567\n",
      "[1200]\teval-auc:0.803591\n",
      "[1300]\teval-auc:0.803588\n",
      "Stopping. Best iteration:\n",
      "[1227]\teval-auc:0.803607\n",
      "\n",
      "[0]\teval-auc:0.7701\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.798687\n",
      "[200]\teval-auc:0.800724\n",
      "[300]\teval-auc:0.802401\n",
      "[400]\teval-auc:0.803617\n",
      "[500]\teval-auc:0.804309\n",
      "[600]\teval-auc:0.804548\n",
      "[700]\teval-auc:0.804721\n",
      "[800]\teval-auc:0.80482\n",
      "[900]\teval-auc:0.804913\n",
      "[1000]\teval-auc:0.804998\n",
      "[1100]\teval-auc:0.805052\n",
      "[1200]\teval-auc:0.80508\n",
      "[1300]\teval-auc:0.805103\n",
      "[1400]\teval-auc:0.805145\n",
      "[1500]\teval-auc:0.805114\n",
      "Stopping. Best iteration:\n",
      "[1413]\teval-auc:0.805149\n",
      "\n",
      "cv score - on train:\n",
      "0.8033725918207484\n",
      "('current score in fold:', 0.8037370047774836, 23)\n",
      "[0]\teval-auc:0.772962\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.795983\n",
      "[200]\teval-auc:0.799976\n",
      "[300]\teval-auc:0.801824\n",
      "[400]\teval-auc:0.803129\n",
      "[500]\teval-auc:0.803625\n",
      "[600]\teval-auc:0.803897\n",
      "[700]\teval-auc:0.803955\n",
      "Stopping. Best iteration:\n",
      "[662]\teval-auc:0.803963\n",
      "\n",
      "[0]\teval-auc:0.768459\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.792017\n",
      "[200]\teval-auc:0.796829\n",
      "[300]\teval-auc:0.798705\n",
      "[400]\teval-auc:0.800061\n",
      "[500]\teval-auc:0.800712\n",
      "[600]\teval-auc:0.801089\n",
      "[700]\teval-auc:0.801257\n",
      "[800]\teval-auc:0.801351\n",
      "[900]\teval-auc:0.801423\n",
      "[1000]\teval-auc:0.801527\n",
      "[1100]\teval-auc:0.801558\n",
      "[1200]\teval-auc:0.801617\n",
      "[1300]\teval-auc:0.801669\n",
      "[1400]\teval-auc:0.801691\n",
      "[1500]\teval-auc:0.801711\n",
      "[1600]\teval-auc:0.801714\n",
      "[1700]\teval-auc:0.801711\n",
      "Stopping. Best iteration:\n",
      "[1655]\teval-auc:0.801724\n",
      "\n",
      "[0]\teval-auc:0.76272\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.794878\n",
      "[200]\teval-auc:0.798353\n",
      "[300]\teval-auc:0.799462\n",
      "[400]\teval-auc:0.801138\n",
      "[500]\teval-auc:0.802057\n",
      "[600]\teval-auc:0.802279\n",
      "[700]\teval-auc:0.802458\n",
      "[800]\teval-auc:0.802495\n",
      "[900]\teval-auc:0.802517\n",
      "Stopping. Best iteration:\n",
      "[864]\teval-auc:0.802519\n",
      "\n",
      "[0]\teval-auc:0.766575\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.798719\n",
      "[200]\teval-auc:0.802965\n",
      "[300]\teval-auc:0.804228\n",
      "[400]\teval-auc:0.804974\n",
      "[500]\teval-auc:0.805517\n",
      "[600]\teval-auc:0.805738\n",
      "[700]\teval-auc:0.805787\n",
      "Stopping. Best iteration:\n",
      "[676]\teval-auc:0.805793\n",
      "\n",
      "[0]\teval-auc:0.764984\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.794879\n",
      "[200]\teval-auc:0.798432\n",
      "[300]\teval-auc:0.800212\n",
      "[400]\teval-auc:0.801598\n",
      "[500]\teval-auc:0.802134\n",
      "[600]\teval-auc:0.802373\n",
      "[700]\teval-auc:0.802453\n",
      "[800]\teval-auc:0.802503\n",
      "[900]\teval-auc:0.802594\n",
      "[1000]\teval-auc:0.802679\n",
      "[1100]\teval-auc:0.802745\n",
      "[1200]\teval-auc:0.802801\n",
      "[1300]\teval-auc:0.802859\n",
      "[1400]\teval-auc:0.802844\n",
      "Stopping. Best iteration:\n",
      "[1321]\teval-auc:0.802863\n",
      "\n",
      "cv score - on train:\n",
      "0.803290533148352\n",
      "('current score in fold:', 0.8037378542747593, 24)\n",
      "[0]\teval-auc:0.764214\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.794016\n",
      "[200]\teval-auc:0.796319\n",
      "[300]\teval-auc:0.797982\n",
      "[400]\teval-auc:0.799145\n",
      "[500]\teval-auc:0.799733\n",
      "[600]\teval-auc:0.800125\n",
      "[700]\teval-auc:0.800321\n",
      "[800]\teval-auc:0.800355\n",
      "[900]\teval-auc:0.800394\n",
      "[1000]\teval-auc:0.800484\n",
      "[1100]\teval-auc:0.800578\n",
      "[1200]\teval-auc:0.800599\n",
      "[1300]\teval-auc:0.800622\n",
      "[1400]\teval-auc:0.800644\n",
      "Stopping. Best iteration:\n",
      "[1392]\teval-auc:0.800653\n",
      "\n",
      "[0]\teval-auc:0.767664\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.79721\n",
      "[200]\teval-auc:0.79995\n",
      "[300]\teval-auc:0.80242\n",
      "[400]\teval-auc:0.803945\n",
      "[500]\teval-auc:0.804612\n",
      "[600]\teval-auc:0.804823\n",
      "[700]\teval-auc:0.804807\n",
      "Stopping. Best iteration:\n",
      "[609]\teval-auc:0.804829\n",
      "\n",
      "[0]\teval-auc:0.770277\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.79525\n",
      "[200]\teval-auc:0.79992\n",
      "[300]\teval-auc:0.80141\n",
      "[400]\teval-auc:0.802566\n",
      "[500]\teval-auc:0.803304\n",
      "[600]\teval-auc:0.803451\n",
      "[700]\teval-auc:0.803572\n",
      "[800]\teval-auc:0.803638\n",
      "[900]\teval-auc:0.803679\n",
      "[1000]\teval-auc:0.80373\n",
      "[1100]\teval-auc:0.803762\n",
      "[1200]\teval-auc:0.803798\n",
      "[1300]\teval-auc:0.803811\n",
      "Stopping. Best iteration:\n",
      "[1281]\teval-auc:0.803818\n",
      "\n",
      "[0]\teval-auc:0.773015\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.796525\n",
      "[200]\teval-auc:0.800468\n",
      "[300]\teval-auc:0.801967\n",
      "[400]\teval-auc:0.803078\n",
      "[500]\teval-auc:0.803521\n",
      "[600]\teval-auc:0.803898\n",
      "[700]\teval-auc:0.804032\n",
      "[800]\teval-auc:0.804153\n",
      "[900]\teval-auc:0.804216\n",
      "[1000]\teval-auc:0.804278\n",
      "[1100]\teval-auc:0.804339\n",
      "[1200]\teval-auc:0.804383\n",
      "[1300]\teval-auc:0.804411\n",
      "[1400]\teval-auc:0.80443\n",
      "[1500]\teval-auc:0.80445\n",
      "[1600]\teval-auc:0.80447\n",
      "[1700]\teval-auc:0.804508\n",
      "[1800]\teval-auc:0.804529\n",
      "[1900]\teval-auc:0.804541\n",
      "[2000]\teval-auc:0.804558\n",
      "[2100]\teval-auc:0.80457\n",
      "[2200]\teval-auc:0.804571\n",
      "[2300]\teval-auc:0.804569\n",
      "Stopping. Best iteration:\n",
      "[2238]\teval-auc:0.804582\n",
      "\n",
      "[0]\teval-auc:0.763571\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.794409\n",
      "[200]\teval-auc:0.798256\n",
      "[300]\teval-auc:0.800927\n",
      "[400]\teval-auc:0.801778\n",
      "[500]\teval-auc:0.802405\n",
      "[600]\teval-auc:0.802603\n",
      "[700]\teval-auc:0.80266\n",
      "[800]\teval-auc:0.802683\n",
      "[900]\teval-auc:0.802696\n",
      "[1000]\teval-auc:0.802781\n",
      "[1100]\teval-auc:0.802809\n",
      "[1200]\teval-auc:0.802799\n",
      "Stopping. Best iteration:\n",
      "[1132]\teval-auc:0.802822\n",
      "\n",
      "cv score - on train:\n",
      "0.8031860644343007\n",
      "('current score in fold:', 0.8037381123372548, 25)\n",
      "[0]\teval-auc:0.760375\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.790712\n",
      "[200]\teval-auc:0.794018\n",
      "[300]\teval-auc:0.796077\n",
      "[400]\teval-auc:0.797664\n",
      "[500]\teval-auc:0.798276\n",
      "[600]\teval-auc:0.798696\n",
      "[700]\teval-auc:0.798859\n",
      "[800]\teval-auc:0.798896\n",
      "[900]\teval-auc:0.798899\n",
      "Stopping. Best iteration:\n",
      "[846]\teval-auc:0.798912\n",
      "\n",
      "[0]\teval-auc:0.762382\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.794922\n",
      "[200]\teval-auc:0.798361\n",
      "[300]\teval-auc:0.799907\n",
      "[400]\teval-auc:0.80103\n",
      "[500]\teval-auc:0.801577\n",
      "[600]\teval-auc:0.801783\n",
      "[700]\teval-auc:0.801838\n",
      "Stopping. Best iteration:\n",
      "[683]\teval-auc:0.80184\n",
      "\n",
      "[0]\teval-auc:0.773668\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.796485\n",
      "[200]\teval-auc:0.799741\n",
      "[300]\teval-auc:0.801334\n",
      "[400]\teval-auc:0.802508\n",
      "[500]\teval-auc:0.802937\n",
      "[600]\teval-auc:0.803177\n",
      "[700]\teval-auc:0.803332\n",
      "[800]\teval-auc:0.803421\n",
      "[900]\teval-auc:0.803475\n",
      "[1000]\teval-auc:0.803526\n",
      "[1100]\teval-auc:0.803538\n",
      "[1200]\teval-auc:0.803552\n",
      "Stopping. Best iteration:\n",
      "[1176]\teval-auc:0.803558\n",
      "\n",
      "[0]\teval-auc:0.769803\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.79746\n",
      "[200]\teval-auc:0.802311\n",
      "[300]\teval-auc:0.803931\n",
      "[400]\teval-auc:0.805098\n",
      "[500]\teval-auc:0.805892\n",
      "[600]\teval-auc:0.806127\n",
      "[700]\teval-auc:0.806169\n",
      "[800]\teval-auc:0.8062\n",
      "[900]\teval-auc:0.806215\n",
      "Stopping. Best iteration:\n",
      "[863]\teval-auc:0.806223\n",
      "\n",
      "[0]\teval-auc:0.766052\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.797951\n",
      "[200]\teval-auc:0.801472\n",
      "[300]\teval-auc:0.803006\n",
      "[400]\teval-auc:0.804301\n",
      "[500]\teval-auc:0.805147\n",
      "[600]\teval-auc:0.80543\n",
      "[700]\teval-auc:0.805511\n",
      "[800]\teval-auc:0.805616\n",
      "[900]\teval-auc:0.805708\n",
      "[1000]\teval-auc:0.805847\n",
      "[1100]\teval-auc:0.805905\n",
      "[1200]\teval-auc:0.805941\n",
      "[1300]\teval-auc:0.805979\n",
      "[1400]\teval-auc:0.806021\n",
      "[1500]\teval-auc:0.806059\n",
      "[1600]\teval-auc:0.806067\n",
      "[1700]\teval-auc:0.806091\n",
      "[1800]\teval-auc:0.806123\n",
      "[1900]\teval-auc:0.806131\n",
      "[2000]\teval-auc:0.806137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2100]\teval-auc:0.806158\n",
      "[2200]\teval-auc:0.806177\n",
      "Stopping. Best iteration:\n",
      "[2189]\teval-auc:0.80618\n",
      "\n",
      "cv score - on train:\n",
      "0.8032929019511641\n",
      "('current score in fold:', 0.8037388563153268, 26)\n",
      "[0]\teval-auc:0.777629\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.800725\n",
      "[200]\teval-auc:0.804466\n",
      "[300]\teval-auc:0.806405\n",
      "[400]\teval-auc:0.807715\n",
      "[500]\teval-auc:0.808318\n",
      "[600]\teval-auc:0.808653\n",
      "[700]\teval-auc:0.80869\n",
      "[800]\teval-auc:0.808742\n",
      "[900]\teval-auc:0.808819\n",
      "[1000]\teval-auc:0.808907\n",
      "[1100]\teval-auc:0.808952\n",
      "[1200]\teval-auc:0.80902\n",
      "[1300]\teval-auc:0.809059\n",
      "Stopping. Best iteration:\n",
      "[1299]\teval-auc:0.809059\n",
      "\n",
      "[0]\teval-auc:0.764677\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.797369\n",
      "[200]\teval-auc:0.800451\n",
      "[300]\teval-auc:0.80171\n",
      "[400]\teval-auc:0.803055\n",
      "[500]\teval-auc:0.803877\n",
      "[600]\teval-auc:0.804009\n",
      "[700]\teval-auc:0.804055\n",
      "[800]\teval-auc:0.80408\n",
      "[900]\teval-auc:0.804145\n",
      "[1000]\teval-auc:0.804192\n",
      "[1100]\teval-auc:0.804228\n",
      "[1200]\teval-auc:0.804269\n",
      "[1300]\teval-auc:0.804283\n",
      "[1400]\teval-auc:0.804303\n",
      "[1500]\teval-auc:0.804292\n",
      "Stopping. Best iteration:\n",
      "[1402]\teval-auc:0.804305\n",
      "\n",
      "[0]\teval-auc:0.755278\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.785214\n",
      "[200]\teval-auc:0.789299\n",
      "[300]\teval-auc:0.791667\n",
      "[400]\teval-auc:0.792965\n",
      "[500]\teval-auc:0.793743\n",
      "[600]\teval-auc:0.794134\n",
      "[700]\teval-auc:0.794187\n",
      "[800]\teval-auc:0.794228\n",
      "[900]\teval-auc:0.794235\n",
      "[1000]\teval-auc:0.794294\n",
      "[1100]\teval-auc:0.794366\n",
      "[1200]\teval-auc:0.794412\n",
      "[1300]\teval-auc:0.794401\n",
      "Stopping. Best iteration:\n",
      "[1241]\teval-auc:0.794422\n",
      "\n",
      "[0]\teval-auc:0.77412\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.79809\n",
      "[200]\teval-auc:0.801804\n",
      "[300]\teval-auc:0.803485\n",
      "[400]\teval-auc:0.804691\n",
      "[500]\teval-auc:0.805285\n",
      "[600]\teval-auc:0.805602\n",
      "[700]\teval-auc:0.805812\n",
      "[800]\teval-auc:0.805902\n",
      "[900]\teval-auc:0.80598\n",
      "[1000]\teval-auc:0.806068\n",
      "[1100]\teval-auc:0.806126\n",
      "[1200]\teval-auc:0.80615\n",
      "[1300]\teval-auc:0.806198\n",
      "[1400]\teval-auc:0.80622\n",
      "[1500]\teval-auc:0.806233\n",
      "[1600]\teval-auc:0.806252\n",
      "Stopping. Best iteration:\n",
      "[1583]\teval-auc:0.806261\n",
      "\n",
      "[0]\teval-auc:0.764568\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.794925\n",
      "[200]\teval-auc:0.799604\n",
      "[300]\teval-auc:0.80081\n",
      "[400]\teval-auc:0.801973\n",
      "[500]\teval-auc:0.802602\n",
      "[600]\teval-auc:0.802783\n",
      "Stopping. Best iteration:\n",
      "[596]\teval-auc:0.802788\n",
      "\n",
      "cv score - on train:\n",
      "0.8032594992451886\n",
      "('current score in fold:', 0.80373963427899, 27)\n",
      "[0]\teval-auc:0.762149\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.794611\n",
      "[200]\teval-auc:0.797239\n",
      "[300]\teval-auc:0.799347\n",
      "[400]\teval-auc:0.800276\n",
      "[500]\teval-auc:0.800824\n",
      "[600]\teval-auc:0.801121\n",
      "[700]\teval-auc:0.801322\n",
      "[800]\teval-auc:0.801352\n",
      "[900]\teval-auc:0.801408\n",
      "[1000]\teval-auc:0.801482\n",
      "[1100]\teval-auc:0.80155\n",
      "[1200]\teval-auc:0.801583\n",
      "[1300]\teval-auc:0.801625\n",
      "[1400]\teval-auc:0.801602\n",
      "Stopping. Best iteration:\n",
      "[1305]\teval-auc:0.801629\n",
      "\n",
      "[0]\teval-auc:0.760348\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.794136\n",
      "[200]\teval-auc:0.797365\n",
      "[300]\teval-auc:0.798837\n",
      "[400]\teval-auc:0.80009\n",
      "[500]\teval-auc:0.80044\n",
      "[600]\teval-auc:0.800702\n",
      "[700]\teval-auc:0.800789\n",
      "[800]\teval-auc:0.800844\n",
      "[900]\teval-auc:0.800872\n",
      "[1000]\teval-auc:0.800925\n",
      "[1100]\teval-auc:0.800943\n",
      "[1200]\teval-auc:0.800958\n",
      "[1300]\teval-auc:0.800944\n",
      "Stopping. Best iteration:\n",
      "[1219]\teval-auc:0.800962\n",
      "\n",
      "[0]\teval-auc:0.762716\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.796376\n",
      "[200]\teval-auc:0.799076\n",
      "[300]\teval-auc:0.800137\n",
      "[400]\teval-auc:0.801445\n",
      "[500]\teval-auc:0.802089\n",
      "[600]\teval-auc:0.802181\n",
      "[700]\teval-auc:0.802217\n",
      "[800]\teval-auc:0.80224\n",
      "[900]\teval-auc:0.80225\n",
      "[1000]\teval-auc:0.802287\n",
      "Stopping. Best iteration:\n",
      "[995]\teval-auc:0.802289\n",
      "\n",
      "[0]\teval-auc:0.765109\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.796771\n",
      "[200]\teval-auc:0.800286\n",
      "[300]\teval-auc:0.802224\n",
      "[400]\teval-auc:0.803725\n",
      "[500]\teval-auc:0.804538\n",
      "[600]\teval-auc:0.804919\n",
      "[700]\teval-auc:0.804969\n",
      "[800]\teval-auc:0.805026\n",
      "[900]\teval-auc:0.805048\n",
      "[1000]\teval-auc:0.805137\n",
      "[1100]\teval-auc:0.805142\n",
      "[1200]\teval-auc:0.805155\n",
      "[1300]\teval-auc:0.805152\n",
      "Stopping. Best iteration:\n",
      "[1208]\teval-auc:0.805156\n",
      "\n",
      "[0]\teval-auc:0.767818\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.797557\n",
      "[200]\teval-auc:0.801079\n",
      "[300]\teval-auc:0.802541\n",
      "[400]\teval-auc:0.803956\n",
      "[500]\teval-auc:0.804773\n",
      "[600]\teval-auc:0.805179\n",
      "[700]\teval-auc:0.805324\n",
      "[800]\teval-auc:0.805373\n",
      "[900]\teval-auc:0.805449\n",
      "[1000]\teval-auc:0.805565\n",
      "[1100]\teval-auc:0.805626\n",
      "[1200]\teval-auc:0.805647\n",
      "[1300]\teval-auc:0.805635\n",
      "Stopping. Best iteration:\n",
      "[1239]\teval-auc:0.805656\n",
      "\n",
      "cv score - on train:\n",
      "0.8030786014970659\n",
      "('current score in fold:', 0.8037305982442245, 28)\n",
      "[0]\teval-auc:0.756726\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.790042\n",
      "[200]\teval-auc:0.794218\n",
      "[300]\teval-auc:0.796166\n",
      "[400]\teval-auc:0.797888\n",
      "[500]\teval-auc:0.798724\n",
      "[600]\teval-auc:0.798977\n",
      "[700]\teval-auc:0.799013\n",
      "Stopping. Best iteration:\n",
      "[655]\teval-auc:0.799033\n",
      "\n",
      "[0]\teval-auc:0.768645\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.800482\n",
      "[200]\teval-auc:0.802976\n",
      "[300]\teval-auc:0.804317\n",
      "[400]\teval-auc:0.805345\n",
      "[500]\teval-auc:0.80591\n",
      "[600]\teval-auc:0.806322\n",
      "[700]\teval-auc:0.806505\n",
      "[800]\teval-auc:0.806602\n",
      "[900]\teval-auc:0.806659\n",
      "[1000]\teval-auc:0.806722\n",
      "[1100]\teval-auc:0.80681\n",
      "[1200]\teval-auc:0.806852\n",
      "[1300]\teval-auc:0.80689\n",
      "[1400]\teval-auc:0.806923\n",
      "[1500]\teval-auc:0.806944\n",
      "[1600]\teval-auc:0.806971\n",
      "[1700]\teval-auc:0.806965\n",
      "Stopping. Best iteration:\n",
      "[1636]\teval-auc:0.806978\n",
      "\n",
      "[0]\teval-auc:0.776408\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.798683\n",
      "[200]\teval-auc:0.803092\n",
      "[300]\teval-auc:0.804709\n",
      "[400]\teval-auc:0.805776\n",
      "[500]\teval-auc:0.806423\n",
      "[600]\teval-auc:0.80658\n",
      "[700]\teval-auc:0.806672\n",
      "[800]\teval-auc:0.806725\n",
      "[900]\teval-auc:0.806765\n",
      "[1000]\teval-auc:0.806753\n",
      "Stopping. Best iteration:\n",
      "[900]\teval-auc:0.806765\n",
      "\n",
      "[0]\teval-auc:0.772251\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.798422\n",
      "[200]\teval-auc:0.802159\n",
      "[300]\teval-auc:0.803258\n",
      "[400]\teval-auc:0.804326\n",
      "[500]\teval-auc:0.80502\n",
      "[600]\teval-auc:0.805137\n",
      "[700]\teval-auc:0.805257\n",
      "[800]\teval-auc:0.805328\n",
      "[900]\teval-auc:0.805395\n",
      "[1000]\teval-auc:0.805437\n",
      "[1100]\teval-auc:0.805509\n",
      "[1200]\teval-auc:0.805534\n",
      "[1300]\teval-auc:0.805527\n",
      "Stopping. Best iteration:\n",
      "[1240]\teval-auc:0.805551\n",
      "\n",
      "[0]\teval-auc:0.765073\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.790282\n",
      "[200]\teval-auc:0.792233\n",
      "[300]\teval-auc:0.795244\n",
      "[400]\teval-auc:0.79691\n",
      "[500]\teval-auc:0.797649\n",
      "[600]\teval-auc:0.797999\n",
      "[700]\teval-auc:0.798124\n",
      "[800]\teval-auc:0.798159\n",
      "[900]\teval-auc:0.798223\n",
      "[1000]\teval-auc:0.798284\n",
      "[1100]\teval-auc:0.79833\n",
      "[1200]\teval-auc:0.798381\n",
      "[1300]\teval-auc:0.798427\n",
      "[1400]\teval-auc:0.798457\n",
      "[1500]\teval-auc:0.798492\n",
      "[1600]\teval-auc:0.798522\n",
      "[1700]\teval-auc:0.798575\n",
      "[1800]\teval-auc:0.798601\n",
      "[1900]\teval-auc:0.798624\n",
      "[2000]\teval-auc:0.798647\n",
      "[2100]\teval-auc:0.79869\n",
      "Stopping. Best iteration:\n",
      "[2086]\teval-auc:0.798693\n",
      "\n",
      "cv score - on train:\n",
      "0.8033288369755307\n",
      "('current score in fold:', 0.8037331693931127, 29)\n",
      "[0]\teval-auc:0.765355\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.793625\n",
      "[200]\teval-auc:0.797318\n",
      "[300]\teval-auc:0.79985\n",
      "[400]\teval-auc:0.800765\n",
      "[500]\teval-auc:0.801229\n",
      "[600]\teval-auc:0.801322\n",
      "[700]\teval-auc:0.801373\n",
      "Stopping. Best iteration:\n",
      "[663]\teval-auc:0.801382\n",
      "\n",
      "[0]\teval-auc:0.766706\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.791263\n",
      "[200]\teval-auc:0.795224\n",
      "[300]\teval-auc:0.796458\n",
      "[400]\teval-auc:0.797905\n",
      "[500]\teval-auc:0.798731\n",
      "[600]\teval-auc:0.799028\n",
      "[700]\teval-auc:0.799208\n",
      "[800]\teval-auc:0.799244\n",
      "[900]\teval-auc:0.799284\n",
      "[1000]\teval-auc:0.799344\n",
      "[1100]\teval-auc:0.799325\n",
      "Stopping. Best iteration:\n",
      "[1050]\teval-auc:0.799357\n",
      "\n",
      "[0]\teval-auc:0.772729\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.800335\n",
      "[200]\teval-auc:0.803226\n",
      "[300]\teval-auc:0.804628\n",
      "[400]\teval-auc:0.806013\n",
      "[500]\teval-auc:0.806496\n",
      "[600]\teval-auc:0.806638\n",
      "[700]\teval-auc:0.8068\n",
      "[800]\teval-auc:0.806862\n",
      "[900]\teval-auc:0.806935\n",
      "[1000]\teval-auc:0.807\n",
      "[1100]\teval-auc:0.807063\n",
      "[1200]\teval-auc:0.80711\n",
      "[1300]\teval-auc:0.80712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping. Best iteration:\n",
      "[1274]\teval-auc:0.807131\n",
      "\n",
      "[0]\teval-auc:0.762301\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.793332\n",
      "[200]\teval-auc:0.798008\n",
      "[300]\teval-auc:0.799506\n",
      "[400]\teval-auc:0.800756\n",
      "[500]\teval-auc:0.801269\n",
      "[600]\teval-auc:0.801494\n",
      "[700]\teval-auc:0.801547\n",
      "[800]\teval-auc:0.801551\n",
      "[900]\teval-auc:0.801573\n",
      "[1000]\teval-auc:0.801603\n",
      "[1100]\teval-auc:0.80165\n",
      "[1200]\teval-auc:0.801679\n",
      "[1300]\teval-auc:0.80168\n",
      "[1400]\teval-auc:0.801725\n",
      "[1500]\teval-auc:0.801764\n",
      "[1600]\teval-auc:0.801773\n",
      "[1700]\teval-auc:0.801794\n",
      "Stopping. Best iteration:\n",
      "[1699]\teval-auc:0.801797\n",
      "\n",
      "[0]\teval-auc:0.769157\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.799634\n",
      "[200]\teval-auc:0.802436\n",
      "[300]\teval-auc:0.804407\n",
      "[400]\teval-auc:0.805994\n",
      "[500]\teval-auc:0.806635\n",
      "[600]\teval-auc:0.806998\n",
      "[700]\teval-auc:0.807151\n",
      "[800]\teval-auc:0.807254\n",
      "[900]\teval-auc:0.807285\n",
      "[1000]\teval-auc:0.807369\n",
      "[1100]\teval-auc:0.807416\n",
      "[1200]\teval-auc:0.807432\n",
      "Stopping. Best iteration:\n",
      "[1133]\teval-auc:0.807441\n",
      "\n",
      "cv score - on train:\n",
      "0.8033080107906603\n",
      "('current score in fold:', 0.8037333872001386, 30)\n",
      "[0]\teval-auc:0.758106\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.791905\n",
      "[200]\teval-auc:0.794956\n",
      "[300]\teval-auc:0.797711\n",
      "[400]\teval-auc:0.798973\n",
      "[500]\teval-auc:0.799511\n",
      "[600]\teval-auc:0.799816\n",
      "[700]\teval-auc:0.799932\n",
      "[800]\teval-auc:0.800011\n",
      "[900]\teval-auc:0.800066\n",
      "[1000]\teval-auc:0.800105\n",
      "[1100]\teval-auc:0.800137\n",
      "[1200]\teval-auc:0.80018\n",
      "[1300]\teval-auc:0.800215\n",
      "[1400]\teval-auc:0.800264\n",
      "[1500]\teval-auc:0.80032\n",
      "[1600]\teval-auc:0.800357\n",
      "[1700]\teval-auc:0.800383\n",
      "[1800]\teval-auc:0.800405\n",
      "Stopping. Best iteration:\n",
      "[1782]\teval-auc:0.800408\n",
      "\n",
      "[0]\teval-auc:0.762601\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.797194\n",
      "[200]\teval-auc:0.800065\n",
      "[300]\teval-auc:0.80135\n",
      "[400]\teval-auc:0.802283\n",
      "[500]\teval-auc:0.80266\n",
      "[600]\teval-auc:0.802731\n",
      "Stopping. Best iteration:\n",
      "[585]\teval-auc:0.802737\n",
      "\n",
      "[0]\teval-auc:0.769457\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.796842\n",
      "[200]\teval-auc:0.799934\n",
      "[300]\teval-auc:0.801565\n",
      "[400]\teval-auc:0.803296\n",
      "[500]\teval-auc:0.803952\n",
      "[600]\teval-auc:0.804208\n",
      "[700]\teval-auc:0.804333\n",
      "[800]\teval-auc:0.804368\n",
      "[900]\teval-auc:0.804416\n",
      "[1000]\teval-auc:0.804462\n",
      "[1100]\teval-auc:0.804535\n",
      "[1200]\teval-auc:0.804565\n",
      "[1300]\teval-auc:0.804565\n",
      "Stopping. Best iteration:\n",
      "[1246]\teval-auc:0.804573\n",
      "\n",
      "[0]\teval-auc:0.765018\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.796154\n",
      "[200]\teval-auc:0.799681\n",
      "[300]\teval-auc:0.801355\n",
      "[400]\teval-auc:0.802758\n",
      "[500]\teval-auc:0.803262\n",
      "[600]\teval-auc:0.803663\n",
      "[700]\teval-auc:0.803808\n",
      "[800]\teval-auc:0.803946\n",
      "[900]\teval-auc:0.803974\n",
      "[1000]\teval-auc:0.804031\n",
      "[1100]\teval-auc:0.804035\n",
      "Stopping. Best iteration:\n",
      "[1031]\teval-auc:0.80405\n",
      "\n",
      "[0]\teval-auc:0.763598\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.795937\n",
      "[200]\teval-auc:0.799842\n",
      "[300]\teval-auc:0.802474\n",
      "[400]\teval-auc:0.803953\n",
      "[500]\teval-auc:0.804678\n",
      "[600]\teval-auc:0.804989\n",
      "[700]\teval-auc:0.805057\n",
      "[800]\teval-auc:0.805092\n",
      "[900]\teval-auc:0.805132\n",
      "[1000]\teval-auc:0.805193\n",
      "[1100]\teval-auc:0.805252\n",
      "[1200]\teval-auc:0.805328\n",
      "[1300]\teval-auc:0.805344\n",
      "[1400]\teval-auc:0.805377\n",
      "Stopping. Best iteration:\n",
      "[1377]\teval-auc:0.80539\n",
      "\n",
      "cv score - on train:\n",
      "0.8033364735449355\n",
      "('current score in fold:', 0.8037362977061955, 31)\n",
      "[0]\teval-auc:0.767054\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.795347\n",
      "[200]\teval-auc:0.798659\n",
      "[300]\teval-auc:0.800188\n",
      "[400]\teval-auc:0.801822\n",
      "[500]\teval-auc:0.802441\n",
      "[600]\teval-auc:0.802732\n",
      "[700]\teval-auc:0.802862\n",
      "[800]\teval-auc:0.802905\n",
      "[900]\teval-auc:0.802938\n",
      "[1000]\teval-auc:0.802933\n",
      "Stopping. Best iteration:\n",
      "[930]\teval-auc:0.802951\n",
      "\n",
      "[0]\teval-auc:0.76448\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.793033\n",
      "[200]\teval-auc:0.797225\n",
      "[300]\teval-auc:0.798629\n",
      "[400]\teval-auc:0.799896\n",
      "[500]\teval-auc:0.80044\n",
      "[600]\teval-auc:0.800589\n",
      "[700]\teval-auc:0.800722\n",
      "[800]\teval-auc:0.800749\n",
      "Stopping. Best iteration:\n",
      "[790]\teval-auc:0.800751\n",
      "\n",
      "[0]\teval-auc:0.76895\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.80047\n",
      "[200]\teval-auc:0.804399\n",
      "[300]\teval-auc:0.805995\n",
      "[400]\teval-auc:0.80691\n",
      "[500]\teval-auc:0.807488\n",
      "[600]\teval-auc:0.807662\n",
      "[700]\teval-auc:0.807756\n",
      "[800]\teval-auc:0.807804\n",
      "[900]\teval-auc:0.807853\n",
      "[1000]\teval-auc:0.807848\n",
      "Stopping. Best iteration:\n",
      "[916]\teval-auc:0.807856\n",
      "\n",
      "[0]\teval-auc:0.759213\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.792789\n",
      "[200]\teval-auc:0.796121\n",
      "[300]\teval-auc:0.797415\n",
      "[400]\teval-auc:0.798554\n",
      "[500]\teval-auc:0.799239\n",
      "[600]\teval-auc:0.799493\n",
      "[700]\teval-auc:0.799586\n",
      "[800]\teval-auc:0.799635\n",
      "[900]\teval-auc:0.799676\n",
      "[1000]\teval-auc:0.799752\n",
      "[1100]\teval-auc:0.799836\n",
      "[1200]\teval-auc:0.799871\n",
      "[1300]\teval-auc:0.799904\n",
      "[1400]\teval-auc:0.799908\n",
      "[1500]\teval-auc:0.799915\n",
      "Stopping. Best iteration:\n",
      "[1469]\teval-auc:0.799929\n",
      "\n",
      "[0]\teval-auc:0.766012\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.796941\n",
      "[200]\teval-auc:0.799682\n",
      "[300]\teval-auc:0.801757\n",
      "[400]\teval-auc:0.803088\n",
      "[500]\teval-auc:0.804045\n",
      "[600]\teval-auc:0.804395\n",
      "[700]\teval-auc:0.804469\n",
      "[800]\teval-auc:0.804559\n",
      "[900]\teval-auc:0.804633\n",
      "[1000]\teval-auc:0.804665\n",
      "[1100]\teval-auc:0.804647\n",
      "Stopping. Best iteration:\n",
      "[1015]\teval-auc:0.804671\n",
      "\n",
      "cv score - on train:\n",
      "0.8031569277393449\n",
      "('current score in fold:', 0.8037305234331753, 32)\n"
     ]
    }
   ],
   "source": [
    "final_cv_train_xgbst = np.zeros(len(labels_train))\n",
    "final_cv_pred_xgbst = np.zeros(len( test_ids ))\n",
    "\n",
    "NFOLDS = 5 \n",
    "\n",
    "M = 32 \n",
    "x_score_xgbst = []\n",
    "dtest = xgb.DMatrix( new_test )\n",
    "for s in range( M ):\n",
    "    \n",
    "    params['seed'] = s\n",
    "    \n",
    "    cv_train = np.zeros( len( labels_train ))\n",
    "    cv_pred = np.zeros( len( test_ids ) )\n",
    "    kfold = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=s)\n",
    "    kf  = kfold.split(  new_train , labels_train )\n",
    "    \n",
    "    for i, (train_fold, validate) in enumerate(kf):\n",
    "        \n",
    "        X_train, X_validate, label_train, label_validate = new_train[train_fold, :], new_train[validate, :], labels_train[train_fold], labels_train[validate]\n",
    "\n",
    "        dtrain = xgb.DMatrix( X_train , label=label_train )\n",
    "        dvalid = xgb.DMatrix( X_validate , label = label_validate )\n",
    "        evallist = [ (dvalid, 'eval') ]\n",
    "        bst = xgb.train(params, dtrain, num_boost_round, evallist  , early_stopping_rounds=100 , verbose_eval=100 )\n",
    "        #bst = lgb.train(params, dtrain , num_boost_round , valid_sets=[dvalid ] , verbose_eval = 100 , early_stopping_rounds = 100 )\n",
    "    #best_trees.append(bst.best_iteration)    \n",
    "        #cv_pred +=  bst.predict(  new_test , num_iteration = bst.best_iteration )\n",
    "        \n",
    "        cv_pred += bst.predict( dtest, ntree_limit=bst.best_ntree_limit )\n",
    "    #cv_eval_total += bst.predict( x_val , num_iteration = bst.best_iteration )          \n",
    "        cv_train[validate] += bst.predict( dvalid , ntree_limit=bst.best_ntree_limit )\n",
    "    \n",
    "    cv_pred /= NFOLDS\n",
    "    \n",
    "    final_cv_train_xgbst += cv_train\n",
    "    final_cv_pred_xgbst += cv_pred\n",
    "    \n",
    "    print(\"cv score - on train:\")\n",
    "    print( roc_auc_score(labels_train, cv_train))\n",
    "    print( \"current score in fold:\", roc_auc_score( labels_train , final_cv_train_xgbst / (s + 1.)), s+1)\n",
    "    \n",
    "    x_score_xgbst.append(roc_auc_score( labels_train , cv_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8032867335753179"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array( x_score_xgbst).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_xgb = final_cv_pred_xgbst/M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07716597, 0.15364012, 0.04291031, ..., 0.01097377, 0.06118458,\n",
       "       0.1338221 ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final_cv_pred/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train = final_cv_train_xgbst/32.0\n",
    "final_train_lgb = final_cv_train/32.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pos = final_train[ labels_train == 1  ]\n",
    "final_neg = final_train[labels_train == 0 ]\n",
    "final_pos_lgb = final_train_lgb[ labels_train == 1  ]\n",
    "final_neg_lgb = final_train_lgb[labels_train == 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7809469043300058\n"
     ]
    }
   ],
   "source": [
    "print( np.array( x_score).mean() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7979566678585848"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score( labels_train , final_cv_train/32 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = len(final_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = len(final_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist( final_pos , density = True , bins = 100 , label = \"pos_xgb\" )\n",
    "plt.hist(  final_neg  , density = True , bins = 100 , alpha = 0.7 , label = \"neg_xgb\")\n",
    "#plt.hist( final_pos_lgb , density = True , bins = 100 , label = \"pos_lgb\" )\n",
    "#plt.hist(  final_neg_lgb , density = True , bins = 100 , alpha = 0.7 , label = \"neg_lgb\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist( final_xgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511,)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_logi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': final_pred_lgb }).to_csv('../data/pred_xgb_oof.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
