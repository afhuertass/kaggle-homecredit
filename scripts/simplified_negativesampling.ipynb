{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from  sklearn.preprocessing import LabelEncoder\n",
    "from  sklearn.preprocessing import OneHotEncoder\n",
    "import scipy \n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "\n",
    "from __future__ import division\n",
    "from scipy.special import erfinv\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 269)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_train = pd.read_csv(\"../data/sparse/train_new2.csv\")\n",
    "#df_test = pd.read_csv(\"../data/sparse/test_new2.csv\")\n",
    "df_train = pd.read_csv(\"../data/sparse/train_good.csv\")\n",
    "df_test = pd.read_csv(\"../data/sparse/test_good.csv\")\n",
    "df_labels = pd.read_csv(\"../data/labels_train.csv\" , header = None )[1]\n",
    "test_ids = pd.read_csv(\"../data/ids_test.csv\" , header = None)[1].values\n",
    "test_ids\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48744,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_data_indx = df_labels[ df_labels == 1 ]\n",
    "positive_data = df_train.iloc[ positive_data_indx.index ]\n",
    "#print( positive_data.shape )\n",
    "negative_data_indx = df_labels[  df_labels == 0 ]\n",
    "negative_data = df_train.iloc[  negative_data_indx.index ]\n",
    "#print( negative_data.shape )\n",
    "positive_ratio = float(len(positive_data)) / len(df_train)\n",
    "positive_ratio\n",
    "\n",
    "positive_data = None\n",
    "negative_data = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "num_leaves = 30\n",
    "min_data_in_leaf = 2000\n",
    "feature_fraction = 0.05\n",
    "num_boost_round = 10000\n",
    "ncat = 43\n",
    "params = {\"objective\": \"binary\",\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"learning_rate\": learning_rate,\n",
    "          \"metric\":[\"auc\" ,\"binary_logloss\"] , \n",
    "          \"num_leaves\": num_leaves,\n",
    "           \"max_bin\": 256,\n",
    "          \"feature_fraction\": feature_fraction,\n",
    "          \"verbosity\": 1,\n",
    "          \"drop_rate\": 0.1,\n",
    "          \"is_unbalance\": False,\n",
    "          \"max_drop\": 50,\n",
    "          \"min_child_samples\": 20,\n",
    "          \"min_child_weight\": 150,\n",
    "          \"min_split_gain\": 0.5,\n",
    "          \"max_depth\": -1, \n",
    "         \"lambda_l2\": 100 , \n",
    "          \"min_gain_to_split\" : 0.5 ,\n",
    "          \"bagging_freq\" : 1 , \n",
    "          \"subsample\" : 0.9 , \n",
    "          \"categorical_feature\" : range(ncat)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19970, 269)\n",
      "(19850, 269)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/lightgbm/basic.py:1036: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/usr/local/lib/python2.7/dist-packages/lightgbm/basic.py:681: UserWarning: categorical_feature in param dict is overrided.\n",
      "  warnings.warn('categorical_feature in param dict is overrided.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.605962\tvalid_0's auc: 0.738561\n",
      "[200]\tvalid_0's binary_logloss: 0.589234\tvalid_0's auc: 0.753709\n",
      "[300]\tvalid_0's binary_logloss: 0.584283\tvalid_0's auc: 0.758082\n",
      "[400]\tvalid_0's binary_logloss: 0.581995\tvalid_0's auc: 0.760293\n",
      "[500]\tvalid_0's binary_logloss: 0.581451\tvalid_0's auc: 0.761069\n",
      "[600]\tvalid_0's binary_logloss: 0.581957\tvalid_0's auc: 0.760892\n",
      "Early stopping, best iteration is:\n",
      "[505]\tvalid_0's binary_logloss: 0.581346\tvalid_0's auc: 0.761139\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.6071\tvalid_0's auc: 0.739302\n",
      "[200]\tvalid_0's binary_logloss: 0.588971\tvalid_0's auc: 0.756256\n",
      "[300]\tvalid_0's binary_logloss: 0.581867\tvalid_0's auc: 0.762211\n",
      "[400]\tvalid_0's binary_logloss: 0.578142\tvalid_0's auc: 0.765301\n",
      "[500]\tvalid_0's binary_logloss: 0.577241\tvalid_0's auc: 0.765784\n",
      "Early stopping, best iteration is:\n",
      "[453]\tvalid_0's binary_logloss: 0.57723\tvalid_0's auc: 0.766002\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.604858\tvalid_0's auc: 0.743387\n",
      "[200]\tvalid_0's binary_logloss: 0.585537\tvalid_0's auc: 0.761883\n",
      "[300]\tvalid_0's binary_logloss: 0.578324\tvalid_0's auc: 0.768019\n",
      "[400]\tvalid_0's binary_logloss: 0.57401\tvalid_0's auc: 0.771473\n",
      "Early stopping, best iteration is:\n",
      "[393]\tvalid_0's binary_logloss: 0.573873\tvalid_0's auc: 0.771706\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.607613\tvalid_0's auc: 0.739091\n",
      "[200]\tvalid_0's binary_logloss: 0.590983\tvalid_0's auc: 0.754124\n",
      "[300]\tvalid_0's binary_logloss: 0.585611\tvalid_0's auc: 0.758229\n",
      "[400]\tvalid_0's binary_logloss: 0.582987\tvalid_0's auc: 0.760482\n",
      "[500]\tvalid_0's binary_logloss: 0.582264\tvalid_0's auc: 0.760874\n",
      "[600]\tvalid_0's binary_logloss: 0.582346\tvalid_0's auc: 0.760853\n",
      "Early stopping, best iteration is:\n",
      "[503]\tvalid_0's binary_logloss: 0.582151\tvalid_0's auc: 0.760994\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.602155\tvalid_0's auc: 0.748739\n",
      "[200]\tvalid_0's binary_logloss: 0.584252\tvalid_0's auc: 0.762994\n",
      "[300]\tvalid_0's binary_logloss: 0.577925\tvalid_0's auc: 0.767812\n",
      "[400]\tvalid_0's binary_logloss: 0.574789\tvalid_0's auc: 0.770196\n",
      "[500]\tvalid_0's binary_logloss: 0.574691\tvalid_0's auc: 0.769944\n",
      "Early stopping, best iteration is:\n",
      "[475]\tvalid_0's binary_logloss: 0.57441\tvalid_0's auc: 0.77029\n",
      "cv score:\n",
      "0.7659542437081315\n",
      "(19855, 269)\n",
      "(19860, 269)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.60013\tvalid_0's auc: 0.752169\n",
      "[200]\tvalid_0's binary_logloss: 0.581704\tvalid_0's auc: 0.766988\n",
      "[300]\tvalid_0's binary_logloss: 0.576562\tvalid_0's auc: 0.770282\n",
      "[400]\tvalid_0's binary_logloss: 0.573734\tvalid_0's auc: 0.772069\n",
      "[500]\tvalid_0's binary_logloss: 0.573196\tvalid_0's auc: 0.772244\n",
      "[600]\tvalid_0's binary_logloss: 0.573733\tvalid_0's auc: 0.771622\n",
      "Early stopping, best iteration is:\n",
      "[508]\tvalid_0's binary_logloss: 0.573007\tvalid_0's auc: 0.772493\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.601157\tvalid_0's auc: 0.750115\n",
      "[200]\tvalid_0's binary_logloss: 0.583451\tvalid_0's auc: 0.763836\n",
      "[300]\tvalid_0's binary_logloss: 0.577673\tvalid_0's auc: 0.7676\n",
      "[400]\tvalid_0's binary_logloss: 0.575827\tvalid_0's auc: 0.768869\n",
      "[500]\tvalid_0's binary_logloss: 0.576551\tvalid_0's auc: 0.767963\n",
      "Early stopping, best iteration is:\n",
      "[422]\tvalid_0's binary_logloss: 0.575477\tvalid_0's auc: 0.769117\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.603343\tvalid_0's auc: 0.745398\n",
      "[200]\tvalid_0's binary_logloss: 0.585981\tvalid_0's auc: 0.760286\n",
      "[300]\tvalid_0's binary_logloss: 0.579833\tvalid_0's auc: 0.765707\n",
      "[400]\tvalid_0's binary_logloss: 0.578168\tvalid_0's auc: 0.766685\n",
      "[500]\tvalid_0's binary_logloss: 0.577625\tvalid_0's auc: 0.767114\n",
      "Early stopping, best iteration is:\n",
      "[487]\tvalid_0's binary_logloss: 0.577499\tvalid_0's auc: 0.767295\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.601747\tvalid_0's auc: 0.747372\n",
      "[200]\tvalid_0's binary_logloss: 0.585823\tvalid_0's auc: 0.758884\n",
      "[300]\tvalid_0's binary_logloss: 0.581149\tvalid_0's auc: 0.762217\n",
      "[400]\tvalid_0's binary_logloss: 0.579978\tvalid_0's auc: 0.763004\n",
      "Early stopping, best iteration is:\n",
      "[378]\tvalid_0's binary_logloss: 0.579843\tvalid_0's auc: 0.763117\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.602474\tvalid_0's auc: 0.747241\n",
      "[200]\tvalid_0's binary_logloss: 0.585355\tvalid_0's auc: 0.761289\n",
      "[300]\tvalid_0's binary_logloss: 0.579335\tvalid_0's auc: 0.765993\n",
      "[400]\tvalid_0's binary_logloss: 0.577107\tvalid_0's auc: 0.767485\n",
      "[500]\tvalid_0's binary_logloss: 0.576268\tvalid_0's auc: 0.768049\n",
      "Early stopping, best iteration is:\n",
      "[451]\tvalid_0's binary_logloss: 0.576076\tvalid_0's auc: 0.768372\n",
      "cv score:\n",
      "0.7679655777295766\n",
      "(19872, 269)\n",
      "(19859, 269)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.598777\tvalid_0's auc: 0.75018\n",
      "[200]\tvalid_0's binary_logloss: 0.582228\tvalid_0's auc: 0.763468\n",
      "[300]\tvalid_0's binary_logloss: 0.577541\tvalid_0's auc: 0.767462\n",
      "[400]\tvalid_0's binary_logloss: 0.575052\tvalid_0's auc: 0.769688\n",
      "[500]\tvalid_0's binary_logloss: 0.575109\tvalid_0's auc: 0.769579\n",
      "Early stopping, best iteration is:\n",
      "[409]\tvalid_0's binary_logloss: 0.57497\tvalid_0's auc: 0.769767\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.600247\tvalid_0's auc: 0.747681\n",
      "[200]\tvalid_0's binary_logloss: 0.581852\tvalid_0's auc: 0.76428\n",
      "[300]\tvalid_0's binary_logloss: 0.576322\tvalid_0's auc: 0.769087\n",
      "[400]\tvalid_0's binary_logloss: 0.574002\tvalid_0's auc: 0.770699\n",
      "[500]\tvalid_0's binary_logloss: 0.573727\tvalid_0's auc: 0.770675\n",
      "Early stopping, best iteration is:\n",
      "[419]\tvalid_0's binary_logloss: 0.573634\tvalid_0's auc: 0.771099\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.601531\tvalid_0's auc: 0.748543\n",
      "[200]\tvalid_0's binary_logloss: 0.584191\tvalid_0's auc: 0.762448\n",
      "[300]\tvalid_0's binary_logloss: 0.580573\tvalid_0's auc: 0.765008\n",
      "[400]\tvalid_0's binary_logloss: 0.578172\tvalid_0's auc: 0.766938\n",
      "[500]\tvalid_0's binary_logloss: 0.578107\tvalid_0's auc: 0.766913\n",
      "Early stopping, best iteration is:\n",
      "[412]\tvalid_0's binary_logloss: 0.577787\tvalid_0's auc: 0.767282\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.595532\tvalid_0's auc: 0.757142\n",
      "[200]\tvalid_0's binary_logloss: 0.578784\tvalid_0's auc: 0.769134\n",
      "[300]\tvalid_0's binary_logloss: 0.574391\tvalid_0's auc: 0.77172\n",
      "[400]\tvalid_0's binary_logloss: 0.572493\tvalid_0's auc: 0.772458\n",
      "[500]\tvalid_0's binary_logloss: 0.57223\tvalid_0's auc: 0.772288\n",
      "[600]\tvalid_0's binary_logloss: 0.571526\tvalid_0's auc: 0.772848\n",
      "Early stopping, best iteration is:\n",
      "[544]\tvalid_0's binary_logloss: 0.571109\tvalid_0's auc: 0.773393\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.598486\tvalid_0's auc: 0.752074\n",
      "[200]\tvalid_0's binary_logloss: 0.581689\tvalid_0's auc: 0.764562\n",
      "[300]\tvalid_0's binary_logloss: 0.577391\tvalid_0's auc: 0.767234\n",
      "[400]\tvalid_0's binary_logloss: 0.576351\tvalid_0's auc: 0.767347\n",
      "Early stopping, best iteration is:\n",
      "[385]\tvalid_0's binary_logloss: 0.576105\tvalid_0's auc: 0.767693\n",
      "cv score:\n",
      "0.7698709071255085\n",
      "(19807, 269)\n",
      "(19865, 269)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.605611\tvalid_0's auc: 0.740232\n",
      "[200]\tvalid_0's binary_logloss: 0.588624\tvalid_0's auc: 0.755996\n",
      "[300]\tvalid_0's binary_logloss: 0.579027\tvalid_0's auc: 0.764696\n",
      "[400]\tvalid_0's binary_logloss: 0.576611\tvalid_0's auc: 0.766753\n",
      "[500]\tvalid_0's binary_logloss: 0.575325\tvalid_0's auc: 0.768\n",
      "[600]\tvalid_0's binary_logloss: 0.574231\tvalid_0's auc: 0.769113\n",
      "Early stopping, best iteration is:\n",
      "[572]\tvalid_0's binary_logloss: 0.574172\tvalid_0's auc: 0.769126\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.598177\tvalid_0's auc: 0.755211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's binary_logloss: 0.583039\tvalid_0's auc: 0.765406\n",
      "[300]\tvalid_0's binary_logloss: 0.574343\tvalid_0's auc: 0.771539\n",
      "[400]\tvalid_0's binary_logloss: 0.573053\tvalid_0's auc: 0.771825\n",
      "Early stopping, best iteration is:\n",
      "[323]\tvalid_0's binary_logloss: 0.573382\tvalid_0's auc: 0.772066\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.599838\tvalid_0's auc: 0.75267\n",
      "[200]\tvalid_0's binary_logloss: 0.58291\tvalid_0's auc: 0.765784\n",
      "[300]\tvalid_0's binary_logloss: 0.57452\tvalid_0's auc: 0.771378\n",
      "[400]\tvalid_0's binary_logloss: 0.573444\tvalid_0's auc: 0.771678\n",
      "Early stopping, best iteration is:\n",
      "[320]\tvalid_0's binary_logloss: 0.57376\tvalid_0's auc: 0.771863\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.604222\tvalid_0's auc: 0.743968\n",
      "[200]\tvalid_0's binary_logloss: 0.588333\tvalid_0's auc: 0.757226\n",
      "[300]\tvalid_0's binary_logloss: 0.58045\tvalid_0's auc: 0.763927\n",
      "[400]\tvalid_0's binary_logloss: 0.57854\tvalid_0's auc: 0.765538\n",
      "[500]\tvalid_0's binary_logloss: 0.578732\tvalid_0's auc: 0.765563\n",
      "Early stopping, best iteration is:\n",
      "[474]\tvalid_0's binary_logloss: 0.578347\tvalid_0's auc: 0.765925\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.598801\tvalid_0's auc: 0.754164\n",
      "[200]\tvalid_0's binary_logloss: 0.583139\tvalid_0's auc: 0.765265\n",
      "[300]\tvalid_0's binary_logloss: 0.5755\tvalid_0's auc: 0.770311\n",
      "[400]\tvalid_0's binary_logloss: 0.57397\tvalid_0's auc: 0.771182\n",
      "[500]\tvalid_0's binary_logloss: 0.572721\tvalid_0's auc: 0.77215\n",
      "[600]\tvalid_0's binary_logloss: 0.572986\tvalid_0's auc: 0.771585\n",
      "Early stopping, best iteration is:\n",
      "[503]\tvalid_0's binary_logloss: 0.572639\tvalid_0's auc: 0.772238\n",
      "cv score:\n",
      "0.7700418299108419\n",
      "(19836, 269)\n",
      "(19862, 269)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.594169\tvalid_0's auc: 0.759988\n",
      "[200]\tvalid_0's binary_logloss: 0.577217\tvalid_0's auc: 0.771391\n",
      "[300]\tvalid_0's binary_logloss: 0.570986\tvalid_0's auc: 0.77535\n",
      "[400]\tvalid_0's binary_logloss: 0.569601\tvalid_0's auc: 0.775467\n",
      "Early stopping, best iteration is:\n",
      "[327]\tvalid_0's binary_logloss: 0.569992\tvalid_0's auc: 0.77596\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.596605\tvalid_0's auc: 0.754841\n",
      "[200]\tvalid_0's binary_logloss: 0.579724\tvalid_0's auc: 0.767612\n",
      "[300]\tvalid_0's binary_logloss: 0.575094\tvalid_0's auc: 0.770443\n",
      "[400]\tvalid_0's binary_logloss: 0.573536\tvalid_0's auc: 0.771216\n",
      "[500]\tvalid_0's binary_logloss: 0.572345\tvalid_0's auc: 0.772307\n",
      "[600]\tvalid_0's binary_logloss: 0.571927\tvalid_0's auc: 0.772637\n",
      "[700]\tvalid_0's binary_logloss: 0.572191\tvalid_0's auc: 0.772357\n",
      "Early stopping, best iteration is:\n",
      "[618]\tvalid_0's binary_logloss: 0.571633\tvalid_0's auc: 0.772976\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.598655\tvalid_0's auc: 0.750914\n",
      "[200]\tvalid_0's binary_logloss: 0.583038\tvalid_0's auc: 0.762602\n",
      "[300]\tvalid_0's binary_logloss: 0.577706\tvalid_0's auc: 0.7666\n",
      "[400]\tvalid_0's binary_logloss: 0.576937\tvalid_0's auc: 0.766723\n",
      "Early stopping, best iteration is:\n",
      "[328]\tvalid_0's binary_logloss: 0.576965\tvalid_0's auc: 0.767133\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.602318\tvalid_0's auc: 0.744907\n",
      "[200]\tvalid_0's binary_logloss: 0.585511\tvalid_0's auc: 0.759046\n",
      "[300]\tvalid_0's binary_logloss: 0.579995\tvalid_0's auc: 0.763503\n",
      "[400]\tvalid_0's binary_logloss: 0.578333\tvalid_0's auc: 0.764949\n",
      "[500]\tvalid_0's binary_logloss: 0.577266\tvalid_0's auc: 0.765949\n",
      "[600]\tvalid_0's binary_logloss: 0.577726\tvalid_0's auc: 0.765676\n",
      "Early stopping, best iteration is:\n",
      "[500]\tvalid_0's binary_logloss: 0.577266\tvalid_0's auc: 0.765949\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.599613\tvalid_0's auc: 0.749153\n",
      "[200]\tvalid_0's binary_logloss: 0.582074\tvalid_0's auc: 0.76434\n",
      "[300]\tvalid_0's binary_logloss: 0.574852\tvalid_0's auc: 0.770358\n",
      "[400]\tvalid_0's binary_logloss: 0.573233\tvalid_0's auc: 0.771116\n",
      "[500]\tvalid_0's binary_logloss: 0.572328\tvalid_0's auc: 0.771659\n",
      "Early stopping, best iteration is:\n",
      "[475]\tvalid_0's binary_logloss: 0.572321\tvalid_0's auc: 0.771856\n",
      "cv score:\n",
      "0.7706045732493101\n",
      "(19961, 269)\n",
      "(19851, 269)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.598501\tvalid_0's auc: 0.753344\n",
      "[200]\tvalid_0's binary_logloss: 0.583284\tvalid_0's auc: 0.764805\n",
      "[300]\tvalid_0's binary_logloss: 0.576062\tvalid_0's auc: 0.76965\n",
      "[400]\tvalid_0's binary_logloss: 0.575323\tvalid_0's auc: 0.769765\n",
      "Early stopping, best iteration is:\n",
      "[330]\tvalid_0's binary_logloss: 0.575422\tvalid_0's auc: 0.770127\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.600554\tvalid_0's auc: 0.747707\n",
      "[200]\tvalid_0's binary_logloss: 0.585602\tvalid_0's auc: 0.759849\n",
      "[300]\tvalid_0's binary_logloss: 0.579234\tvalid_0's auc: 0.764573\n",
      "[400]\tvalid_0's binary_logloss: 0.57839\tvalid_0's auc: 0.765128\n",
      "Early stopping, best iteration is:\n",
      "[343]\tvalid_0's binary_logloss: 0.578218\tvalid_0's auc: 0.765444\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.604485\tvalid_0's auc: 0.74219\n",
      "[200]\tvalid_0's binary_logloss: 0.589201\tvalid_0's auc: 0.756411\n",
      "[300]\tvalid_0's binary_logloss: 0.582303\tvalid_0's auc: 0.762561\n",
      "[400]\tvalid_0's binary_logloss: 0.580578\tvalid_0's auc: 0.764161\n",
      "[500]\tvalid_0's binary_logloss: 0.580627\tvalid_0's auc: 0.764375\n",
      "Early stopping, best iteration is:\n",
      "[427]\tvalid_0's binary_logloss: 0.580299\tvalid_0's auc: 0.764501\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.594438\tvalid_0's auc: 0.760649\n",
      "[200]\tvalid_0's binary_logloss: 0.576181\tvalid_0's auc: 0.774424\n",
      "[300]\tvalid_0's binary_logloss: 0.567958\tvalid_0's auc: 0.778914\n",
      "[400]\tvalid_0's binary_logloss: 0.565556\tvalid_0's auc: 0.780152\n",
      "[500]\tvalid_0's binary_logloss: 0.564764\tvalid_0's auc: 0.780099\n",
      "Early stopping, best iteration is:\n",
      "[431]\tvalid_0's binary_logloss: 0.564772\tvalid_0's auc: 0.780764\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.600189\tvalid_0's auc: 0.750459\n",
      "[200]\tvalid_0's binary_logloss: 0.583069\tvalid_0's auc: 0.76458\n",
      "[300]\tvalid_0's binary_logloss: 0.575221\tvalid_0's auc: 0.770607\n",
      "[400]\tvalid_0's binary_logloss: 0.572835\tvalid_0's auc: 0.772488\n",
      "[500]\tvalid_0's binary_logloss: 0.571996\tvalid_0's auc: 0.773078\n",
      "[600]\tvalid_0's binary_logloss: 0.571238\tvalid_0's auc: 0.773902\n",
      "Early stopping, best iteration is:\n",
      "[586]\tvalid_0's binary_logloss: 0.571184\tvalid_0's auc: 0.773957\n",
      "cv score:\n",
      "0.7708691234593267\n",
      "(19909, 269)\n",
      "(19856, 269)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.600565\tvalid_0's auc: 0.7509\n",
      "[200]\tvalid_0's binary_logloss: 0.582761\tvalid_0's auc: 0.763931\n",
      "[300]\tvalid_0's binary_logloss: 0.574426\tvalid_0's auc: 0.770047\n",
      "[400]\tvalid_0's binary_logloss: 0.572379\tvalid_0's auc: 0.771074\n",
      "[500]\tvalid_0's binary_logloss: 0.57182\tvalid_0's auc: 0.771272\n",
      "[600]\tvalid_0's binary_logloss: 0.571491\tvalid_0's auc: 0.771497\n",
      "Early stopping, best iteration is:\n",
      "[568]\tvalid_0's binary_logloss: 0.571429\tvalid_0's auc: 0.771697\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.600833\tvalid_0's auc: 0.751934\n",
      "[200]\tvalid_0's binary_logloss: 0.583876\tvalid_0's auc: 0.765263\n",
      "[300]\tvalid_0's binary_logloss: 0.577425\tvalid_0's auc: 0.768984\n",
      "[400]\tvalid_0's binary_logloss: 0.575219\tvalid_0's auc: 0.77029\n",
      "[500]\tvalid_0's binary_logloss: 0.575106\tvalid_0's auc: 0.769961\n",
      "[600]\tvalid_0's binary_logloss: 0.574011\tvalid_0's auc: 0.771102\n",
      "[700]\tvalid_0's binary_logloss: 0.573487\tvalid_0's auc: 0.771755\n",
      "Early stopping, best iteration is:\n",
      "[656]\tvalid_0's binary_logloss: 0.57311\tvalid_0's auc: 0.772063\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.598978\tvalid_0's auc: 0.754323\n",
      "[200]\tvalid_0's binary_logloss: 0.580838\tvalid_0's auc: 0.767174\n",
      "[300]\tvalid_0's binary_logloss: 0.573085\tvalid_0's auc: 0.772173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\tvalid_0's binary_logloss: 0.571282\tvalid_0's auc: 0.772723\n",
      "[500]\tvalid_0's binary_logloss: 0.571001\tvalid_0's auc: 0.77266\n",
      "Early stopping, best iteration is:\n",
      "[418]\tvalid_0's binary_logloss: 0.570967\tvalid_0's auc: 0.773056\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.608271\tvalid_0's auc: 0.740118\n",
      "[200]\tvalid_0's binary_logloss: 0.592732\tvalid_0's auc: 0.753486\n",
      "[300]\tvalid_0's binary_logloss: 0.585273\tvalid_0's auc: 0.760198\n",
      "[400]\tvalid_0's binary_logloss: 0.582711\tvalid_0's auc: 0.762524\n",
      "[500]\tvalid_0's binary_logloss: 0.582395\tvalid_0's auc: 0.76286\n",
      "[600]\tvalid_0's binary_logloss: 0.582489\tvalid_0's auc: 0.762942\n",
      "Early stopping, best iteration is:\n",
      "[561]\tvalid_0's binary_logloss: 0.582022\tvalid_0's auc: 0.763356\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.604986\tvalid_0's auc: 0.743366\n",
      "[200]\tvalid_0's binary_logloss: 0.588719\tvalid_0's auc: 0.756852\n",
      "[300]\tvalid_0's binary_logloss: 0.581294\tvalid_0's auc: 0.762919\n",
      "[400]\tvalid_0's binary_logloss: 0.578994\tvalid_0's auc: 0.764976\n",
      "[500]\tvalid_0's binary_logloss: 0.578826\tvalid_0's auc: 0.765022\n",
      "Early stopping, best iteration is:\n",
      "[488]\tvalid_0's binary_logloss: 0.578573\tvalid_0's auc: 0.765426\n",
      "cv score:\n",
      "0.7690297612800612\n",
      "(19852, 269)\n",
      "(19861, 269)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.596141\tvalid_0's auc: 0.757683\n",
      "[200]\tvalid_0's binary_logloss: 0.577781\tvalid_0's auc: 0.770873\n",
      "[300]\tvalid_0's binary_logloss: 0.571884\tvalid_0's auc: 0.774648\n",
      "[400]\tvalid_0's binary_logloss: 0.569814\tvalid_0's auc: 0.775762\n",
      "[500]\tvalid_0's binary_logloss: 0.569018\tvalid_0's auc: 0.776109\n",
      "Early stopping, best iteration is:\n",
      "[442]\tvalid_0's binary_logloss: 0.568836\tvalid_0's auc: 0.776504\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.601727\tvalid_0's auc: 0.747589\n",
      "[200]\tvalid_0's binary_logloss: 0.585429\tvalid_0's auc: 0.760531\n",
      "[300]\tvalid_0's binary_logloss: 0.580371\tvalid_0's auc: 0.764462\n",
      "[400]\tvalid_0's binary_logloss: 0.578055\tvalid_0's auc: 0.766213\n",
      "[500]\tvalid_0's binary_logloss: 0.577677\tvalid_0's auc: 0.766625\n",
      "[600]\tvalid_0's binary_logloss: 0.577545\tvalid_0's auc: 0.766905\n",
      "[700]\tvalid_0's binary_logloss: 0.578633\tvalid_0's auc: 0.765943\n",
      "Early stopping, best iteration is:\n",
      "[607]\tvalid_0's binary_logloss: 0.577441\tvalid_0's auc: 0.767006\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.603565\tvalid_0's auc: 0.744283\n",
      "[200]\tvalid_0's binary_logloss: 0.58868\tvalid_0's auc: 0.755787\n",
      "[300]\tvalid_0's binary_logloss: 0.58471\tvalid_0's auc: 0.75864\n",
      "[400]\tvalid_0's binary_logloss: 0.584048\tvalid_0's auc: 0.758917\n",
      "[500]\tvalid_0's binary_logloss: 0.583742\tvalid_0's auc: 0.759499\n",
      "Early stopping, best iteration is:\n",
      "[481]\tvalid_0's binary_logloss: 0.583345\tvalid_0's auc: 0.75977\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.599483\tvalid_0's auc: 0.751869\n",
      "[200]\tvalid_0's binary_logloss: 0.582149\tvalid_0's auc: 0.764999\n",
      "[300]\tvalid_0's binary_logloss: 0.576445\tvalid_0's auc: 0.768823\n",
      "[400]\tvalid_0's binary_logloss: 0.574361\tvalid_0's auc: 0.770244\n",
      "[500]\tvalid_0's binary_logloss: 0.573473\tvalid_0's auc: 0.770706\n",
      "[600]\tvalid_0's binary_logloss: 0.572959\tvalid_0's auc: 0.771125\n",
      "[700]\tvalid_0's binary_logloss: 0.573766\tvalid_0's auc: 0.770375\n",
      "Early stopping, best iteration is:\n",
      "[611]\tvalid_0's binary_logloss: 0.572784\tvalid_0's auc: 0.771314\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.597959\tvalid_0's auc: 0.754427\n",
      "[200]\tvalid_0's binary_logloss: 0.58038\tvalid_0's auc: 0.767225\n",
      "[300]\tvalid_0's binary_logloss: 0.574368\tvalid_0's auc: 0.771745\n",
      "[400]\tvalid_0's binary_logloss: 0.571738\tvalid_0's auc: 0.77339\n",
      "[500]\tvalid_0's binary_logloss: 0.570981\tvalid_0's auc: 0.773721\n",
      "[600]\tvalid_0's binary_logloss: 0.570518\tvalid_0's auc: 0.773947\n",
      "Early stopping, best iteration is:\n",
      "[518]\tvalid_0's binary_logloss: 0.570409\tvalid_0's auc: 0.774253\n",
      "cv score:\n",
      "0.7697086936355566\n",
      "(19910, 269)\n",
      "(19856, 269)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.589888\tvalid_0's auc: 0.762659\n",
      "[200]\tvalid_0's binary_logloss: 0.577267\tvalid_0's auc: 0.770026\n",
      "[300]\tvalid_0's binary_logloss: 0.570725\tvalid_0's auc: 0.774702\n",
      "[400]\tvalid_0's binary_logloss: 0.568549\tvalid_0's auc: 0.776043\n",
      "[500]\tvalid_0's binary_logloss: 0.566756\tvalid_0's auc: 0.777576\n",
      "[600]\tvalid_0's binary_logloss: 0.56603\tvalid_0's auc: 0.778296\n",
      "Early stopping, best iteration is:\n",
      "[581]\tvalid_0's binary_logloss: 0.565851\tvalid_0's auc: 0.77843\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.593564\tvalid_0's auc: 0.757837\n",
      "[200]\tvalid_0's binary_logloss: 0.581042\tvalid_0's auc: 0.765729\n",
      "[300]\tvalid_0's binary_logloss: 0.57448\tvalid_0's auc: 0.770257\n",
      "[400]\tvalid_0's binary_logloss: 0.57164\tvalid_0's auc: 0.772165\n",
      "[500]\tvalid_0's binary_logloss: 0.570383\tvalid_0's auc: 0.773084\n",
      "Early stopping, best iteration is:\n",
      "[457]\tvalid_0's binary_logloss: 0.570263\tvalid_0's auc: 0.773328\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.587906\tvalid_0's auc: 0.766601\n",
      "[200]\tvalid_0's binary_logloss: 0.573447\tvalid_0's auc: 0.776311\n",
      "[300]\tvalid_0's binary_logloss: 0.566126\tvalid_0's auc: 0.781246\n",
      "[400]\tvalid_0's binary_logloss: 0.562411\tvalid_0's auc: 0.783247\n",
      "[500]\tvalid_0's binary_logloss: 0.561397\tvalid_0's auc: 0.783406\n",
      "Early stopping, best iteration is:\n",
      "[451]\tvalid_0's binary_logloss: 0.561307\tvalid_0's auc: 0.783934\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.597074\tvalid_0's auc: 0.752322\n",
      "[200]\tvalid_0's binary_logloss: 0.586265\tvalid_0's auc: 0.760383\n",
      "[300]\tvalid_0's binary_logloss: 0.582227\tvalid_0's auc: 0.76347\n",
      "[400]\tvalid_0's binary_logloss: 0.579859\tvalid_0's auc: 0.765748\n",
      "[500]\tvalid_0's binary_logloss: 0.579686\tvalid_0's auc: 0.766178\n",
      "Early stopping, best iteration is:\n",
      "[477]\tvalid_0's binary_logloss: 0.579513\tvalid_0's auc: 0.766308\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.594527\tvalid_0's auc: 0.756942\n",
      "[200]\tvalid_0's binary_logloss: 0.583817\tvalid_0's auc: 0.763016\n",
      "[300]\tvalid_0's binary_logloss: 0.579851\tvalid_0's auc: 0.765197\n",
      "[400]\tvalid_0's binary_logloss: 0.578689\tvalid_0's auc: 0.765824\n",
      "[500]\tvalid_0's binary_logloss: 0.577832\tvalid_0's auc: 0.766658\n",
      "Early stopping, best iteration is:\n",
      "[499]\tvalid_0's binary_logloss: 0.577819\tvalid_0's auc: 0.766644\n",
      "cv score:\n",
      "0.7736609161047436\n",
      "(19952, 269)\n",
      "(19852, 269)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.600636\tvalid_0's auc: 0.750791\n",
      "[200]\tvalid_0's binary_logloss: 0.585253\tvalid_0's auc: 0.762051\n",
      "[300]\tvalid_0's binary_logloss: 0.578777\tvalid_0's auc: 0.766485\n",
      "[400]\tvalid_0's binary_logloss: 0.576182\tvalid_0's auc: 0.768482\n",
      "[500]\tvalid_0's binary_logloss: 0.576562\tvalid_0's auc: 0.767966\n",
      "Early stopping, best iteration is:\n",
      "[459]\tvalid_0's binary_logloss: 0.575936\tvalid_0's auc: 0.768637\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.602848\tvalid_0's auc: 0.746141\n",
      "[200]\tvalid_0's binary_logloss: 0.58863\tvalid_0's auc: 0.757123\n",
      "[300]\tvalid_0's binary_logloss: 0.581049\tvalid_0's auc: 0.763688\n",
      "[400]\tvalid_0's binary_logloss: 0.578064\tvalid_0's auc: 0.766431\n",
      "[500]\tvalid_0's binary_logloss: 0.577087\tvalid_0's auc: 0.767183\n",
      "[600]\tvalid_0's binary_logloss: 0.576393\tvalid_0's auc: 0.767918\n",
      "[700]\tvalid_0's binary_logloss: 0.575966\tvalid_0's auc: 0.768378\n",
      "[800]\tvalid_0's binary_logloss: 0.576585\tvalid_0's auc: 0.767909\n",
      "Early stopping, best iteration is:\n",
      "[714]\tvalid_0's binary_logloss: 0.575914\tvalid_0's auc: 0.768483\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.593658\tvalid_0's auc: 0.760888\n",
      "[200]\tvalid_0's binary_logloss: 0.578903\tvalid_0's auc: 0.769385\n",
      "[300]\tvalid_0's binary_logloss: 0.571496\tvalid_0's auc: 0.774486\n",
      "[400]\tvalid_0's binary_logloss: 0.569215\tvalid_0's auc: 0.775875\n",
      "[500]\tvalid_0's binary_logloss: 0.569344\tvalid_0's auc: 0.775615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[436]\tvalid_0's binary_logloss: 0.568742\tvalid_0's auc: 0.776274\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.600605\tvalid_0's auc: 0.74956\n",
      "[200]\tvalid_0's binary_logloss: 0.585503\tvalid_0's auc: 0.760474\n",
      "[300]\tvalid_0's binary_logloss: 0.578763\tvalid_0's auc: 0.765547\n",
      "[400]\tvalid_0's binary_logloss: 0.576803\tvalid_0's auc: 0.766721\n",
      "[500]\tvalid_0's binary_logloss: 0.576044\tvalid_0's auc: 0.767137\n",
      "Early stopping, best iteration is:\n",
      "[466]\tvalid_0's binary_logloss: 0.575965\tvalid_0's auc: 0.767412\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.600512\tvalid_0's auc: 0.750608\n",
      "[200]\tvalid_0's binary_logloss: 0.584893\tvalid_0's auc: 0.762147\n",
      "[300]\tvalid_0's binary_logloss: 0.57829\tvalid_0's auc: 0.766675\n",
      "[400]\tvalid_0's binary_logloss: 0.575864\tvalid_0's auc: 0.768594\n",
      "Early stopping, best iteration is:\n",
      "[390]\tvalid_0's binary_logloss: 0.575624\tvalid_0's auc: 0.768944\n",
      "cv score:\n",
      "0.7697957669432227\n",
      "(19860, 269)\n",
      "(19860, 269)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.604897\tvalid_0's auc: 0.741987\n",
      "[200]\tvalid_0's binary_logloss: 0.58391\tvalid_0's auc: 0.761894\n",
      "[300]\tvalid_0's binary_logloss: 0.576199\tvalid_0's auc: 0.768525\n",
      "[400]\tvalid_0's binary_logloss: 0.574591\tvalid_0's auc: 0.769535\n",
      "[500]\tvalid_0's binary_logloss: 0.574041\tvalid_0's auc: 0.770094\n",
      "[600]\tvalid_0's binary_logloss: 0.57418\tvalid_0's auc: 0.770251\n",
      "Early stopping, best iteration is:\n",
      "[510]\tvalid_0's binary_logloss: 0.573908\tvalid_0's auc: 0.770209\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.607286\tvalid_0's auc: 0.739708\n",
      "[200]\tvalid_0's binary_logloss: 0.587384\tvalid_0's auc: 0.758482\n",
      "[300]\tvalid_0's binary_logloss: 0.580253\tvalid_0's auc: 0.764587\n",
      "[400]\tvalid_0's binary_logloss: 0.579033\tvalid_0's auc: 0.765341\n",
      "[500]\tvalid_0's binary_logloss: 0.578303\tvalid_0's auc: 0.765876\n",
      "Early stopping, best iteration is:\n",
      "[412]\tvalid_0's binary_logloss: 0.578131\tvalid_0's auc: 0.766243\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.603908\tvalid_0's auc: 0.743877\n",
      "[200]\tvalid_0's binary_logloss: 0.583692\tvalid_0's auc: 0.761619\n",
      "[300]\tvalid_0's binary_logloss: 0.575184\tvalid_0's auc: 0.768591\n",
      "[400]\tvalid_0's binary_logloss: 0.57374\tvalid_0's auc: 0.769547\n",
      "[500]\tvalid_0's binary_logloss: 0.572612\tvalid_0's auc: 0.770375\n",
      "[600]\tvalid_0's binary_logloss: 0.572473\tvalid_0's auc: 0.770375\n",
      "[700]\tvalid_0's binary_logloss: 0.572442\tvalid_0's auc: 0.770598\n",
      "Early stopping, best iteration is:\n",
      "[629]\tvalid_0's binary_logloss: 0.571888\tvalid_0's auc: 0.770975\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.601735\tvalid_0's auc: 0.748603\n",
      "[200]\tvalid_0's binary_logloss: 0.581445\tvalid_0's auc: 0.765368\n",
      "[300]\tvalid_0's binary_logloss: 0.574881\tvalid_0's auc: 0.769495\n",
      "[400]\tvalid_0's binary_logloss: 0.573155\tvalid_0's auc: 0.770674\n",
      "[500]\tvalid_0's binary_logloss: 0.571844\tvalid_0's auc: 0.771674\n",
      "Early stopping, best iteration is:\n",
      "[494]\tvalid_0's binary_logloss: 0.571777\tvalid_0's auc: 0.771709\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.609887\tvalid_0's auc: 0.735619\n",
      "[200]\tvalid_0's binary_logloss: 0.591183\tvalid_0's auc: 0.754371\n",
      "[300]\tvalid_0's binary_logloss: 0.584086\tvalid_0's auc: 0.760799\n",
      "[400]\tvalid_0's binary_logloss: 0.582855\tvalid_0's auc: 0.761898\n",
      "[500]\tvalid_0's binary_logloss: 0.581189\tvalid_0's auc: 0.763495\n",
      "Early stopping, best iteration is:\n",
      "[494]\tvalid_0's binary_logloss: 0.581143\tvalid_0's auc: 0.763576\n",
      "cv score:\n",
      "0.7684350422747754\n",
      "(19856, 269)\n",
      "(19860, 269)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.590418\tvalid_0's auc: 0.764154\n",
      "[200]\tvalid_0's binary_logloss: 0.577169\tvalid_0's auc: 0.771446\n",
      "[300]\tvalid_0's binary_logloss: 0.572678\tvalid_0's auc: 0.774167\n",
      "[400]\tvalid_0's binary_logloss: 0.570054\tvalid_0's auc: 0.775698\n",
      "[500]\tvalid_0's binary_logloss: 0.569769\tvalid_0's auc: 0.775473\n",
      "Early stopping, best iteration is:\n",
      "[420]\tvalid_0's binary_logloss: 0.569706\tvalid_0's auc: 0.775894\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.597943\tvalid_0's auc: 0.751506\n",
      "[200]\tvalid_0's binary_logloss: 0.582538\tvalid_0's auc: 0.763492\n",
      "[300]\tvalid_0's binary_logloss: 0.57949\tvalid_0's auc: 0.764435\n",
      "Early stopping, best iteration is:\n",
      "[262]\tvalid_0's binary_logloss: 0.579486\tvalid_0's auc: 0.765496\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.595805\tvalid_0's auc: 0.755653\n",
      "[200]\tvalid_0's binary_logloss: 0.583244\tvalid_0's auc: 0.764172\n",
      "[300]\tvalid_0's binary_logloss: 0.580757\tvalid_0's auc: 0.765109\n",
      "[400]\tvalid_0's binary_logloss: 0.579502\tvalid_0's auc: 0.766048\n",
      "[500]\tvalid_0's binary_logloss: 0.579438\tvalid_0's auc: 0.766262\n",
      "Early stopping, best iteration is:\n",
      "[472]\tvalid_0's binary_logloss: 0.579169\tvalid_0's auc: 0.766515\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.595247\tvalid_0's auc: 0.756815\n",
      "[200]\tvalid_0's binary_logloss: 0.58038\tvalid_0's auc: 0.767302\n",
      "[300]\tvalid_0's binary_logloss: 0.577182\tvalid_0's auc: 0.768406\n",
      "[400]\tvalid_0's binary_logloss: 0.575087\tvalid_0's auc: 0.770065\n",
      "[500]\tvalid_0's binary_logloss: 0.574959\tvalid_0's auc: 0.770013\n",
      "Early stopping, best iteration is:\n",
      "[489]\tvalid_0's binary_logloss: 0.574767\tvalid_0's auc: 0.770234\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.594519\tvalid_0's auc: 0.758447\n",
      "[200]\tvalid_0's binary_logloss: 0.580389\tvalid_0's auc: 0.768345\n",
      "[300]\tvalid_0's binary_logloss: 0.576036\tvalid_0's auc: 0.770981\n",
      "[400]\tvalid_0's binary_logloss: 0.574576\tvalid_0's auc: 0.771664\n",
      "[500]\tvalid_0's binary_logloss: 0.574124\tvalid_0's auc: 0.771861\n",
      "Early stopping, best iteration is:\n",
      "[495]\tvalid_0's binary_logloss: 0.57403\tvalid_0's auc: 0.771995\n",
      "cv score:\n",
      "0.76992462294482\n",
      "(19881, 269)\n",
      "(19858, 269)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.601684\tvalid_0's auc: 0.74624\n",
      "[200]\tvalid_0's binary_logloss: 0.586316\tvalid_0's auc: 0.758823\n",
      "[300]\tvalid_0's binary_logloss: 0.580738\tvalid_0's auc: 0.763092\n",
      "[400]\tvalid_0's binary_logloss: 0.57976\tvalid_0's auc: 0.763537\n",
      "Early stopping, best iteration is:\n",
      "[325]\tvalid_0's binary_logloss: 0.580012\tvalid_0's auc: 0.763564\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.599522\tvalid_0's auc: 0.750004\n",
      "[200]\tvalid_0's binary_logloss: 0.583606\tvalid_0's auc: 0.762555\n",
      "[300]\tvalid_0's binary_logloss: 0.577726\tvalid_0's auc: 0.766778\n",
      "[400]\tvalid_0's binary_logloss: 0.574753\tvalid_0's auc: 0.769101\n",
      "[500]\tvalid_0's binary_logloss: 0.574202\tvalid_0's auc: 0.769354\n",
      "[600]\tvalid_0's binary_logloss: 0.573233\tvalid_0's auc: 0.770206\n",
      "[700]\tvalid_0's binary_logloss: 0.573499\tvalid_0's auc: 0.770166\n",
      "Early stopping, best iteration is:\n",
      "[603]\tvalid_0's binary_logloss: 0.573158\tvalid_0's auc: 0.770271\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.597963\tvalid_0's auc: 0.750908\n",
      "[200]\tvalid_0's binary_logloss: 0.581157\tvalid_0's auc: 0.765\n",
      "[300]\tvalid_0's binary_logloss: 0.575514\tvalid_0's auc: 0.768821\n",
      "[400]\tvalid_0's binary_logloss: 0.573654\tvalid_0's auc: 0.769734\n",
      "Early stopping, best iteration is:\n",
      "[328]\tvalid_0's binary_logloss: 0.573913\tvalid_0's auc: 0.769958\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.597711\tvalid_0's auc: 0.753433\n",
      "[200]\tvalid_0's binary_logloss: 0.580554\tvalid_0's auc: 0.767475\n",
      "[300]\tvalid_0's binary_logloss: 0.574672\tvalid_0's auc: 0.771871\n",
      "[400]\tvalid_0's binary_logloss: 0.572858\tvalid_0's auc: 0.772914\n",
      "[500]\tvalid_0's binary_logloss: 0.571877\tvalid_0's auc: 0.773347\n",
      "[600]\tvalid_0's binary_logloss: 0.571968\tvalid_0's auc: 0.77317\n",
      "Early stopping, best iteration is:\n",
      "[538]\tvalid_0's binary_logloss: 0.571367\tvalid_0's auc: 0.773786\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.599059\tvalid_0's auc: 0.749331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's binary_logloss: 0.582034\tvalid_0's auc: 0.764253\n",
      "[300]\tvalid_0's binary_logloss: 0.575897\tvalid_0's auc: 0.768942\n",
      "[400]\tvalid_0's binary_logloss: 0.573763\tvalid_0's auc: 0.770694\n",
      "[500]\tvalid_0's binary_logloss: 0.573049\tvalid_0's auc: 0.771002\n",
      "[600]\tvalid_0's binary_logloss: 0.572984\tvalid_0's auc: 0.771137\n",
      "Early stopping, best iteration is:\n",
      "[555]\tvalid_0's binary_logloss: 0.572832\tvalid_0's auc: 0.771245\n",
      "cv score:\n",
      "0.7697162048117207\n",
      "(19889, 269)\n",
      "(19857, 269)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.594831\tvalid_0's auc: 0.755585\n",
      "[200]\tvalid_0's binary_logloss: 0.583863\tvalid_0's auc: 0.762421\n",
      "[300]\tvalid_0's binary_logloss: 0.58085\tvalid_0's auc: 0.763708\n",
      "[400]\tvalid_0's binary_logloss: 0.578789\tvalid_0's auc: 0.765318\n",
      "[500]\tvalid_0's binary_logloss: 0.578129\tvalid_0's auc: 0.766067\n",
      "[600]\tvalid_0's binary_logloss: 0.57784\tvalid_0's auc: 0.7665\n",
      "Early stopping, best iteration is:\n",
      "[533]\tvalid_0's binary_logloss: 0.57755\tvalid_0's auc: 0.766699\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.596344\tvalid_0's auc: 0.753772\n",
      "[200]\tvalid_0's binary_logloss: 0.584376\tvalid_0's auc: 0.761265\n",
      "[300]\tvalid_0's binary_logloss: 0.580159\tvalid_0's auc: 0.763811\n",
      "[400]\tvalid_0's binary_logloss: 0.579073\tvalid_0's auc: 0.764623\n",
      "[500]\tvalid_0's binary_logloss: 0.577902\tvalid_0's auc: 0.76566\n",
      "[600]\tvalid_0's binary_logloss: 0.578431\tvalid_0's auc: 0.765343\n",
      "Early stopping, best iteration is:\n",
      "[511]\tvalid_0's binary_logloss: 0.577688\tvalid_0's auc: 0.76588\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.594946\tvalid_0's auc: 0.755676\n",
      "[200]\tvalid_0's binary_logloss: 0.582073\tvalid_0's auc: 0.764688\n",
      "[300]\tvalid_0's binary_logloss: 0.57785\tvalid_0's auc: 0.767318\n",
      "[400]\tvalid_0's binary_logloss: 0.575861\tvalid_0's auc: 0.768759\n",
      "[500]\tvalid_0's binary_logloss: 0.575612\tvalid_0's auc: 0.768766\n",
      "Early stopping, best iteration is:\n",
      "[491]\tvalid_0's binary_logloss: 0.575311\tvalid_0's auc: 0.769213\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.593661\tvalid_0's auc: 0.759148\n",
      "[200]\tvalid_0's binary_logloss: 0.5816\tvalid_0's auc: 0.766037\n",
      "[300]\tvalid_0's binary_logloss: 0.5772\tvalid_0's auc: 0.768564\n",
      "[400]\tvalid_0's binary_logloss: 0.574785\tvalid_0's auc: 0.770155\n",
      "[500]\tvalid_0's binary_logloss: 0.573599\tvalid_0's auc: 0.770764\n",
      "[600]\tvalid_0's binary_logloss: 0.573521\tvalid_0's auc: 0.770666\n",
      "Early stopping, best iteration is:\n",
      "[511]\tvalid_0's binary_logloss: 0.573444\tvalid_0's auc: 0.770915\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.591146\tvalid_0's auc: 0.761598\n",
      "[200]\tvalid_0's binary_logloss: 0.577887\tvalid_0's auc: 0.769965\n",
      "[300]\tvalid_0's binary_logloss: 0.573352\tvalid_0's auc: 0.772327\n",
      "[400]\tvalid_0's binary_logloss: 0.57153\tvalid_0's auc: 0.773302\n",
      "[500]\tvalid_0's binary_logloss: 0.5696\tvalid_0's auc: 0.774957\n",
      "[600]\tvalid_0's binary_logloss: 0.569404\tvalid_0's auc: 0.775057\n",
      "Early stopping, best iteration is:\n",
      "[517]\tvalid_0's binary_logloss: 0.569184\tvalid_0's auc: 0.775367\n",
      "cv score:\n",
      "0.7695108972792655\n",
      "(19906, 269)\n",
      "(19856, 269)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.594069\tvalid_0's auc: 0.758164\n",
      "[200]\tvalid_0's binary_logloss: 0.578515\tvalid_0's auc: 0.768686\n",
      "[300]\tvalid_0's binary_logloss: 0.574492\tvalid_0's auc: 0.770928\n",
      "[400]\tvalid_0's binary_logloss: 0.57178\tvalid_0's auc: 0.772569\n",
      "[500]\tvalid_0's binary_logloss: 0.570423\tvalid_0's auc: 0.773696\n",
      "[600]\tvalid_0's binary_logloss: 0.570224\tvalid_0's auc: 0.773932\n",
      "[700]\tvalid_0's binary_logloss: 0.570502\tvalid_0's auc: 0.773434\n",
      "Early stopping, best iteration is:\n",
      "[655]\tvalid_0's binary_logloss: 0.569992\tvalid_0's auc: 0.774089\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.595776\tvalid_0's auc: 0.754856\n",
      "[200]\tvalid_0's binary_logloss: 0.578768\tvalid_0's auc: 0.767857\n",
      "[300]\tvalid_0's binary_logloss: 0.574354\tvalid_0's auc: 0.770402\n",
      "[400]\tvalid_0's binary_logloss: 0.571773\tvalid_0's auc: 0.772127\n",
      "[500]\tvalid_0's binary_logloss: 0.570442\tvalid_0's auc: 0.773236\n",
      "[600]\tvalid_0's binary_logloss: 0.569871\tvalid_0's auc: 0.773771\n",
      "[700]\tvalid_0's binary_logloss: 0.570331\tvalid_0's auc: 0.773304\n",
      "Early stopping, best iteration is:\n",
      "[622]\tvalid_0's binary_logloss: 0.56958\tvalid_0's auc: 0.774054\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.60047\tvalid_0's auc: 0.748494\n",
      "[200]\tvalid_0's binary_logloss: 0.587882\tvalid_0's auc: 0.757869\n",
      "[300]\tvalid_0's binary_logloss: 0.584757\tvalid_0's auc: 0.760697\n",
      "[400]\tvalid_0's binary_logloss: 0.584225\tvalid_0's auc: 0.761372\n",
      "[500]\tvalid_0's binary_logloss: 0.583811\tvalid_0's auc: 0.762151\n",
      "Early stopping, best iteration is:\n",
      "[476]\tvalid_0's binary_logloss: 0.583704\tvalid_0's auc: 0.762222\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.596279\tvalid_0's auc: 0.754084\n",
      "[200]\tvalid_0's binary_logloss: 0.580617\tvalid_0's auc: 0.765699\n",
      "[300]\tvalid_0's binary_logloss: 0.575793\tvalid_0's auc: 0.769088\n",
      "[400]\tvalid_0's binary_logloss: 0.574563\tvalid_0's auc: 0.769819\n",
      "Early stopping, best iteration is:\n",
      "[355]\tvalid_0's binary_logloss: 0.574476\tvalid_0's auc: 0.770053\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.591585\tvalid_0's auc: 0.764552\n",
      "[200]\tvalid_0's binary_logloss: 0.574227\tvalid_0's auc: 0.775905\n",
      "[300]\tvalid_0's binary_logloss: 0.569643\tvalid_0's auc: 0.777438\n",
      "[400]\tvalid_0's binary_logloss: 0.567348\tvalid_0's auc: 0.778572\n",
      "[500]\tvalid_0's binary_logloss: 0.566529\tvalid_0's auc: 0.778523\n",
      "Early stopping, best iteration is:\n",
      "[471]\tvalid_0's binary_logloss: 0.566335\tvalid_0's auc: 0.778961\n",
      "cv score:\n",
      "0.771776323842932\n",
      "(19878, 269)\n",
      "(19858, 269)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.596068\tvalid_0's auc: 0.754763\n",
      "[200]\tvalid_0's binary_logloss: 0.579136\tvalid_0's auc: 0.767985\n",
      "[300]\tvalid_0's binary_logloss: 0.574195\tvalid_0's auc: 0.771295\n",
      "[400]\tvalid_0's binary_logloss: 0.571719\tvalid_0's auc: 0.773096\n",
      "[500]\tvalid_0's binary_logloss: 0.571517\tvalid_0's auc: 0.772976\n",
      "Early stopping, best iteration is:\n",
      "[418]\tvalid_0's binary_logloss: 0.571263\tvalid_0's auc: 0.77341\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.596561\tvalid_0's auc: 0.75478\n",
      "[200]\tvalid_0's binary_logloss: 0.581274\tvalid_0's auc: 0.765874\n",
      "[300]\tvalid_0's binary_logloss: 0.575724\tvalid_0's auc: 0.769888\n",
      "[400]\tvalid_0's binary_logloss: 0.573842\tvalid_0's auc: 0.770991\n",
      "[500]\tvalid_0's binary_logloss: 0.573531\tvalid_0's auc: 0.771139\n",
      "[600]\tvalid_0's binary_logloss: 0.573592\tvalid_0's auc: 0.771094\n",
      "Early stopping, best iteration is:\n",
      "[509]\tvalid_0's binary_logloss: 0.573295\tvalid_0's auc: 0.771339\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.597155\tvalid_0's auc: 0.752614\n",
      "[200]\tvalid_0's binary_logloss: 0.581011\tvalid_0's auc: 0.764634\n",
      "[300]\tvalid_0's binary_logloss: 0.576228\tvalid_0's auc: 0.767779\n",
      "[400]\tvalid_0's binary_logloss: 0.573852\tvalid_0's auc: 0.769468\n",
      "[500]\tvalid_0's binary_logloss: 0.573046\tvalid_0's auc: 0.769882\n",
      "Early stopping, best iteration is:\n",
      "[430]\tvalid_0's binary_logloss: 0.572912\tvalid_0's auc: 0.770285\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.598683\tvalid_0's auc: 0.750772\n",
      "[200]\tvalid_0's binary_logloss: 0.584572\tvalid_0's auc: 0.760804\n",
      "[300]\tvalid_0's binary_logloss: 0.579948\tvalid_0's auc: 0.764456\n",
      "[400]\tvalid_0's binary_logloss: 0.577546\tvalid_0's auc: 0.76672\n",
      "[500]\tvalid_0's binary_logloss: 0.577808\tvalid_0's auc: 0.766433\n",
      "Early stopping, best iteration is:\n",
      "[400]\tvalid_0's binary_logloss: 0.577546\tvalid_0's auc: 0.76672\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.600775\tvalid_0's auc: 0.746596\n",
      "[200]\tvalid_0's binary_logloss: 0.586701\tvalid_0's auc: 0.757655\n",
      "[300]\tvalid_0's binary_logloss: 0.582973\tvalid_0's auc: 0.760199\n",
      "[400]\tvalid_0's binary_logloss: 0.580634\tvalid_0's auc: 0.762591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\tvalid_0's binary_logloss: 0.580729\tvalid_0's auc: 0.762403\n",
      "Early stopping, best iteration is:\n",
      "[401]\tvalid_0's binary_logloss: 0.58063\tvalid_0's auc: 0.762613\n",
      "cv score:\n",
      "0.7689132482440398\n"
     ]
    }
   ],
   "source": [
    "NFOLDS = 5\n",
    "ncat = 43\n",
    "#X = features_train_t.values\n",
    "X_test = df_test.values\n",
    "\n",
    "labels_train = df_labels.values\n",
    "final_cv_train = np.zeros(len( labels_train ))\n",
    "\n",
    "final_cv_pred = np.zeros(len( test_ids ))\n",
    "x_score = []\n",
    "\n",
    "best_trees = []\n",
    "fold_scores = []\n",
    "N = 16\n",
    "\n",
    "oof_train_full = []\n",
    "oof_test_full = [] \n",
    "for s in range(N):\n",
    "    \n",
    "    \n",
    "    params['seed'] = s\n",
    "    \n",
    "    x_train , x_val , y_train , y_val = train_test_split( df_train , df_labels , test_size = 0.2 , random_state=s)\n",
    "\n",
    "    positive_indx = y_train[ y_train == 1 ]\n",
    "    positive_data = x_train.loc[ positive_indx.index.values  ]\n",
    "\n",
    "\n",
    "    negative_indx = y_train[ y_train == 0 ]\n",
    "    negative_data = x_train.loc[  negative_indx.index.values  ]\n",
    "    negative_data = negative_data.sample( frac= positive_ratio / (1 - positive_ratio), random_state=s*5 )\n",
    "\n",
    "    print(positive_data.shape)\n",
    "    print(negative_data.shape )\n",
    "\n",
    "    labels = [ 0 for x in range( negative_data.shape[0]) ] + [ 1 for x in range( positive_data.shape[0]) ]\n",
    "\n",
    "    x_train_sampled = pd.concat( [ negative_data , positive_data] , axis = 0 )\n",
    "    x_train_sampled[\"y\"] = labels\n",
    "    x_train_sampled = x_train_sampled.sample(frac = 1 ,random_state = s )\n",
    "    labels_sampled = x_train_sampled[\"y\"].values\n",
    "    \n",
    "    x_train_sampled = x_train_sampled.drop( [\"y\"] , axis = 1 ).values\n",
    "    \n",
    "    kfold = KFold(n_splits=NFOLDS, shuffle=True, random_state=s)\n",
    "    kf = kfold.split( x_train_sampled , labels_sampled  )\n",
    "    best_trees = []\n",
    "    fold_scores = []\n",
    "    \n",
    "    cv_train = np.zeros( len( labels_sampled ))\n",
    "    #cv_eval_total = np.zeros( len( y_val ) )\n",
    "    \n",
    "    cv_pred = np.zeros( len( test_ids ) )\n",
    "    \n",
    "    \n",
    "    oof_train = np.zeros((  len( labels_train ) , ))\n",
    "    oof_test = np.zeros((  len( test_ids )  , ))\n",
    "    \n",
    "    \n",
    "    oof_test_skf = np.empty((NFOLDS, len( test_ids )  ))\n",
    "    oof_train_skf = np.empty((NFOLDS, len( labels_train )  ))\n",
    "    \n",
    "    for i, (train_fold, validate) in enumerate(kf):\n",
    "        \n",
    "        X_train, X_validate, label_train, label_validate = x_train_sampled[train_fold, :], x_train_sampled[validate, :], labels_sampled[train_fold], labels_sampled[validate]\n",
    "    \n",
    "    #X_train, X_validate, label_train, label_validate = X[train_fold, :], X[validate, :], labels_train[train_fold], labels_train[validate]\n",
    "        dtrain = lgb.Dataset( X_train , label_train , categorical_feature = range(ncat)  )\n",
    "    \n",
    "        dvalid = lgb.Dataset(  X_validate  , label_validate , reference=dtrain , categorical_feature = range(ncat) )\n",
    "        bst = lgb.train(params, dtrain , num_boost_round , valid_sets=[dvalid ] , verbose_eval = 100 , early_stopping_rounds = 100 )\n",
    "        #best_trees.append(bst.best_iteration)    \n",
    "        cv_pred +=  bst.predict(  X_test , num_iteration = bst.best_iteration )\n",
    "        #cv_eval_total += bst.predict( x_val , num_iteration = bst.best_iteration )\n",
    "                \n",
    "        cv_train[validate] += bst.predict( X_validate )\n",
    "        \n",
    "        \n",
    "        oof_train_skf[i, :] = bst.predict( df_train.values )\n",
    "        oof_test_skf[ i , : ] = bst.predict( X_test )\n",
    "        \n",
    "    oof_test[:] = oof_test_skf.mean( axis = 0 )\n",
    "    oof_train[:] = oof_train_skf.mean( axis = 0 )\n",
    "    \n",
    "    oof_train = oof_train.reshape(-1, 1)\n",
    "    oof_test = oof_test.reshape( -1 , 1 )\n",
    "    \n",
    "    oof_train_full.append( oof_train ) \n",
    "    oof_test_full.append( oof_test )\n",
    "\n",
    "    cv_pred /= NFOLDS\n",
    "    final_cv_pred += cv_pred    \n",
    "\n",
    "    print(\"cv score:\")\n",
    "    print( roc_auc_score( labels_sampled , cv_train )   )\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = np.hstack( oof_train_full )\n",
    "new_test = np.hstack( oof_test_full )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final_cv_pred/16.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82669019, 0.1075067 , 0.25765525, ..., 0.37167225, 0.4791128 ,\n",
       "       0.44050015])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48744, 16)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "num_leaves = 30\n",
    "min_data_in_leaf = 2000\n",
    "feature_fraction = 0.9\n",
    "num_boost_round = 10000\n",
    "params = {\"objective\": \"binary\",\n",
    "          \"boosting_type\": \"dart\",\n",
    "          \"learning_rate\": learning_rate,\n",
    "          \"metric\":[\"auc\" ,\"binary_logloss\"] , \n",
    "          \"num_leaves\": num_leaves,\n",
    "           \"max_bin\": 256,\n",
    "          \"feature_fraction\": feature_fraction,\n",
    "          \"verbosity\": 1,\n",
    "          \"drop_rate\": 0.01,\n",
    "          \"is_unbalance\": False,\n",
    "          \"max_drop\": 50,\n",
    "          \"min_child_samples\": 20,\n",
    "          \"min_child_weight\": 150,\n",
    "          \"min_split_gain\": 0.5,\n",
    "          \"max_depth\": -1, \n",
    "         \"lambda_l2\": 100 , \n",
    "          \"min_gain_to_split\" : 0.5 ,\n",
    "          \"bagging_freq\" : 1 , \n",
    "          \"subsample\" : 0.9\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightgbm model with oof_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.377866\tvalid_0's auc: 0.801263\n",
      "[200]\tvalid_0's binary_logloss: 0.304333\tvalid_0's auc: 0.803434\n",
      "[300]\tvalid_0's binary_logloss: 0.279653\tvalid_0's auc: 0.805306\n",
      "[400]\tvalid_0's binary_logloss: 0.2641\tvalid_0's auc: 0.805818\n",
      "[500]\tvalid_0's binary_logloss: 0.251555\tvalid_0's auc: 0.80615\n",
      "[600]\tvalid_0's binary_logloss: 0.247543\tvalid_0's auc: 0.806475\n",
      "[700]\tvalid_0's binary_logloss: 0.240484\tvalid_0's auc: 0.806775\n",
      "[800]\tvalid_0's binary_logloss: 0.238284\tvalid_0's auc: 0.806865\n",
      "[900]\tvalid_0's binary_logloss: 0.235611\tvalid_0's auc: 0.807113\n",
      "[1000]\tvalid_0's binary_logloss: 0.23396\tvalid_0's auc: 0.807375\n",
      "[1100]\tvalid_0's binary_logloss: 0.233552\tvalid_0's auc: 0.807537\n",
      "[1200]\tvalid_0's binary_logloss: 0.233171\tvalid_0's auc: 0.807635\n",
      "[1300]\tvalid_0's binary_logloss: 0.233137\tvalid_0's auc: 0.807721\n",
      "Early stopping, best iteration is:\n",
      "[1220]\tvalid_0's binary_logloss: 0.232957\tvalid_0's auc: 0.80765\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.377803\tvalid_0's auc: 0.805418\n",
      "[200]\tvalid_0's binary_logloss: 0.304117\tvalid_0's auc: 0.807541\n",
      "[300]\tvalid_0's binary_logloss: 0.279316\tvalid_0's auc: 0.808765\n",
      "[400]\tvalid_0's binary_logloss: 0.263646\tvalid_0's auc: 0.808968\n",
      "[500]\tvalid_0's binary_logloss: 0.250981\tvalid_0's auc: 0.809093\n",
      "[600]\tvalid_0's binary_logloss: 0.246925\tvalid_0's auc: 0.809163\n",
      "Early stopping, best iteration is:\n",
      "[548]\tvalid_0's binary_logloss: 0.249497\tvalid_0's auc: 0.80917\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.377657\tvalid_0's auc: 0.801354\n",
      "[200]\tvalid_0's binary_logloss: 0.30401\tvalid_0's auc: 0.803757\n",
      "[300]\tvalid_0's binary_logloss: 0.279258\tvalid_0's auc: 0.805646\n",
      "[400]\tvalid_0's binary_logloss: 0.263639\tvalid_0's auc: 0.805844\n",
      "[500]\tvalid_0's binary_logloss: 0.251037\tvalid_0's auc: 0.806002\n",
      "[600]\tvalid_0's binary_logloss: 0.247018\tvalid_0's auc: 0.806469\n",
      "[700]\tvalid_0's binary_logloss: 0.239936\tvalid_0's auc: 0.806919\n",
      "[800]\tvalid_0's binary_logloss: 0.237769\tvalid_0's auc: 0.807135\n",
      "[900]\tvalid_0's binary_logloss: 0.235117\tvalid_0's auc: 0.807379\n",
      "[1000]\tvalid_0's binary_logloss: 0.233481\tvalid_0's auc: 0.807656\n",
      "[1100]\tvalid_0's binary_logloss: 0.233101\tvalid_0's auc: 0.807817\n",
      "[1200]\tvalid_0's binary_logloss: 0.232738\tvalid_0's auc: 0.807956\n",
      "[1300]\tvalid_0's binary_logloss: 0.232729\tvalid_0's auc: 0.808023\n",
      "Early stopping, best iteration is:\n",
      "[1220]\tvalid_0's binary_logloss: 0.232522\tvalid_0's auc: 0.807976\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.376917\tvalid_0's auc: 0.808431\n",
      "[200]\tvalid_0's binary_logloss: 0.302914\tvalid_0's auc: 0.811375\n",
      "[300]\tvalid_0's binary_logloss: 0.277999\tvalid_0's auc: 0.812394\n",
      "[400]\tvalid_0's binary_logloss: 0.262233\tvalid_0's auc: 0.812701\n",
      "[500]\tvalid_0's binary_logloss: 0.249462\tvalid_0's auc: 0.813023\n",
      "[600]\tvalid_0's binary_logloss: 0.245365\tvalid_0's auc: 0.813154\n",
      "[700]\tvalid_0's binary_logloss: 0.238134\tvalid_0's auc: 0.813477\n",
      "[800]\tvalid_0's binary_logloss: 0.235874\tvalid_0's auc: 0.813627\n",
      "[900]\tvalid_0's binary_logloss: 0.233111\tvalid_0's auc: 0.81384\n",
      "[1000]\tvalid_0's binary_logloss: 0.231371\tvalid_0's auc: 0.814059\n",
      "[1100]\tvalid_0's binary_logloss: 0.23096\tvalid_0's auc: 0.814276\n",
      "[1200]\tvalid_0's binary_logloss: 0.230554\tvalid_0's auc: 0.814421\n",
      "[1300]\tvalid_0's binary_logloss: 0.230548\tvalid_0's auc: 0.814467\n",
      "Early stopping, best iteration is:\n",
      "[1220]\tvalid_0's binary_logloss: 0.230331\tvalid_0's auc: 0.814424\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.377216\tvalid_0's auc: 0.804604\n",
      "[200]\tvalid_0's binary_logloss: 0.303515\tvalid_0's auc: 0.808853\n",
      "[300]\tvalid_0's binary_logloss: 0.278743\tvalid_0's auc: 0.809312\n",
      "[400]\tvalid_0's binary_logloss: 0.263074\tvalid_0's auc: 0.81035\n",
      "[500]\tvalid_0's binary_logloss: 0.25042\tvalid_0's auc: 0.810649\n",
      "[600]\tvalid_0's binary_logloss: 0.246348\tvalid_0's auc: 0.810926\n",
      "[700]\tvalid_0's binary_logloss: 0.239224\tvalid_0's auc: 0.811218\n",
      "[800]\tvalid_0's binary_logloss: 0.237005\tvalid_0's auc: 0.811248\n",
      "[900]\tvalid_0's binary_logloss: 0.234313\tvalid_0's auc: 0.8113\n",
      "[1000]\tvalid_0's binary_logloss: 0.232653\tvalid_0's auc: 0.811456\n",
      "[1100]\tvalid_0's binary_logloss: 0.232261\tvalid_0's auc: 0.811531\n",
      "[1200]\tvalid_0's binary_logloss: 0.231868\tvalid_0's auc: 0.811659\n",
      "[1300]\tvalid_0's binary_logloss: 0.231847\tvalid_0's auc: 0.811701\n",
      "Early stopping, best iteration is:\n",
      "[1220]\tvalid_0's binary_logloss: 0.231654\tvalid_0's auc: 0.811664\n",
      "cv score - on train:\n",
      "0.8034499487255756\n",
      "('current score in fold:', 0.8034499487255756, 1)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.375754\tvalid_0's auc: 0.803075\n",
      "[200]\tvalid_0's binary_logloss: 0.299991\tvalid_0's auc: 0.80468\n",
      "[300]\tvalid_0's binary_logloss: 0.268919\tvalid_0's auc: 0.805794\n",
      "[400]\tvalid_0's binary_logloss: 0.256932\tvalid_0's auc: 0.80638\n",
      "[500]\tvalid_0's binary_logloss: 0.249255\tvalid_0's auc: 0.806706\n",
      "[600]\tvalid_0's binary_logloss: 0.245738\tvalid_0's auc: 0.806796\n",
      "[700]\tvalid_0's binary_logloss: 0.242813\tvalid_0's auc: 0.806951\n",
      "[800]\tvalid_0's binary_logloss: 0.240334\tvalid_0's auc: 0.80698\n",
      "[900]\tvalid_0's binary_logloss: 0.237864\tvalid_0's auc: 0.807144\n",
      "[1000]\tvalid_0's binary_logloss: 0.23722\tvalid_0's auc: 0.807175\n",
      "[1100]\tvalid_0's binary_logloss: 0.235746\tvalid_0's auc: 0.807226\n",
      "[1200]\tvalid_0's binary_logloss: 0.234714\tvalid_0's auc: 0.807297\n",
      "Early stopping, best iteration is:\n",
      "[1197]\tvalid_0's binary_logloss: 0.234585\tvalid_0's auc: 0.807297\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.375492\tvalid_0's auc: 0.804334\n",
      "[200]\tvalid_0's binary_logloss: 0.299494\tvalid_0's auc: 0.808587\n",
      "[300]\tvalid_0's binary_logloss: 0.268217\tvalid_0's auc: 0.810413\n",
      "[400]\tvalid_0's binary_logloss: 0.256099\tvalid_0's auc: 0.810738\n",
      "[500]\tvalid_0's binary_logloss: 0.248318\tvalid_0's auc: 0.811083\n",
      "[600]\tvalid_0's binary_logloss: 0.244747\tvalid_0's auc: 0.811142\n",
      "[700]\tvalid_0's binary_logloss: 0.241776\tvalid_0's auc: 0.811173\n",
      "[800]\tvalid_0's binary_logloss: 0.239237\tvalid_0's auc: 0.811348\n",
      "[900]\tvalid_0's binary_logloss: 0.236703\tvalid_0's auc: 0.811419\n",
      "[1000]\tvalid_0's binary_logloss: 0.236037\tvalid_0's auc: 0.811461\n",
      "[1100]\tvalid_0's binary_logloss: 0.23451\tvalid_0's auc: 0.811494\n",
      "[1200]\tvalid_0's binary_logloss: 0.233422\tvalid_0's auc: 0.811653\n",
      "Early stopping, best iteration is:\n",
      "[1197]\tvalid_0's binary_logloss: 0.233288\tvalid_0's auc: 0.81165\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.375008\tvalid_0's auc: 0.80668\n",
      "[200]\tvalid_0's binary_logloss: 0.298892\tvalid_0's auc: 0.809016\n",
      "[300]\tvalid_0's binary_logloss: 0.267636\tvalid_0's auc: 0.809978\n",
      "Early stopping, best iteration is:\n",
      "[290]\tvalid_0's binary_logloss: 0.26952\tvalid_0's auc: 0.810009\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.375612\tvalid_0's auc: 0.803167\n",
      "[200]\tvalid_0's binary_logloss: 0.299635\tvalid_0's auc: 0.807668\n",
      "[300]\tvalid_0's binary_logloss: 0.268412\tvalid_0's auc: 0.8083\n",
      "[400]\tvalid_0's binary_logloss: 0.25633\tvalid_0's auc: 0.808681\n",
      "[500]\tvalid_0's binary_logloss: 0.248615\tvalid_0's auc: 0.809124\n",
      "[600]\tvalid_0's binary_logloss: 0.245072\tvalid_0's auc: 0.809482\n",
      "[700]\tvalid_0's binary_logloss: 0.242119\tvalid_0's auc: 0.809573\n",
      "[800]\tvalid_0's binary_logloss: 0.239606\tvalid_0's auc: 0.809636\n",
      "[900]\tvalid_0's binary_logloss: 0.237105\tvalid_0's auc: 0.80976\n",
      "[1000]\tvalid_0's binary_logloss: 0.236464\tvalid_0's auc: 0.80991\n",
      "[1100]\tvalid_0's binary_logloss: 0.234954\tvalid_0's auc: 0.809984\n",
      "[1200]\tvalid_0's binary_logloss: 0.233874\tvalid_0's auc: 0.810179\n",
      "Early stopping, best iteration is:\n",
      "[1197]\tvalid_0's binary_logloss: 0.23374\tvalid_0's auc: 0.810178\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.375295\tvalid_0's auc: 0.804398\n",
      "[200]\tvalid_0's binary_logloss: 0.299399\tvalid_0's auc: 0.806669\n",
      "[300]\tvalid_0's binary_logloss: 0.268267\tvalid_0's auc: 0.808329\n",
      "[400]\tvalid_0's binary_logloss: 0.256249\tvalid_0's auc: 0.808473\n",
      "[500]\tvalid_0's binary_logloss: 0.248584\tvalid_0's auc: 0.808655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[600]\tvalid_0's binary_logloss: 0.245044\tvalid_0's auc: 0.8089\n",
      "[700]\tvalid_0's binary_logloss: 0.242101\tvalid_0's auc: 0.80908\n",
      "[800]\tvalid_0's binary_logloss: 0.239597\tvalid_0's auc: 0.80916\n",
      "[900]\tvalid_0's binary_logloss: 0.237136\tvalid_0's auc: 0.809371\n",
      "[1000]\tvalid_0's binary_logloss: 0.236486\tvalid_0's auc: 0.809449\n",
      "[1100]\tvalid_0's binary_logloss: 0.235001\tvalid_0's auc: 0.809533\n",
      "[1200]\tvalid_0's binary_logloss: 0.233943\tvalid_0's auc: 0.809618\n",
      "Early stopping, best iteration is:\n",
      "[1197]\tvalid_0's binary_logloss: 0.233816\tvalid_0's auc: 0.809617\n",
      "cv score - on train:\n",
      "0.7922649210441692\n",
      "('current score in fold:', 0.8020842398918464, 2)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.375905\tvalid_0's auc: 0.799728\n",
      "[200]\tvalid_0's binary_logloss: 0.31486\tvalid_0's auc: 0.80223\n",
      "[300]\tvalid_0's binary_logloss: 0.280832\tvalid_0's auc: 0.804092\n",
      "[400]\tvalid_0's binary_logloss: 0.264639\tvalid_0's auc: 0.804533\n",
      "[500]\tvalid_0's binary_logloss: 0.256072\tvalid_0's auc: 0.804778\n",
      "[600]\tvalid_0's binary_logloss: 0.2475\tvalid_0's auc: 0.804975\n",
      "[700]\tvalid_0's binary_logloss: 0.2454\tvalid_0's auc: 0.805231\n",
      "[800]\tvalid_0's binary_logloss: 0.241348\tvalid_0's auc: 0.805298\n",
      "[900]\tvalid_0's binary_logloss: 0.239505\tvalid_0's auc: 0.805305\n",
      "[1000]\tvalid_0's binary_logloss: 0.23754\tvalid_0's auc: 0.80539\n",
      "[1100]\tvalid_0's binary_logloss: 0.236097\tvalid_0's auc: 0.805664\n",
      "[1200]\tvalid_0's binary_logloss: 0.234571\tvalid_0's auc: 0.805796\n",
      "[1300]\tvalid_0's binary_logloss: 0.233634\tvalid_0's auc: 0.805996\n",
      "[1400]\tvalid_0's binary_logloss: 0.232972\tvalid_0's auc: 0.806091\n",
      "[1500]\tvalid_0's binary_logloss: 0.23275\tvalid_0's auc: 0.806261\n",
      "[1600]\tvalid_0's binary_logloss: 0.232338\tvalid_0's auc: 0.806384\n",
      "[1700]\tvalid_0's binary_logloss: 0.232204\tvalid_0's auc: 0.806461\n",
      "[1800]\tvalid_0's binary_logloss: 0.231967\tvalid_0's auc: 0.806529\n",
      "[1900]\tvalid_0's binary_logloss: 0.231951\tvalid_0's auc: 0.806562\n",
      "[2000]\tvalid_0's binary_logloss: 0.231624\tvalid_0's auc: 0.806624\n",
      "Early stopping, best iteration is:\n",
      "[1998]\tvalid_0's binary_logloss: 0.231601\tvalid_0's auc: 0.806623\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.375625\tvalid_0's auc: 0.803532\n",
      "[200]\tvalid_0's binary_logloss: 0.314472\tvalid_0's auc: 0.805888\n",
      "[300]\tvalid_0's binary_logloss: 0.280377\tvalid_0's auc: 0.806945\n",
      "[400]\tvalid_0's binary_logloss: 0.264111\tvalid_0's auc: 0.807463\n",
      "[500]\tvalid_0's binary_logloss: 0.255483\tvalid_0's auc: 0.80751\n",
      "[600]\tvalid_0's binary_logloss: 0.24687\tvalid_0's auc: 0.807773\n",
      "[700]\tvalid_0's binary_logloss: 0.244757\tvalid_0's auc: 0.807908\n",
      "[800]\tvalid_0's binary_logloss: 0.240667\tvalid_0's auc: 0.807933\n",
      "[900]\tvalid_0's binary_logloss: 0.238787\tvalid_0's auc: 0.808033\n",
      "[1000]\tvalid_0's binary_logloss: 0.23679\tvalid_0's auc: 0.808115\n",
      "[1100]\tvalid_0's binary_logloss: 0.235333\tvalid_0's auc: 0.808303\n",
      "[1200]\tvalid_0's binary_logloss: 0.233784\tvalid_0's auc: 0.808587\n",
      "[1300]\tvalid_0's binary_logloss: 0.232822\tvalid_0's auc: 0.808793\n",
      "[1400]\tvalid_0's binary_logloss: 0.232128\tvalid_0's auc: 0.808927\n",
      "[1500]\tvalid_0's binary_logloss: 0.231898\tvalid_0's auc: 0.809076\n",
      "[1600]\tvalid_0's binary_logloss: 0.231469\tvalid_0's auc: 0.809221\n",
      "[1700]\tvalid_0's binary_logloss: 0.23132\tvalid_0's auc: 0.809334\n",
      "[1800]\tvalid_0's binary_logloss: 0.23108\tvalid_0's auc: 0.809404\n",
      "[1900]\tvalid_0's binary_logloss: 0.231045\tvalid_0's auc: 0.809539\n",
      "[2000]\tvalid_0's binary_logloss: 0.230709\tvalid_0's auc: 0.809632\n",
      "Early stopping, best iteration is:\n",
      "[1998]\tvalid_0's binary_logloss: 0.230686\tvalid_0's auc: 0.809632\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.375338\tvalid_0's auc: 0.804703\n",
      "[200]\tvalid_0's binary_logloss: 0.314\tvalid_0's auc: 0.806872\n",
      "[300]\tvalid_0's binary_logloss: 0.279702\tvalid_0's auc: 0.80948\n",
      "[400]\tvalid_0's binary_logloss: 0.263343\tvalid_0's auc: 0.809793\n",
      "[500]\tvalid_0's binary_logloss: 0.254665\tvalid_0's auc: 0.810033\n",
      "[600]\tvalid_0's binary_logloss: 0.245968\tvalid_0's auc: 0.810438\n",
      "[700]\tvalid_0's binary_logloss: 0.24384\tvalid_0's auc: 0.810592\n",
      "[800]\tvalid_0's binary_logloss: 0.239678\tvalid_0's auc: 0.810736\n",
      "[900]\tvalid_0's binary_logloss: 0.237779\tvalid_0's auc: 0.810834\n",
      "[1000]\tvalid_0's binary_logloss: 0.235761\tvalid_0's auc: 0.810914\n",
      "[1100]\tvalid_0's binary_logloss: 0.234276\tvalid_0's auc: 0.810953\n",
      "[1200]\tvalid_0's binary_logloss: 0.232678\tvalid_0's auc: 0.811098\n",
      "[1300]\tvalid_0's binary_logloss: 0.231688\tvalid_0's auc: 0.811273\n",
      "[1400]\tvalid_0's binary_logloss: 0.230949\tvalid_0's auc: 0.811396\n",
      "[1500]\tvalid_0's binary_logloss: 0.230734\tvalid_0's auc: 0.811494\n",
      "[1600]\tvalid_0's binary_logloss: 0.230294\tvalid_0's auc: 0.811605\n",
      "[1700]\tvalid_0's binary_logloss: 0.230139\tvalid_0's auc: 0.81176\n",
      "[1800]\tvalid_0's binary_logloss: 0.229877\tvalid_0's auc: 0.811853\n",
      "[1900]\tvalid_0's binary_logloss: 0.229861\tvalid_0's auc: 0.811893\n",
      "[2000]\tvalid_0's binary_logloss: 0.229499\tvalid_0's auc: 0.811944\n",
      "Early stopping, best iteration is:\n",
      "[1998]\tvalid_0's binary_logloss: 0.229473\tvalid_0's auc: 0.811944\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.374854\tvalid_0's auc: 0.807944\n",
      "[200]\tvalid_0's binary_logloss: 0.313364\tvalid_0's auc: 0.811744\n",
      "[300]\tvalid_0's binary_logloss: 0.278945\tvalid_0's auc: 0.812506\n",
      "[400]\tvalid_0's binary_logloss: 0.262488\tvalid_0's auc: 0.812948\n",
      "[500]\tvalid_0's binary_logloss: 0.253747\tvalid_0's auc: 0.813271\n",
      "[600]\tvalid_0's binary_logloss: 0.244953\tvalid_0's auc: 0.813586\n",
      "[700]\tvalid_0's binary_logloss: 0.242798\tvalid_0's auc: 0.81369\n",
      "[800]\tvalid_0's binary_logloss: 0.238585\tvalid_0's auc: 0.813905\n",
      "Early stopping, best iteration is:\n",
      "[707]\tvalid_0's binary_logloss: 0.242599\tvalid_0's auc: 0.813929\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.375553\tvalid_0's auc: 0.804714\n",
      "[200]\tvalid_0's binary_logloss: 0.314384\tvalid_0's auc: 0.807249\n",
      "[300]\tvalid_0's binary_logloss: 0.280223\tvalid_0's auc: 0.807615\n",
      "[400]\tvalid_0's binary_logloss: 0.263892\tvalid_0's auc: 0.808365\n",
      "[500]\tvalid_0's binary_logloss: 0.255213\tvalid_0's auc: 0.808543\n",
      "[600]\tvalid_0's binary_logloss: 0.246545\tvalid_0's auc: 0.808959\n",
      "[700]\tvalid_0's binary_logloss: 0.244425\tvalid_0's auc: 0.809071\n",
      "[800]\tvalid_0's binary_logloss: 0.240312\tvalid_0's auc: 0.809137\n",
      "[900]\tvalid_0's binary_logloss: 0.238421\tvalid_0's auc: 0.809304\n",
      "[1000]\tvalid_0's binary_logloss: 0.236429\tvalid_0's auc: 0.809424\n",
      "[1100]\tvalid_0's binary_logloss: 0.234965\tvalid_0's auc: 0.8095\n",
      "[1200]\tvalid_0's binary_logloss: 0.233405\tvalid_0's auc: 0.809743\n",
      "[1300]\tvalid_0's binary_logloss: 0.232441\tvalid_0's auc: 0.80991\n",
      "[1400]\tvalid_0's binary_logloss: 0.231737\tvalid_0's auc: 0.810138\n",
      "[1500]\tvalid_0's binary_logloss: 0.231528\tvalid_0's auc: 0.810293\n",
      "[1600]\tvalid_0's binary_logloss: 0.231116\tvalid_0's auc: 0.81038\n",
      "[1700]\tvalid_0's binary_logloss: 0.230992\tvalid_0's auc: 0.810502\n",
      "[1800]\tvalid_0's binary_logloss: 0.230753\tvalid_0's auc: 0.810579\n",
      "[1900]\tvalid_0's binary_logloss: 0.230741\tvalid_0's auc: 0.810624\n",
      "[2000]\tvalid_0's binary_logloss: 0.230398\tvalid_0's auc: 0.810695\n",
      "Early stopping, best iteration is:\n",
      "[1998]\tvalid_0's binary_logloss: 0.230373\tvalid_0's auc: 0.810695\n",
      "cv score - on train:\n",
      "0.8037118935582123\n",
      "('current score in fold:', 0.8052413023623284, 3)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.380823\tvalid_0's auc: 0.799672\n",
      "[200]\tvalid_0's binary_logloss: 0.308827\tvalid_0's auc: 0.802389\n",
      "[300]\tvalid_0's binary_logloss: 0.278209\tvalid_0's auc: 0.804928\n",
      "[400]\tvalid_0's binary_logloss: 0.256324\tvalid_0's auc: 0.80531\n",
      "[500]\tvalid_0's binary_logloss: 0.247033\tvalid_0's auc: 0.805727\n",
      "[600]\tvalid_0's binary_logloss: 0.243257\tvalid_0's auc: 0.806163\n",
      "[700]\tvalid_0's binary_logloss: 0.239488\tvalid_0's auc: 0.806491\n",
      "[800]\tvalid_0's binary_logloss: 0.237668\tvalid_0's auc: 0.806581\n",
      "[900]\tvalid_0's binary_logloss: 0.236293\tvalid_0's auc: 0.80667\n",
      "[1000]\tvalid_0's binary_logloss: 0.234688\tvalid_0's auc: 0.806762\n",
      "[1100]\tvalid_0's binary_logloss: 0.233922\tvalid_0's auc: 0.806991\n",
      "[1200]\tvalid_0's binary_logloss: 0.233249\tvalid_0's auc: 0.807086\n",
      "[1300]\tvalid_0's binary_logloss: 0.233\tvalid_0's auc: 0.807137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1400]\tvalid_0's binary_logloss: 0.232439\tvalid_0's auc: 0.80721\n",
      "[1500]\tvalid_0's binary_logloss: 0.232029\tvalid_0's auc: 0.807241\n",
      "[1600]\tvalid_0's binary_logloss: 0.231875\tvalid_0's auc: 0.807337\n",
      "[1700]\tvalid_0's binary_logloss: 0.231891\tvalid_0's auc: 0.807424\n",
      "[1800]\tvalid_0's binary_logloss: 0.231818\tvalid_0's auc: 0.807482\n",
      "Early stopping, best iteration is:\n",
      "[1735]\tvalid_0's binary_logloss: 0.23154\tvalid_0's auc: 0.807461\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.380658\tvalid_0's auc: 0.80486\n",
      "[200]\tvalid_0's binary_logloss: 0.308514\tvalid_0's auc: 0.80571\n",
      "[300]\tvalid_0's binary_logloss: 0.277765\tvalid_0's auc: 0.807727\n",
      "[400]\tvalid_0's binary_logloss: 0.255714\tvalid_0's auc: 0.808604\n",
      "[500]\tvalid_0's binary_logloss: 0.246316\tvalid_0's auc: 0.808781\n",
      "[600]\tvalid_0's binary_logloss: 0.242468\tvalid_0's auc: 0.809231\n",
      "[700]\tvalid_0's binary_logloss: 0.238636\tvalid_0's auc: 0.809483\n",
      "[800]\tvalid_0's binary_logloss: 0.236778\tvalid_0's auc: 0.809653\n",
      "[900]\tvalid_0's binary_logloss: 0.235378\tvalid_0's auc: 0.809823\n",
      "[1000]\tvalid_0's binary_logloss: 0.233725\tvalid_0's auc: 0.810006\n",
      "[1100]\tvalid_0's binary_logloss: 0.232934\tvalid_0's auc: 0.810209\n",
      "[1200]\tvalid_0's binary_logloss: 0.232203\tvalid_0's auc: 0.810427\n",
      "[1300]\tvalid_0's binary_logloss: 0.231936\tvalid_0's auc: 0.810518\n",
      "[1400]\tvalid_0's binary_logloss: 0.23134\tvalid_0's auc: 0.8106\n",
      "[1500]\tvalid_0's binary_logloss: 0.230901\tvalid_0's auc: 0.810739\n",
      "[1600]\tvalid_0's binary_logloss: 0.230724\tvalid_0's auc: 0.810836\n",
      "[1700]\tvalid_0's binary_logloss: 0.230746\tvalid_0's auc: 0.810907\n",
      "[1800]\tvalid_0's binary_logloss: 0.230668\tvalid_0's auc: 0.810979\n",
      "Early stopping, best iteration is:\n",
      "[1735]\tvalid_0's binary_logloss: 0.230378\tvalid_0's auc: 0.810943\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.380355\tvalid_0's auc: 0.807203\n",
      "[200]\tvalid_0's binary_logloss: 0.308113\tvalid_0's auc: 0.810057\n",
      "[300]\tvalid_0's binary_logloss: 0.277305\tvalid_0's auc: 0.811183\n",
      "[400]\tvalid_0's binary_logloss: 0.255135\tvalid_0's auc: 0.81207\n",
      "[500]\tvalid_0's binary_logloss: 0.245696\tvalid_0's auc: 0.812216\n",
      "[600]\tvalid_0's binary_logloss: 0.241825\tvalid_0's auc: 0.812184\n",
      "Early stopping, best iteration is:\n",
      "[503]\tvalid_0's binary_logloss: 0.24561\tvalid_0's auc: 0.812221\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.380948\tvalid_0's auc: 0.801301\n",
      "[200]\tvalid_0's binary_logloss: 0.308988\tvalid_0's auc: 0.803263\n",
      "[300]\tvalid_0's binary_logloss: 0.278379\tvalid_0's auc: 0.805247\n",
      "[400]\tvalid_0's binary_logloss: 0.256459\tvalid_0's auc: 0.805981\n",
      "[500]\tvalid_0's binary_logloss: 0.247154\tvalid_0's auc: 0.806415\n",
      "[600]\tvalid_0's binary_logloss: 0.243361\tvalid_0's auc: 0.806434\n",
      "[700]\tvalid_0's binary_logloss: 0.239626\tvalid_0's auc: 0.806616\n",
      "[800]\tvalid_0's binary_logloss: 0.237824\tvalid_0's auc: 0.806781\n",
      "[900]\tvalid_0's binary_logloss: 0.236453\tvalid_0's auc: 0.80687\n",
      "[1000]\tvalid_0's binary_logloss: 0.234863\tvalid_0's auc: 0.80709\n",
      "[1100]\tvalid_0's binary_logloss: 0.234109\tvalid_0's auc: 0.807167\n",
      "[1200]\tvalid_0's binary_logloss: 0.233436\tvalid_0's auc: 0.807362\n",
      "[1300]\tvalid_0's binary_logloss: 0.233185\tvalid_0's auc: 0.807468\n",
      "[1400]\tvalid_0's binary_logloss: 0.232613\tvalid_0's auc: 0.807613\n",
      "[1500]\tvalid_0's binary_logloss: 0.232191\tvalid_0's auc: 0.807743\n",
      "[1600]\tvalid_0's binary_logloss: 0.232026\tvalid_0's auc: 0.807852\n",
      "[1700]\tvalid_0's binary_logloss: 0.232037\tvalid_0's auc: 0.807927\n",
      "[1800]\tvalid_0's binary_logloss: 0.23197\tvalid_0's auc: 0.807981\n",
      "Early stopping, best iteration is:\n",
      "[1735]\tvalid_0's binary_logloss: 0.231706\tvalid_0's auc: 0.807947\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.379946\tvalid_0's auc: 0.808988\n",
      "[200]\tvalid_0's binary_logloss: 0.307569\tvalid_0's auc: 0.811218\n",
      "[300]\tvalid_0's binary_logloss: 0.276683\tvalid_0's auc: 0.812041\n",
      "[400]\tvalid_0's binary_logloss: 0.254548\tvalid_0's auc: 0.812156\n",
      "[500]\tvalid_0's binary_logloss: 0.245102\tvalid_0's auc: 0.812377\n",
      "[600]\tvalid_0's binary_logloss: 0.241224\tvalid_0's auc: 0.812814\n",
      "[700]\tvalid_0's binary_logloss: 0.237377\tvalid_0's auc: 0.812984\n",
      "[800]\tvalid_0's binary_logloss: 0.23552\tvalid_0's auc: 0.813086\n",
      "[900]\tvalid_0's binary_logloss: 0.234106\tvalid_0's auc: 0.81323\n",
      "[1000]\tvalid_0's binary_logloss: 0.232455\tvalid_0's auc: 0.813392\n",
      "[1100]\tvalid_0's binary_logloss: 0.231665\tvalid_0's auc: 0.813509\n",
      "[1200]\tvalid_0's binary_logloss: 0.230968\tvalid_0's auc: 0.813676\n",
      "[1300]\tvalid_0's binary_logloss: 0.230714\tvalid_0's auc: 0.813747\n",
      "[1400]\tvalid_0's binary_logloss: 0.230126\tvalid_0's auc: 0.813955\n",
      "[1500]\tvalid_0's binary_logloss: 0.229683\tvalid_0's auc: 0.814044\n",
      "[1600]\tvalid_0's binary_logloss: 0.229516\tvalid_0's auc: 0.81414\n",
      "[1700]\tvalid_0's binary_logloss: 0.229559\tvalid_0's auc: 0.814163\n",
      "[1800]\tvalid_0's binary_logloss: 0.229496\tvalid_0's auc: 0.814201\n",
      "Early stopping, best iteration is:\n",
      "[1735]\tvalid_0's binary_logloss: 0.2292\tvalid_0's auc: 0.814182\n",
      "cv score - on train:\n",
      "0.8028072287622634\n",
      "('current score in fold:', 0.8066034338029338, 4)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.386186\tvalid_0's auc: 0.803109\n",
      "[200]\tvalid_0's binary_logloss: 0.311319\tvalid_0's auc: 0.806466\n",
      "[300]\tvalid_0's binary_logloss: 0.271549\tvalid_0's auc: 0.807186\n",
      "[400]\tvalid_0's binary_logloss: 0.258934\tvalid_0's auc: 0.807464\n",
      "[500]\tvalid_0's binary_logloss: 0.251179\tvalid_0's auc: 0.807772\n",
      "[600]\tvalid_0's binary_logloss: 0.245136\tvalid_0's auc: 0.808116\n",
      "[700]\tvalid_0's binary_logloss: 0.240216\tvalid_0's auc: 0.808382\n",
      "[800]\tvalid_0's binary_logloss: 0.23878\tvalid_0's auc: 0.808426\n",
      "[900]\tvalid_0's binary_logloss: 0.237082\tvalid_0's auc: 0.80852\n",
      "[1000]\tvalid_0's binary_logloss: 0.23458\tvalid_0's auc: 0.808608\n",
      "[1100]\tvalid_0's binary_logloss: 0.233188\tvalid_0's auc: 0.8088\n",
      "[1200]\tvalid_0's binary_logloss: 0.233048\tvalid_0's auc: 0.808912\n",
      "Early stopping, best iteration is:\n",
      "[1161]\tvalid_0's binary_logloss: 0.232398\tvalid_0's auc: 0.808902\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.386209\tvalid_0's auc: 0.80592\n",
      "[200]\tvalid_0's binary_logloss: 0.311296\tvalid_0's auc: 0.808095\n",
      "[300]\tvalid_0's binary_logloss: 0.271378\tvalid_0's auc: 0.810126\n",
      "[400]\tvalid_0's binary_logloss: 0.258677\tvalid_0's auc: 0.810298\n",
      "[500]\tvalid_0's binary_logloss: 0.250878\tvalid_0's auc: 0.810403\n",
      "[600]\tvalid_0's binary_logloss: 0.244787\tvalid_0's auc: 0.810697\n",
      "[700]\tvalid_0's binary_logloss: 0.239815\tvalid_0's auc: 0.810891\n",
      "[800]\tvalid_0's binary_logloss: 0.238352\tvalid_0's auc: 0.811075\n",
      "[900]\tvalid_0's binary_logloss: 0.23662\tvalid_0's auc: 0.811153\n",
      "[1000]\tvalid_0's binary_logloss: 0.234064\tvalid_0's auc: 0.811382\n",
      "[1100]\tvalid_0's binary_logloss: 0.232627\tvalid_0's auc: 0.811707\n",
      "[1200]\tvalid_0's binary_logloss: 0.232462\tvalid_0's auc: 0.811797\n",
      "Early stopping, best iteration is:\n",
      "[1161]\tvalid_0's binary_logloss: 0.231803\tvalid_0's auc: 0.81179\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.38648\tvalid_0's auc: 0.798641\n",
      "[200]\tvalid_0's binary_logloss: 0.311787\tvalid_0's auc: 0.802646\n",
      "[300]\tvalid_0's binary_logloss: 0.272097\tvalid_0's auc: 0.804339\n",
      "[400]\tvalid_0's binary_logloss: 0.259532\tvalid_0's auc: 0.80447\n",
      "[500]\tvalid_0's binary_logloss: 0.251845\tvalid_0's auc: 0.804535\n",
      "[600]\tvalid_0's binary_logloss: 0.24588\tvalid_0's auc: 0.804849\n",
      "[700]\tvalid_0's binary_logloss: 0.241023\tvalid_0's auc: 0.804939\n",
      "[800]\tvalid_0's binary_logloss: 0.239618\tvalid_0's auc: 0.80501\n",
      "[900]\tvalid_0's binary_logloss: 0.237941\tvalid_0's auc: 0.805045\n",
      "[1000]\tvalid_0's binary_logloss: 0.23549\tvalid_0's auc: 0.805156\n",
      "[1100]\tvalid_0's binary_logloss: 0.234119\tvalid_0's auc: 0.805358\n",
      "[1200]\tvalid_0's binary_logloss: 0.233967\tvalid_0's auc: 0.80556\n",
      "Early stopping, best iteration is:\n",
      "[1161]\tvalid_0's binary_logloss: 0.233334\tvalid_0's auc: 0.805563\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.386042\tvalid_0's auc: 0.804429\n",
      "[200]\tvalid_0's binary_logloss: 0.311152\tvalid_0's auc: 0.807299\n",
      "[300]\tvalid_0's binary_logloss: 0.271246\tvalid_0's auc: 0.809066\n",
      "[400]\tvalid_0's binary_logloss: 0.258564\tvalid_0's auc: 0.809772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\tvalid_0's binary_logloss: 0.250761\tvalid_0's auc: 0.809822\n",
      "[600]\tvalid_0's binary_logloss: 0.244697\tvalid_0's auc: 0.810065\n",
      "[700]\tvalid_0's binary_logloss: 0.239757\tvalid_0's auc: 0.810258\n",
      "[800]\tvalid_0's binary_logloss: 0.2383\tvalid_0's auc: 0.810326\n",
      "[900]\tvalid_0's binary_logloss: 0.236572\tvalid_0's auc: 0.810443\n",
      "[1000]\tvalid_0's binary_logloss: 0.234058\tvalid_0's auc: 0.810762\n",
      "[1100]\tvalid_0's binary_logloss: 0.232626\tvalid_0's auc: 0.81106\n",
      "[1200]\tvalid_0's binary_logloss: 0.232441\tvalid_0's auc: 0.811356\n",
      "Early stopping, best iteration is:\n",
      "[1161]\tvalid_0's binary_logloss: 0.231805\tvalid_0's auc: 0.811337\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.385982\tvalid_0's auc: 0.80771\n",
      "[200]\tvalid_0's binary_logloss: 0.311015\tvalid_0's auc: 0.809415\n",
      "[300]\tvalid_0's binary_logloss: 0.27106\tvalid_0's auc: 0.811193\n",
      "[400]\tvalid_0's binary_logloss: 0.258355\tvalid_0's auc: 0.811602\n",
      "[500]\tvalid_0's binary_logloss: 0.250537\tvalid_0's auc: 0.811938\n",
      "[600]\tvalid_0's binary_logloss: 0.244426\tvalid_0's auc: 0.812062\n",
      "[700]\tvalid_0's binary_logloss: 0.239427\tvalid_0's auc: 0.812535\n",
      "[800]\tvalid_0's binary_logloss: 0.237948\tvalid_0's auc: 0.812704\n",
      "[900]\tvalid_0's binary_logloss: 0.236202\tvalid_0's auc: 0.812852\n",
      "[1000]\tvalid_0's binary_logloss: 0.233618\tvalid_0's auc: 0.812985\n",
      "[1100]\tvalid_0's binary_logloss: 0.23216\tvalid_0's auc: 0.813136\n",
      "[1200]\tvalid_0's binary_logloss: 0.231978\tvalid_0's auc: 0.813266\n",
      "Early stopping, best iteration is:\n",
      "[1161]\tvalid_0's binary_logloss: 0.231313\tvalid_0's auc: 0.813257\n",
      "cv score - on train:\n",
      "0.8099148464301225\n",
      "('current score in fold:', 0.8077116318905366, 5)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.378141\tvalid_0's auc: 0.804154\n",
      "[200]\tvalid_0's binary_logloss: 0.299979\tvalid_0's auc: 0.806105\n",
      "[300]\tvalid_0's binary_logloss: 0.271239\tvalid_0's auc: 0.808385\n",
      "[400]\tvalid_0's binary_logloss: 0.255714\tvalid_0's auc: 0.808695\n",
      "[500]\tvalid_0's binary_logloss: 0.253398\tvalid_0's auc: 0.808705\n",
      "Early stopping, best iteration is:\n",
      "[414]\tvalid_0's binary_logloss: 0.255637\tvalid_0's auc: 0.808748\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.377759\tvalid_0's auc: 0.806962\n",
      "[200]\tvalid_0's binary_logloss: 0.299452\tvalid_0's auc: 0.810115\n",
      "[300]\tvalid_0's binary_logloss: 0.270601\tvalid_0's auc: 0.811082\n",
      "[400]\tvalid_0's binary_logloss: 0.254967\tvalid_0's auc: 0.811396\n",
      "[500]\tvalid_0's binary_logloss: 0.252593\tvalid_0's auc: 0.811612\n",
      "[600]\tvalid_0's binary_logloss: 0.244704\tvalid_0's auc: 0.811754\n",
      "Early stopping, best iteration is:\n",
      "[577]\tvalid_0's binary_logloss: 0.246908\tvalid_0's auc: 0.811767\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.378047\tvalid_0's auc: 0.802538\n",
      "[200]\tvalid_0's binary_logloss: 0.299956\tvalid_0's auc: 0.805781\n",
      "[300]\tvalid_0's binary_logloss: 0.271249\tvalid_0's auc: 0.806715\n",
      "[400]\tvalid_0's binary_logloss: 0.255781\tvalid_0's auc: 0.806713\n",
      "[500]\tvalid_0's binary_logloss: 0.253436\tvalid_0's auc: 0.806807\n",
      "[600]\tvalid_0's binary_logloss: 0.24565\tvalid_0's auc: 0.806935\n",
      "[700]\tvalid_0's binary_logloss: 0.242834\tvalid_0's auc: 0.807132\n",
      "[800]\tvalid_0's binary_logloss: 0.239883\tvalid_0's auc: 0.80733\n",
      "[900]\tvalid_0's binary_logloss: 0.237855\tvalid_0's auc: 0.807408\n",
      "[1000]\tvalid_0's binary_logloss: 0.235992\tvalid_0's auc: 0.8075\n",
      "[1100]\tvalid_0's binary_logloss: 0.23511\tvalid_0's auc: 0.807703\n",
      "[1200]\tvalid_0's binary_logloss: 0.234398\tvalid_0's auc: 0.807865\n",
      "[1300]\tvalid_0's binary_logloss: 0.233211\tvalid_0's auc: 0.807961\n",
      "[1400]\tvalid_0's binary_logloss: 0.233224\tvalid_0's auc: 0.808067\n",
      "Early stopping, best iteration is:\n",
      "[1310]\tvalid_0's binary_logloss: 0.233069\tvalid_0's auc: 0.807956\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.377457\tvalid_0's auc: 0.804332\n",
      "[200]\tvalid_0's binary_logloss: 0.299146\tvalid_0's auc: 0.808073\n",
      "[300]\tvalid_0's binary_logloss: 0.270307\tvalid_0's auc: 0.809081\n",
      "[400]\tvalid_0's binary_logloss: 0.254739\tvalid_0's auc: 0.809925\n",
      "[500]\tvalid_0's binary_logloss: 0.252378\tvalid_0's auc: 0.810159\n",
      "[600]\tvalid_0's binary_logloss: 0.244546\tvalid_0's auc: 0.810627\n",
      "[700]\tvalid_0's binary_logloss: 0.241699\tvalid_0's auc: 0.810779\n",
      "[800]\tvalid_0's binary_logloss: 0.238726\tvalid_0's auc: 0.810954\n",
      "[900]\tvalid_0's binary_logloss: 0.236672\tvalid_0's auc: 0.811009\n",
      "[1000]\tvalid_0's binary_logloss: 0.234779\tvalid_0's auc: 0.811099\n",
      "[1100]\tvalid_0's binary_logloss: 0.233886\tvalid_0's auc: 0.811221\n",
      "[1200]\tvalid_0's binary_logloss: 0.233164\tvalid_0's auc: 0.81138\n",
      "[1300]\tvalid_0's binary_logloss: 0.231951\tvalid_0's auc: 0.811573\n",
      "[1400]\tvalid_0's binary_logloss: 0.231954\tvalid_0's auc: 0.81165\n",
      "Early stopping, best iteration is:\n",
      "[1310]\tvalid_0's binary_logloss: 0.231794\tvalid_0's auc: 0.811594\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.378205\tvalid_0's auc: 0.802761\n",
      "[200]\tvalid_0's binary_logloss: 0.300072\tvalid_0's auc: 0.805641\n",
      "[300]\tvalid_0's binary_logloss: 0.271304\tvalid_0's auc: 0.807634\n",
      "[400]\tvalid_0's binary_logloss: 0.255786\tvalid_0's auc: 0.807722\n",
      "[500]\tvalid_0's binary_logloss: 0.253468\tvalid_0's auc: 0.80791\n",
      "[600]\tvalid_0's binary_logloss: 0.245629\tvalid_0's auc: 0.808063\n",
      "[700]\tvalid_0's binary_logloss: 0.242808\tvalid_0's auc: 0.808236\n",
      "[800]\tvalid_0's binary_logloss: 0.239825\tvalid_0's auc: 0.808396\n",
      "[900]\tvalid_0's binary_logloss: 0.237763\tvalid_0's auc: 0.808652\n",
      "[1000]\tvalid_0's binary_logloss: 0.23587\tvalid_0's auc: 0.808713\n",
      "[1100]\tvalid_0's binary_logloss: 0.234985\tvalid_0's auc: 0.808821\n",
      "[1200]\tvalid_0's binary_logloss: 0.234262\tvalid_0's auc: 0.808911\n",
      "[1300]\tvalid_0's binary_logloss: 0.233034\tvalid_0's auc: 0.80901\n",
      "[1400]\tvalid_0's binary_logloss: 0.233048\tvalid_0's auc: 0.809123\n",
      "Early stopping, best iteration is:\n",
      "[1310]\tvalid_0's binary_logloss: 0.232881\tvalid_0's auc: 0.809023\n",
      "cv score - on train:\n",
      "0.7957325275998088\n",
      "('current score in fold:', 0.8077067898344381, 6)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.384995\tvalid_0's auc: 0.804853\n",
      "[200]\tvalid_0's binary_logloss: 0.311589\tvalid_0's auc: 0.807489\n",
      "[300]\tvalid_0's binary_logloss: 0.27661\tvalid_0's auc: 0.808508\n",
      "[400]\tvalid_0's binary_logloss: 0.264247\tvalid_0's auc: 0.809218\n",
      "[500]\tvalid_0's binary_logloss: 0.249912\tvalid_0's auc: 0.80985\n",
      "[600]\tvalid_0's binary_logloss: 0.243719\tvalid_0's auc: 0.809993\n",
      "[700]\tvalid_0's binary_logloss: 0.240667\tvalid_0's auc: 0.810195\n",
      "[800]\tvalid_0's binary_logloss: 0.239412\tvalid_0's auc: 0.810253\n",
      "[900]\tvalid_0's binary_logloss: 0.235776\tvalid_0's auc: 0.810401\n",
      "[1000]\tvalid_0's binary_logloss: 0.235275\tvalid_0's auc: 0.810463\n",
      "[1100]\tvalid_0's binary_logloss: 0.233289\tvalid_0's auc: 0.810669\n",
      "[1200]\tvalid_0's binary_logloss: 0.23192\tvalid_0's auc: 0.810781\n",
      "[1300]\tvalid_0's binary_logloss: 0.231113\tvalid_0's auc: 0.811045\n",
      "[1400]\tvalid_0's binary_logloss: 0.230819\tvalid_0's auc: 0.811154\n",
      "[1500]\tvalid_0's binary_logloss: 0.230865\tvalid_0's auc: 0.811221\n",
      "Early stopping, best iteration is:\n",
      "[1404]\tvalid_0's binary_logloss: 0.230717\tvalid_0's auc: 0.811158\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.385349\tvalid_0's auc: 0.800619\n",
      "[200]\tvalid_0's binary_logloss: 0.312131\tvalid_0's auc: 0.803435\n",
      "[300]\tvalid_0's binary_logloss: 0.277272\tvalid_0's auc: 0.80412\n",
      "[400]\tvalid_0's binary_logloss: 0.264989\tvalid_0's auc: 0.805262\n",
      "[500]\tvalid_0's binary_logloss: 0.250775\tvalid_0's auc: 0.805534\n",
      "[600]\tvalid_0's binary_logloss: 0.244684\tvalid_0's auc: 0.805681\n",
      "[700]\tvalid_0's binary_logloss: 0.241685\tvalid_0's auc: 0.805749\n",
      "[800]\tvalid_0's binary_logloss: 0.240455\tvalid_0's auc: 0.805886\n",
      "[900]\tvalid_0's binary_logloss: 0.236878\tvalid_0's auc: 0.805958\n",
      "[1000]\tvalid_0's binary_logloss: 0.236389\tvalid_0's auc: 0.806003\n",
      "[1100]\tvalid_0's binary_logloss: 0.234469\tvalid_0's auc: 0.806245\n",
      "[1200]\tvalid_0's binary_logloss: 0.233131\tvalid_0's auc: 0.806413\n",
      "[1300]\tvalid_0's binary_logloss: 0.232379\tvalid_0's auc: 0.806545\n",
      "[1400]\tvalid_0's binary_logloss: 0.232094\tvalid_0's auc: 0.806683\n",
      "[1500]\tvalid_0's binary_logloss: 0.232151\tvalid_0's auc: 0.806721\n",
      "Early stopping, best iteration is:\n",
      "[1404]\tvalid_0's binary_logloss: 0.231996\tvalid_0's auc: 0.806681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.385103\tvalid_0's auc: 0.80327\n",
      "[200]\tvalid_0's binary_logloss: 0.311752\tvalid_0's auc: 0.806185\n",
      "[300]\tvalid_0's binary_logloss: 0.276813\tvalid_0's auc: 0.808537\n",
      "[400]\tvalid_0's binary_logloss: 0.264462\tvalid_0's auc: 0.808706\n",
      "[500]\tvalid_0's binary_logloss: 0.250163\tvalid_0's auc: 0.808999\n",
      "[600]\tvalid_0's binary_logloss: 0.243992\tvalid_0's auc: 0.809313\n",
      "[700]\tvalid_0's binary_logloss: 0.240956\tvalid_0's auc: 0.809348\n",
      "[800]\tvalid_0's binary_logloss: 0.239691\tvalid_0's auc: 0.809416\n",
      "[900]\tvalid_0's binary_logloss: 0.23604\tvalid_0's auc: 0.809591\n",
      "[1000]\tvalid_0's binary_logloss: 0.235532\tvalid_0's auc: 0.809647\n",
      "[1100]\tvalid_0's binary_logloss: 0.233526\tvalid_0's auc: 0.809801\n",
      "[1200]\tvalid_0's binary_logloss: 0.23214\tvalid_0's auc: 0.809932\n",
      "[1300]\tvalid_0's binary_logloss: 0.231308\tvalid_0's auc: 0.810149\n",
      "[1400]\tvalid_0's binary_logloss: 0.230991\tvalid_0's auc: 0.81033\n",
      "[1500]\tvalid_0's binary_logloss: 0.231027\tvalid_0's auc: 0.810441\n",
      "Early stopping, best iteration is:\n",
      "[1404]\tvalid_0's binary_logloss: 0.230886\tvalid_0's auc: 0.810338\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.384947\tvalid_0's auc: 0.805966\n",
      "[200]\tvalid_0's binary_logloss: 0.311571\tvalid_0's auc: 0.808676\n",
      "[300]\tvalid_0's binary_logloss: 0.276581\tvalid_0's auc: 0.809676\n",
      "[400]\tvalid_0's binary_logloss: 0.264202\tvalid_0's auc: 0.809809\n",
      "[500]\tvalid_0's binary_logloss: 0.249867\tvalid_0's auc: 0.810133\n",
      "[600]\tvalid_0's binary_logloss: 0.243683\tvalid_0's auc: 0.810372\n",
      "[700]\tvalid_0's binary_logloss: 0.240628\tvalid_0's auc: 0.810444\n",
      "[800]\tvalid_0's binary_logloss: 0.239375\tvalid_0's auc: 0.810564\n",
      "[900]\tvalid_0's binary_logloss: 0.235716\tvalid_0's auc: 0.810717\n",
      "[1000]\tvalid_0's binary_logloss: 0.235201\tvalid_0's auc: 0.810771\n",
      "[1100]\tvalid_0's binary_logloss: 0.233218\tvalid_0's auc: 0.810935\n",
      "[1200]\tvalid_0's binary_logloss: 0.231826\tvalid_0's auc: 0.811187\n",
      "[1300]\tvalid_0's binary_logloss: 0.231007\tvalid_0's auc: 0.811364\n",
      "[1400]\tvalid_0's binary_logloss: 0.23071\tvalid_0's auc: 0.811455\n",
      "[1500]\tvalid_0's binary_logloss: 0.230757\tvalid_0's auc: 0.811539\n",
      "Early stopping, best iteration is:\n",
      "[1404]\tvalid_0's binary_logloss: 0.230606\tvalid_0's auc: 0.811458\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.384691\tvalid_0's auc: 0.806671\n",
      "[200]\tvalid_0's binary_logloss: 0.31122\tvalid_0's auc: 0.808981\n",
      "[300]\tvalid_0's binary_logloss: 0.276175\tvalid_0's auc: 0.810258\n",
      "[400]\tvalid_0's binary_logloss: 0.263764\tvalid_0's auc: 0.81112\n",
      "[500]\tvalid_0's binary_logloss: 0.24938\tvalid_0's auc: 0.811258\n",
      "[600]\tvalid_0's binary_logloss: 0.243171\tvalid_0's auc: 0.811736\n",
      "[700]\tvalid_0's binary_logloss: 0.240089\tvalid_0's auc: 0.811923\n",
      "[800]\tvalid_0's binary_logloss: 0.238819\tvalid_0's auc: 0.812067\n",
      "[900]\tvalid_0's binary_logloss: 0.235125\tvalid_0's auc: 0.812416\n",
      "[1000]\tvalid_0's binary_logloss: 0.234598\tvalid_0's auc: 0.812522\n",
      "[1100]\tvalid_0's binary_logloss: 0.232605\tvalid_0's auc: 0.812696\n",
      "[1200]\tvalid_0's binary_logloss: 0.231185\tvalid_0's auc: 0.812872\n",
      "[1300]\tvalid_0's binary_logloss: 0.230331\tvalid_0's auc: 0.813113\n",
      "[1400]\tvalid_0's binary_logloss: 0.230019\tvalid_0's auc: 0.81324\n",
      "[1500]\tvalid_0's binary_logloss: 0.230068\tvalid_0's auc: 0.813279\n",
      "Early stopping, best iteration is:\n",
      "[1404]\tvalid_0's binary_logloss: 0.229911\tvalid_0's auc: 0.813249\n",
      "cv score - on train:\n",
      "0.8104329385240773\n",
      "('current score in fold:', 0.8083118509843128, 7)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.379302\tvalid_0's auc: 0.803602\n",
      "[200]\tvalid_0's binary_logloss: 0.302201\tvalid_0's auc: 0.80484\n",
      "[300]\tvalid_0's binary_logloss: 0.269512\tvalid_0's auc: 0.806714\n",
      "[400]\tvalid_0's binary_logloss: 0.259461\tvalid_0's auc: 0.806975\n",
      "[500]\tvalid_0's binary_logloss: 0.248286\tvalid_0's auc: 0.807425\n",
      "[600]\tvalid_0's binary_logloss: 0.242857\tvalid_0's auc: 0.807619\n",
      "[700]\tvalid_0's binary_logloss: 0.240546\tvalid_0's auc: 0.807668\n",
      "[800]\tvalid_0's binary_logloss: 0.236285\tvalid_0's auc: 0.807833\n",
      "[900]\tvalid_0's binary_logloss: 0.235071\tvalid_0's auc: 0.807912\n",
      "[1000]\tvalid_0's binary_logloss: 0.234802\tvalid_0's auc: 0.807987\n",
      "[1100]\tvalid_0's binary_logloss: 0.233286\tvalid_0's auc: 0.808072\n",
      "[1200]\tvalid_0's binary_logloss: 0.232929\tvalid_0's auc: 0.808202\n",
      "[1300]\tvalid_0's binary_logloss: 0.232927\tvalid_0's auc: 0.808272\n",
      "Early stopping, best iteration is:\n",
      "[1212]\tvalid_0's binary_logloss: 0.232721\tvalid_0's auc: 0.808204\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.379077\tvalid_0's auc: 0.803625\n",
      "[200]\tvalid_0's binary_logloss: 0.301853\tvalid_0's auc: 0.804889\n",
      "[300]\tvalid_0's binary_logloss: 0.26911\tvalid_0's auc: 0.807254\n",
      "[400]\tvalid_0's binary_logloss: 0.259044\tvalid_0's auc: 0.807801\n",
      "[500]\tvalid_0's binary_logloss: 0.247879\tvalid_0's auc: 0.807866\n",
      "[600]\tvalid_0's binary_logloss: 0.242466\tvalid_0's auc: 0.8081\n",
      "[700]\tvalid_0's binary_logloss: 0.240164\tvalid_0's auc: 0.808352\n",
      "[800]\tvalid_0's binary_logloss: 0.235928\tvalid_0's auc: 0.808512\n",
      "[900]\tvalid_0's binary_logloss: 0.234695\tvalid_0's auc: 0.808719\n",
      "[1000]\tvalid_0's binary_logloss: 0.234413\tvalid_0's auc: 0.808824\n",
      "[1100]\tvalid_0's binary_logloss: 0.232874\tvalid_0's auc: 0.808983\n",
      "[1200]\tvalid_0's binary_logloss: 0.232504\tvalid_0's auc: 0.809214\n",
      "[1300]\tvalid_0's binary_logloss: 0.232502\tvalid_0's auc: 0.80931\n",
      "Early stopping, best iteration is:\n",
      "[1212]\tvalid_0's binary_logloss: 0.232298\tvalid_0's auc: 0.809223\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.379387\tvalid_0's auc: 0.799999\n",
      "[200]\tvalid_0's binary_logloss: 0.302421\tvalid_0's auc: 0.803747\n",
      "[300]\tvalid_0's binary_logloss: 0.269889\tvalid_0's auc: 0.804398\n",
      "[400]\tvalid_0's binary_logloss: 0.259905\tvalid_0's auc: 0.8045\n",
      "[500]\tvalid_0's binary_logloss: 0.248867\tvalid_0's auc: 0.804815\n",
      "[600]\tvalid_0's binary_logloss: 0.243533\tvalid_0's auc: 0.805236\n",
      "[700]\tvalid_0's binary_logloss: 0.241256\tvalid_0's auc: 0.805392\n",
      "[800]\tvalid_0's binary_logloss: 0.23712\tvalid_0's auc: 0.805574\n",
      "[900]\tvalid_0's binary_logloss: 0.235928\tvalid_0's auc: 0.805741\n",
      "[1000]\tvalid_0's binary_logloss: 0.235647\tvalid_0's auc: 0.805848\n",
      "[1100]\tvalid_0's binary_logloss: 0.234192\tvalid_0's auc: 0.806079\n",
      "[1200]\tvalid_0's binary_logloss: 0.233833\tvalid_0's auc: 0.806174\n",
      "[1300]\tvalid_0's binary_logloss: 0.233828\tvalid_0's auc: 0.806226\n",
      "Early stopping, best iteration is:\n",
      "[1212]\tvalid_0's binary_logloss: 0.233636\tvalid_0's auc: 0.806173\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.378869\tvalid_0's auc: 0.805724\n",
      "[200]\tvalid_0's binary_logloss: 0.301531\tvalid_0's auc: 0.809713\n",
      "[300]\tvalid_0's binary_logloss: 0.26867\tvalid_0's auc: 0.810692\n",
      "[400]\tvalid_0's binary_logloss: 0.258545\tvalid_0's auc: 0.81153\n",
      "[500]\tvalid_0's binary_logloss: 0.247278\tvalid_0's auc: 0.812059\n",
      "[600]\tvalid_0's binary_logloss: 0.241797\tvalid_0's auc: 0.81223\n",
      "[700]\tvalid_0's binary_logloss: 0.239455\tvalid_0's auc: 0.812403\n",
      "[800]\tvalid_0's binary_logloss: 0.235131\tvalid_0's auc: 0.812529\n",
      "[900]\tvalid_0's binary_logloss: 0.233848\tvalid_0's auc: 0.81268\n",
      "[1000]\tvalid_0's binary_logloss: 0.233534\tvalid_0's auc: 0.81276\n",
      "[1100]\tvalid_0's binary_logloss: 0.231966\tvalid_0's auc: 0.812903\n",
      "[1200]\tvalid_0's binary_logloss: 0.23157\tvalid_0's auc: 0.813034\n",
      "[1300]\tvalid_0's binary_logloss: 0.231564\tvalid_0's auc: 0.813144\n",
      "Early stopping, best iteration is:\n",
      "[1212]\tvalid_0's binary_logloss: 0.23135\tvalid_0's auc: 0.813059\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.378683\tvalid_0's auc: 0.808975\n",
      "[200]\tvalid_0's binary_logloss: 0.301259\tvalid_0's auc: 0.812163\n",
      "[300]\tvalid_0's binary_logloss: 0.268295\tvalid_0's auc: 0.812707\n",
      "[400]\tvalid_0's binary_logloss: 0.258127\tvalid_0's auc: 0.812911\n",
      "Early stopping, best iteration is:\n",
      "[351]\tvalid_0's binary_logloss: 0.260551\tvalid_0's auc: 0.813006\n",
      "cv score - on train:\n",
      "0.7947093041055542\n",
      "('current score in fold:', 0.8081595153822883, 8)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.384564\tvalid_0's auc: 0.807869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's binary_logloss: 0.317664\tvalid_0's auc: 0.809305\n",
      "[300]\tvalid_0's binary_logloss: 0.285649\tvalid_0's auc: 0.810044\n",
      "[400]\tvalid_0's binary_logloss: 0.269152\tvalid_0's auc: 0.811283\n",
      "[500]\tvalid_0's binary_logloss: 0.255287\tvalid_0's auc: 0.811764\n",
      "[600]\tvalid_0's binary_logloss: 0.250121\tvalid_0's auc: 0.812125\n",
      "[700]\tvalid_0's binary_logloss: 0.244302\tvalid_0's auc: 0.812222\n",
      "[800]\tvalid_0's binary_logloss: 0.238936\tvalid_0's auc: 0.812911\n",
      "[900]\tvalid_0's binary_logloss: 0.235627\tvalid_0's auc: 0.81312\n",
      "[1000]\tvalid_0's binary_logloss: 0.234306\tvalid_0's auc: 0.813276\n",
      "[1100]\tvalid_0's binary_logloss: 0.232687\tvalid_0's auc: 0.813547\n",
      "[1200]\tvalid_0's binary_logloss: 0.232393\tvalid_0's auc: 0.813649\n",
      "[1300]\tvalid_0's binary_logloss: 0.231579\tvalid_0's auc: 0.813831\n",
      "Early stopping, best iteration is:\n",
      "[1248]\tvalid_0's binary_logloss: 0.231436\tvalid_0's auc: 0.813733\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.384041\tvalid_0's auc: 0.808047\n",
      "[200]\tvalid_0's binary_logloss: 0.31707\tvalid_0's auc: 0.810503\n",
      "[300]\tvalid_0's binary_logloss: 0.285058\tvalid_0's auc: 0.812196\n",
      "[400]\tvalid_0's binary_logloss: 0.268556\tvalid_0's auc: 0.812994\n",
      "[500]\tvalid_0's binary_logloss: 0.254676\tvalid_0's auc: 0.813197\n",
      "[600]\tvalid_0's binary_logloss: 0.249503\tvalid_0's auc: 0.813607\n",
      "[700]\tvalid_0's binary_logloss: 0.243701\tvalid_0's auc: 0.813643\n",
      "[800]\tvalid_0's binary_logloss: 0.238376\tvalid_0's auc: 0.813716\n",
      "[900]\tvalid_0's binary_logloss: 0.23509\tvalid_0's auc: 0.813902\n",
      "[1000]\tvalid_0's binary_logloss: 0.233787\tvalid_0's auc: 0.813984\n",
      "[1100]\tvalid_0's binary_logloss: 0.232212\tvalid_0's auc: 0.814148\n",
      "[1200]\tvalid_0's binary_logloss: 0.231907\tvalid_0's auc: 0.814272\n",
      "[1300]\tvalid_0's binary_logloss: 0.231109\tvalid_0's auc: 0.814511\n",
      "Early stopping, best iteration is:\n",
      "[1248]\tvalid_0's binary_logloss: 0.230969\tvalid_0's auc: 0.814454\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.384522\tvalid_0's auc: 0.802338\n",
      "[200]\tvalid_0's binary_logloss: 0.317698\tvalid_0's auc: 0.804652\n",
      "[300]\tvalid_0's binary_logloss: 0.285845\tvalid_0's auc: 0.806971\n",
      "[400]\tvalid_0's binary_logloss: 0.269435\tvalid_0's auc: 0.807716\n",
      "[500]\tvalid_0's binary_logloss: 0.25565\tvalid_0's auc: 0.807924\n",
      "[600]\tvalid_0's binary_logloss: 0.250546\tvalid_0's auc: 0.808247\n",
      "[700]\tvalid_0's binary_logloss: 0.244824\tvalid_0's auc: 0.808334\n",
      "[800]\tvalid_0's binary_logloss: 0.239568\tvalid_0's auc: 0.808562\n",
      "[900]\tvalid_0's binary_logloss: 0.236351\tvalid_0's auc: 0.808848\n",
      "[1000]\tvalid_0's binary_logloss: 0.235076\tvalid_0's auc: 0.808942\n",
      "[1100]\tvalid_0's binary_logloss: 0.23354\tvalid_0's auc: 0.809122\n",
      "[1200]\tvalid_0's binary_logloss: 0.23327\tvalid_0's auc: 0.809247\n",
      "[1300]\tvalid_0's binary_logloss: 0.232498\tvalid_0's auc: 0.809362\n",
      "Early stopping, best iteration is:\n",
      "[1248]\tvalid_0's binary_logloss: 0.232361\tvalid_0's auc: 0.809329\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.38507\tvalid_0's auc: 0.799755\n",
      "[200]\tvalid_0's binary_logloss: 0.318445\tvalid_0's auc: 0.801897\n",
      "[300]\tvalid_0's binary_logloss: 0.286698\tvalid_0's auc: 0.802767\n",
      "[400]\tvalid_0's binary_logloss: 0.270382\tvalid_0's auc: 0.804451\n",
      "[500]\tvalid_0's binary_logloss: 0.25672\tvalid_0's auc: 0.804563\n",
      "[600]\tvalid_0's binary_logloss: 0.25166\tvalid_0's auc: 0.805084\n",
      "[700]\tvalid_0's binary_logloss: 0.245993\tvalid_0's auc: 0.805294\n",
      "[800]\tvalid_0's binary_logloss: 0.24083\tvalid_0's auc: 0.805398\n",
      "[900]\tvalid_0's binary_logloss: 0.23769\tvalid_0's auc: 0.805708\n",
      "[1000]\tvalid_0's binary_logloss: 0.236459\tvalid_0's auc: 0.805817\n",
      "[1100]\tvalid_0's binary_logloss: 0.234976\tvalid_0's auc: 0.806108\n",
      "[1200]\tvalid_0's binary_logloss: 0.234698\tvalid_0's auc: 0.806187\n",
      "[1300]\tvalid_0's binary_logloss: 0.233963\tvalid_0's auc: 0.806271\n",
      "Early stopping, best iteration is:\n",
      "[1248]\tvalid_0's binary_logloss: 0.233826\tvalid_0's auc: 0.806243\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.384568\tvalid_0's auc: 0.801139\n",
      "[200]\tvalid_0's binary_logloss: 0.317763\tvalid_0's auc: 0.803889\n",
      "[300]\tvalid_0's binary_logloss: 0.285884\tvalid_0's auc: 0.804791\n",
      "[400]\tvalid_0's binary_logloss: 0.269507\tvalid_0's auc: 0.80571\n",
      "[500]\tvalid_0's binary_logloss: 0.255783\tvalid_0's auc: 0.805827\n",
      "[600]\tvalid_0's binary_logloss: 0.25073\tvalid_0's auc: 0.805974\n",
      "[700]\tvalid_0's binary_logloss: 0.24506\tvalid_0's auc: 0.806108\n",
      "[800]\tvalid_0's binary_logloss: 0.239854\tvalid_0's auc: 0.806273\n",
      "[900]\tvalid_0's binary_logloss: 0.2367\tvalid_0's auc: 0.806628\n",
      "[1000]\tvalid_0's binary_logloss: 0.235464\tvalid_0's auc: 0.806775\n",
      "[1100]\tvalid_0's binary_logloss: 0.233979\tvalid_0's auc: 0.806938\n",
      "[1200]\tvalid_0's binary_logloss: 0.233723\tvalid_0's auc: 0.807069\n",
      "[1300]\tvalid_0's binary_logloss: 0.232986\tvalid_0's auc: 0.807125\n",
      "Early stopping, best iteration is:\n",
      "[1248]\tvalid_0's binary_logloss: 0.232847\tvalid_0's auc: 0.807098\n",
      "cv score - on train:\n",
      "0.8098990459090402\n",
      "('current score in fold:', 0.8084926020315304, 9)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.374007\tvalid_0's auc: 0.802015\n",
      "[200]\tvalid_0's binary_logloss: 0.310056\tvalid_0's auc: 0.803617\n",
      "[300]\tvalid_0's binary_logloss: 0.281161\tvalid_0's auc: 0.803826\n",
      "[400]\tvalid_0's binary_logloss: 0.25844\tvalid_0's auc: 0.805375\n",
      "[500]\tvalid_0's binary_logloss: 0.250318\tvalid_0's auc: 0.805582\n",
      "[600]\tvalid_0's binary_logloss: 0.24358\tvalid_0's auc: 0.806402\n",
      "[700]\tvalid_0's binary_logloss: 0.240989\tvalid_0's auc: 0.806619\n",
      "[800]\tvalid_0's binary_logloss: 0.238735\tvalid_0's auc: 0.806738\n",
      "[900]\tvalid_0's binary_logloss: 0.236131\tvalid_0's auc: 0.806888\n",
      "[1000]\tvalid_0's binary_logloss: 0.235202\tvalid_0's auc: 0.807123\n",
      "[1100]\tvalid_0's binary_logloss: 0.233796\tvalid_0's auc: 0.807241\n",
      "[1200]\tvalid_0's binary_logloss: 0.233057\tvalid_0's auc: 0.807421\n",
      "[1300]\tvalid_0's binary_logloss: 0.232642\tvalid_0's auc: 0.80756\n",
      "[1400]\tvalid_0's binary_logloss: 0.232277\tvalid_0's auc: 0.807651\n",
      "[1500]\tvalid_0's binary_logloss: 0.231898\tvalid_0's auc: 0.807825\n",
      "[1600]\tvalid_0's binary_logloss: 0.231493\tvalid_0's auc: 0.807912\n",
      "[1700]\tvalid_0's binary_logloss: 0.23133\tvalid_0's auc: 0.807985\n",
      "[1800]\tvalid_0's binary_logloss: 0.231167\tvalid_0's auc: 0.808083\n",
      "[1900]\tvalid_0's binary_logloss: 0.230956\tvalid_0's auc: 0.8082\n",
      "Early stopping, best iteration is:\n",
      "[1856]\tvalid_0's binary_logloss: 0.230862\tvalid_0's auc: 0.808163\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.373657\tvalid_0's auc: 0.80129\n",
      "[200]\tvalid_0's binary_logloss: 0.30967\tvalid_0's auc: 0.804342\n",
      "[300]\tvalid_0's binary_logloss: 0.280743\tvalid_0's auc: 0.805992\n",
      "[400]\tvalid_0's binary_logloss: 0.258029\tvalid_0's auc: 0.806916\n",
      "[500]\tvalid_0's binary_logloss: 0.249866\tvalid_0's auc: 0.807168\n",
      "[600]\tvalid_0's binary_logloss: 0.243142\tvalid_0's auc: 0.807283\n",
      "[700]\tvalid_0's binary_logloss: 0.240549\tvalid_0's auc: 0.80736\n",
      "[800]\tvalid_0's binary_logloss: 0.238295\tvalid_0's auc: 0.807385\n",
      "[900]\tvalid_0's binary_logloss: 0.235684\tvalid_0's auc: 0.807456\n",
      "[1000]\tvalid_0's binary_logloss: 0.234764\tvalid_0's auc: 0.8075\n",
      "[1100]\tvalid_0's binary_logloss: 0.233369\tvalid_0's auc: 0.807775\n",
      "[1200]\tvalid_0's binary_logloss: 0.232635\tvalid_0's auc: 0.808109\n",
      "[1300]\tvalid_0's binary_logloss: 0.23223\tvalid_0's auc: 0.808207\n",
      "[1400]\tvalid_0's binary_logloss: 0.231846\tvalid_0's auc: 0.808338\n",
      "[1500]\tvalid_0's binary_logloss: 0.231465\tvalid_0's auc: 0.80847\n",
      "[1600]\tvalid_0's binary_logloss: 0.231053\tvalid_0's auc: 0.808606\n",
      "[1700]\tvalid_0's binary_logloss: 0.230898\tvalid_0's auc: 0.808682\n",
      "[1800]\tvalid_0's binary_logloss: 0.230735\tvalid_0's auc: 0.808774\n",
      "[1900]\tvalid_0's binary_logloss: 0.230537\tvalid_0's auc: 0.808838\n",
      "Early stopping, best iteration is:\n",
      "[1856]\tvalid_0's binary_logloss: 0.230448\tvalid_0's auc: 0.808807\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.373874\tvalid_0's auc: 0.804719\n",
      "[200]\tvalid_0's binary_logloss: 0.309821\tvalid_0's auc: 0.80812\n",
      "[300]\tvalid_0's binary_logloss: 0.280813\tvalid_0's auc: 0.808468\n",
      "[400]\tvalid_0's binary_logloss: 0.257975\tvalid_0's auc: 0.808852\n",
      "[500]\tvalid_0's binary_logloss: 0.2498\tvalid_0's auc: 0.808944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[600]\tvalid_0's binary_logloss: 0.243013\tvalid_0's auc: 0.809312\n",
      "[700]\tvalid_0's binary_logloss: 0.240384\tvalid_0's auc: 0.809429\n",
      "[800]\tvalid_0's binary_logloss: 0.238106\tvalid_0's auc: 0.809566\n",
      "[900]\tvalid_0's binary_logloss: 0.235457\tvalid_0's auc: 0.809687\n",
      "[1000]\tvalid_0's binary_logloss: 0.234507\tvalid_0's auc: 0.809939\n",
      "[1100]\tvalid_0's binary_logloss: 0.233096\tvalid_0's auc: 0.810175\n",
      "[1200]\tvalid_0's binary_logloss: 0.232346\tvalid_0's auc: 0.810292\n",
      "[1300]\tvalid_0's binary_logloss: 0.231935\tvalid_0's auc: 0.810365\n",
      "[1400]\tvalid_0's binary_logloss: 0.231564\tvalid_0's auc: 0.810475\n",
      "[1500]\tvalid_0's binary_logloss: 0.231187\tvalid_0's auc: 0.810583\n",
      "[1600]\tvalid_0's binary_logloss: 0.230755\tvalid_0's auc: 0.810692\n",
      "[1700]\tvalid_0's binary_logloss: 0.230598\tvalid_0's auc: 0.810748\n",
      "[1800]\tvalid_0's binary_logloss: 0.230441\tvalid_0's auc: 0.810834\n",
      "[1900]\tvalid_0's binary_logloss: 0.230223\tvalid_0's auc: 0.81094\n",
      "Early stopping, best iteration is:\n",
      "[1856]\tvalid_0's binary_logloss: 0.230118\tvalid_0's auc: 0.810927\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.373637\tvalid_0's auc: 0.807272\n",
      "[200]\tvalid_0's binary_logloss: 0.309466\tvalid_0's auc: 0.808611\n",
      "[300]\tvalid_0's binary_logloss: 0.280361\tvalid_0's auc: 0.810963\n",
      "[400]\tvalid_0's binary_logloss: 0.257433\tvalid_0's auc: 0.811092\n",
      "[500]\tvalid_0's binary_logloss: 0.2492\tvalid_0's auc: 0.811564\n",
      "[600]\tvalid_0's binary_logloss: 0.242359\tvalid_0's auc: 0.811878\n",
      "[700]\tvalid_0's binary_logloss: 0.239719\tvalid_0's auc: 0.812107\n",
      "[800]\tvalid_0's binary_logloss: 0.237417\tvalid_0's auc: 0.812314\n",
      "[900]\tvalid_0's binary_logloss: 0.234735\tvalid_0's auc: 0.812422\n",
      "[1000]\tvalid_0's binary_logloss: 0.233779\tvalid_0's auc: 0.812658\n",
      "[1100]\tvalid_0's binary_logloss: 0.232318\tvalid_0's auc: 0.812851\n",
      "[1200]\tvalid_0's binary_logloss: 0.231556\tvalid_0's auc: 0.813026\n",
      "[1300]\tvalid_0's binary_logloss: 0.231124\tvalid_0's auc: 0.813119\n",
      "[1400]\tvalid_0's binary_logloss: 0.230734\tvalid_0's auc: 0.813209\n",
      "[1500]\tvalid_0's binary_logloss: 0.230338\tvalid_0's auc: 0.813288\n",
      "[1600]\tvalid_0's binary_logloss: 0.229901\tvalid_0's auc: 0.813396\n",
      "[1700]\tvalid_0's binary_logloss: 0.229723\tvalid_0's auc: 0.813462\n",
      "[1800]\tvalid_0's binary_logloss: 0.229555\tvalid_0's auc: 0.81353\n",
      "[1900]\tvalid_0's binary_logloss: 0.229333\tvalid_0's auc: 0.813609\n",
      "Early stopping, best iteration is:\n",
      "[1856]\tvalid_0's binary_logloss: 0.229226\tvalid_0's auc: 0.813593\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.373758\tvalid_0's auc: 0.80618\n",
      "[200]\tvalid_0's binary_logloss: 0.309668\tvalid_0's auc: 0.807969\n",
      "[300]\tvalid_0's binary_logloss: 0.28064\tvalid_0's auc: 0.809661\n",
      "[400]\tvalid_0's binary_logloss: 0.257837\tvalid_0's auc: 0.810175\n",
      "[500]\tvalid_0's binary_logloss: 0.249622\tvalid_0's auc: 0.810438\n",
      "[600]\tvalid_0's binary_logloss: 0.242807\tvalid_0's auc: 0.81102\n",
      "[700]\tvalid_0's binary_logloss: 0.240169\tvalid_0's auc: 0.811106\n",
      "[800]\tvalid_0's binary_logloss: 0.237877\tvalid_0's auc: 0.811284\n",
      "[900]\tvalid_0's binary_logloss: 0.235217\tvalid_0's auc: 0.811374\n",
      "[1000]\tvalid_0's binary_logloss: 0.234252\tvalid_0's auc: 0.811467\n",
      "[1100]\tvalid_0's binary_logloss: 0.232821\tvalid_0's auc: 0.811654\n",
      "[1200]\tvalid_0's binary_logloss: 0.232073\tvalid_0's auc: 0.811747\n",
      "[1300]\tvalid_0's binary_logloss: 0.231642\tvalid_0's auc: 0.811919\n",
      "[1400]\tvalid_0's binary_logloss: 0.231258\tvalid_0's auc: 0.812028\n",
      "[1500]\tvalid_0's binary_logloss: 0.23086\tvalid_0's auc: 0.812121\n",
      "[1600]\tvalid_0's binary_logloss: 0.230425\tvalid_0's auc: 0.812236\n",
      "[1700]\tvalid_0's binary_logloss: 0.230283\tvalid_0's auc: 0.812278\n",
      "[1800]\tvalid_0's binary_logloss: 0.230112\tvalid_0's auc: 0.812333\n",
      "[1900]\tvalid_0's binary_logloss: 0.229891\tvalid_0's auc: 0.812409\n",
      "Early stopping, best iteration is:\n",
      "[1856]\tvalid_0's binary_logloss: 0.229793\tvalid_0's auc: 0.81239\n",
      "cv score - on train:\n",
      "0.8106626515505313\n",
      "('current score in fold:', 0.808815643836821, 10)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.38488\tvalid_0's auc: 0.806143\n",
      "[200]\tvalid_0's binary_logloss: 0.326748\tvalid_0's auc: 0.808572\n",
      "[300]\tvalid_0's binary_logloss: 0.288336\tvalid_0's auc: 0.810909\n",
      "[400]\tvalid_0's binary_logloss: 0.271269\tvalid_0's auc: 0.811112\n",
      "[500]\tvalid_0's binary_logloss: 0.25524\tvalid_0's auc: 0.81137\n",
      "[600]\tvalid_0's binary_logloss: 0.246002\tvalid_0's auc: 0.811677\n",
      "[700]\tvalid_0's binary_logloss: 0.240342\tvalid_0's auc: 0.81186\n",
      "[800]\tvalid_0's binary_logloss: 0.237803\tvalid_0's auc: 0.811905\n",
      "[900]\tvalid_0's binary_logloss: 0.235497\tvalid_0's auc: 0.812054\n",
      "[1000]\tvalid_0's binary_logloss: 0.23396\tvalid_0's auc: 0.812217\n",
      "[1100]\tvalid_0's binary_logloss: 0.232648\tvalid_0's auc: 0.812367\n",
      "[1200]\tvalid_0's binary_logloss: 0.232652\tvalid_0's auc: 0.812486\n",
      "[1300]\tvalid_0's binary_logloss: 0.231706\tvalid_0's auc: 0.812589\n",
      "[1400]\tvalid_0's binary_logloss: 0.231836\tvalid_0's auc: 0.812696\n",
      "Early stopping, best iteration is:\n",
      "[1342]\tvalid_0's binary_logloss: 0.231336\tvalid_0's auc: 0.812704\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.385075\tvalid_0's auc: 0.806547\n",
      "[200]\tvalid_0's binary_logloss: 0.326975\tvalid_0's auc: 0.809442\n",
      "[300]\tvalid_0's binary_logloss: 0.288483\tvalid_0's auc: 0.810284\n",
      "[400]\tvalid_0's binary_logloss: 0.271394\tvalid_0's auc: 0.811204\n",
      "[500]\tvalid_0's binary_logloss: 0.255316\tvalid_0's auc: 0.811497\n",
      "[600]\tvalid_0's binary_logloss: 0.246015\tvalid_0's auc: 0.812076\n",
      "[700]\tvalid_0's binary_logloss: 0.240317\tvalid_0's auc: 0.812741\n",
      "[800]\tvalid_0's binary_logloss: 0.237761\tvalid_0's auc: 0.812843\n",
      "[900]\tvalid_0's binary_logloss: 0.235424\tvalid_0's auc: 0.812977\n",
      "[1000]\tvalid_0's binary_logloss: 0.233867\tvalid_0's auc: 0.813071\n",
      "[1100]\tvalid_0's binary_logloss: 0.232528\tvalid_0's auc: 0.813322\n",
      "[1200]\tvalid_0's binary_logloss: 0.232534\tvalid_0's auc: 0.81341\n",
      "[1300]\tvalid_0's binary_logloss: 0.231571\tvalid_0's auc: 0.813492\n",
      "[1400]\tvalid_0's binary_logloss: 0.2317\tvalid_0's auc: 0.813554\n",
      "Early stopping, best iteration is:\n",
      "[1342]\tvalid_0's binary_logloss: 0.231198\tvalid_0's auc: 0.813518\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.38548\tvalid_0's auc: 0.802242\n",
      "[200]\tvalid_0's binary_logloss: 0.327609\tvalid_0's auc: 0.80474\n",
      "[300]\tvalid_0's binary_logloss: 0.289378\tvalid_0's auc: 0.805367\n",
      "[400]\tvalid_0's binary_logloss: 0.272462\tvalid_0's auc: 0.805695\n",
      "[500]\tvalid_0's binary_logloss: 0.25657\tvalid_0's auc: 0.805825\n",
      "[600]\tvalid_0's binary_logloss: 0.247424\tvalid_0's auc: 0.806237\n",
      "[700]\tvalid_0's binary_logloss: 0.241862\tvalid_0's auc: 0.806457\n",
      "[800]\tvalid_0's binary_logloss: 0.239381\tvalid_0's auc: 0.806636\n",
      "[900]\tvalid_0's binary_logloss: 0.237126\tvalid_0's auc: 0.806724\n",
      "[1000]\tvalid_0's binary_logloss: 0.235631\tvalid_0's auc: 0.806852\n",
      "[1100]\tvalid_0's binary_logloss: 0.234368\tvalid_0's auc: 0.807012\n",
      "[1200]\tvalid_0's binary_logloss: 0.234376\tvalid_0's auc: 0.807107\n",
      "[1300]\tvalid_0's binary_logloss: 0.233473\tvalid_0's auc: 0.807342\n",
      "[1400]\tvalid_0's binary_logloss: 0.233602\tvalid_0's auc: 0.807443\n",
      "Early stopping, best iteration is:\n",
      "[1342]\tvalid_0's binary_logloss: 0.233126\tvalid_0's auc: 0.807408\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.384999\tvalid_0's auc: 0.80388\n",
      "[200]\tvalid_0's binary_logloss: 0.327018\tvalid_0's auc: 0.805093\n",
      "[300]\tvalid_0's binary_logloss: 0.288709\tvalid_0's auc: 0.806249\n",
      "[400]\tvalid_0's binary_logloss: 0.271747\tvalid_0's auc: 0.807637\n",
      "[500]\tvalid_0's binary_logloss: 0.255816\tvalid_0's auc: 0.808166\n",
      "[600]\tvalid_0's binary_logloss: 0.246664\tvalid_0's auc: 0.808378\n",
      "[700]\tvalid_0's binary_logloss: 0.24109\tvalid_0's auc: 0.808384\n",
      "Early stopping, best iteration is:\n",
      "[614]\tvalid_0's binary_logloss: 0.245033\tvalid_0's auc: 0.808443\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.384945\tvalid_0's auc: 0.802751\n",
      "[200]\tvalid_0's binary_logloss: 0.326906\tvalid_0's auc: 0.805188\n",
      "[300]\tvalid_0's binary_logloss: 0.288507\tvalid_0's auc: 0.805608\n",
      "[400]\tvalid_0's binary_logloss: 0.271458\tvalid_0's auc: 0.806852\n",
      "[500]\tvalid_0's binary_logloss: 0.255468\tvalid_0's auc: 0.807018\n",
      "[600]\tvalid_0's binary_logloss: 0.246275\tvalid_0's auc: 0.807541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[700]\tvalid_0's binary_logloss: 0.240712\tvalid_0's auc: 0.807879\n",
      "[800]\tvalid_0's binary_logloss: 0.238256\tvalid_0's auc: 0.808008\n",
      "[900]\tvalid_0's binary_logloss: 0.236015\tvalid_0's auc: 0.808202\n",
      "[1000]\tvalid_0's binary_logloss: 0.234544\tvalid_0's auc: 0.808307\n",
      "[1100]\tvalid_0's binary_logloss: 0.233286\tvalid_0's auc: 0.808385\n",
      "[1200]\tvalid_0's binary_logloss: 0.233317\tvalid_0's auc: 0.808542\n",
      "[1300]\tvalid_0's binary_logloss: 0.232424\tvalid_0's auc: 0.808621\n",
      "[1400]\tvalid_0's binary_logloss: 0.232562\tvalid_0's auc: 0.808702\n",
      "Early stopping, best iteration is:\n",
      "[1342]\tvalid_0's binary_logloss: 0.23207\tvalid_0's auc: 0.808674\n",
      "cv score - on train:\n",
      "0.8054755700992036\n",
      "('current score in fold:', 0.8089682149155292, 11)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.391486\tvalid_0's auc: 0.801744\n",
      "[200]\tvalid_0's binary_logloss: 0.309635\tvalid_0's auc: 0.805853\n",
      "[300]\tvalid_0's binary_logloss: 0.283321\tvalid_0's auc: 0.807034\n",
      "[400]\tvalid_0's binary_logloss: 0.265255\tvalid_0's auc: 0.807372\n",
      "[500]\tvalid_0's binary_logloss: 0.252369\tvalid_0's auc: 0.807596\n",
      "[600]\tvalid_0's binary_logloss: 0.245634\tvalid_0's auc: 0.808163\n",
      "[700]\tvalid_0's binary_logloss: 0.241694\tvalid_0's auc: 0.808161\n",
      "[800]\tvalid_0's binary_logloss: 0.238643\tvalid_0's auc: 0.808433\n",
      "[900]\tvalid_0's binary_logloss: 0.23518\tvalid_0's auc: 0.808713\n",
      "[1000]\tvalid_0's binary_logloss: 0.233667\tvalid_0's auc: 0.808854\n",
      "[1100]\tvalid_0's binary_logloss: 0.233528\tvalid_0's auc: 0.808936\n",
      "[1200]\tvalid_0's binary_logloss: 0.232803\tvalid_0's auc: 0.809025\n",
      "[1300]\tvalid_0's binary_logloss: 0.232009\tvalid_0's auc: 0.809195\n",
      "[1400]\tvalid_0's binary_logloss: 0.231809\tvalid_0's auc: 0.809265\n",
      "[1500]\tvalid_0's binary_logloss: 0.231531\tvalid_0's auc: 0.809336\n",
      "[1600]\tvalid_0's binary_logloss: 0.231524\tvalid_0's auc: 0.809405\n",
      "Early stopping, best iteration is:\n",
      "[1571]\tvalid_0's binary_logloss: 0.231309\tvalid_0's auc: 0.809388\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.392126\tvalid_0's auc: 0.803339\n",
      "[200]\tvalid_0's binary_logloss: 0.310359\tvalid_0's auc: 0.805479\n",
      "[300]\tvalid_0's binary_logloss: 0.284005\tvalid_0's auc: 0.806943\n",
      "[400]\tvalid_0's binary_logloss: 0.265892\tvalid_0's auc: 0.808105\n",
      "[500]\tvalid_0's binary_logloss: 0.252927\tvalid_0's auc: 0.808498\n",
      "[600]\tvalid_0's binary_logloss: 0.246124\tvalid_0's auc: 0.808765\n",
      "[700]\tvalid_0's binary_logloss: 0.242127\tvalid_0's auc: 0.808965\n",
      "[800]\tvalid_0's binary_logloss: 0.239022\tvalid_0's auc: 0.809133\n",
      "[900]\tvalid_0's binary_logloss: 0.235469\tvalid_0's auc: 0.809298\n",
      "[1000]\tvalid_0's binary_logloss: 0.233924\tvalid_0's auc: 0.809425\n",
      "[1100]\tvalid_0's binary_logloss: 0.233791\tvalid_0's auc: 0.809522\n",
      "[1200]\tvalid_0's binary_logloss: 0.233032\tvalid_0's auc: 0.809653\n",
      "[1300]\tvalid_0's binary_logloss: 0.232198\tvalid_0's auc: 0.80994\n",
      "[1400]\tvalid_0's binary_logloss: 0.231995\tvalid_0's auc: 0.810034\n",
      "[1500]\tvalid_0's binary_logloss: 0.231701\tvalid_0's auc: 0.810138\n",
      "[1600]\tvalid_0's binary_logloss: 0.231694\tvalid_0's auc: 0.810201\n",
      "Early stopping, best iteration is:\n",
      "[1571]\tvalid_0's binary_logloss: 0.231456\tvalid_0's auc: 0.81022\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.391778\tvalid_0's auc: 0.804585\n",
      "[200]\tvalid_0's binary_logloss: 0.310021\tvalid_0's auc: 0.806627\n",
      "[300]\tvalid_0's binary_logloss: 0.283715\tvalid_0's auc: 0.80671\n",
      "[400]\tvalid_0's binary_logloss: 0.265651\tvalid_0's auc: 0.807566\n",
      "[500]\tvalid_0's binary_logloss: 0.252734\tvalid_0's auc: 0.807867\n",
      "[600]\tvalid_0's binary_logloss: 0.245971\tvalid_0's auc: 0.807944\n",
      "[700]\tvalid_0's binary_logloss: 0.241995\tvalid_0's auc: 0.808291\n",
      "[800]\tvalid_0's binary_logloss: 0.238891\tvalid_0's auc: 0.808577\n",
      "[900]\tvalid_0's binary_logloss: 0.235394\tvalid_0's auc: 0.808874\n",
      "[1000]\tvalid_0's binary_logloss: 0.233851\tvalid_0's auc: 0.80922\n",
      "[1100]\tvalid_0's binary_logloss: 0.233708\tvalid_0's auc: 0.809337\n",
      "[1200]\tvalid_0's binary_logloss: 0.232967\tvalid_0's auc: 0.80947\n",
      "[1300]\tvalid_0's binary_logloss: 0.23215\tvalid_0's auc: 0.809597\n",
      "[1400]\tvalid_0's binary_logloss: 0.231939\tvalid_0's auc: 0.809829\n",
      "[1500]\tvalid_0's binary_logloss: 0.231653\tvalid_0's auc: 0.809907\n",
      "[1600]\tvalid_0's binary_logloss: 0.231644\tvalid_0's auc: 0.809966\n",
      "Early stopping, best iteration is:\n",
      "[1571]\tvalid_0's binary_logloss: 0.231424\tvalid_0's auc: 0.809954\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.391947\tvalid_0's auc: 0.804555\n",
      "[200]\tvalid_0's binary_logloss: 0.310114\tvalid_0's auc: 0.808208\n",
      "[300]\tvalid_0's binary_logloss: 0.283762\tvalid_0's auc: 0.809741\n",
      "[400]\tvalid_0's binary_logloss: 0.265633\tvalid_0's auc: 0.810101\n",
      "Early stopping, best iteration is:\n",
      "[334]\tvalid_0's binary_logloss: 0.277817\tvalid_0's auc: 0.810245\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.39174\tvalid_0's auc: 0.805764\n",
      "[200]\tvalid_0's binary_logloss: 0.309977\tvalid_0's auc: 0.808132\n",
      "[300]\tvalid_0's binary_logloss: 0.283664\tvalid_0's auc: 0.808494\n",
      "[400]\tvalid_0's binary_logloss: 0.265581\tvalid_0's auc: 0.809874\n",
      "[500]\tvalid_0's binary_logloss: 0.252656\tvalid_0's auc: 0.810218\n",
      "[600]\tvalid_0's binary_logloss: 0.245856\tvalid_0's auc: 0.81047\n",
      "[700]\tvalid_0's binary_logloss: 0.241859\tvalid_0's auc: 0.810642\n",
      "[800]\tvalid_0's binary_logloss: 0.238745\tvalid_0's auc: 0.810799\n",
      "[900]\tvalid_0's binary_logloss: 0.235201\tvalid_0's auc: 0.810904\n",
      "[1000]\tvalid_0's binary_logloss: 0.233637\tvalid_0's auc: 0.811071\n",
      "[1100]\tvalid_0's binary_logloss: 0.233479\tvalid_0's auc: 0.811192\n",
      "[1200]\tvalid_0's binary_logloss: 0.232711\tvalid_0's auc: 0.811351\n",
      "[1300]\tvalid_0's binary_logloss: 0.231877\tvalid_0's auc: 0.811609\n",
      "[1400]\tvalid_0's binary_logloss: 0.231654\tvalid_0's auc: 0.811712\n",
      "[1500]\tvalid_0's binary_logloss: 0.231348\tvalid_0's auc: 0.811775\n",
      "[1600]\tvalid_0's binary_logloss: 0.231341\tvalid_0's auc: 0.811829\n",
      "Early stopping, best iteration is:\n",
      "[1571]\tvalid_0's binary_logloss: 0.231117\tvalid_0's auc: 0.811815\n",
      "cv score - on train:\n",
      "0.7877350738259302\n",
      "('current score in fold:', 0.8087724343997762, 12)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.373646\tvalid_0's auc: 0.802293\n",
      "[200]\tvalid_0's binary_logloss: 0.305154\tvalid_0's auc: 0.805829\n",
      "[300]\tvalid_0's binary_logloss: 0.281315\tvalid_0's auc: 0.806061\n",
      "[400]\tvalid_0's binary_logloss: 0.261487\tvalid_0's auc: 0.806462\n",
      "[500]\tvalid_0's binary_logloss: 0.250282\tvalid_0's auc: 0.806826\n",
      "[600]\tvalid_0's binary_logloss: 0.244334\tvalid_0's auc: 0.80713\n",
      "[700]\tvalid_0's binary_logloss: 0.23929\tvalid_0's auc: 0.807195\n",
      "[800]\tvalid_0's binary_logloss: 0.237632\tvalid_0's auc: 0.807318\n",
      "[900]\tvalid_0's binary_logloss: 0.235756\tvalid_0's auc: 0.807455\n",
      "[1000]\tvalid_0's binary_logloss: 0.234657\tvalid_0's auc: 0.807569\n",
      "[1100]\tvalid_0's binary_logloss: 0.23348\tvalid_0's auc: 0.80776\n",
      "[1200]\tvalid_0's binary_logloss: 0.232724\tvalid_0's auc: 0.8079\n",
      "[1300]\tvalid_0's binary_logloss: 0.232261\tvalid_0's auc: 0.808003\n",
      "[1400]\tvalid_0's binary_logloss: 0.231738\tvalid_0's auc: 0.808291\n",
      "[1500]\tvalid_0's binary_logloss: 0.231842\tvalid_0's auc: 0.808404\n",
      "Early stopping, best iteration is:\n",
      "[1412]\tvalid_0's binary_logloss: 0.231541\tvalid_0's auc: 0.808302\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.374124\tvalid_0's auc: 0.799295\n",
      "[200]\tvalid_0's binary_logloss: 0.305916\tvalid_0's auc: 0.803787\n",
      "[300]\tvalid_0's binary_logloss: 0.282221\tvalid_0's auc: 0.80469\n",
      "[400]\tvalid_0's binary_logloss: 0.262533\tvalid_0's auc: 0.805372\n",
      "[500]\tvalid_0's binary_logloss: 0.251411\tvalid_0's auc: 0.805792\n",
      "[600]\tvalid_0's binary_logloss: 0.245508\tvalid_0's auc: 0.806087\n",
      "[700]\tvalid_0's binary_logloss: 0.24048\tvalid_0's auc: 0.80614\n",
      "[800]\tvalid_0's binary_logloss: 0.238797\tvalid_0's auc: 0.806194\n",
      "[900]\tvalid_0's binary_logloss: 0.236921\tvalid_0's auc: 0.806226\n",
      "[1000]\tvalid_0's binary_logloss: 0.23581\tvalid_0's auc: 0.806514\n",
      "[1100]\tvalid_0's binary_logloss: 0.234623\tvalid_0's auc: 0.806638\n",
      "[1200]\tvalid_0's binary_logloss: 0.233866\tvalid_0's auc: 0.806791\n",
      "[1300]\tvalid_0's binary_logloss: 0.233376\tvalid_0's auc: 0.806881\n",
      "[1400]\tvalid_0's binary_logloss: 0.232853\tvalid_0's auc: 0.806984\n",
      "[1500]\tvalid_0's binary_logloss: 0.232948\tvalid_0's auc: 0.807042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1412]\tvalid_0's binary_logloss: 0.232661\tvalid_0's auc: 0.807008\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.373138\tvalid_0's auc: 0.810479\n",
      "[200]\tvalid_0's binary_logloss: 0.304326\tvalid_0's auc: 0.812828\n",
      "[300]\tvalid_0's binary_logloss: 0.280319\tvalid_0's auc: 0.813563\n",
      "[400]\tvalid_0's binary_logloss: 0.260266\tvalid_0's auc: 0.814301\n",
      "[500]\tvalid_0's binary_logloss: 0.248865\tvalid_0's auc: 0.814436\n",
      "[600]\tvalid_0's binary_logloss: 0.242805\tvalid_0's auc: 0.81471\n",
      "[700]\tvalid_0's binary_logloss: 0.237595\tvalid_0's auc: 0.81484\n",
      "[800]\tvalid_0's binary_logloss: 0.235849\tvalid_0's auc: 0.815007\n",
      "[900]\tvalid_0's binary_logloss: 0.233886\tvalid_0's auc: 0.815113\n",
      "[1000]\tvalid_0's binary_logloss: 0.23273\tvalid_0's auc: 0.815248\n",
      "[1100]\tvalid_0's binary_logloss: 0.231471\tvalid_0's auc: 0.815415\n",
      "[1200]\tvalid_0's binary_logloss: 0.230665\tvalid_0's auc: 0.815534\n",
      "[1300]\tvalid_0's binary_logloss: 0.230159\tvalid_0's auc: 0.815596\n",
      "[1400]\tvalid_0's binary_logloss: 0.229582\tvalid_0's auc: 0.815716\n",
      "[1500]\tvalid_0's binary_logloss: 0.229683\tvalid_0's auc: 0.815829\n",
      "Early stopping, best iteration is:\n",
      "[1412]\tvalid_0's binary_logloss: 0.229363\tvalid_0's auc: 0.815779\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.374163\tvalid_0's auc: 0.801463\n",
      "[200]\tvalid_0's binary_logloss: 0.305899\tvalid_0's auc: 0.804224\n",
      "[300]\tvalid_0's binary_logloss: 0.282177\tvalid_0's auc: 0.805267\n",
      "[400]\tvalid_0's binary_logloss: 0.262422\tvalid_0's auc: 0.80609\n",
      "[500]\tvalid_0's binary_logloss: 0.251237\tvalid_0's auc: 0.806544\n",
      "[600]\tvalid_0's binary_logloss: 0.245298\tvalid_0's auc: 0.807034\n",
      "[700]\tvalid_0's binary_logloss: 0.240221\tvalid_0's auc: 0.807197\n",
      "[800]\tvalid_0's binary_logloss: 0.238526\tvalid_0's auc: 0.807297\n",
      "[900]\tvalid_0's binary_logloss: 0.236621\tvalid_0's auc: 0.807602\n",
      "[1000]\tvalid_0's binary_logloss: 0.235493\tvalid_0's auc: 0.807732\n",
      "[1100]\tvalid_0's binary_logloss: 0.234282\tvalid_0's auc: 0.807836\n",
      "[1200]\tvalid_0's binary_logloss: 0.233511\tvalid_0's auc: 0.807972\n",
      "[1300]\tvalid_0's binary_logloss: 0.23301\tvalid_0's auc: 0.808098\n",
      "[1400]\tvalid_0's binary_logloss: 0.232474\tvalid_0's auc: 0.808219\n",
      "[1500]\tvalid_0's binary_logloss: 0.232575\tvalid_0's auc: 0.80829\n",
      "Early stopping, best iteration is:\n",
      "[1412]\tvalid_0's binary_logloss: 0.232273\tvalid_0's auc: 0.808248\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.373212\tvalid_0's auc: 0.808325\n",
      "[200]\tvalid_0's binary_logloss: 0.304595\tvalid_0's auc: 0.809325\n",
      "[300]\tvalid_0's binary_logloss: 0.280656\tvalid_0's auc: 0.810876\n",
      "[400]\tvalid_0's binary_logloss: 0.260714\tvalid_0's auc: 0.81166\n",
      "[500]\tvalid_0's binary_logloss: 0.249403\tvalid_0's auc: 0.811976\n",
      "[600]\tvalid_0's binary_logloss: 0.243385\tvalid_0's auc: 0.812259\n",
      "[700]\tvalid_0's binary_logloss: 0.238242\tvalid_0's auc: 0.812448\n",
      "[800]\tvalid_0's binary_logloss: 0.23652\tvalid_0's auc: 0.812554\n",
      "[900]\tvalid_0's binary_logloss: 0.23459\tvalid_0's auc: 0.812721\n",
      "[1000]\tvalid_0's binary_logloss: 0.233455\tvalid_0's auc: 0.812829\n",
      "[1100]\tvalid_0's binary_logloss: 0.232228\tvalid_0's auc: 0.812957\n",
      "[1200]\tvalid_0's binary_logloss: 0.231453\tvalid_0's auc: 0.813162\n",
      "[1300]\tvalid_0's binary_logloss: 0.230952\tvalid_0's auc: 0.813254\n",
      "[1400]\tvalid_0's binary_logloss: 0.230411\tvalid_0's auc: 0.81332\n",
      "[1500]\tvalid_0's binary_logloss: 0.230514\tvalid_0's auc: 0.813368\n",
      "Early stopping, best iteration is:\n",
      "[1412]\tvalid_0's binary_logloss: 0.2302\tvalid_0's auc: 0.813335\n",
      "cv score - on train:\n",
      "0.8102617486139418\n",
      "('current score in fold:', 0.808962055757473, 13)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.386296\tvalid_0's auc: 0.801501\n",
      "[200]\tvalid_0's binary_logloss: 0.322488\tvalid_0's auc: 0.804212\n",
      "[300]\tvalid_0's binary_logloss: 0.285815\tvalid_0's auc: 0.806081\n",
      "[400]\tvalid_0's binary_logloss: 0.262764\tvalid_0's auc: 0.806972\n",
      "[500]\tvalid_0's binary_logloss: 0.248921\tvalid_0's auc: 0.807352\n",
      "[600]\tvalid_0's binary_logloss: 0.243448\tvalid_0's auc: 0.807812\n",
      "[700]\tvalid_0's binary_logloss: 0.240612\tvalid_0's auc: 0.808023\n",
      "[800]\tvalid_0's binary_logloss: 0.237511\tvalid_0's auc: 0.808073\n",
      "[900]\tvalid_0's binary_logloss: 0.235799\tvalid_0's auc: 0.808197\n",
      "[1000]\tvalid_0's binary_logloss: 0.235176\tvalid_0's auc: 0.808315\n",
      "[1100]\tvalid_0's binary_logloss: 0.2338\tvalid_0's auc: 0.808527\n",
      "[1200]\tvalid_0's binary_logloss: 0.23378\tvalid_0's auc: 0.808668\n",
      "[1300]\tvalid_0's binary_logloss: 0.233522\tvalid_0's auc: 0.808733\n",
      "[1400]\tvalid_0's binary_logloss: 0.232466\tvalid_0's auc: 0.808823\n",
      "[1500]\tvalid_0's binary_logloss: 0.232206\tvalid_0's auc: 0.808929\n",
      "[1600]\tvalid_0's binary_logloss: 0.231886\tvalid_0's auc: 0.809023\n",
      "[1700]\tvalid_0's binary_logloss: 0.231663\tvalid_0's auc: 0.809103\n",
      "[1800]\tvalid_0's binary_logloss: 0.231363\tvalid_0's auc: 0.809149\n",
      "[1900]\tvalid_0's binary_logloss: 0.231074\tvalid_0's auc: 0.809209\n",
      "[2000]\tvalid_0's binary_logloss: 0.231167\tvalid_0's auc: 0.809259\n",
      "Early stopping, best iteration is:\n",
      "[1903]\tvalid_0's binary_logloss: 0.231057\tvalid_0's auc: 0.809218\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.385626\tvalid_0's auc: 0.808225\n",
      "[200]\tvalid_0's binary_logloss: 0.321518\tvalid_0's auc: 0.81062\n",
      "[300]\tvalid_0's binary_logloss: 0.284577\tvalid_0's auc: 0.811299\n",
      "[400]\tvalid_0's binary_logloss: 0.261273\tvalid_0's auc: 0.812199\n",
      "[500]\tvalid_0's binary_logloss: 0.247276\tvalid_0's auc: 0.812499\n",
      "[600]\tvalid_0's binary_logloss: 0.241727\tvalid_0's auc: 0.812769\n",
      "[700]\tvalid_0's binary_logloss: 0.238849\tvalid_0's auc: 0.812802\n",
      "[800]\tvalid_0's binary_logloss: 0.235633\tvalid_0's auc: 0.812989\n",
      "[900]\tvalid_0's binary_logloss: 0.233841\tvalid_0's auc: 0.813141\n",
      "[1000]\tvalid_0's binary_logloss: 0.233191\tvalid_0's auc: 0.813268\n",
      "[1100]\tvalid_0's binary_logloss: 0.231709\tvalid_0's auc: 0.813451\n",
      "[1200]\tvalid_0's binary_logloss: 0.2317\tvalid_0's auc: 0.81352\n",
      "[1300]\tvalid_0's binary_logloss: 0.231441\tvalid_0's auc: 0.813623\n",
      "[1400]\tvalid_0's binary_logloss: 0.230288\tvalid_0's auc: 0.813785\n",
      "[1500]\tvalid_0's binary_logloss: 0.230008\tvalid_0's auc: 0.813856\n",
      "[1600]\tvalid_0's binary_logloss: 0.229669\tvalid_0's auc: 0.813969\n",
      "[1700]\tvalid_0's binary_logloss: 0.229413\tvalid_0's auc: 0.81408\n",
      "[1800]\tvalid_0's binary_logloss: 0.22909\tvalid_0's auc: 0.814146\n",
      "[1900]\tvalid_0's binary_logloss: 0.228765\tvalid_0's auc: 0.814233\n",
      "[2000]\tvalid_0's binary_logloss: 0.228863\tvalid_0's auc: 0.814297\n",
      "Early stopping, best iteration is:\n",
      "[1903]\tvalid_0's binary_logloss: 0.228747\tvalid_0's auc: 0.814234\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.386077\tvalid_0's auc: 0.802299\n",
      "[200]\tvalid_0's binary_logloss: 0.32226\tvalid_0's auc: 0.803939\n",
      "[300]\tvalid_0's binary_logloss: 0.285577\tvalid_0's auc: 0.806097\n",
      "[400]\tvalid_0's binary_logloss: 0.262555\tvalid_0's auc: 0.806295\n",
      "Early stopping, best iteration is:\n",
      "[330]\tvalid_0's binary_logloss: 0.272686\tvalid_0's auc: 0.806386\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.385869\tvalid_0's auc: 0.803486\n",
      "[200]\tvalid_0's binary_logloss: 0.321854\tvalid_0's auc: 0.806342\n",
      "[300]\tvalid_0's binary_logloss: 0.284996\tvalid_0's auc: 0.807294\n",
      "[400]\tvalid_0's binary_logloss: 0.261767\tvalid_0's auc: 0.808462\n",
      "[500]\tvalid_0's binary_logloss: 0.247815\tvalid_0's auc: 0.808789\n",
      "[600]\tvalid_0's binary_logloss: 0.242304\tvalid_0's auc: 0.809142\n",
      "[700]\tvalid_0's binary_logloss: 0.23946\tvalid_0's auc: 0.809207\n",
      "[800]\tvalid_0's binary_logloss: 0.236318\tvalid_0's auc: 0.809578\n",
      "[900]\tvalid_0's binary_logloss: 0.234585\tvalid_0's auc: 0.809724\n",
      "[1000]\tvalid_0's binary_logloss: 0.233967\tvalid_0's auc: 0.809832\n",
      "[1100]\tvalid_0's binary_logloss: 0.232556\tvalid_0's auc: 0.809972\n",
      "[1200]\tvalid_0's binary_logloss: 0.232565\tvalid_0's auc: 0.810066\n",
      "[1300]\tvalid_0's binary_logloss: 0.232308\tvalid_0's auc: 0.810123\n",
      "[1400]\tvalid_0's binary_logloss: 0.231192\tvalid_0's auc: 0.81024\n",
      "[1500]\tvalid_0's binary_logloss: 0.230929\tvalid_0's auc: 0.810295\n",
      "[1600]\tvalid_0's binary_logloss: 0.230604\tvalid_0's auc: 0.810359\n",
      "[1700]\tvalid_0's binary_logloss: 0.230372\tvalid_0's auc: 0.810416\n",
      "[1800]\tvalid_0's binary_logloss: 0.230059\tvalid_0's auc: 0.810467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1900]\tvalid_0's binary_logloss: 0.229747\tvalid_0's auc: 0.810623\n",
      "[2000]\tvalid_0's binary_logloss: 0.229856\tvalid_0's auc: 0.810656\n",
      "Early stopping, best iteration is:\n",
      "[1903]\tvalid_0's binary_logloss: 0.229732\tvalid_0's auc: 0.810626\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.385779\tvalid_0's auc: 0.803664\n",
      "[200]\tvalid_0's binary_logloss: 0.321782\tvalid_0's auc: 0.807221\n",
      "[300]\tvalid_0's binary_logloss: 0.284962\tvalid_0's auc: 0.809263\n",
      "[400]\tvalid_0's binary_logloss: 0.261765\tvalid_0's auc: 0.809689\n",
      "[500]\tvalid_0's binary_logloss: 0.247856\tvalid_0's auc: 0.810352\n",
      "[600]\tvalid_0's binary_logloss: 0.242353\tvalid_0's auc: 0.810512\n",
      "Early stopping, best iteration is:\n",
      "[594]\tvalid_0's binary_logloss: 0.243527\tvalid_0's auc: 0.810576\n",
      "cv score - on train:\n",
      "0.7863474088042445\n",
      "('current score in fold:', 0.808904448827137, 14)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.367676\tvalid_0's auc: 0.805768\n",
      "[200]\tvalid_0's binary_logloss: 0.299244\tvalid_0's auc: 0.809894\n",
      "[300]\tvalid_0's binary_logloss: 0.268829\tvalid_0's auc: 0.811956\n",
      "[400]\tvalid_0's binary_logloss: 0.255648\tvalid_0's auc: 0.812381\n",
      "[500]\tvalid_0's binary_logloss: 0.249266\tvalid_0's auc: 0.812505\n",
      "[600]\tvalid_0's binary_logloss: 0.242831\tvalid_0's auc: 0.812574\n",
      "[700]\tvalid_0's binary_logloss: 0.240299\tvalid_0's auc: 0.812876\n",
      "[800]\tvalid_0's binary_logloss: 0.238496\tvalid_0's auc: 0.812978\n",
      "[900]\tvalid_0's binary_logloss: 0.236785\tvalid_0's auc: 0.812974\n",
      "[1000]\tvalid_0's binary_logloss: 0.234253\tvalid_0's auc: 0.81302\n",
      "[1100]\tvalid_0's binary_logloss: 0.232495\tvalid_0's auc: 0.813137\n",
      "[1200]\tvalid_0's binary_logloss: 0.232588\tvalid_0's auc: 0.813199\n",
      "Early stopping, best iteration is:\n",
      "[1121]\tvalid_0's binary_logloss: 0.231994\tvalid_0's auc: 0.813146\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.368627\tvalid_0's auc: 0.808267\n",
      "[200]\tvalid_0's binary_logloss: 0.300471\tvalid_0's auc: 0.809933\n",
      "[300]\tvalid_0's binary_logloss: 0.27016\tvalid_0's auc: 0.812588\n",
      "[400]\tvalid_0's binary_logloss: 0.257019\tvalid_0's auc: 0.812844\n",
      "[500]\tvalid_0's binary_logloss: 0.250625\tvalid_0's auc: 0.812976\n",
      "[600]\tvalid_0's binary_logloss: 0.244165\tvalid_0's auc: 0.813274\n",
      "[700]\tvalid_0's binary_logloss: 0.241614\tvalid_0's auc: 0.813423\n",
      "[800]\tvalid_0's binary_logloss: 0.239787\tvalid_0's auc: 0.813504\n",
      "[900]\tvalid_0's binary_logloss: 0.238047\tvalid_0's auc: 0.81356\n",
      "[1000]\tvalid_0's binary_logloss: 0.235464\tvalid_0's auc: 0.813701\n",
      "[1100]\tvalid_0's binary_logloss: 0.233644\tvalid_0's auc: 0.814004\n",
      "[1200]\tvalid_0's binary_logloss: 0.233707\tvalid_0's auc: 0.81412\n",
      "Early stopping, best iteration is:\n",
      "[1121]\tvalid_0's binary_logloss: 0.23312\tvalid_0's auc: 0.814046\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.369279\tvalid_0's auc: 0.798557\n",
      "[200]\tvalid_0's binary_logloss: 0.301431\tvalid_0's auc: 0.801575\n",
      "[300]\tvalid_0's binary_logloss: 0.271449\tvalid_0's auc: 0.802118\n",
      "[400]\tvalid_0's binary_logloss: 0.25851\tvalid_0's auc: 0.803019\n",
      "[500]\tvalid_0's binary_logloss: 0.252268\tvalid_0's auc: 0.80302\n",
      "[600]\tvalid_0's binary_logloss: 0.245984\tvalid_0's auc: 0.80353\n",
      "[700]\tvalid_0's binary_logloss: 0.243549\tvalid_0's auc: 0.803565\n",
      "[800]\tvalid_0's binary_logloss: 0.241817\tvalid_0's auc: 0.803693\n",
      "[900]\tvalid_0's binary_logloss: 0.240183\tvalid_0's auc: 0.803705\n",
      "[1000]\tvalid_0's binary_logloss: 0.237764\tvalid_0's auc: 0.803834\n",
      "[1100]\tvalid_0's binary_logloss: 0.23612\tvalid_0's auc: 0.803939\n",
      "[1200]\tvalid_0's binary_logloss: 0.236211\tvalid_0's auc: 0.804011\n",
      "Early stopping, best iteration is:\n",
      "[1121]\tvalid_0's binary_logloss: 0.235645\tvalid_0's auc: 0.803966\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.368393\tvalid_0's auc: 0.806231\n",
      "[200]\tvalid_0's binary_logloss: 0.300133\tvalid_0's auc: 0.808266\n",
      "[300]\tvalid_0's binary_logloss: 0.269849\tvalid_0's auc: 0.809193\n",
      "[400]\tvalid_0's binary_logloss: 0.256766\tvalid_0's auc: 0.809457\n",
      "[500]\tvalid_0's binary_logloss: 0.250416\tvalid_0's auc: 0.809686\n",
      "[600]\tvalid_0's binary_logloss: 0.244034\tvalid_0's auc: 0.810088\n",
      "[700]\tvalid_0's binary_logloss: 0.241544\tvalid_0's auc: 0.810051\n",
      "Early stopping, best iteration is:\n",
      "[626]\tvalid_0's binary_logloss: 0.24359\tvalid_0's auc: 0.810094\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.368805\tvalid_0's auc: 0.804296\n",
      "[200]\tvalid_0's binary_logloss: 0.300684\tvalid_0's auc: 0.806089\n",
      "[300]\tvalid_0's binary_logloss: 0.270469\tvalid_0's auc: 0.8065\n",
      "[400]\tvalid_0's binary_logloss: 0.257434\tvalid_0's auc: 0.807006\n",
      "[500]\tvalid_0's binary_logloss: 0.251125\tvalid_0's auc: 0.807025\n",
      "[600]\tvalid_0's binary_logloss: 0.244763\tvalid_0's auc: 0.807694\n",
      "[700]\tvalid_0's binary_logloss: 0.242286\tvalid_0's auc: 0.807791\n",
      "[800]\tvalid_0's binary_logloss: 0.240511\tvalid_0's auc: 0.807829\n",
      "[900]\tvalid_0's binary_logloss: 0.238829\tvalid_0's auc: 0.807867\n",
      "[1000]\tvalid_0's binary_logloss: 0.236316\tvalid_0's auc: 0.808093\n",
      "[1100]\tvalid_0's binary_logloss: 0.234571\tvalid_0's auc: 0.808318\n",
      "[1200]\tvalid_0's binary_logloss: 0.234676\tvalid_0's auc: 0.808435\n",
      "Early stopping, best iteration is:\n",
      "[1121]\tvalid_0's binary_logloss: 0.23407\tvalid_0's auc: 0.808357\n",
      "cv score - on train:\n",
      "0.8064907774826636\n",
      "('current score in fold:', 0.8090045162290423, 15)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.36586\tvalid_0's auc: 0.809468\n",
      "[200]\tvalid_0's binary_logloss: 0.298853\tvalid_0's auc: 0.811128\n",
      "[300]\tvalid_0's binary_logloss: 0.270578\tvalid_0's auc: 0.813213\n",
      "[400]\tvalid_0's binary_logloss: 0.255218\tvalid_0's auc: 0.813707\n",
      "[500]\tvalid_0's binary_logloss: 0.245584\tvalid_0's auc: 0.813721\n",
      "[600]\tvalid_0's binary_logloss: 0.2402\tvalid_0's auc: 0.814125\n",
      "[700]\tvalid_0's binary_logloss: 0.237374\tvalid_0's auc: 0.814327\n",
      "[800]\tvalid_0's binary_logloss: 0.235427\tvalid_0's auc: 0.81439\n",
      "[900]\tvalid_0's binary_logloss: 0.23438\tvalid_0's auc: 0.814489\n",
      "[1000]\tvalid_0's binary_logloss: 0.233926\tvalid_0's auc: 0.814524\n",
      "[1100]\tvalid_0's binary_logloss: 0.232296\tvalid_0's auc: 0.814656\n",
      "[1200]\tvalid_0's binary_logloss: 0.231625\tvalid_0's auc: 0.814826\n",
      "[1300]\tvalid_0's binary_logloss: 0.230493\tvalid_0's auc: 0.814993\n",
      "[1400]\tvalid_0's binary_logloss: 0.229826\tvalid_0's auc: 0.815107\n",
      "[1500]\tvalid_0's binary_logloss: 0.229623\tvalid_0's auc: 0.815233\n",
      "[1600]\tvalid_0's binary_logloss: 0.229203\tvalid_0's auc: 0.815309\n",
      "[1700]\tvalid_0's binary_logloss: 0.229163\tvalid_0's auc: 0.815372\n",
      "[1800]\tvalid_0's binary_logloss: 0.228764\tvalid_0's auc: 0.815495\n",
      "[1900]\tvalid_0's binary_logloss: 0.228649\tvalid_0's auc: 0.815536\n",
      "[2000]\tvalid_0's binary_logloss: 0.228275\tvalid_0's auc: 0.815646\n",
      "[2100]\tvalid_0's binary_logloss: 0.228249\tvalid_0's auc: 0.81568\n",
      "[2200]\tvalid_0's binary_logloss: 0.22839\tvalid_0's auc: 0.815691\n",
      "Early stopping, best iteration is:\n",
      "[2128]\tvalid_0's binary_logloss: 0.228177\tvalid_0's auc: 0.815674\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.36663\tvalid_0's auc: 0.805724\n",
      "[200]\tvalid_0's binary_logloss: 0.299766\tvalid_0's auc: 0.809451\n",
      "[300]\tvalid_0's binary_logloss: 0.271601\tvalid_0's auc: 0.80988\n",
      "[400]\tvalid_0's binary_logloss: 0.25631\tvalid_0's auc: 0.810259\n",
      "[500]\tvalid_0's binary_logloss: 0.246717\tvalid_0's auc: 0.810683\n",
      "[600]\tvalid_0's binary_logloss: 0.241392\tvalid_0's auc: 0.810874\n",
      "[700]\tvalid_0's binary_logloss: 0.238612\tvalid_0's auc: 0.811091\n",
      "[800]\tvalid_0's binary_logloss: 0.236679\tvalid_0's auc: 0.811118\n",
      "[900]\tvalid_0's binary_logloss: 0.23565\tvalid_0's auc: 0.811327\n",
      "[1000]\tvalid_0's binary_logloss: 0.235203\tvalid_0's auc: 0.811405\n",
      "[1100]\tvalid_0's binary_logloss: 0.233572\tvalid_0's auc: 0.811482\n",
      "[1200]\tvalid_0's binary_logloss: 0.232919\tvalid_0's auc: 0.811613\n",
      "[1300]\tvalid_0's binary_logloss: 0.231782\tvalid_0's auc: 0.811846\n",
      "[1400]\tvalid_0's binary_logloss: 0.231124\tvalid_0's auc: 0.811926\n",
      "[1500]\tvalid_0's binary_logloss: 0.230926\tvalid_0's auc: 0.812013\n",
      "[1600]\tvalid_0's binary_logloss: 0.230499\tvalid_0's auc: 0.812104\n",
      "[1700]\tvalid_0's binary_logloss: 0.23045\tvalid_0's auc: 0.812181\n",
      "[1800]\tvalid_0's binary_logloss: 0.230059\tvalid_0's auc: 0.812274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1900]\tvalid_0's binary_logloss: 0.229936\tvalid_0's auc: 0.812344\n",
      "[2000]\tvalid_0's binary_logloss: 0.229569\tvalid_0's auc: 0.812446\n",
      "[2100]\tvalid_0's binary_logloss: 0.22955\tvalid_0's auc: 0.812489\n",
      "Early stopping, best iteration is:\n",
      "[2027]\tvalid_0's binary_logloss: 0.229488\tvalid_0's auc: 0.812459\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.366997\tvalid_0's auc: 0.802914\n",
      "[200]\tvalid_0's binary_logloss: 0.30035\tvalid_0's auc: 0.805595\n",
      "[300]\tvalid_0's binary_logloss: 0.272292\tvalid_0's auc: 0.806857\n",
      "[400]\tvalid_0's binary_logloss: 0.257125\tvalid_0's auc: 0.807166\n",
      "[500]\tvalid_0's binary_logloss: 0.247638\tvalid_0's auc: 0.80741\n",
      "[600]\tvalid_0's binary_logloss: 0.242374\tvalid_0's auc: 0.807681\n",
      "[700]\tvalid_0's binary_logloss: 0.239646\tvalid_0's auc: 0.807831\n",
      "[800]\tvalid_0's binary_logloss: 0.237749\tvalid_0's auc: 0.807924\n",
      "[900]\tvalid_0's binary_logloss: 0.236748\tvalid_0's auc: 0.80794\n",
      "[1000]\tvalid_0's binary_logloss: 0.236314\tvalid_0's auc: 0.808016\n",
      "[1100]\tvalid_0's binary_logloss: 0.234744\tvalid_0's auc: 0.808108\n",
      "[1200]\tvalid_0's binary_logloss: 0.234115\tvalid_0's auc: 0.808333\n",
      "[1300]\tvalid_0's binary_logloss: 0.233026\tvalid_0's auc: 0.808447\n",
      "[1400]\tvalid_0's binary_logloss: 0.232386\tvalid_0's auc: 0.808654\n",
      "[1500]\tvalid_0's binary_logloss: 0.232197\tvalid_0's auc: 0.80875\n",
      "[1600]\tvalid_0's binary_logloss: 0.231784\tvalid_0's auc: 0.808845\n",
      "[1700]\tvalid_0's binary_logloss: 0.231734\tvalid_0's auc: 0.80894\n",
      "[1800]\tvalid_0's binary_logloss: 0.231378\tvalid_0's auc: 0.808993\n",
      "[1900]\tvalid_0's binary_logloss: 0.231268\tvalid_0's auc: 0.809068\n",
      "[2000]\tvalid_0's binary_logloss: 0.230917\tvalid_0's auc: 0.809205\n",
      "[2100]\tvalid_0's binary_logloss: 0.2309\tvalid_0's auc: 0.809252\n",
      "[2200]\tvalid_0's binary_logloss: 0.231025\tvalid_0's auc: 0.80929\n",
      "Early stopping, best iteration is:\n",
      "[2128]\tvalid_0's binary_logloss: 0.230828\tvalid_0's auc: 0.809263\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.366473\tvalid_0's auc: 0.799091\n",
      "[200]\tvalid_0's binary_logloss: 0.299819\tvalid_0's auc: 0.803131\n",
      "[300]\tvalid_0's binary_logloss: 0.271877\tvalid_0's auc: 0.803885\n",
      "[400]\tvalid_0's binary_logloss: 0.256803\tvalid_0's auc: 0.804121\n",
      "[500]\tvalid_0's binary_logloss: 0.247421\tvalid_0's auc: 0.804586\n",
      "[600]\tvalid_0's binary_logloss: 0.242233\tvalid_0's auc: 0.804774\n",
      "[700]\tvalid_0's binary_logloss: 0.239545\tvalid_0's auc: 0.805069\n",
      "[800]\tvalid_0's binary_logloss: 0.237686\tvalid_0's auc: 0.805229\n",
      "[900]\tvalid_0's binary_logloss: 0.236716\tvalid_0's auc: 0.805306\n",
      "[1000]\tvalid_0's binary_logloss: 0.236291\tvalid_0's auc: 0.805436\n",
      "[1100]\tvalid_0's binary_logloss: 0.234774\tvalid_0's auc: 0.805614\n",
      "[1200]\tvalid_0's binary_logloss: 0.234161\tvalid_0's auc: 0.80575\n",
      "[1300]\tvalid_0's binary_logloss: 0.233137\tvalid_0's auc: 0.805946\n",
      "[1400]\tvalid_0's binary_logloss: 0.232555\tvalid_0's auc: 0.806041\n",
      "[1500]\tvalid_0's binary_logloss: 0.232385\tvalid_0's auc: 0.806138\n",
      "[1600]\tvalid_0's binary_logloss: 0.23201\tvalid_0's auc: 0.806283\n",
      "[1700]\tvalid_0's binary_logloss: 0.231983\tvalid_0's auc: 0.806323\n",
      "[1800]\tvalid_0's binary_logloss: 0.231655\tvalid_0's auc: 0.806387\n",
      "[1900]\tvalid_0's binary_logloss: 0.23156\tvalid_0's auc: 0.806436\n",
      "[2000]\tvalid_0's binary_logloss: 0.231248\tvalid_0's auc: 0.806594\n",
      "[2100]\tvalid_0's binary_logloss: 0.231223\tvalid_0's auc: 0.806662\n",
      "[2200]\tvalid_0's binary_logloss: 0.231337\tvalid_0's auc: 0.806703\n",
      "Early stopping, best iteration is:\n",
      "[2128]\tvalid_0's binary_logloss: 0.231156\tvalid_0's auc: 0.80669\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.36619\tvalid_0's auc: 0.804253\n",
      "[200]\tvalid_0's binary_logloss: 0.299281\tvalid_0's auc: 0.807068\n",
      "[300]\tvalid_0's binary_logloss: 0.271151\tvalid_0's auc: 0.808174\n",
      "[400]\tvalid_0's binary_logloss: 0.255937\tvalid_0's auc: 0.808784\n",
      "[500]\tvalid_0's binary_logloss: 0.246407\tvalid_0's auc: 0.80895\n",
      "[600]\tvalid_0's binary_logloss: 0.241133\tvalid_0's auc: 0.809328\n",
      "[700]\tvalid_0's binary_logloss: 0.238418\tvalid_0's auc: 0.809524\n",
      "[800]\tvalid_0's binary_logloss: 0.236527\tvalid_0's auc: 0.809575\n",
      "[900]\tvalid_0's binary_logloss: 0.235529\tvalid_0's auc: 0.809691\n",
      "[1000]\tvalid_0's binary_logloss: 0.235119\tvalid_0's auc: 0.809723\n",
      "[1100]\tvalid_0's binary_logloss: 0.23355\tvalid_0's auc: 0.809796\n",
      "[1200]\tvalid_0's binary_logloss: 0.232937\tvalid_0's auc: 0.809865\n",
      "[1300]\tvalid_0's binary_logloss: 0.231858\tvalid_0's auc: 0.810082\n",
      "[1400]\tvalid_0's binary_logloss: 0.231241\tvalid_0's auc: 0.810293\n",
      "[1500]\tvalid_0's binary_logloss: 0.231059\tvalid_0's auc: 0.810429\n",
      "[1600]\tvalid_0's binary_logloss: 0.230654\tvalid_0's auc: 0.810517\n",
      "[1700]\tvalid_0's binary_logloss: 0.230616\tvalid_0's auc: 0.810594\n",
      "[1800]\tvalid_0's binary_logloss: 0.230252\tvalid_0's auc: 0.810687\n",
      "[1900]\tvalid_0's binary_logloss: 0.230139\tvalid_0's auc: 0.810766\n",
      "[2000]\tvalid_0's binary_logloss: 0.229799\tvalid_0's auc: 0.810895\n",
      "[2100]\tvalid_0's binary_logloss: 0.229785\tvalid_0's auc: 0.810942\n",
      "Early stopping, best iteration is:\n",
      "[2027]\tvalid_0's binary_logloss: 0.229718\tvalid_0's auc: 0.810926\n",
      "cv score - on train:\n",
      "0.8108442207456327\n",
      "('current score in fold:', 0.809178714968328, 16)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.378712\tvalid_0's auc: 0.805963\n",
      "[200]\tvalid_0's binary_logloss: 0.299031\tvalid_0's auc: 0.809449\n",
      "[300]\tvalid_0's binary_logloss: 0.280171\tvalid_0's auc: 0.809826\n",
      "[400]\tvalid_0's binary_logloss: 0.259734\tvalid_0's auc: 0.810142\n",
      "[500]\tvalid_0's binary_logloss: 0.25\tvalid_0's auc: 0.810495\n",
      "[600]\tvalid_0's binary_logloss: 0.244309\tvalid_0's auc: 0.81061\n",
      "[700]\tvalid_0's binary_logloss: 0.242106\tvalid_0's auc: 0.8108\n",
      "[800]\tvalid_0's binary_logloss: 0.238927\tvalid_0's auc: 0.810895\n",
      "Early stopping, best iteration is:\n",
      "[745]\tvalid_0's binary_logloss: 0.23985\tvalid_0's auc: 0.810907\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.379546\tvalid_0's auc: 0.802305\n",
      "[200]\tvalid_0's binary_logloss: 0.300171\tvalid_0's auc: 0.804675\n",
      "[300]\tvalid_0's binary_logloss: 0.281462\tvalid_0's auc: 0.805831\n",
      "[400]\tvalid_0's binary_logloss: 0.261109\tvalid_0's auc: 0.806821\n",
      "[500]\tvalid_0's binary_logloss: 0.251412\tvalid_0's auc: 0.807223\n",
      "[600]\tvalid_0's binary_logloss: 0.24574\tvalid_0's auc: 0.80736\n",
      "[700]\tvalid_0's binary_logloss: 0.243562\tvalid_0's auc: 0.807394\n",
      "[800]\tvalid_0's binary_logloss: 0.240378\tvalid_0's auc: 0.807603\n",
      "[900]\tvalid_0's binary_logloss: 0.237781\tvalid_0's auc: 0.807692\n",
      "[1000]\tvalid_0's binary_logloss: 0.237171\tvalid_0's auc: 0.80776\n",
      "[1100]\tvalid_0's binary_logloss: 0.235809\tvalid_0's auc: 0.807871\n",
      "[1200]\tvalid_0's binary_logloss: 0.234696\tvalid_0's auc: 0.807923\n",
      "[1300]\tvalid_0's binary_logloss: 0.234138\tvalid_0's auc: 0.808105\n",
      "[1400]\tvalid_0's binary_logloss: 0.233792\tvalid_0's auc: 0.8082\n",
      "[1500]\tvalid_0's binary_logloss: 0.232731\tvalid_0's auc: 0.808348\n",
      "[1600]\tvalid_0's binary_logloss: 0.232421\tvalid_0's auc: 0.808434\n",
      "[1700]\tvalid_0's binary_logloss: 0.231855\tvalid_0's auc: 0.808628\n",
      "[1800]\tvalid_0's binary_logloss: 0.231545\tvalid_0's auc: 0.808756\n",
      "[1900]\tvalid_0's binary_logloss: 0.231579\tvalid_0's auc: 0.808831\n",
      "Early stopping, best iteration is:\n",
      "[1828]\tvalid_0's binary_logloss: 0.231354\tvalid_0's auc: 0.808803\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.378617\tvalid_0's auc: 0.808607\n",
      "[200]\tvalid_0's binary_logloss: 0.29885\tvalid_0's auc: 0.81146\n",
      "[300]\tvalid_0's binary_logloss: 0.279947\tvalid_0's auc: 0.812561\n",
      "[400]\tvalid_0's binary_logloss: 0.259406\tvalid_0's auc: 0.81292\n",
      "[500]\tvalid_0's binary_logloss: 0.249588\tvalid_0's auc: 0.812957\n",
      "[600]\tvalid_0's binary_logloss: 0.243832\tvalid_0's auc: 0.813238\n",
      "[700]\tvalid_0's binary_logloss: 0.241598\tvalid_0's auc: 0.813332\n",
      "[800]\tvalid_0's binary_logloss: 0.238374\tvalid_0's auc: 0.813404\n",
      "[900]\tvalid_0's binary_logloss: 0.235722\tvalid_0's auc: 0.813496\n",
      "[1000]\tvalid_0's binary_logloss: 0.235088\tvalid_0's auc: 0.813609\n",
      "[1100]\tvalid_0's binary_logloss: 0.233698\tvalid_0's auc: 0.813774\n",
      "[1200]\tvalid_0's binary_logloss: 0.23255\tvalid_0's auc: 0.813868\n",
      "[1300]\tvalid_0's binary_logloss: 0.231978\tvalid_0's auc: 0.813976\n",
      "[1400]\tvalid_0's binary_logloss: 0.231583\tvalid_0's auc: 0.814129\n",
      "[1500]\tvalid_0's binary_logloss: 0.230497\tvalid_0's auc: 0.814299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1600]\tvalid_0's binary_logloss: 0.230165\tvalid_0's auc: 0.814424\n",
      "[1700]\tvalid_0's binary_logloss: 0.22958\tvalid_0's auc: 0.814552\n",
      "[1800]\tvalid_0's binary_logloss: 0.229258\tvalid_0's auc: 0.814689\n",
      "[1900]\tvalid_0's binary_logloss: 0.229282\tvalid_0's auc: 0.814837\n",
      "Early stopping, best iteration is:\n",
      "[1847]\tvalid_0's binary_logloss: 0.229058\tvalid_0's auc: 0.814802\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.379097\tvalid_0's auc: 0.801166\n",
      "[200]\tvalid_0's binary_logloss: 0.299577\tvalid_0's auc: 0.805043\n",
      "[300]\tvalid_0's binary_logloss: 0.28078\tvalid_0's auc: 0.805908\n",
      "[400]\tvalid_0's binary_logloss: 0.26038\tvalid_0's auc: 0.806953\n",
      "[500]\tvalid_0's binary_logloss: 0.250701\tvalid_0's auc: 0.807199\n",
      "[600]\tvalid_0's binary_logloss: 0.245061\tvalid_0's auc: 0.807225\n",
      "Early stopping, best iteration is:\n",
      "[531]\tvalid_0's binary_logloss: 0.248218\tvalid_0's auc: 0.80728\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.378789\tvalid_0's auc: 0.802563\n",
      "[200]\tvalid_0's binary_logloss: 0.299188\tvalid_0's auc: 0.805631\n",
      "[300]\tvalid_0's binary_logloss: 0.280391\tvalid_0's auc: 0.805793\n",
      "[400]\tvalid_0's binary_logloss: 0.260003\tvalid_0's auc: 0.807021\n",
      "[500]\tvalid_0's binary_logloss: 0.250311\tvalid_0's auc: 0.807119\n",
      "[600]\tvalid_0's binary_logloss: 0.244659\tvalid_0's auc: 0.807849\n",
      "[700]\tvalid_0's binary_logloss: 0.242469\tvalid_0's auc: 0.808229\n",
      "[800]\tvalid_0's binary_logloss: 0.23932\tvalid_0's auc: 0.808434\n",
      "[900]\tvalid_0's binary_logloss: 0.236741\tvalid_0's auc: 0.80868\n",
      "[1000]\tvalid_0's binary_logloss: 0.236138\tvalid_0's auc: 0.808805\n",
      "[1100]\tvalid_0's binary_logloss: 0.234788\tvalid_0's auc: 0.808921\n",
      "[1200]\tvalid_0's binary_logloss: 0.23368\tvalid_0's auc: 0.808988\n",
      "[1300]\tvalid_0's binary_logloss: 0.233143\tvalid_0's auc: 0.809095\n",
      "[1400]\tvalid_0's binary_logloss: 0.232799\tvalid_0's auc: 0.809206\n",
      "[1500]\tvalid_0's binary_logloss: 0.231762\tvalid_0's auc: 0.809347\n",
      "[1600]\tvalid_0's binary_logloss: 0.231458\tvalid_0's auc: 0.809445\n",
      "[1700]\tvalid_0's binary_logloss: 0.230924\tvalid_0's auc: 0.809605\n",
      "[1800]\tvalid_0's binary_logloss: 0.230636\tvalid_0's auc: 0.809696\n",
      "[1900]\tvalid_0's binary_logloss: 0.230669\tvalid_0's auc: 0.809763\n",
      "Early stopping, best iteration is:\n",
      "[1847]\tvalid_0's binary_logloss: 0.230455\tvalid_0's auc: 0.809753\n",
      "cv score - on train:\n",
      "0.8005212320918111\n",
      "('current score in fold:', 0.8092353211405715, 17)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.388817\tvalid_0's auc: 0.804146\n",
      "[200]\tvalid_0's binary_logloss: 0.316689\tvalid_0's auc: 0.806896\n",
      "[300]\tvalid_0's binary_logloss: 0.286458\tvalid_0's auc: 0.808878\n",
      "[400]\tvalid_0's binary_logloss: 0.264027\tvalid_0's auc: 0.809819\n",
      "[500]\tvalid_0's binary_logloss: 0.25522\tvalid_0's auc: 0.810065\n",
      "[600]\tvalid_0's binary_logloss: 0.250613\tvalid_0's auc: 0.810422\n",
      "Early stopping, best iteration is:\n",
      "[546]\tvalid_0's binary_logloss: 0.253924\tvalid_0's auc: 0.810437\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.389407\tvalid_0's auc: 0.80336\n",
      "[200]\tvalid_0's binary_logloss: 0.31753\tvalid_0's auc: 0.805768\n",
      "[300]\tvalid_0's binary_logloss: 0.287404\tvalid_0's auc: 0.806441\n",
      "[400]\tvalid_0's binary_logloss: 0.265111\tvalid_0's auc: 0.807207\n",
      "Early stopping, best iteration is:\n",
      "[359]\tvalid_0's binary_logloss: 0.270899\tvalid_0's auc: 0.807277\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.389177\tvalid_0's auc: 0.80478\n",
      "[200]\tvalid_0's binary_logloss: 0.317239\tvalid_0's auc: 0.807401\n",
      "[300]\tvalid_0's binary_logloss: 0.287064\tvalid_0's auc: 0.809308\n",
      "[400]\tvalid_0's binary_logloss: 0.264748\tvalid_0's auc: 0.810204\n",
      "[500]\tvalid_0's binary_logloss: 0.256005\tvalid_0's auc: 0.810322\n",
      "[600]\tvalid_0's binary_logloss: 0.251395\tvalid_0's auc: 0.810377\n",
      "[700]\tvalid_0's binary_logloss: 0.242696\tvalid_0's auc: 0.810727\n",
      "[800]\tvalid_0's binary_logloss: 0.240838\tvalid_0's auc: 0.810718\n",
      "Early stopping, best iteration is:\n",
      "[768]\tvalid_0's binary_logloss: 0.241442\tvalid_0's auc: 0.810744\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.388856\tvalid_0's auc: 0.802703\n",
      "[200]\tvalid_0's binary_logloss: 0.316893\tvalid_0's auc: 0.804215\n",
      "[300]\tvalid_0's binary_logloss: 0.286769\tvalid_0's auc: 0.806588\n",
      "[400]\tvalid_0's binary_logloss: 0.264493\tvalid_0's auc: 0.80726\n",
      "[500]\tvalid_0's binary_logloss: 0.255788\tvalid_0's auc: 0.807398\n",
      "[600]\tvalid_0's binary_logloss: 0.251222\tvalid_0's auc: 0.807531\n",
      "[700]\tvalid_0's binary_logloss: 0.242598\tvalid_0's auc: 0.807836\n",
      "[800]\tvalid_0's binary_logloss: 0.240791\tvalid_0's auc: 0.807883\n",
      "[900]\tvalid_0's binary_logloss: 0.238358\tvalid_0's auc: 0.807933\n",
      "[1000]\tvalid_0's binary_logloss: 0.235257\tvalid_0's auc: 0.808067\n",
      "[1100]\tvalid_0's binary_logloss: 0.234254\tvalid_0's auc: 0.808187\n",
      "[1200]\tvalid_0's binary_logloss: 0.233243\tvalid_0's auc: 0.808275\n",
      "[1300]\tvalid_0's binary_logloss: 0.231874\tvalid_0's auc: 0.808478\n",
      "Early stopping, best iteration is:\n",
      "[1296]\tvalid_0's binary_logloss: 0.231825\tvalid_0's auc: 0.808447\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.389212\tvalid_0's auc: 0.805677\n",
      "[200]\tvalid_0's binary_logloss: 0.31724\tvalid_0's auc: 0.807666\n",
      "[300]\tvalid_0's binary_logloss: 0.287064\tvalid_0's auc: 0.80865\n",
      "[400]\tvalid_0's binary_logloss: 0.264723\tvalid_0's auc: 0.809088\n",
      "[500]\tvalid_0's binary_logloss: 0.255966\tvalid_0's auc: 0.809555\n",
      "[600]\tvalid_0's binary_logloss: 0.251369\tvalid_0's auc: 0.809791\n",
      "[700]\tvalid_0's binary_logloss: 0.242651\tvalid_0's auc: 0.809973\n",
      "[800]\tvalid_0's binary_logloss: 0.2408\tvalid_0's auc: 0.81013\n",
      "[900]\tvalid_0's binary_logloss: 0.238336\tvalid_0's auc: 0.81017\n",
      "[1000]\tvalid_0's binary_logloss: 0.235165\tvalid_0's auc: 0.810615\n",
      "[1100]\tvalid_0's binary_logloss: 0.234149\tvalid_0's auc: 0.81074\n",
      "[1200]\tvalid_0's binary_logloss: 0.23312\tvalid_0's auc: 0.810831\n",
      "[1300]\tvalid_0's binary_logloss: 0.231699\tvalid_0's auc: 0.811095\n",
      "Early stopping, best iteration is:\n",
      "[1296]\tvalid_0's binary_logloss: 0.231647\tvalid_0's auc: 0.810968\n",
      "cv score - on train:\n",
      "0.7876745094366978\n",
      "('current score in fold:', 0.8091806617655739, 18)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.373804\tvalid_0's auc: 0.800134\n",
      "[200]\tvalid_0's binary_logloss: 0.311929\tvalid_0's auc: 0.801982\n",
      "[300]\tvalid_0's binary_logloss: 0.274724\tvalid_0's auc: 0.80384\n",
      "[400]\tvalid_0's binary_logloss: 0.262639\tvalid_0's auc: 0.805119\n",
      "[500]\tvalid_0's binary_logloss: 0.255968\tvalid_0's auc: 0.805581\n",
      "[600]\tvalid_0's binary_logloss: 0.248864\tvalid_0's auc: 0.805632\n",
      "[700]\tvalid_0's binary_logloss: 0.242321\tvalid_0's auc: 0.806139\n",
      "[800]\tvalid_0's binary_logloss: 0.23961\tvalid_0's auc: 0.806165\n",
      "[900]\tvalid_0's binary_logloss: 0.23776\tvalid_0's auc: 0.806357\n",
      "[1000]\tvalid_0's binary_logloss: 0.237076\tvalid_0's auc: 0.806412\n",
      "[1100]\tvalid_0's binary_logloss: 0.234879\tvalid_0's auc: 0.806472\n",
      "[1200]\tvalid_0's binary_logloss: 0.234174\tvalid_0's auc: 0.806552\n",
      "[1300]\tvalid_0's binary_logloss: 0.233824\tvalid_0's auc: 0.806622\n",
      "[1400]\tvalid_0's binary_logloss: 0.232949\tvalid_0's auc: 0.806732\n",
      "[1500]\tvalid_0's binary_logloss: 0.232086\tvalid_0's auc: 0.806793\n",
      "[1600]\tvalid_0's binary_logloss: 0.231837\tvalid_0's auc: 0.806904\n",
      "[1700]\tvalid_0's binary_logloss: 0.231408\tvalid_0's auc: 0.8071\n",
      "[1800]\tvalid_0's binary_logloss: 0.23127\tvalid_0's auc: 0.80721\n",
      "Early stopping, best iteration is:\n",
      "[1761]\tvalid_0's binary_logloss: 0.231164\tvalid_0's auc: 0.807181\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.373508\tvalid_0's auc: 0.804169\n",
      "[200]\tvalid_0's binary_logloss: 0.311398\tvalid_0's auc: 0.80764\n",
      "Early stopping, best iteration is:\n",
      "[157]\tvalid_0's binary_logloss: 0.328634\tvalid_0's auc: 0.807683\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.37402\tvalid_0's auc: 0.805161\n",
      "[200]\tvalid_0's binary_logloss: 0.312084\tvalid_0's auc: 0.808242\n",
      "[300]\tvalid_0's binary_logloss: 0.274832\tvalid_0's auc: 0.808611\n",
      "[400]\tvalid_0's binary_logloss: 0.262698\tvalid_0's auc: 0.809728\n",
      "[500]\tvalid_0's binary_logloss: 0.255974\tvalid_0's auc: 0.809874\n",
      "[600]\tvalid_0's binary_logloss: 0.248802\tvalid_0's auc: 0.809924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[700]\tvalid_0's binary_logloss: 0.242154\tvalid_0's auc: 0.810105\n",
      "[800]\tvalid_0's binary_logloss: 0.239365\tvalid_0's auc: 0.810494\n",
      "[900]\tvalid_0's binary_logloss: 0.237446\tvalid_0's auc: 0.810597\n",
      "[1000]\tvalid_0's binary_logloss: 0.236714\tvalid_0's auc: 0.810678\n",
      "[1100]\tvalid_0's binary_logloss: 0.23442\tvalid_0's auc: 0.810789\n",
      "[1200]\tvalid_0's binary_logloss: 0.233663\tvalid_0's auc: 0.811009\n",
      "[1300]\tvalid_0's binary_logloss: 0.233291\tvalid_0's auc: 0.811089\n",
      "[1400]\tvalid_0's binary_logloss: 0.232358\tvalid_0's auc: 0.811246\n",
      "[1500]\tvalid_0's binary_logloss: 0.231431\tvalid_0's auc: 0.811434\n",
      "[1600]\tvalid_0's binary_logloss: 0.23115\tvalid_0's auc: 0.811557\n",
      "[1700]\tvalid_0's binary_logloss: 0.230678\tvalid_0's auc: 0.811677\n",
      "[1800]\tvalid_0's binary_logloss: 0.230509\tvalid_0's auc: 0.811831\n",
      "Early stopping, best iteration is:\n",
      "[1761]\tvalid_0's binary_logloss: 0.23041\tvalid_0's auc: 0.811776\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.373658\tvalid_0's auc: 0.801644\n",
      "[200]\tvalid_0's binary_logloss: 0.311708\tvalid_0's auc: 0.804845\n",
      "[300]\tvalid_0's binary_logloss: 0.274535\tvalid_0's auc: 0.806196\n",
      "[400]\tvalid_0's binary_logloss: 0.262485\tvalid_0's auc: 0.806452\n",
      "Early stopping, best iteration is:\n",
      "[333]\tvalid_0's binary_logloss: 0.268242\tvalid_0's auc: 0.806513\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.373216\tvalid_0's auc: 0.808172\n",
      "[200]\tvalid_0's binary_logloss: 0.31099\tvalid_0's auc: 0.811579\n",
      "[300]\tvalid_0's binary_logloss: 0.273487\tvalid_0's auc: 0.813156\n",
      "[400]\tvalid_0's binary_logloss: 0.261234\tvalid_0's auc: 0.813566\n",
      "[500]\tvalid_0's binary_logloss: 0.254464\tvalid_0's auc: 0.813556\n",
      "Early stopping, best iteration is:\n",
      "[414]\tvalid_0's binary_logloss: 0.259152\tvalid_0's auc: 0.813606\n",
      "cv score - on train:\n",
      "0.750899955476026\n",
      "('current score in fold:', 0.8088351769305182, 19)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.380023\tvalid_0's auc: 0.801198\n",
      "[200]\tvalid_0's binary_logloss: 0.303064\tvalid_0's auc: 0.803302\n",
      "[300]\tvalid_0's binary_logloss: 0.273247\tvalid_0's auc: 0.803805\n",
      "[400]\tvalid_0's binary_logloss: 0.253417\tvalid_0's auc: 0.804045\n",
      "[500]\tvalid_0's binary_logloss: 0.248116\tvalid_0's auc: 0.804458\n",
      "[600]\tvalid_0's binary_logloss: 0.24049\tvalid_0's auc: 0.805007\n",
      "[700]\tvalid_0's binary_logloss: 0.238881\tvalid_0's auc: 0.80521\n",
      "[800]\tvalid_0's binary_logloss: 0.236175\tvalid_0's auc: 0.805388\n",
      "[900]\tvalid_0's binary_logloss: 0.235635\tvalid_0's auc: 0.805497\n",
      "[1000]\tvalid_0's binary_logloss: 0.23449\tvalid_0's auc: 0.80569\n",
      "[1100]\tvalid_0's binary_logloss: 0.234247\tvalid_0's auc: 0.805798\n",
      "[1200]\tvalid_0's binary_logloss: 0.233813\tvalid_0's auc: 0.805922\n",
      "[1300]\tvalid_0's binary_logloss: 0.233031\tvalid_0's auc: 0.806088\n",
      "[1400]\tvalid_0's binary_logloss: 0.232727\tvalid_0's auc: 0.806346\n",
      "[1500]\tvalid_0's binary_logloss: 0.232704\tvalid_0's auc: 0.806457\n",
      "[1600]\tvalid_0's binary_logloss: 0.232372\tvalid_0's auc: 0.806552\n",
      "Early stopping, best iteration is:\n",
      "[1589]\tvalid_0's binary_logloss: 0.232284\tvalid_0's auc: 0.806554\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.378556\tvalid_0's auc: 0.810741\n",
      "[200]\tvalid_0's binary_logloss: 0.300915\tvalid_0's auc: 0.812552\n",
      "[300]\tvalid_0's binary_logloss: 0.270631\tvalid_0's auc: 0.814668\n",
      "[400]\tvalid_0's binary_logloss: 0.250239\tvalid_0's auc: 0.815336\n",
      "[500]\tvalid_0's binary_logloss: 0.244736\tvalid_0's auc: 0.816107\n",
      "[600]\tvalid_0's binary_logloss: 0.236811\tvalid_0's auc: 0.816133\n",
      "[700]\tvalid_0's binary_logloss: 0.235133\tvalid_0's auc: 0.816174\n",
      "[800]\tvalid_0's binary_logloss: 0.232292\tvalid_0's auc: 0.816342\n",
      "[900]\tvalid_0's binary_logloss: 0.231726\tvalid_0's auc: 0.816497\n",
      "[1000]\tvalid_0's binary_logloss: 0.230507\tvalid_0's auc: 0.816702\n",
      "[1100]\tvalid_0's binary_logloss: 0.230249\tvalid_0's auc: 0.816863\n",
      "[1200]\tvalid_0's binary_logloss: 0.229801\tvalid_0's auc: 0.816904\n",
      "[1300]\tvalid_0's binary_logloss: 0.228949\tvalid_0's auc: 0.817038\n",
      "[1400]\tvalid_0's binary_logloss: 0.228648\tvalid_0's auc: 0.817107\n",
      "[1500]\tvalid_0's binary_logloss: 0.228643\tvalid_0's auc: 0.817148\n",
      "[1600]\tvalid_0's binary_logloss: 0.228284\tvalid_0's auc: 0.81723\n",
      "Early stopping, best iteration is:\n",
      "[1589]\tvalid_0's binary_logloss: 0.228187\tvalid_0's auc: 0.817222\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.378822\tvalid_0's auc: 0.808911\n",
      "[200]\tvalid_0's binary_logloss: 0.301269\tvalid_0's auc: 0.811015\n",
      "[300]\tvalid_0's binary_logloss: 0.271048\tvalid_0's auc: 0.812007\n",
      "[400]\tvalid_0's binary_logloss: 0.250742\tvalid_0's auc: 0.812537\n",
      "[500]\tvalid_0's binary_logloss: 0.245299\tvalid_0's auc: 0.812822\n",
      "[600]\tvalid_0's binary_logloss: 0.237414\tvalid_0's auc: 0.812947\n",
      "[700]\tvalid_0's binary_logloss: 0.235781\tvalid_0's auc: 0.813138\n",
      "[800]\tvalid_0's binary_logloss: 0.232972\tvalid_0's auc: 0.813232\n",
      "[900]\tvalid_0's binary_logloss: 0.232427\tvalid_0's auc: 0.813422\n",
      "[1000]\tvalid_0's binary_logloss: 0.23124\tvalid_0's auc: 0.81349\n",
      "[1100]\tvalid_0's binary_logloss: 0.230996\tvalid_0's auc: 0.813574\n",
      "[1200]\tvalid_0's binary_logloss: 0.230547\tvalid_0's auc: 0.813774\n",
      "[1300]\tvalid_0's binary_logloss: 0.2297\tvalid_0's auc: 0.813903\n",
      "[1400]\tvalid_0's binary_logloss: 0.229392\tvalid_0's auc: 0.81402\n",
      "[1500]\tvalid_0's binary_logloss: 0.229402\tvalid_0's auc: 0.814123\n",
      "[1600]\tvalid_0's binary_logloss: 0.229059\tvalid_0's auc: 0.814163\n",
      "Early stopping, best iteration is:\n",
      "[1589]\tvalid_0's binary_logloss: 0.228959\tvalid_0's auc: 0.814161\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.379406\tvalid_0's auc: 0.806158\n",
      "[200]\tvalid_0's binary_logloss: 0.302226\tvalid_0's auc: 0.808088\n",
      "[300]\tvalid_0's binary_logloss: 0.272214\tvalid_0's auc: 0.809154\n",
      "[400]\tvalid_0's binary_logloss: 0.252148\tvalid_0's auc: 0.809909\n",
      "[500]\tvalid_0's binary_logloss: 0.246746\tvalid_0's auc: 0.80997\n",
      "[600]\tvalid_0's binary_logloss: 0.238996\tvalid_0's auc: 0.810366\n",
      "[700]\tvalid_0's binary_logloss: 0.237335\tvalid_0's auc: 0.81052\n",
      "[800]\tvalid_0's binary_logloss: 0.234586\tvalid_0's auc: 0.810664\n",
      "[900]\tvalid_0's binary_logloss: 0.234037\tvalid_0's auc: 0.810818\n",
      "[1000]\tvalid_0's binary_logloss: 0.232887\tvalid_0's auc: 0.81095\n",
      "[1100]\tvalid_0's binary_logloss: 0.232627\tvalid_0's auc: 0.811081\n",
      "[1200]\tvalid_0's binary_logloss: 0.232202\tvalid_0's auc: 0.81116\n",
      "[1300]\tvalid_0's binary_logloss: 0.231411\tvalid_0's auc: 0.811344\n",
      "[1400]\tvalid_0's binary_logloss: 0.231125\tvalid_0's auc: 0.811451\n",
      "[1500]\tvalid_0's binary_logloss: 0.23113\tvalid_0's auc: 0.811516\n",
      "[1600]\tvalid_0's binary_logloss: 0.230794\tvalid_0's auc: 0.811583\n",
      "Early stopping, best iteration is:\n",
      "[1589]\tvalid_0's binary_logloss: 0.230705\tvalid_0's auc: 0.81158\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.379989\tvalid_0's auc: 0.796906\n",
      "[200]\tvalid_0's binary_logloss: 0.303146\tvalid_0's auc: 0.801177\n",
      "[300]\tvalid_0's binary_logloss: 0.27339\tvalid_0's auc: 0.802316\n",
      "[400]\tvalid_0's binary_logloss: 0.253657\tvalid_0's auc: 0.80257\n",
      "[500]\tvalid_0's binary_logloss: 0.248385\tvalid_0's auc: 0.802574\n",
      "Early stopping, best iteration is:\n",
      "[433]\tvalid_0's binary_logloss: 0.250874\tvalid_0's auc: 0.802642\n",
      "cv score - on train:\n",
      "0.8024170939855985\n",
      "('current score in fold:', 0.8089838442974304, 20)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.385167\tvalid_0's auc: 0.800944\n",
      "[200]\tvalid_0's binary_logloss: 0.29907\tvalid_0's auc: 0.803153\n",
      "[300]\tvalid_0's binary_logloss: 0.269437\tvalid_0's auc: 0.804514\n",
      "[400]\tvalid_0's binary_logloss: 0.255928\tvalid_0's auc: 0.804638\n",
      "[500]\tvalid_0's binary_logloss: 0.24864\tvalid_0's auc: 0.80491\n",
      "[600]\tvalid_0's binary_logloss: 0.245348\tvalid_0's auc: 0.8053\n",
      "[700]\tvalid_0's binary_logloss: 0.240702\tvalid_0's auc: 0.805516\n",
      "[800]\tvalid_0's binary_logloss: 0.238323\tvalid_0's auc: 0.805756\n",
      "[900]\tvalid_0's binary_logloss: 0.238171\tvalid_0's auc: 0.805885\n",
      "Early stopping, best iteration is:\n",
      "[827]\tvalid_0's binary_logloss: 0.237944\tvalid_0's auc: 0.805848\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.385103\tvalid_0's auc: 0.806107\n",
      "[200]\tvalid_0's binary_logloss: 0.298745\tvalid_0's auc: 0.807932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\tvalid_0's binary_logloss: 0.268889\tvalid_0's auc: 0.809508\n",
      "[400]\tvalid_0's binary_logloss: 0.255204\tvalid_0's auc: 0.809597\n",
      "[500]\tvalid_0's binary_logloss: 0.247799\tvalid_0's auc: 0.810256\n",
      "[600]\tvalid_0's binary_logloss: 0.244435\tvalid_0's auc: 0.810362\n",
      "[700]\tvalid_0's binary_logloss: 0.239647\tvalid_0's auc: 0.810444\n",
      "[800]\tvalid_0's binary_logloss: 0.237184\tvalid_0's auc: 0.810797\n",
      "[900]\tvalid_0's binary_logloss: 0.237013\tvalid_0's auc: 0.810849\n",
      "Early stopping, best iteration is:\n",
      "[827]\tvalid_0's binary_logloss: 0.236784\tvalid_0's auc: 0.810812\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.385065\tvalid_0's auc: 0.806157\n",
      "[200]\tvalid_0's binary_logloss: 0.29879\tvalid_0's auc: 0.80976\n",
      "[300]\tvalid_0's binary_logloss: 0.268971\tvalid_0's auc: 0.810763\n",
      "[400]\tvalid_0's binary_logloss: 0.25527\tvalid_0's auc: 0.811017\n",
      "[500]\tvalid_0's binary_logloss: 0.247845\tvalid_0's auc: 0.811174\n",
      "[600]\tvalid_0's binary_logloss: 0.244449\tvalid_0's auc: 0.811314\n",
      "[700]\tvalid_0's binary_logloss: 0.239652\tvalid_0's auc: 0.811495\n",
      "[800]\tvalid_0's binary_logloss: 0.237177\tvalid_0's auc: 0.811637\n",
      "[900]\tvalid_0's binary_logloss: 0.236995\tvalid_0's auc: 0.811687\n",
      "Early stopping, best iteration is:\n",
      "[827]\tvalid_0's binary_logloss: 0.236768\tvalid_0's auc: 0.81167\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.384852\tvalid_0's auc: 0.80525\n",
      "[200]\tvalid_0's binary_logloss: 0.298546\tvalid_0's auc: 0.806462\n",
      "[300]\tvalid_0's binary_logloss: 0.268755\tvalid_0's auc: 0.808931\n",
      "[400]\tvalid_0's binary_logloss: 0.255113\tvalid_0's auc: 0.809105\n",
      "[500]\tvalid_0's binary_logloss: 0.247723\tvalid_0's auc: 0.809388\n",
      "[600]\tvalid_0's binary_logloss: 0.244379\tvalid_0's auc: 0.809575\n",
      "[700]\tvalid_0's binary_logloss: 0.239657\tvalid_0's auc: 0.809562\n",
      "Early stopping, best iteration is:\n",
      "[601]\tvalid_0's binary_logloss: 0.244163\tvalid_0's auc: 0.809579\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.38496\tvalid_0's auc: 0.804176\n",
      "[200]\tvalid_0's binary_logloss: 0.298617\tvalid_0's auc: 0.807893\n",
      "[300]\tvalid_0's binary_logloss: 0.2688\tvalid_0's auc: 0.80924\n",
      "[400]\tvalid_0's binary_logloss: 0.255113\tvalid_0's auc: 0.809628\n",
      "[500]\tvalid_0's binary_logloss: 0.24772\tvalid_0's auc: 0.809968\n",
      "[600]\tvalid_0's binary_logloss: 0.244364\tvalid_0's auc: 0.810087\n",
      "Early stopping, best iteration is:\n",
      "[599]\tvalid_0's binary_logloss: 0.244582\tvalid_0's auc: 0.810089\n",
      "cv score - on train:\n",
      "0.8077684367751766\n",
      "('current score in fold:', 0.8090405650374523, 21)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.382\tvalid_0's auc: 0.80687\n",
      "[200]\tvalid_0's binary_logloss: 0.306539\tvalid_0's auc: 0.807899\n",
      "[300]\tvalid_0's binary_logloss: 0.270246\tvalid_0's auc: 0.810234\n",
      "[400]\tvalid_0's binary_logloss: 0.257316\tvalid_0's auc: 0.810427\n",
      "[500]\tvalid_0's binary_logloss: 0.250227\tvalid_0's auc: 0.810923\n",
      "[600]\tvalid_0's binary_logloss: 0.244312\tvalid_0's auc: 0.810971\n",
      "[700]\tvalid_0's binary_logloss: 0.240497\tvalid_0's auc: 0.810994\n",
      "[800]\tvalid_0's binary_logloss: 0.236873\tvalid_0's auc: 0.811174\n",
      "[900]\tvalid_0's binary_logloss: 0.236194\tvalid_0's auc: 0.811232\n",
      "[1000]\tvalid_0's binary_logloss: 0.234964\tvalid_0's auc: 0.811303\n",
      "[1100]\tvalid_0's binary_logloss: 0.232729\tvalid_0's auc: 0.811443\n",
      "[1200]\tvalid_0's binary_logloss: 0.232891\tvalid_0's auc: 0.811582\n",
      "[1300]\tvalid_0's binary_logloss: 0.23159\tvalid_0's auc: 0.811656\n",
      "[1400]\tvalid_0's binary_logloss: 0.230922\tvalid_0's auc: 0.811769\n",
      "[1500]\tvalid_0's binary_logloss: 0.230483\tvalid_0's auc: 0.811902\n",
      "[1600]\tvalid_0's binary_logloss: 0.230174\tvalid_0's auc: 0.811979\n",
      "[1700]\tvalid_0's binary_logloss: 0.230314\tvalid_0's auc: 0.812072\n",
      "Early stopping, best iteration is:\n",
      "[1609]\tvalid_0's binary_logloss: 0.230078\tvalid_0's auc: 0.811989\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.382034\tvalid_0's auc: 0.805356\n",
      "[200]\tvalid_0's binary_logloss: 0.306621\tvalid_0's auc: 0.808368\n",
      "[300]\tvalid_0's binary_logloss: 0.270321\tvalid_0's auc: 0.809951\n",
      "[400]\tvalid_0's binary_logloss: 0.257369\tvalid_0's auc: 0.810235\n",
      "[500]\tvalid_0's binary_logloss: 0.250281\tvalid_0's auc: 0.810575\n",
      "[600]\tvalid_0's binary_logloss: 0.244366\tvalid_0's auc: 0.810714\n",
      "Early stopping, best iteration is:\n",
      "[589]\tvalid_0's binary_logloss: 0.24497\tvalid_0's auc: 0.810726\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.382793\tvalid_0's auc: 0.804358\n",
      "[200]\tvalid_0's binary_logloss: 0.307612\tvalid_0's auc: 0.807568\n",
      "[300]\tvalid_0's binary_logloss: 0.27143\tvalid_0's auc: 0.809779\n",
      "[400]\tvalid_0's binary_logloss: 0.258483\tvalid_0's auc: 0.810058\n",
      "[500]\tvalid_0's binary_logloss: 0.251391\tvalid_0's auc: 0.810568\n",
      "[600]\tvalid_0's binary_logloss: 0.245476\tvalid_0's auc: 0.810607\n",
      "[700]\tvalid_0's binary_logloss: 0.241633\tvalid_0's auc: 0.810762\n",
      "[800]\tvalid_0's binary_logloss: 0.238018\tvalid_0's auc: 0.810897\n",
      "[900]\tvalid_0's binary_logloss: 0.237317\tvalid_0's auc: 0.810992\n",
      "[1000]\tvalid_0's binary_logloss: 0.236079\tvalid_0's auc: 0.81111\n",
      "[1100]\tvalid_0's binary_logloss: 0.233851\tvalid_0's auc: 0.811184\n",
      "[1200]\tvalid_0's binary_logloss: 0.234008\tvalid_0's auc: 0.81135\n",
      "[1300]\tvalid_0's binary_logloss: 0.232702\tvalid_0's auc: 0.811435\n",
      "[1400]\tvalid_0's binary_logloss: 0.232034\tvalid_0's auc: 0.811532\n",
      "[1500]\tvalid_0's binary_logloss: 0.231593\tvalid_0's auc: 0.811609\n",
      "[1600]\tvalid_0's binary_logloss: 0.231292\tvalid_0's auc: 0.811677\n",
      "[1700]\tvalid_0's binary_logloss: 0.231424\tvalid_0's auc: 0.811741\n",
      "Early stopping, best iteration is:\n",
      "[1609]\tvalid_0's binary_logloss: 0.231195\tvalid_0's auc: 0.811685\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.382514\tvalid_0's auc: 0.802096\n",
      "[200]\tvalid_0's binary_logloss: 0.307298\tvalid_0's auc: 0.806306\n",
      "[300]\tvalid_0's binary_logloss: 0.27113\tvalid_0's auc: 0.807788\n",
      "[400]\tvalid_0's binary_logloss: 0.258235\tvalid_0's auc: 0.808142\n",
      "[500]\tvalid_0's binary_logloss: 0.251166\tvalid_0's auc: 0.808477\n",
      "[600]\tvalid_0's binary_logloss: 0.245277\tvalid_0's auc: 0.808569\n",
      "[700]\tvalid_0's binary_logloss: 0.241474\tvalid_0's auc: 0.808992\n",
      "[800]\tvalid_0's binary_logloss: 0.237859\tvalid_0's auc: 0.809099\n",
      "[900]\tvalid_0's binary_logloss: 0.237181\tvalid_0's auc: 0.809131\n",
      "[1000]\tvalid_0's binary_logloss: 0.235978\tvalid_0's auc: 0.809347\n",
      "[1100]\tvalid_0's binary_logloss: 0.233754\tvalid_0's auc: 0.809454\n",
      "[1200]\tvalid_0's binary_logloss: 0.233919\tvalid_0's auc: 0.809492\n",
      "[1300]\tvalid_0's binary_logloss: 0.232618\tvalid_0's auc: 0.809616\n",
      "[1400]\tvalid_0's binary_logloss: 0.231955\tvalid_0's auc: 0.809744\n",
      "[1500]\tvalid_0's binary_logloss: 0.231521\tvalid_0's auc: 0.80986\n",
      "[1600]\tvalid_0's binary_logloss: 0.231211\tvalid_0's auc: 0.809999\n",
      "[1700]\tvalid_0's binary_logloss: 0.23134\tvalid_0's auc: 0.810105\n",
      "Early stopping, best iteration is:\n",
      "[1609]\tvalid_0's binary_logloss: 0.231114\tvalid_0's auc: 0.810009\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.382407\tvalid_0's auc: 0.799819\n",
      "[200]\tvalid_0's binary_logloss: 0.307173\tvalid_0's auc: 0.803346\n",
      "[300]\tvalid_0's binary_logloss: 0.27105\tvalid_0's auc: 0.804784\n",
      "[400]\tvalid_0's binary_logloss: 0.258209\tvalid_0's auc: 0.804752\n",
      "[500]\tvalid_0's binary_logloss: 0.251212\tvalid_0's auc: 0.805265\n",
      "Early stopping, best iteration is:\n",
      "[456]\tvalid_0's binary_logloss: 0.252678\tvalid_0's auc: 0.805321\n",
      "cv score - on train:\n",
      "0.7969797519762924\n",
      "('current score in fold:', 0.8090975768993284, 22)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.396635\tvalid_0's auc: 0.801418\n",
      "[200]\tvalid_0's binary_logloss: 0.310044\tvalid_0's auc: 0.804514\n",
      "[300]\tvalid_0's binary_logloss: 0.275084\tvalid_0's auc: 0.805817\n",
      "[400]\tvalid_0's binary_logloss: 0.257742\tvalid_0's auc: 0.806525\n",
      "[500]\tvalid_0's binary_logloss: 0.250518\tvalid_0's auc: 0.806566\n",
      "[600]\tvalid_0's binary_logloss: 0.244411\tvalid_0's auc: 0.806848\n",
      "[700]\tvalid_0's binary_logloss: 0.242213\tvalid_0's auc: 0.807012\n",
      "[800]\tvalid_0's binary_logloss: 0.237658\tvalid_0's auc: 0.807148\n",
      "[900]\tvalid_0's binary_logloss: 0.235411\tvalid_0's auc: 0.807306\n",
      "[1000]\tvalid_0's binary_logloss: 0.234635\tvalid_0's auc: 0.807423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1100]\tvalid_0's binary_logloss: 0.233436\tvalid_0's auc: 0.807589\n",
      "[1200]\tvalid_0's binary_logloss: 0.232991\tvalid_0's auc: 0.807662\n",
      "[1300]\tvalid_0's binary_logloss: 0.232752\tvalid_0's auc: 0.807748\n",
      "[1400]\tvalid_0's binary_logloss: 0.232494\tvalid_0's auc: 0.807821\n",
      "[1500]\tvalid_0's binary_logloss: 0.231895\tvalid_0's auc: 0.807951\n",
      "[1600]\tvalid_0's binary_logloss: 0.231889\tvalid_0's auc: 0.807985\n",
      "[1700]\tvalid_0's binary_logloss: 0.231867\tvalid_0's auc: 0.808045\n",
      "Early stopping, best iteration is:\n",
      "[1640]\tvalid_0's binary_logloss: 0.231772\tvalid_0's auc: 0.808014\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.396374\tvalid_0's auc: 0.803497\n",
      "[200]\tvalid_0's binary_logloss: 0.309573\tvalid_0's auc: 0.805267\n",
      "[300]\tvalid_0's binary_logloss: 0.274455\tvalid_0's auc: 0.808761\n",
      "[400]\tvalid_0's binary_logloss: 0.256998\tvalid_0's auc: 0.809009\n",
      "[500]\tvalid_0's binary_logloss: 0.249728\tvalid_0's auc: 0.809369\n",
      "[600]\tvalid_0's binary_logloss: 0.243566\tvalid_0's auc: 0.809608\n",
      "[700]\tvalid_0's binary_logloss: 0.241343\tvalid_0's auc: 0.809968\n",
      "[800]\tvalid_0's binary_logloss: 0.236727\tvalid_0's auc: 0.810071\n",
      "[900]\tvalid_0's binary_logloss: 0.234429\tvalid_0's auc: 0.810393\n",
      "[1000]\tvalid_0's binary_logloss: 0.233638\tvalid_0's auc: 0.810478\n",
      "[1100]\tvalid_0's binary_logloss: 0.232387\tvalid_0's auc: 0.81064\n",
      "[1200]\tvalid_0's binary_logloss: 0.231908\tvalid_0's auc: 0.810867\n",
      "[1300]\tvalid_0's binary_logloss: 0.231665\tvalid_0's auc: 0.810968\n",
      "[1400]\tvalid_0's binary_logloss: 0.231407\tvalid_0's auc: 0.811082\n",
      "[1500]\tvalid_0's binary_logloss: 0.230765\tvalid_0's auc: 0.811194\n",
      "[1600]\tvalid_0's binary_logloss: 0.230746\tvalid_0's auc: 0.811261\n",
      "[1700]\tvalid_0's binary_logloss: 0.230736\tvalid_0's auc: 0.811314\n",
      "Early stopping, best iteration is:\n",
      "[1640]\tvalid_0's binary_logloss: 0.230627\tvalid_0's auc: 0.811286\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.396659\tvalid_0's auc: 0.805203\n",
      "[200]\tvalid_0's binary_logloss: 0.309947\tvalid_0's auc: 0.807697\n",
      "[300]\tvalid_0's binary_logloss: 0.274848\tvalid_0's auc: 0.809578\n",
      "[400]\tvalid_0's binary_logloss: 0.257382\tvalid_0's auc: 0.810015\n",
      "[500]\tvalid_0's binary_logloss: 0.250073\tvalid_0's auc: 0.810562\n",
      "[600]\tvalid_0's binary_logloss: 0.243908\tvalid_0's auc: 0.810799\n",
      "[700]\tvalid_0's binary_logloss: 0.241671\tvalid_0's auc: 0.810818\n",
      "[800]\tvalid_0's binary_logloss: 0.237062\tvalid_0's auc: 0.810919\n",
      "[900]\tvalid_0's binary_logloss: 0.234764\tvalid_0's auc: 0.811054\n",
      "[1000]\tvalid_0's binary_logloss: 0.233957\tvalid_0's auc: 0.811128\n",
      "[1100]\tvalid_0's binary_logloss: 0.232713\tvalid_0's auc: 0.811266\n",
      "[1200]\tvalid_0's binary_logloss: 0.232249\tvalid_0's auc: 0.811393\n",
      "[1300]\tvalid_0's binary_logloss: 0.232013\tvalid_0's auc: 0.81162\n",
      "[1400]\tvalid_0's binary_logloss: 0.231748\tvalid_0's auc: 0.811708\n",
      "[1500]\tvalid_0's binary_logloss: 0.231123\tvalid_0's auc: 0.811811\n",
      "[1600]\tvalid_0's binary_logloss: 0.231108\tvalid_0's auc: 0.8119\n",
      "[1700]\tvalid_0's binary_logloss: 0.231084\tvalid_0's auc: 0.811967\n",
      "Early stopping, best iteration is:\n",
      "[1640]\tvalid_0's binary_logloss: 0.230984\tvalid_0's auc: 0.811939\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.396331\tvalid_0's auc: 0.804483\n",
      "[200]\tvalid_0's binary_logloss: 0.309518\tvalid_0's auc: 0.807439\n",
      "[300]\tvalid_0's binary_logloss: 0.274426\tvalid_0's auc: 0.809006\n",
      "[400]\tvalid_0's binary_logloss: 0.257006\tvalid_0's auc: 0.809113\n",
      "[500]\tvalid_0's binary_logloss: 0.249734\tvalid_0's auc: 0.809319\n",
      "Early stopping, best iteration is:\n",
      "[465]\tvalid_0's binary_logloss: 0.253678\tvalid_0's auc: 0.809339\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.396164\tvalid_0's auc: 0.80416\n",
      "[200]\tvalid_0's binary_logloss: 0.309337\tvalid_0's auc: 0.807433\n",
      "[300]\tvalid_0's binary_logloss: 0.274228\tvalid_0's auc: 0.808963\n",
      "[400]\tvalid_0's binary_logloss: 0.256784\tvalid_0's auc: 0.80951\n",
      "[500]\tvalid_0's binary_logloss: 0.249524\tvalid_0's auc: 0.809688\n",
      "[600]\tvalid_0's binary_logloss: 0.243376\tvalid_0's auc: 0.809833\n",
      "[700]\tvalid_0's binary_logloss: 0.241144\tvalid_0's auc: 0.810126\n",
      "[800]\tvalid_0's binary_logloss: 0.236558\tvalid_0's auc: 0.810383\n",
      "[900]\tvalid_0's binary_logloss: 0.234296\tvalid_0's auc: 0.810555\n",
      "[1000]\tvalid_0's binary_logloss: 0.233501\tvalid_0's auc: 0.810856\n",
      "[1100]\tvalid_0's binary_logloss: 0.232287\tvalid_0's auc: 0.811004\n",
      "[1200]\tvalid_0's binary_logloss: 0.231828\tvalid_0's auc: 0.811137\n",
      "[1300]\tvalid_0's binary_logloss: 0.231598\tvalid_0's auc: 0.811223\n",
      "[1400]\tvalid_0's binary_logloss: 0.231339\tvalid_0's auc: 0.811304\n",
      "[1500]\tvalid_0's binary_logloss: 0.230724\tvalid_0's auc: 0.811459\n",
      "[1600]\tvalid_0's binary_logloss: 0.230716\tvalid_0's auc: 0.811506\n",
      "[1700]\tvalid_0's binary_logloss: 0.230704\tvalid_0's auc: 0.811524\n",
      "Early stopping, best iteration is:\n",
      "[1640]\tvalid_0's binary_logloss: 0.230611\tvalid_0's auc: 0.811501\n",
      "cv score - on train:\n",
      "0.8001050767497597\n",
      "('current score in fold:', 0.809157047266027, 23)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.3592\tvalid_0's auc: 0.804835\n",
      "[200]\tvalid_0's binary_logloss: 0.293969\tvalid_0's auc: 0.808068\n",
      "[300]\tvalid_0's binary_logloss: 0.274132\tvalid_0's auc: 0.808807\n",
      "[400]\tvalid_0's binary_logloss: 0.257957\tvalid_0's auc: 0.809033\n",
      "[500]\tvalid_0's binary_logloss: 0.251886\tvalid_0's auc: 0.809156\n",
      "[600]\tvalid_0's binary_logloss: 0.246327\tvalid_0's auc: 0.809352\n",
      "[700]\tvalid_0's binary_logloss: 0.242838\tvalid_0's auc: 0.809582\n",
      "[800]\tvalid_0's binary_logloss: 0.238375\tvalid_0's auc: 0.809816\n",
      "[900]\tvalid_0's binary_logloss: 0.235686\tvalid_0's auc: 0.810026\n",
      "[1000]\tvalid_0's binary_logloss: 0.234616\tvalid_0's auc: 0.810103\n",
      "[1100]\tvalid_0's binary_logloss: 0.233997\tvalid_0's auc: 0.810163\n",
      "[1200]\tvalid_0's binary_logloss: 0.232882\tvalid_0's auc: 0.810379\n",
      "[1300]\tvalid_0's binary_logloss: 0.232555\tvalid_0's auc: 0.810453\n",
      "[1400]\tvalid_0's binary_logloss: 0.231587\tvalid_0's auc: 0.810647\n",
      "[1500]\tvalid_0's binary_logloss: 0.231234\tvalid_0's auc: 0.810775\n",
      "[1600]\tvalid_0's binary_logloss: 0.230758\tvalid_0's auc: 0.810848\n",
      "[1700]\tvalid_0's binary_logloss: 0.230715\tvalid_0's auc: 0.810923\n",
      "[1800]\tvalid_0's binary_logloss: 0.230522\tvalid_0's auc: 0.810966\n",
      "[1900]\tvalid_0's binary_logloss: 0.230842\tvalid_0's auc: 0.811\n",
      "Early stopping, best iteration is:\n",
      "[1804]\tvalid_0's binary_logloss: 0.23051\tvalid_0's auc: 0.810964\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.359697\tvalid_0's auc: 0.801416\n",
      "[200]\tvalid_0's binary_logloss: 0.2947\tvalid_0's auc: 0.804269\n",
      "[300]\tvalid_0's binary_logloss: 0.274952\tvalid_0's auc: 0.805958\n",
      "[400]\tvalid_0's binary_logloss: 0.258847\tvalid_0's auc: 0.806398\n",
      "[500]\tvalid_0's binary_logloss: 0.252798\tvalid_0's auc: 0.806572\n",
      "[600]\tvalid_0's binary_logloss: 0.247295\tvalid_0's auc: 0.806595\n",
      "[700]\tvalid_0's binary_logloss: 0.243851\tvalid_0's auc: 0.806974\n",
      "[800]\tvalid_0's binary_logloss: 0.239433\tvalid_0's auc: 0.807166\n",
      "[900]\tvalid_0's binary_logloss: 0.236804\tvalid_0's auc: 0.807239\n",
      "[1000]\tvalid_0's binary_logloss: 0.235748\tvalid_0's auc: 0.807353\n",
      "[1100]\tvalid_0's binary_logloss: 0.23514\tvalid_0's auc: 0.807427\n",
      "[1200]\tvalid_0's binary_logloss: 0.234059\tvalid_0's auc: 0.80753\n",
      "[1300]\tvalid_0's binary_logloss: 0.233736\tvalid_0's auc: 0.807632\n",
      "[1400]\tvalid_0's binary_logloss: 0.232802\tvalid_0's auc: 0.807743\n",
      "[1500]\tvalid_0's binary_logloss: 0.232473\tvalid_0's auc: 0.807802\n",
      "[1600]\tvalid_0's binary_logloss: 0.231989\tvalid_0's auc: 0.807932\n",
      "[1700]\tvalid_0's binary_logloss: 0.231943\tvalid_0's auc: 0.807992\n",
      "[1800]\tvalid_0's binary_logloss: 0.231757\tvalid_0's auc: 0.808051\n",
      "[1900]\tvalid_0's binary_logloss: 0.232055\tvalid_0's auc: 0.808144\n",
      "Early stopping, best iteration is:\n",
      "[1804]\tvalid_0's binary_logloss: 0.231746\tvalid_0's auc: 0.80805\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.35959\tvalid_0's auc: 0.803523\n",
      "[200]\tvalid_0's binary_logloss: 0.294502\tvalid_0's auc: 0.80615\n",
      "[300]\tvalid_0's binary_logloss: 0.27469\tvalid_0's auc: 0.807039\n",
      "[400]\tvalid_0's binary_logloss: 0.258544\tvalid_0's auc: 0.807433\n",
      "[500]\tvalid_0's binary_logloss: 0.252508\tvalid_0's auc: 0.807629\n",
      "[600]\tvalid_0's binary_logloss: 0.246991\tvalid_0's auc: 0.807549\n",
      "Early stopping, best iteration is:\n",
      "[501]\tvalid_0's binary_logloss: 0.252739\tvalid_0's auc: 0.80763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.358853\tvalid_0's auc: 0.808935\n",
      "[200]\tvalid_0's binary_logloss: 0.293558\tvalid_0's auc: 0.811394\n",
      "[300]\tvalid_0's binary_logloss: 0.273673\tvalid_0's auc: 0.812052\n",
      "[400]\tvalid_0's binary_logloss: 0.257442\tvalid_0's auc: 0.812272\n",
      "[500]\tvalid_0's binary_logloss: 0.251334\tvalid_0's auc: 0.81248\n",
      "[600]\tvalid_0's binary_logloss: 0.245734\tvalid_0's auc: 0.812614\n",
      "[700]\tvalid_0's binary_logloss: 0.242224\tvalid_0's auc: 0.812769\n",
      "[800]\tvalid_0's binary_logloss: 0.237704\tvalid_0's auc: 0.812861\n",
      "[900]\tvalid_0's binary_logloss: 0.234966\tvalid_0's auc: 0.81313\n",
      "[1000]\tvalid_0's binary_logloss: 0.233872\tvalid_0's auc: 0.813217\n",
      "[1100]\tvalid_0's binary_logloss: 0.233221\tvalid_0's auc: 0.813329\n",
      "[1200]\tvalid_0's binary_logloss: 0.232087\tvalid_0's auc: 0.81346\n",
      "[1300]\tvalid_0's binary_logloss: 0.231751\tvalid_0's auc: 0.813547\n",
      "[1400]\tvalid_0's binary_logloss: 0.230774\tvalid_0's auc: 0.813679\n",
      "[1500]\tvalid_0's binary_logloss: 0.2304\tvalid_0's auc: 0.813773\n",
      "[1600]\tvalid_0's binary_logloss: 0.229906\tvalid_0's auc: 0.813891\n",
      "[1700]\tvalid_0's binary_logloss: 0.229849\tvalid_0's auc: 0.813964\n",
      "[1800]\tvalid_0's binary_logloss: 0.229636\tvalid_0's auc: 0.814058\n",
      "[1900]\tvalid_0's binary_logloss: 0.229969\tvalid_0's auc: 0.814106\n",
      "Early stopping, best iteration is:\n",
      "[1804]\tvalid_0's binary_logloss: 0.229626\tvalid_0's auc: 0.814058\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.359756\tvalid_0's auc: 0.803161\n",
      "[200]\tvalid_0's binary_logloss: 0.294731\tvalid_0's auc: 0.807131\n",
      "[300]\tvalid_0's binary_logloss: 0.274923\tvalid_0's auc: 0.808344\n",
      "[400]\tvalid_0's binary_logloss: 0.258768\tvalid_0's auc: 0.808784\n",
      "[500]\tvalid_0's binary_logloss: 0.252702\tvalid_0's auc: 0.808788\n",
      "[600]\tvalid_0's binary_logloss: 0.247158\tvalid_0's auc: 0.808957\n",
      "[700]\tvalid_0's binary_logloss: 0.243695\tvalid_0's auc: 0.809203\n",
      "[800]\tvalid_0's binary_logloss: 0.239242\tvalid_0's auc: 0.809336\n",
      "[900]\tvalid_0's binary_logloss: 0.236564\tvalid_0's auc: 0.809454\n",
      "[1000]\tvalid_0's binary_logloss: 0.235493\tvalid_0's auc: 0.809595\n",
      "[1100]\tvalid_0's binary_logloss: 0.234861\tvalid_0's auc: 0.809653\n",
      "[1200]\tvalid_0's binary_logloss: 0.233749\tvalid_0's auc: 0.809733\n",
      "[1300]\tvalid_0's binary_logloss: 0.233402\tvalid_0's auc: 0.809913\n",
      "[1400]\tvalid_0's binary_logloss: 0.232448\tvalid_0's auc: 0.810012\n",
      "[1500]\tvalid_0's binary_logloss: 0.23209\tvalid_0's auc: 0.810112\n",
      "[1600]\tvalid_0's binary_logloss: 0.231595\tvalid_0's auc: 0.81023\n",
      "[1700]\tvalid_0's binary_logloss: 0.231532\tvalid_0's auc: 0.810446\n",
      "[1800]\tvalid_0's binary_logloss: 0.231326\tvalid_0's auc: 0.810522\n",
      "[1900]\tvalid_0's binary_logloss: 0.231633\tvalid_0's auc: 0.810583\n",
      "Early stopping, best iteration is:\n",
      "[1804]\tvalid_0's binary_logloss: 0.231315\tvalid_0's auc: 0.810521\n",
      "cv score - on train:\n",
      "0.8001182690726727\n",
      "('current score in fold:', 0.8092158614329512, 24)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.373277\tvalid_0's auc: 0.803303\n",
      "[200]\tvalid_0's binary_logloss: 0.296288\tvalid_0's auc: 0.805432\n",
      "[300]\tvalid_0's binary_logloss: 0.269921\tvalid_0's auc: 0.806504\n",
      "[400]\tvalid_0's binary_logloss: 0.256715\tvalid_0's auc: 0.806781\n",
      "Early stopping, best iteration is:\n",
      "[369]\tvalid_0's binary_logloss: 0.258154\tvalid_0's auc: 0.806798\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.373229\tvalid_0's auc: 0.806533\n",
      "[200]\tvalid_0's binary_logloss: 0.296065\tvalid_0's auc: 0.809775\n",
      "[300]\tvalid_0's binary_logloss: 0.269594\tvalid_0's auc: 0.810395\n",
      "[400]\tvalid_0's binary_logloss: 0.256285\tvalid_0's auc: 0.810871\n",
      "[500]\tvalid_0's binary_logloss: 0.24793\tvalid_0's auc: 0.811176\n",
      "[600]\tvalid_0's binary_logloss: 0.242088\tvalid_0's auc: 0.811392\n",
      "[700]\tvalid_0's binary_logloss: 0.240247\tvalid_0's auc: 0.811431\n",
      "[800]\tvalid_0's binary_logloss: 0.238649\tvalid_0's auc: 0.811653\n",
      "[900]\tvalid_0's binary_logloss: 0.236572\tvalid_0's auc: 0.811677\n",
      "[1000]\tvalid_0's binary_logloss: 0.235378\tvalid_0's auc: 0.811729\n",
      "[1100]\tvalid_0's binary_logloss: 0.233719\tvalid_0's auc: 0.811901\n",
      "[1200]\tvalid_0's binary_logloss: 0.233411\tvalid_0's auc: 0.812037\n",
      "[1300]\tvalid_0's binary_logloss: 0.232557\tvalid_0's auc: 0.812219\n",
      "[1400]\tvalid_0's binary_logloss: 0.231272\tvalid_0's auc: 0.812441\n",
      "[1500]\tvalid_0's binary_logloss: 0.231165\tvalid_0's auc: 0.812527\n",
      "[1600]\tvalid_0's binary_logloss: 0.231048\tvalid_0's auc: 0.812615\n",
      "[1700]\tvalid_0's binary_logloss: 0.230762\tvalid_0's auc: 0.812673\n",
      "Early stopping, best iteration is:\n",
      "[1689]\tvalid_0's binary_logloss: 0.230548\tvalid_0's auc: 0.81267\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.372476\tvalid_0's auc: 0.803194\n",
      "[200]\tvalid_0's binary_logloss: 0.29523\tvalid_0's auc: 0.807501\n",
      "[300]\tvalid_0's binary_logloss: 0.268748\tvalid_0's auc: 0.808587\n",
      "[400]\tvalid_0's binary_logloss: 0.255469\tvalid_0's auc: 0.809021\n",
      "[500]\tvalid_0's binary_logloss: 0.247156\tvalid_0's auc: 0.809272\n",
      "[600]\tvalid_0's binary_logloss: 0.241359\tvalid_0's auc: 0.809366\n",
      "[700]\tvalid_0's binary_logloss: 0.239556\tvalid_0's auc: 0.809649\n",
      "[800]\tvalid_0's binary_logloss: 0.237998\tvalid_0's auc: 0.809761\n",
      "[900]\tvalid_0's binary_logloss: 0.235977\tvalid_0's auc: 0.809884\n",
      "[1000]\tvalid_0's binary_logloss: 0.234838\tvalid_0's auc: 0.810054\n",
      "[1100]\tvalid_0's binary_logloss: 0.23324\tvalid_0's auc: 0.810216\n",
      "[1200]\tvalid_0's binary_logloss: 0.23294\tvalid_0's auc: 0.810301\n",
      "[1300]\tvalid_0's binary_logloss: 0.232133\tvalid_0's auc: 0.81044\n",
      "[1400]\tvalid_0's binary_logloss: 0.230944\tvalid_0's auc: 0.810581\n",
      "[1500]\tvalid_0's binary_logloss: 0.230854\tvalid_0's auc: 0.810707\n",
      "[1600]\tvalid_0's binary_logloss: 0.230754\tvalid_0's auc: 0.810803\n",
      "[1700]\tvalid_0's binary_logloss: 0.230499\tvalid_0's auc: 0.810849\n",
      "Early stopping, best iteration is:\n",
      "[1689]\tvalid_0's binary_logloss: 0.230299\tvalid_0's auc: 0.810848\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.372876\tvalid_0's auc: 0.805866\n",
      "[200]\tvalid_0's binary_logloss: 0.29567\tvalid_0's auc: 0.808269\n",
      "[300]\tvalid_0's binary_logloss: 0.269181\tvalid_0's auc: 0.809331\n",
      "[400]\tvalid_0's binary_logloss: 0.255931\tvalid_0's auc: 0.809439\n",
      "[500]\tvalid_0's binary_logloss: 0.247621\tvalid_0's auc: 0.809706\n",
      "[600]\tvalid_0's binary_logloss: 0.24181\tvalid_0's auc: 0.809971\n",
      "[700]\tvalid_0's binary_logloss: 0.240009\tvalid_0's auc: 0.810189\n",
      "[800]\tvalid_0's binary_logloss: 0.238428\tvalid_0's auc: 0.810352\n",
      "[900]\tvalid_0's binary_logloss: 0.236362\tvalid_0's auc: 0.810494\n",
      "[1000]\tvalid_0's binary_logloss: 0.235189\tvalid_0's auc: 0.810594\n",
      "[1100]\tvalid_0's binary_logloss: 0.23354\tvalid_0's auc: 0.810825\n",
      "[1200]\tvalid_0's binary_logloss: 0.233225\tvalid_0's auc: 0.810908\n",
      "[1300]\tvalid_0's binary_logloss: 0.23241\tvalid_0's auc: 0.811005\n",
      "[1400]\tvalid_0's binary_logloss: 0.231163\tvalid_0's auc: 0.811309\n",
      "[1500]\tvalid_0's binary_logloss: 0.231049\tvalid_0's auc: 0.811486\n",
      "[1600]\tvalid_0's binary_logloss: 0.230943\tvalid_0's auc: 0.811569\n",
      "[1700]\tvalid_0's binary_logloss: 0.230664\tvalid_0's auc: 0.81165\n",
      "Early stopping, best iteration is:\n",
      "[1689]\tvalid_0's binary_logloss: 0.230456\tvalid_0's auc: 0.811648\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.373599\tvalid_0's auc: 0.803389\n",
      "[200]\tvalid_0's binary_logloss: 0.296654\tvalid_0's auc: 0.805997\n",
      "[300]\tvalid_0's binary_logloss: 0.270265\tvalid_0's auc: 0.80806\n",
      "[400]\tvalid_0's binary_logloss: 0.257001\tvalid_0's auc: 0.808641\n",
      "[500]\tvalid_0's binary_logloss: 0.248694\tvalid_0's auc: 0.808727\n",
      "[600]\tvalid_0's binary_logloss: 0.24288\tvalid_0's auc: 0.809044\n",
      "[700]\tvalid_0's binary_logloss: 0.241043\tvalid_0's auc: 0.809115\n",
      "[800]\tvalid_0's binary_logloss: 0.23947\tvalid_0's auc: 0.809166\n",
      "[900]\tvalid_0's binary_logloss: 0.237383\tvalid_0's auc: 0.809316\n",
      "[1000]\tvalid_0's binary_logloss: 0.236209\tvalid_0's auc: 0.809371\n",
      "[1100]\tvalid_0's binary_logloss: 0.234574\tvalid_0's auc: 0.809507\n",
      "[1200]\tvalid_0's binary_logloss: 0.234267\tvalid_0's auc: 0.809574\n",
      "[1300]\tvalid_0's binary_logloss: 0.233429\tvalid_0's auc: 0.809733\n",
      "[1400]\tvalid_0's binary_logloss: 0.232207\tvalid_0's auc: 0.809773\n",
      "[1500]\tvalid_0's binary_logloss: 0.232106\tvalid_0's auc: 0.80984\n",
      "[1600]\tvalid_0's binary_logloss: 0.231996\tvalid_0's auc: 0.809908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1700]\tvalid_0's binary_logloss: 0.231727\tvalid_0's auc: 0.810002\n",
      "Early stopping, best iteration is:\n",
      "[1689]\tvalid_0's binary_logloss: 0.23152\tvalid_0's auc: 0.809981\n",
      "cv score - on train:\n",
      "0.7968490304976077\n",
      "('current score in fold:', 0.8092856421872019, 25)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.36444\tvalid_0's auc: 0.800612\n",
      "[200]\tvalid_0's binary_logloss: 0.302738\tvalid_0's auc: 0.803366\n",
      "[300]\tvalid_0's binary_logloss: 0.278432\tvalid_0's auc: 0.804685\n",
      "[400]\tvalid_0's binary_logloss: 0.260854\tvalid_0's auc: 0.804664\n",
      "Early stopping, best iteration is:\n",
      "[352]\tvalid_0's binary_logloss: 0.267871\tvalid_0's auc: 0.80472\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.364345\tvalid_0's auc: 0.803103\n",
      "[200]\tvalid_0's binary_logloss: 0.30263\tvalid_0's auc: 0.805264\n",
      "[300]\tvalid_0's binary_logloss: 0.278292\tvalid_0's auc: 0.806792\n",
      "[400]\tvalid_0's binary_logloss: 0.260673\tvalid_0's auc: 0.80689\n",
      "[500]\tvalid_0's binary_logloss: 0.250199\tvalid_0's auc: 0.807091\n",
      "[600]\tvalid_0's binary_logloss: 0.24673\tvalid_0's auc: 0.807505\n",
      "[700]\tvalid_0's binary_logloss: 0.242578\tvalid_0's auc: 0.807752\n",
      "[800]\tvalid_0's binary_logloss: 0.239077\tvalid_0's auc: 0.808032\n",
      "[900]\tvalid_0's binary_logloss: 0.237501\tvalid_0's auc: 0.808127\n",
      "[1000]\tvalid_0's binary_logloss: 0.235131\tvalid_0's auc: 0.808271\n",
      "[1100]\tvalid_0's binary_logloss: 0.234495\tvalid_0's auc: 0.808361\n",
      "[1200]\tvalid_0's binary_logloss: 0.234001\tvalid_0's auc: 0.80844\n",
      "[1300]\tvalid_0's binary_logloss: 0.233234\tvalid_0's auc: 0.808524\n",
      "[1400]\tvalid_0's binary_logloss: 0.233316\tvalid_0's auc: 0.808579\n",
      "[1500]\tvalid_0's binary_logloss: 0.232809\tvalid_0's auc: 0.808646\n",
      "Early stopping, best iteration is:\n",
      "[1475]\tvalid_0's binary_logloss: 0.232558\tvalid_0's auc: 0.808626\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.36404\tvalid_0's auc: 0.803788\n",
      "[200]\tvalid_0's binary_logloss: 0.302301\tvalid_0's auc: 0.807774\n",
      "[300]\tvalid_0's binary_logloss: 0.277955\tvalid_0's auc: 0.808555\n",
      "[400]\tvalid_0's binary_logloss: 0.260308\tvalid_0's auc: 0.808927\n",
      "[500]\tvalid_0's binary_logloss: 0.249776\tvalid_0's auc: 0.809294\n",
      "[600]\tvalid_0's binary_logloss: 0.246279\tvalid_0's auc: 0.809407\n",
      "Early stopping, best iteration is:\n",
      "[562]\tvalid_0's binary_logloss: 0.249831\tvalid_0's auc: 0.809416\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.364171\tvalid_0's auc: 0.808706\n",
      "[200]\tvalid_0's binary_logloss: 0.302296\tvalid_0's auc: 0.810286\n",
      "[300]\tvalid_0's binary_logloss: 0.277857\tvalid_0's auc: 0.811869\n",
      "[400]\tvalid_0's binary_logloss: 0.260048\tvalid_0's auc: 0.812438\n",
      "[500]\tvalid_0's binary_logloss: 0.249434\tvalid_0's auc: 0.812516\n",
      "Early stopping, best iteration is:\n",
      "[457]\tvalid_0's binary_logloss: 0.256591\tvalid_0's auc: 0.812545\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.363606\tvalid_0's auc: 0.807516\n",
      "[200]\tvalid_0's binary_logloss: 0.301635\tvalid_0's auc: 0.810112\n",
      "[300]\tvalid_0's binary_logloss: 0.277178\tvalid_0's auc: 0.810973\n",
      "[400]\tvalid_0's binary_logloss: 0.259402\tvalid_0's auc: 0.811213\n",
      "[500]\tvalid_0's binary_logloss: 0.248792\tvalid_0's auc: 0.81126\n",
      "[600]\tvalid_0's binary_logloss: 0.24526\tvalid_0's auc: 0.81168\n",
      "[700]\tvalid_0's binary_logloss: 0.241047\tvalid_0's auc: 0.811838\n",
      "[800]\tvalid_0's binary_logloss: 0.237455\tvalid_0's auc: 0.811983\n",
      "[900]\tvalid_0's binary_logloss: 0.235841\tvalid_0's auc: 0.8123\n",
      "[1000]\tvalid_0's binary_logloss: 0.233386\tvalid_0's auc: 0.812448\n",
      "[1100]\tvalid_0's binary_logloss: 0.232724\tvalid_0's auc: 0.812545\n",
      "[1200]\tvalid_0's binary_logloss: 0.232214\tvalid_0's auc: 0.812578\n",
      "[1300]\tvalid_0's binary_logloss: 0.231416\tvalid_0's auc: 0.812665\n",
      "[1400]\tvalid_0's binary_logloss: 0.231503\tvalid_0's auc: 0.812709\n",
      "[1500]\tvalid_0's binary_logloss: 0.230984\tvalid_0's auc: 0.812797\n",
      "Early stopping, best iteration is:\n",
      "[1475]\tvalid_0's binary_logloss: 0.230711\tvalid_0's auc: 0.812787\n",
      "cv score - on train:\n",
      "0.789256754506167\n",
      "('current score in fold:', 0.8092926805532076, 26)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.365601\tvalid_0's auc: 0.809554\n",
      "[200]\tvalid_0's binary_logloss: 0.291716\tvalid_0's auc: 0.812863\n",
      "[300]\tvalid_0's binary_logloss: 0.269976\tvalid_0's auc: 0.814093\n",
      "[400]\tvalid_0's binary_logloss: 0.2555\tvalid_0's auc: 0.814181\n",
      "Early stopping, best iteration is:\n",
      "[341]\tvalid_0's binary_logloss: 0.264446\tvalid_0's auc: 0.814196\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.366168\tvalid_0's auc: 0.805396\n",
      "[200]\tvalid_0's binary_logloss: 0.292665\tvalid_0's auc: 0.807373\n",
      "[300]\tvalid_0's binary_logloss: 0.271132\tvalid_0's auc: 0.809021\n",
      "[400]\tvalid_0's binary_logloss: 0.256845\tvalid_0's auc: 0.809434\n",
      "[500]\tvalid_0's binary_logloss: 0.24438\tvalid_0's auc: 0.809681\n",
      "[600]\tvalid_0's binary_logloss: 0.237386\tvalid_0's auc: 0.810008\n",
      "[700]\tvalid_0's binary_logloss: 0.235893\tvalid_0's auc: 0.810212\n",
      "[800]\tvalid_0's binary_logloss: 0.234131\tvalid_0's auc: 0.810428\n",
      "[900]\tvalid_0's binary_logloss: 0.232733\tvalid_0's auc: 0.81072\n",
      "Early stopping, best iteration is:\n",
      "[860]\tvalid_0's binary_logloss: 0.232458\tvalid_0's auc: 0.810665\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.366968\tvalid_0's auc: 0.794752\n",
      "[200]\tvalid_0's binary_logloss: 0.293914\tvalid_0's auc: 0.798828\n",
      "[300]\tvalid_0's binary_logloss: 0.272651\tvalid_0's auc: 0.799801\n",
      "[400]\tvalid_0's binary_logloss: 0.258587\tvalid_0's auc: 0.800165\n",
      "[500]\tvalid_0's binary_logloss: 0.246415\tvalid_0's auc: 0.80039\n",
      "[600]\tvalid_0's binary_logloss: 0.239677\tvalid_0's auc: 0.800663\n",
      "[700]\tvalid_0's binary_logloss: 0.238278\tvalid_0's auc: 0.80091\n",
      "[800]\tvalid_0's binary_logloss: 0.236613\tvalid_0's auc: 0.801045\n",
      "[900]\tvalid_0's binary_logloss: 0.235303\tvalid_0's auc: 0.801424\n",
      "Early stopping, best iteration is:\n",
      "[860]\tvalid_0's binary_logloss: 0.235031\tvalid_0's auc: 0.801328\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.365568\tvalid_0's auc: 0.807105\n",
      "[200]\tvalid_0's binary_logloss: 0.29185\tvalid_0's auc: 0.809774\n",
      "[300]\tvalid_0's binary_logloss: 0.270251\tvalid_0's auc: 0.810952\n",
      "[400]\tvalid_0's binary_logloss: 0.255914\tvalid_0's auc: 0.810967\n",
      "Early stopping, best iteration is:\n",
      "[302]\tvalid_0's binary_logloss: 0.269124\tvalid_0's auc: 0.810974\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.366145\tvalid_0's auc: 0.806259\n",
      "[200]\tvalid_0's binary_logloss: 0.292513\tvalid_0's auc: 0.807744\n",
      "[300]\tvalid_0's binary_logloss: 0.270951\tvalid_0's auc: 0.808366\n",
      "[400]\tvalid_0's binary_logloss: 0.256633\tvalid_0's auc: 0.808431\n",
      "[500]\tvalid_0's binary_logloss: 0.244162\tvalid_0's auc: 0.808824\n",
      "[600]\tvalid_0's binary_logloss: 0.237172\tvalid_0's auc: 0.809396\n",
      "[700]\tvalid_0's binary_logloss: 0.235732\tvalid_0's auc: 0.809681\n",
      "[800]\tvalid_0's binary_logloss: 0.233976\tvalid_0's auc: 0.809827\n",
      "[900]\tvalid_0's binary_logloss: 0.232574\tvalid_0's auc: 0.810177\n",
      "Early stopping, best iteration is:\n",
      "[860]\tvalid_0's binary_logloss: 0.232278\tvalid_0's auc: 0.810051\n",
      "cv score - on train:\n",
      "0.7833206751613117\n",
      "('current score in fold:', 0.8092048978380668, 27)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.374149\tvalid_0's auc: 0.802181\n",
      "[200]\tvalid_0's binary_logloss: 0.303716\tvalid_0's auc: 0.804961\n",
      "[300]\tvalid_0's binary_logloss: 0.270268\tvalid_0's auc: 0.80695\n",
      "[400]\tvalid_0's binary_logloss: 0.259067\tvalid_0's auc: 0.80728\n",
      "[500]\tvalid_0's binary_logloss: 0.247143\tvalid_0's auc: 0.807607\n",
      "[600]\tvalid_0's binary_logloss: 0.242281\tvalid_0's auc: 0.807884\n",
      "[700]\tvalid_0's binary_logloss: 0.240787\tvalid_0's auc: 0.807993\n",
      "[800]\tvalid_0's binary_logloss: 0.238797\tvalid_0's auc: 0.808165\n",
      "[900]\tvalid_0's binary_logloss: 0.236606\tvalid_0's auc: 0.808233\n",
      "[1000]\tvalid_0's binary_logloss: 0.235489\tvalid_0's auc: 0.808301\n",
      "[1100]\tvalid_0's binary_logloss: 0.23467\tvalid_0's auc: 0.808384\n",
      "[1200]\tvalid_0's binary_logloss: 0.233189\tvalid_0's auc: 0.808561\n",
      "[1300]\tvalid_0's binary_logloss: 0.23292\tvalid_0's auc: 0.808751\n",
      "Early stopping, best iteration is:\n",
      "[1241]\tvalid_0's binary_logloss: 0.232714\tvalid_0's auc: 0.808678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.373985\tvalid_0's auc: 0.804894\n",
      "[200]\tvalid_0's binary_logloss: 0.303557\tvalid_0's auc: 0.80539\n",
      "[300]\tvalid_0's binary_logloss: 0.270128\tvalid_0's auc: 0.807297\n",
      "[400]\tvalid_0's binary_logloss: 0.258939\tvalid_0's auc: 0.807411\n",
      "[500]\tvalid_0's binary_logloss: 0.247027\tvalid_0's auc: 0.807698\n",
      "[600]\tvalid_0's binary_logloss: 0.242143\tvalid_0's auc: 0.807998\n",
      "[700]\tvalid_0's binary_logloss: 0.240644\tvalid_0's auc: 0.808139\n",
      "[800]\tvalid_0's binary_logloss: 0.238663\tvalid_0's auc: 0.808119\n",
      "Early stopping, best iteration is:\n",
      "[742]\tvalid_0's binary_logloss: 0.238481\tvalid_0's auc: 0.808144\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.374145\tvalid_0's auc: 0.801339\n",
      "[200]\tvalid_0's binary_logloss: 0.303732\tvalid_0's auc: 0.805566\n",
      "[300]\tvalid_0's binary_logloss: 0.2703\tvalid_0's auc: 0.807657\n",
      "[400]\tvalid_0's binary_logloss: 0.259103\tvalid_0's auc: 0.808024\n",
      "[500]\tvalid_0's binary_logloss: 0.247158\tvalid_0's auc: 0.808377\n",
      "[600]\tvalid_0's binary_logloss: 0.242265\tvalid_0's auc: 0.808842\n",
      "[700]\tvalid_0's binary_logloss: 0.24076\tvalid_0's auc: 0.808921\n",
      "[800]\tvalid_0's binary_logloss: 0.238754\tvalid_0's auc: 0.809011\n",
      "[900]\tvalid_0's binary_logloss: 0.236516\tvalid_0's auc: 0.809142\n",
      "[1000]\tvalid_0's binary_logloss: 0.235371\tvalid_0's auc: 0.809276\n",
      "[1100]\tvalid_0's binary_logloss: 0.234524\tvalid_0's auc: 0.809364\n",
      "[1200]\tvalid_0's binary_logloss: 0.233008\tvalid_0's auc: 0.809494\n",
      "[1300]\tvalid_0's binary_logloss: 0.23272\tvalid_0's auc: 0.809669\n",
      "Early stopping, best iteration is:\n",
      "[1243]\tvalid_0's binary_logloss: 0.232525\tvalid_0's auc: 0.809616\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.373766\tvalid_0's auc: 0.807521\n",
      "[200]\tvalid_0's binary_logloss: 0.303162\tvalid_0's auc: 0.809781\n",
      "[300]\tvalid_0's binary_logloss: 0.26955\tvalid_0's auc: 0.810516\n",
      "[400]\tvalid_0's binary_logloss: 0.25827\tvalid_0's auc: 0.810904\n",
      "[500]\tvalid_0's binary_logloss: 0.24622\tvalid_0's auc: 0.811159\n",
      "[600]\tvalid_0's binary_logloss: 0.241252\tvalid_0's auc: 0.811661\n",
      "[700]\tvalid_0's binary_logloss: 0.239706\tvalid_0's auc: 0.811876\n",
      "[800]\tvalid_0's binary_logloss: 0.237676\tvalid_0's auc: 0.812014\n",
      "[900]\tvalid_0's binary_logloss: 0.235421\tvalid_0's auc: 0.812231\n",
      "[1000]\tvalid_0's binary_logloss: 0.234259\tvalid_0's auc: 0.812332\n",
      "[1100]\tvalid_0's binary_logloss: 0.233403\tvalid_0's auc: 0.812432\n",
      "[1200]\tvalid_0's binary_logloss: 0.231851\tvalid_0's auc: 0.812658\n",
      "[1300]\tvalid_0's binary_logloss: 0.231555\tvalid_0's auc: 0.812821\n",
      "Early stopping, best iteration is:\n",
      "[1243]\tvalid_0's binary_logloss: 0.231352\tvalid_0's auc: 0.812765\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.373639\tvalid_0's auc: 0.806146\n",
      "[200]\tvalid_0's binary_logloss: 0.303019\tvalid_0's auc: 0.808746\n",
      "[300]\tvalid_0's binary_logloss: 0.269425\tvalid_0's auc: 0.809636\n",
      "[400]\tvalid_0's binary_logloss: 0.258187\tvalid_0's auc: 0.81019\n",
      "[500]\tvalid_0's binary_logloss: 0.246165\tvalid_0's auc: 0.810293\n",
      "[600]\tvalid_0's binary_logloss: 0.24122\tvalid_0's auc: 0.810476\n",
      "[700]\tvalid_0's binary_logloss: 0.239703\tvalid_0's auc: 0.810641\n",
      "[800]\tvalid_0's binary_logloss: 0.237682\tvalid_0's auc: 0.81091\n",
      "[900]\tvalid_0's binary_logloss: 0.23542\tvalid_0's auc: 0.811081\n",
      "[1000]\tvalid_0's binary_logloss: 0.234286\tvalid_0's auc: 0.811138\n",
      "[1100]\tvalid_0's binary_logloss: 0.233436\tvalid_0's auc: 0.811249\n",
      "[1200]\tvalid_0's binary_logloss: 0.231891\tvalid_0's auc: 0.811404\n",
      "[1300]\tvalid_0's binary_logloss: 0.231618\tvalid_0's auc: 0.811598\n",
      "Early stopping, best iteration is:\n",
      "[1241]\tvalid_0's binary_logloss: 0.231404\tvalid_0's auc: 0.811554\n",
      "cv score - on train:\n",
      "0.8084362762938483\n",
      "('current score in fold:', 0.8092626164862363, 28)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.377327\tvalid_0's auc: 0.799469\n",
      "[200]\tvalid_0's binary_logloss: 0.310198\tvalid_0's auc: 0.802533\n",
      "[300]\tvalid_0's binary_logloss: 0.279909\tvalid_0's auc: 0.803541\n",
      "[400]\tvalid_0's binary_logloss: 0.26785\tvalid_0's auc: 0.8036\n",
      "[500]\tvalid_0's binary_logloss: 0.254017\tvalid_0's auc: 0.803674\n",
      "[600]\tvalid_0's binary_logloss: 0.243651\tvalid_0's auc: 0.804548\n",
      "[700]\tvalid_0's binary_logloss: 0.241067\tvalid_0's auc: 0.804718\n",
      "[800]\tvalid_0's binary_logloss: 0.238671\tvalid_0's auc: 0.80481\n",
      "[900]\tvalid_0's binary_logloss: 0.237729\tvalid_0's auc: 0.80486\n",
      "[1000]\tvalid_0's binary_logloss: 0.236348\tvalid_0's auc: 0.804946\n",
      "[1100]\tvalid_0's binary_logloss: 0.234957\tvalid_0's auc: 0.805108\n",
      "[1200]\tvalid_0's binary_logloss: 0.234305\tvalid_0's auc: 0.805428\n",
      "[1300]\tvalid_0's binary_logloss: 0.233965\tvalid_0's auc: 0.805529\n",
      "[1400]\tvalid_0's binary_logloss: 0.233544\tvalid_0's auc: 0.805615\n",
      "[1500]\tvalid_0's binary_logloss: 0.233214\tvalid_0's auc: 0.805726\n",
      "[1600]\tvalid_0's binary_logloss: 0.233005\tvalid_0's auc: 0.805795\n",
      "[1700]\tvalid_0's binary_logloss: 0.232993\tvalid_0's auc: 0.805965\n",
      "[1800]\tvalid_0's binary_logloss: 0.23271\tvalid_0's auc: 0.806034\n",
      "[1900]\tvalid_0's binary_logloss: 0.232244\tvalid_0's auc: 0.806155\n",
      "[2000]\tvalid_0's binary_logloss: 0.232133\tvalid_0's auc: 0.806212\n",
      "[2100]\tvalid_0's binary_logloss: 0.232127\tvalid_0's auc: 0.806251\n",
      "[2200]\tvalid_0's binary_logloss: 0.231965\tvalid_0's auc: 0.806302\n",
      "[2300]\tvalid_0's binary_logloss: 0.232068\tvalid_0's auc: 0.806332\n",
      "Early stopping, best iteration is:\n",
      "[2257]\tvalid_0's binary_logloss: 0.231841\tvalid_0's auc: 0.806329\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.376378\tvalid_0's auc: 0.808174\n",
      "[200]\tvalid_0's binary_logloss: 0.308715\tvalid_0's auc: 0.811084\n",
      "[300]\tvalid_0's binary_logloss: 0.278041\tvalid_0's auc: 0.812868\n",
      "[400]\tvalid_0's binary_logloss: 0.265759\tvalid_0's auc: 0.813024\n",
      "[500]\tvalid_0's binary_logloss: 0.251609\tvalid_0's auc: 0.813071\n",
      "[600]\tvalid_0's binary_logloss: 0.240951\tvalid_0's auc: 0.813462\n",
      "Early stopping, best iteration is:\n",
      "[562]\tvalid_0's binary_logloss: 0.242302\tvalid_0's auc: 0.813504\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.376441\tvalid_0's auc: 0.806801\n",
      "[200]\tvalid_0's binary_logloss: 0.308862\tvalid_0's auc: 0.81005\n",
      "[300]\tvalid_0's binary_logloss: 0.278252\tvalid_0's auc: 0.81118\n",
      "[400]\tvalid_0's binary_logloss: 0.266004\tvalid_0's auc: 0.812082\n",
      "[500]\tvalid_0's binary_logloss: 0.25189\tvalid_0's auc: 0.812347\n",
      "[600]\tvalid_0's binary_logloss: 0.241272\tvalid_0's auc: 0.812519\n",
      "[700]\tvalid_0's binary_logloss: 0.238616\tvalid_0's auc: 0.812642\n",
      "[800]\tvalid_0's binary_logloss: 0.236145\tvalid_0's auc: 0.81269\n",
      "[900]\tvalid_0's binary_logloss: 0.235156\tvalid_0's auc: 0.812772\n",
      "[1000]\tvalid_0's binary_logloss: 0.233715\tvalid_0's auc: 0.812971\n",
      "[1100]\tvalid_0's binary_logloss: 0.232255\tvalid_0's auc: 0.813063\n",
      "[1200]\tvalid_0's binary_logloss: 0.231572\tvalid_0's auc: 0.813399\n",
      "[1300]\tvalid_0's binary_logloss: 0.231213\tvalid_0's auc: 0.813501\n",
      "[1400]\tvalid_0's binary_logloss: 0.230771\tvalid_0's auc: 0.813568\n",
      "[1500]\tvalid_0's binary_logloss: 0.230415\tvalid_0's auc: 0.813625\n",
      "[1600]\tvalid_0's binary_logloss: 0.230203\tvalid_0's auc: 0.813691\n",
      "[1700]\tvalid_0's binary_logloss: 0.230186\tvalid_0's auc: 0.81379\n",
      "[1800]\tvalid_0's binary_logloss: 0.229889\tvalid_0's auc: 0.813849\n",
      "[1900]\tvalid_0's binary_logloss: 0.229373\tvalid_0's auc: 0.813972\n",
      "[2000]\tvalid_0's binary_logloss: 0.229256\tvalid_0's auc: 0.814034\n",
      "[2100]\tvalid_0's binary_logloss: 0.229252\tvalid_0's auc: 0.814065\n",
      "[2200]\tvalid_0's binary_logloss: 0.229068\tvalid_0's auc: 0.814123\n",
      "[2300]\tvalid_0's binary_logloss: 0.229185\tvalid_0's auc: 0.814162\n",
      "Early stopping, best iteration is:\n",
      "[2257]\tvalid_0's binary_logloss: 0.228931\tvalid_0's auc: 0.814135\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.376457\tvalid_0's auc: 0.806453\n",
      "[200]\tvalid_0's binary_logloss: 0.308883\tvalid_0's auc: 0.809436\n",
      "[300]\tvalid_0's binary_logloss: 0.278302\tvalid_0's auc: 0.809825\n",
      "[400]\tvalid_0's binary_logloss: 0.266055\tvalid_0's auc: 0.811063\n",
      "[500]\tvalid_0's binary_logloss: 0.25197\tvalid_0's auc: 0.811532\n",
      "[600]\tvalid_0's binary_logloss: 0.241382\tvalid_0's auc: 0.811709\n",
      "[700]\tvalid_0's binary_logloss: 0.238762\tvalid_0's auc: 0.811708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[800]\tvalid_0's binary_logloss: 0.236333\tvalid_0's auc: 0.81196\n",
      "Early stopping, best iteration is:\n",
      "[748]\tvalid_0's binary_logloss: 0.237469\tvalid_0's auc: 0.811968\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.377161\tvalid_0's auc: 0.79831\n",
      "[200]\tvalid_0's binary_logloss: 0.309874\tvalid_0's auc: 0.802673\n",
      "[300]\tvalid_0's binary_logloss: 0.27951\tvalid_0's auc: 0.803618\n",
      "[400]\tvalid_0's binary_logloss: 0.267429\tvalid_0's auc: 0.803785\n",
      "[500]\tvalid_0's binary_logloss: 0.253584\tvalid_0's auc: 0.803958\n",
      "[600]\tvalid_0's binary_logloss: 0.243252\tvalid_0's auc: 0.804608\n",
      "[700]\tvalid_0's binary_logloss: 0.240682\tvalid_0's auc: 0.804873\n",
      "[800]\tvalid_0's binary_logloss: 0.238314\tvalid_0's auc: 0.804982\n",
      "[900]\tvalid_0's binary_logloss: 0.237397\tvalid_0's auc: 0.805053\n",
      "[1000]\tvalid_0's binary_logloss: 0.236043\tvalid_0's auc: 0.805207\n",
      "[1100]\tvalid_0's binary_logloss: 0.234672\tvalid_0's auc: 0.805444\n",
      "[1200]\tvalid_0's binary_logloss: 0.234045\tvalid_0's auc: 0.805578\n",
      "[1300]\tvalid_0's binary_logloss: 0.233706\tvalid_0's auc: 0.805705\n",
      "[1400]\tvalid_0's binary_logloss: 0.233306\tvalid_0's auc: 0.805843\n",
      "[1500]\tvalid_0's binary_logloss: 0.232984\tvalid_0's auc: 0.805937\n",
      "[1600]\tvalid_0's binary_logloss: 0.232781\tvalid_0's auc: 0.80603\n",
      "[1700]\tvalid_0's binary_logloss: 0.232769\tvalid_0's auc: 0.806089\n",
      "[1800]\tvalid_0's binary_logloss: 0.232495\tvalid_0's auc: 0.806159\n",
      "[1900]\tvalid_0's binary_logloss: 0.232051\tvalid_0's auc: 0.806229\n",
      "[2000]\tvalid_0's binary_logloss: 0.23193\tvalid_0's auc: 0.806328\n",
      "[2100]\tvalid_0's binary_logloss: 0.231918\tvalid_0's auc: 0.806375\n",
      "[2200]\tvalid_0's binary_logloss: 0.231757\tvalid_0's auc: 0.80642\n",
      "[2300]\tvalid_0's binary_logloss: 0.231866\tvalid_0's auc: 0.806453\n",
      "Early stopping, best iteration is:\n",
      "[2257]\tvalid_0's binary_logloss: 0.231631\tvalid_0's auc: 0.806459\n",
      "cv score - on train:\n",
      "0.8017240973635453\n",
      "('current score in fold:', 0.8093017091781167, 29)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.379896\tvalid_0's auc: 0.804968\n",
      "[200]\tvalid_0's binary_logloss: 0.299777\tvalid_0's auc: 0.806801\n",
      "[300]\tvalid_0's binary_logloss: 0.274897\tvalid_0's auc: 0.807263\n",
      "[400]\tvalid_0's binary_logloss: 0.260567\tvalid_0's auc: 0.807727\n",
      "[500]\tvalid_0's binary_logloss: 0.253617\tvalid_0's auc: 0.808103\n",
      "[600]\tvalid_0's binary_logloss: 0.249689\tvalid_0's auc: 0.808288\n",
      "[700]\tvalid_0's binary_logloss: 0.247161\tvalid_0's auc: 0.80843\n",
      "[800]\tvalid_0's binary_logloss: 0.24244\tvalid_0's auc: 0.808579\n",
      "[900]\tvalid_0's binary_logloss: 0.239604\tvalid_0's auc: 0.808637\n",
      "[1000]\tvalid_0's binary_logloss: 0.236471\tvalid_0's auc: 0.808935\n",
      "[1100]\tvalid_0's binary_logloss: 0.234362\tvalid_0's auc: 0.809147\n",
      "[1200]\tvalid_0's binary_logloss: 0.233431\tvalid_0's auc: 0.809299\n",
      "[1300]\tvalid_0's binary_logloss: 0.232429\tvalid_0's auc: 0.809568\n",
      "[1400]\tvalid_0's binary_logloss: 0.232234\tvalid_0's auc: 0.80965\n",
      "[1500]\tvalid_0's binary_logloss: 0.231747\tvalid_0's auc: 0.809706\n",
      "[1600]\tvalid_0's binary_logloss: 0.231398\tvalid_0's auc: 0.809753\n",
      "[1700]\tvalid_0's binary_logloss: 0.2309\tvalid_0's auc: 0.80989\n",
      "[1800]\tvalid_0's binary_logloss: 0.230673\tvalid_0's auc: 0.810017\n",
      "Early stopping, best iteration is:\n",
      "[1793]\tvalid_0's binary_logloss: 0.23056\tvalid_0's auc: 0.810018\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.379782\tvalid_0's auc: 0.798543\n",
      "[200]\tvalid_0's binary_logloss: 0.299895\tvalid_0's auc: 0.80212\n",
      "[300]\tvalid_0's binary_logloss: 0.275139\tvalid_0's auc: 0.802861\n",
      "[400]\tvalid_0's binary_logloss: 0.260928\tvalid_0's auc: 0.803284\n",
      "[500]\tvalid_0's binary_logloss: 0.254052\tvalid_0's auc: 0.803614\n",
      "[600]\tvalid_0's binary_logloss: 0.250169\tvalid_0's auc: 0.804059\n",
      "[700]\tvalid_0's binary_logloss: 0.247694\tvalid_0's auc: 0.804138\n",
      "[800]\tvalid_0's binary_logloss: 0.243078\tvalid_0's auc: 0.804269\n",
      "[900]\tvalid_0's binary_logloss: 0.24032\tvalid_0's auc: 0.80429\n",
      "[1000]\tvalid_0's binary_logloss: 0.237318\tvalid_0's auc: 0.804445\n",
      "[1100]\tvalid_0's binary_logloss: 0.235308\tvalid_0's auc: 0.804592\n",
      "[1200]\tvalid_0's binary_logloss: 0.234435\tvalid_0's auc: 0.804734\n",
      "[1300]\tvalid_0's binary_logloss: 0.233513\tvalid_0's auc: 0.804888\n",
      "[1400]\tvalid_0's binary_logloss: 0.233321\tvalid_0's auc: 0.805068\n",
      "[1500]\tvalid_0's binary_logloss: 0.232862\tvalid_0's auc: 0.805147\n",
      "[1600]\tvalid_0's binary_logloss: 0.232534\tvalid_0's auc: 0.805279\n",
      "[1700]\tvalid_0's binary_logloss: 0.232079\tvalid_0's auc: 0.805439\n",
      "[1800]\tvalid_0's binary_logloss: 0.231872\tvalid_0's auc: 0.805553\n",
      "[1900]\tvalid_0's binary_logloss: 0.231862\tvalid_0's auc: 0.805635\n",
      "[2000]\tvalid_0's binary_logloss: 0.231786\tvalid_0's auc: 0.805699\n",
      "Early stopping, best iteration is:\n",
      "[1954]\tvalid_0's binary_logloss: 0.23172\tvalid_0's auc: 0.805688\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.379569\tvalid_0's auc: 0.806939\n",
      "[200]\tvalid_0's binary_logloss: 0.299282\tvalid_0's auc: 0.81134\n",
      "[300]\tvalid_0's binary_logloss: 0.274259\tvalid_0's auc: 0.811656\n",
      "[400]\tvalid_0's binary_logloss: 0.259813\tvalid_0's auc: 0.812231\n",
      "[500]\tvalid_0's binary_logloss: 0.252784\tvalid_0's auc: 0.81244\n",
      "[600]\tvalid_0's binary_logloss: 0.248801\tvalid_0's auc: 0.812589\n",
      "[700]\tvalid_0's binary_logloss: 0.246261\tvalid_0's auc: 0.812591\n",
      "[800]\tvalid_0's binary_logloss: 0.241455\tvalid_0's auc: 0.812786\n",
      "[900]\tvalid_0's binary_logloss: 0.238567\tvalid_0's auc: 0.812826\n",
      "[1000]\tvalid_0's binary_logloss: 0.235372\tvalid_0's auc: 0.813112\n",
      "[1100]\tvalid_0's binary_logloss: 0.233219\tvalid_0's auc: 0.813317\n",
      "[1200]\tvalid_0's binary_logloss: 0.23225\tvalid_0's auc: 0.813507\n",
      "[1300]\tvalid_0's binary_logloss: 0.231218\tvalid_0's auc: 0.813711\n",
      "[1400]\tvalid_0's binary_logloss: 0.231\tvalid_0's auc: 0.813885\n",
      "[1500]\tvalid_0's binary_logloss: 0.230465\tvalid_0's auc: 0.814057\n",
      "[1600]\tvalid_0's binary_logloss: 0.230077\tvalid_0's auc: 0.814203\n",
      "[1700]\tvalid_0's binary_logloss: 0.229544\tvalid_0's auc: 0.814345\n",
      "[1800]\tvalid_0's binary_logloss: 0.229293\tvalid_0's auc: 0.814467\n",
      "Early stopping, best iteration is:\n",
      "[1793]\tvalid_0's binary_logloss: 0.229171\tvalid_0's auc: 0.81447\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.379134\tvalid_0's auc: 0.803185\n",
      "[200]\tvalid_0's binary_logloss: 0.2989\tvalid_0's auc: 0.806909\n",
      "[300]\tvalid_0's binary_logloss: 0.273992\tvalid_0's auc: 0.807617\n",
      "[400]\tvalid_0's binary_logloss: 0.259673\tvalid_0's auc: 0.807797\n",
      "[500]\tvalid_0's binary_logloss: 0.252738\tvalid_0's auc: 0.807812\n",
      "[600]\tvalid_0's binary_logloss: 0.248824\tvalid_0's auc: 0.80801\n",
      "[700]\tvalid_0's binary_logloss: 0.246305\tvalid_0's auc: 0.808137\n",
      "[800]\tvalid_0's binary_logloss: 0.24164\tvalid_0's auc: 0.808208\n",
      "[900]\tvalid_0's binary_logloss: 0.238851\tvalid_0's auc: 0.808375\n",
      "[1000]\tvalid_0's binary_logloss: 0.235791\tvalid_0's auc: 0.808537\n",
      "[1100]\tvalid_0's binary_logloss: 0.233743\tvalid_0's auc: 0.808732\n",
      "[1200]\tvalid_0's binary_logloss: 0.232852\tvalid_0's auc: 0.808884\n",
      "[1300]\tvalid_0's binary_logloss: 0.231896\tvalid_0's auc: 0.809022\n",
      "[1400]\tvalid_0's binary_logloss: 0.231706\tvalid_0's auc: 0.809136\n",
      "[1500]\tvalid_0's binary_logloss: 0.23123\tvalid_0's auc: 0.809249\n",
      "[1600]\tvalid_0's binary_logloss: 0.230878\tvalid_0's auc: 0.809349\n",
      "[1700]\tvalid_0's binary_logloss: 0.230415\tvalid_0's auc: 0.809556\n",
      "[1800]\tvalid_0's binary_logloss: 0.230211\tvalid_0's auc: 0.809634\n",
      "Early stopping, best iteration is:\n",
      "[1793]\tvalid_0's binary_logloss: 0.230108\tvalid_0's auc: 0.809637\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.379164\tvalid_0's auc: 0.808255\n",
      "[200]\tvalid_0's binary_logloss: 0.298766\tvalid_0's auc: 0.809192\n",
      "[300]\tvalid_0's binary_logloss: 0.273711\tvalid_0's auc: 0.81153\n",
      "[400]\tvalid_0's binary_logloss: 0.259266\tvalid_0's auc: 0.812149\n",
      "[500]\tvalid_0's binary_logloss: 0.252247\tvalid_0's auc: 0.812216\n",
      "[600]\tvalid_0's binary_logloss: 0.248265\tvalid_0's auc: 0.812396\n",
      "[700]\tvalid_0's binary_logloss: 0.245737\tvalid_0's auc: 0.812633\n",
      "[800]\tvalid_0's binary_logloss: 0.240968\tvalid_0's auc: 0.812829\n",
      "[900]\tvalid_0's binary_logloss: 0.238093\tvalid_0's auc: 0.813024\n",
      "[1000]\tvalid_0's binary_logloss: 0.234919\tvalid_0's auc: 0.81322\n",
      "[1100]\tvalid_0's binary_logloss: 0.232777\tvalid_0's auc: 0.813432\n",
      "[1200]\tvalid_0's binary_logloss: 0.231823\tvalid_0's auc: 0.813607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1300]\tvalid_0's binary_logloss: 0.230813\tvalid_0's auc: 0.813762\n",
      "[1400]\tvalid_0's binary_logloss: 0.230604\tvalid_0's auc: 0.813908\n",
      "[1500]\tvalid_0's binary_logloss: 0.230092\tvalid_0's auc: 0.81401\n",
      "[1600]\tvalid_0's binary_logloss: 0.22972\tvalid_0's auc: 0.814121\n",
      "[1700]\tvalid_0's binary_logloss: 0.229212\tvalid_0's auc: 0.814246\n",
      "[1800]\tvalid_0's binary_logloss: 0.228981\tvalid_0's auc: 0.814367\n",
      "Early stopping, best iteration is:\n",
      "[1793]\tvalid_0's binary_logloss: 0.228864\tvalid_0's auc: 0.814369\n",
      "cv score - on train:\n",
      "0.8106310520045874\n",
      "('current score in fold:', 0.8093748733867522, 30)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.375131\tvalid_0's auc: 0.799691\n",
      "[200]\tvalid_0's binary_logloss: 0.292301\tvalid_0's auc: 0.802668\n",
      "[300]\tvalid_0's binary_logloss: 0.269051\tvalid_0's auc: 0.804475\n",
      "[400]\tvalid_0's binary_logloss: 0.254742\tvalid_0's auc: 0.805207\n",
      "[500]\tvalid_0's binary_logloss: 0.246297\tvalid_0's auc: 0.805253\n",
      "[600]\tvalid_0's binary_logloss: 0.242662\tvalid_0's auc: 0.805573\n",
      "[700]\tvalid_0's binary_logloss: 0.239312\tvalid_0's auc: 0.80575\n",
      "[800]\tvalid_0's binary_logloss: 0.237373\tvalid_0's auc: 0.805839\n",
      "[900]\tvalid_0's binary_logloss: 0.236232\tvalid_0's auc: 0.805937\n",
      "[1000]\tvalid_0's binary_logloss: 0.235925\tvalid_0's auc: 0.806148\n",
      "[1100]\tvalid_0's binary_logloss: 0.234644\tvalid_0's auc: 0.806256\n",
      "[1200]\tvalid_0's binary_logloss: 0.233856\tvalid_0's auc: 0.806436\n",
      "[1300]\tvalid_0's binary_logloss: 0.233641\tvalid_0's auc: 0.806511\n",
      "[1400]\tvalid_0's binary_logloss: 0.233486\tvalid_0's auc: 0.806588\n",
      "[1500]\tvalid_0's binary_logloss: 0.232631\tvalid_0's auc: 0.806665\n",
      "[1600]\tvalid_0's binary_logloss: 0.232488\tvalid_0's auc: 0.806741\n",
      "[1700]\tvalid_0's binary_logloss: 0.232133\tvalid_0's auc: 0.806837\n",
      "[1800]\tvalid_0's binary_logloss: 0.231781\tvalid_0's auc: 0.806915\n",
      "[1900]\tvalid_0's binary_logloss: 0.231472\tvalid_0's auc: 0.806989\n",
      "[2000]\tvalid_0's binary_logloss: 0.231327\tvalid_0's auc: 0.807086\n",
      "[2100]\tvalid_0's binary_logloss: 0.231277\tvalid_0's auc: 0.80715\n",
      "[2200]\tvalid_0's binary_logloss: 0.231223\tvalid_0's auc: 0.80722\n",
      "[2300]\tvalid_0's binary_logloss: 0.230939\tvalid_0's auc: 0.807298\n",
      "[2400]\tvalid_0's binary_logloss: 0.231189\tvalid_0's auc: 0.807335\n",
      "Early stopping, best iteration is:\n",
      "[2309]\tvalid_0's binary_logloss: 0.230923\tvalid_0's auc: 0.807302\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.374996\tvalid_0's auc: 0.804493\n",
      "[200]\tvalid_0's binary_logloss: 0.292033\tvalid_0's auc: 0.808102\n",
      "[300]\tvalid_0's binary_logloss: 0.268741\tvalid_0's auc: 0.808814\n",
      "[400]\tvalid_0's binary_logloss: 0.25433\tvalid_0's auc: 0.809283\n",
      "[500]\tvalid_0's binary_logloss: 0.245762\tvalid_0's auc: 0.809701\n",
      "[600]\tvalid_0's binary_logloss: 0.242033\tvalid_0's auc: 0.810052\n",
      "[700]\tvalid_0's binary_logloss: 0.238594\tvalid_0's auc: 0.810148\n",
      "[800]\tvalid_0's binary_logloss: 0.23658\tvalid_0's auc: 0.810339\n",
      "[900]\tvalid_0's binary_logloss: 0.235391\tvalid_0's auc: 0.810445\n",
      "[1000]\tvalid_0's binary_logloss: 0.235076\tvalid_0's auc: 0.8105\n",
      "[1100]\tvalid_0's binary_logloss: 0.233752\tvalid_0's auc: 0.810533\n",
      "[1200]\tvalid_0's binary_logloss: 0.23294\tvalid_0's auc: 0.810726\n",
      "[1300]\tvalid_0's binary_logloss: 0.23271\tvalid_0's auc: 0.810792\n",
      "[1400]\tvalid_0's binary_logloss: 0.23254\tvalid_0's auc: 0.810853\n",
      "[1500]\tvalid_0's binary_logloss: 0.231641\tvalid_0's auc: 0.810931\n",
      "[1600]\tvalid_0's binary_logloss: 0.231498\tvalid_0's auc: 0.811013\n",
      "[1700]\tvalid_0's binary_logloss: 0.231125\tvalid_0's auc: 0.811097\n",
      "[1800]\tvalid_0's binary_logloss: 0.230735\tvalid_0's auc: 0.811233\n",
      "[1900]\tvalid_0's binary_logloss: 0.230389\tvalid_0's auc: 0.811329\n",
      "[2000]\tvalid_0's binary_logloss: 0.230242\tvalid_0's auc: 0.811412\n",
      "[2100]\tvalid_0's binary_logloss: 0.230192\tvalid_0's auc: 0.811463\n",
      "[2200]\tvalid_0's binary_logloss: 0.230145\tvalid_0's auc: 0.811503\n",
      "[2300]\tvalid_0's binary_logloss: 0.229841\tvalid_0's auc: 0.811568\n",
      "[2400]\tvalid_0's binary_logloss: 0.230109\tvalid_0's auc: 0.811605\n",
      "Early stopping, best iteration is:\n",
      "[2309]\tvalid_0's binary_logloss: 0.229821\tvalid_0's auc: 0.811571\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.374643\tvalid_0's auc: 0.804673\n",
      "[200]\tvalid_0's binary_logloss: 0.291483\tvalid_0's auc: 0.809105\n",
      "[300]\tvalid_0's binary_logloss: 0.268088\tvalid_0's auc: 0.809564\n",
      "[400]\tvalid_0's binary_logloss: 0.253672\tvalid_0's auc: 0.809776\n",
      "[500]\tvalid_0's binary_logloss: 0.245115\tvalid_0's auc: 0.809964\n",
      "[600]\tvalid_0's binary_logloss: 0.241401\tvalid_0's auc: 0.810435\n",
      "[700]\tvalid_0's binary_logloss: 0.237968\tvalid_0's auc: 0.810609\n",
      "[800]\tvalid_0's binary_logloss: 0.235959\tvalid_0's auc: 0.810805\n",
      "[900]\tvalid_0's binary_logloss: 0.234769\tvalid_0's auc: 0.811002\n",
      "[1000]\tvalid_0's binary_logloss: 0.234439\tvalid_0's auc: 0.811092\n",
      "[1100]\tvalid_0's binary_logloss: 0.233102\tvalid_0's auc: 0.811203\n",
      "[1200]\tvalid_0's binary_logloss: 0.232261\tvalid_0's auc: 0.811349\n",
      "[1300]\tvalid_0's binary_logloss: 0.232019\tvalid_0's auc: 0.811464\n",
      "[1400]\tvalid_0's binary_logloss: 0.23184\tvalid_0's auc: 0.811515\n",
      "[1500]\tvalid_0's binary_logloss: 0.230927\tvalid_0's auc: 0.811625\n",
      "[1600]\tvalid_0's binary_logloss: 0.230784\tvalid_0's auc: 0.811711\n",
      "[1700]\tvalid_0's binary_logloss: 0.230402\tvalid_0's auc: 0.811862\n",
      "[1800]\tvalid_0's binary_logloss: 0.230008\tvalid_0's auc: 0.811952\n",
      "[1900]\tvalid_0's binary_logloss: 0.229665\tvalid_0's auc: 0.81205\n",
      "[2000]\tvalid_0's binary_logloss: 0.229513\tvalid_0's auc: 0.812147\n",
      "[2100]\tvalid_0's binary_logloss: 0.22945\tvalid_0's auc: 0.812219\n",
      "[2200]\tvalid_0's binary_logloss: 0.229382\tvalid_0's auc: 0.812298\n",
      "[2300]\tvalid_0's binary_logloss: 0.229058\tvalid_0's auc: 0.812368\n",
      "[2400]\tvalid_0's binary_logloss: 0.229337\tvalid_0's auc: 0.812399\n",
      "Early stopping, best iteration is:\n",
      "[2309]\tvalid_0's binary_logloss: 0.229037\tvalid_0's auc: 0.812369\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.375077\tvalid_0's auc: 0.804019\n",
      "[200]\tvalid_0's binary_logloss: 0.292112\tvalid_0's auc: 0.807839\n",
      "[300]\tvalid_0's binary_logloss: 0.268768\tvalid_0's auc: 0.809128\n",
      "[400]\tvalid_0's binary_logloss: 0.254364\tvalid_0's auc: 0.809151\n",
      "Early stopping, best iteration is:\n",
      "[315]\tvalid_0's binary_logloss: 0.268176\tvalid_0's auc: 0.809197\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.374753\tvalid_0's auc: 0.806508\n",
      "[200]\tvalid_0's binary_logloss: 0.291628\tvalid_0's auc: 0.808222\n",
      "[300]\tvalid_0's binary_logloss: 0.268253\tvalid_0's auc: 0.809613\n",
      "[400]\tvalid_0's binary_logloss: 0.253775\tvalid_0's auc: 0.809885\n",
      "[500]\tvalid_0's binary_logloss: 0.245183\tvalid_0's auc: 0.810141\n",
      "[600]\tvalid_0's binary_logloss: 0.241456\tvalid_0's auc: 0.810836\n",
      "[700]\tvalid_0's binary_logloss: 0.238013\tvalid_0's auc: 0.811015\n",
      "[800]\tvalid_0's binary_logloss: 0.236014\tvalid_0's auc: 0.811182\n",
      "[900]\tvalid_0's binary_logloss: 0.234846\tvalid_0's auc: 0.811227\n",
      "[1000]\tvalid_0's binary_logloss: 0.234517\tvalid_0's auc: 0.81132\n",
      "[1100]\tvalid_0's binary_logloss: 0.233169\tvalid_0's auc: 0.8114\n",
      "[1200]\tvalid_0's binary_logloss: 0.232339\tvalid_0's auc: 0.811524\n",
      "[1300]\tvalid_0's binary_logloss: 0.232105\tvalid_0's auc: 0.811593\n",
      "[1400]\tvalid_0's binary_logloss: 0.231937\tvalid_0's auc: 0.811702\n",
      "[1500]\tvalid_0's binary_logloss: 0.231018\tvalid_0's auc: 0.811846\n",
      "[1600]\tvalid_0's binary_logloss: 0.230868\tvalid_0's auc: 0.811913\n",
      "[1700]\tvalid_0's binary_logloss: 0.230507\tvalid_0's auc: 0.811949\n",
      "[1800]\tvalid_0's binary_logloss: 0.230114\tvalid_0's auc: 0.812092\n",
      "[1900]\tvalid_0's binary_logloss: 0.229766\tvalid_0's auc: 0.812157\n",
      "[2000]\tvalid_0's binary_logloss: 0.22963\tvalid_0's auc: 0.812197\n",
      "[2100]\tvalid_0's binary_logloss: 0.229579\tvalid_0's auc: 0.81225\n",
      "[2200]\tvalid_0's binary_logloss: 0.229517\tvalid_0's auc: 0.812302\n",
      "[2300]\tvalid_0's binary_logloss: 0.229217\tvalid_0's auc: 0.812301\n",
      "Early stopping, best iteration is:\n",
      "[2202]\tvalid_0's binary_logloss: 0.229515\tvalid_0's auc: 0.812303\n",
      "cv score - on train:\n",
      "0.7895970638415906\n",
      "('current score in fold:', 0.8093856949118918, 31)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.37229\tvalid_0's auc: 0.802982\n",
      "[200]\tvalid_0's binary_logloss: 0.299357\tvalid_0's auc: 0.805901\n",
      "[300]\tvalid_0's binary_logloss: 0.274338\tvalid_0's auc: 0.807147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\tvalid_0's binary_logloss: 0.267257\tvalid_0's auc: 0.807229\n",
      "[500]\tvalid_0's binary_logloss: 0.251754\tvalid_0's auc: 0.807252\n",
      "[600]\tvalid_0's binary_logloss: 0.246028\tvalid_0's auc: 0.808088\n",
      "[700]\tvalid_0's binary_logloss: 0.242261\tvalid_0's auc: 0.808232\n",
      "[800]\tvalid_0's binary_logloss: 0.240109\tvalid_0's auc: 0.80829\n",
      "[900]\tvalid_0's binary_logloss: 0.23764\tvalid_0's auc: 0.808425\n",
      "[1000]\tvalid_0's binary_logloss: 0.235575\tvalid_0's auc: 0.808645\n",
      "[1100]\tvalid_0's binary_logloss: 0.234495\tvalid_0's auc: 0.80877\n",
      "[1200]\tvalid_0's binary_logloss: 0.233697\tvalid_0's auc: 0.8089\n",
      "Early stopping, best iteration is:\n",
      "[1171]\tvalid_0's binary_logloss: 0.233338\tvalid_0's auc: 0.808877\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.37181\tvalid_0's auc: 0.801444\n",
      "[200]\tvalid_0's binary_logloss: 0.298684\tvalid_0's auc: 0.804462\n",
      "[300]\tvalid_0's binary_logloss: 0.273588\tvalid_0's auc: 0.806629\n",
      "[400]\tvalid_0's binary_logloss: 0.266526\tvalid_0's auc: 0.806843\n",
      "Early stopping, best iteration is:\n",
      "[383]\tvalid_0's binary_logloss: 0.267769\tvalid_0's auc: 0.806863\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.371148\tvalid_0's auc: 0.807291\n",
      "[200]\tvalid_0's binary_logloss: 0.297779\tvalid_0's auc: 0.809819\n",
      "[300]\tvalid_0's binary_logloss: 0.272541\tvalid_0's auc: 0.8124\n",
      "[400]\tvalid_0's binary_logloss: 0.26536\tvalid_0's auc: 0.812694\n",
      "[500]\tvalid_0's binary_logloss: 0.249693\tvalid_0's auc: 0.81301\n",
      "[600]\tvalid_0's binary_logloss: 0.243881\tvalid_0's auc: 0.813314\n",
      "[700]\tvalid_0's binary_logloss: 0.240028\tvalid_0's auc: 0.813481\n",
      "[800]\tvalid_0's binary_logloss: 0.23785\tvalid_0's auc: 0.813547\n",
      "[900]\tvalid_0's binary_logloss: 0.235348\tvalid_0's auc: 0.813595\n",
      "[1000]\tvalid_0's binary_logloss: 0.233264\tvalid_0's auc: 0.81363\n",
      "[1100]\tvalid_0's binary_logloss: 0.232187\tvalid_0's auc: 0.813784\n",
      "[1200]\tvalid_0's binary_logloss: 0.231392\tvalid_0's auc: 0.813959\n",
      "Early stopping, best iteration is:\n",
      "[1171]\tvalid_0's binary_logloss: 0.231021\tvalid_0's auc: 0.813962\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.372032\tvalid_0's auc: 0.802742\n",
      "[200]\tvalid_0's binary_logloss: 0.299057\tvalid_0's auc: 0.804385\n",
      "[300]\tvalid_0's binary_logloss: 0.274016\tvalid_0's auc: 0.806074\n",
      "[400]\tvalid_0's binary_logloss: 0.266925\tvalid_0's auc: 0.806341\n",
      "[500]\tvalid_0's binary_logloss: 0.25138\tvalid_0's auc: 0.806706\n",
      "[600]\tvalid_0's binary_logloss: 0.245665\tvalid_0's auc: 0.807099\n",
      "[700]\tvalid_0's binary_logloss: 0.241902\tvalid_0's auc: 0.807279\n",
      "[800]\tvalid_0's binary_logloss: 0.23976\tvalid_0's auc: 0.807343\n",
      "[900]\tvalid_0's binary_logloss: 0.237312\tvalid_0's auc: 0.807513\n",
      "[1000]\tvalid_0's binary_logloss: 0.23528\tvalid_0's auc: 0.807616\n",
      "[1100]\tvalid_0's binary_logloss: 0.234227\tvalid_0's auc: 0.807745\n",
      "[1200]\tvalid_0's binary_logloss: 0.233445\tvalid_0's auc: 0.807896\n",
      "Early stopping, best iteration is:\n",
      "[1171]\tvalid_0's binary_logloss: 0.233086\tvalid_0's auc: 0.807866\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.371456\tvalid_0's auc: 0.806817\n",
      "[200]\tvalid_0's binary_logloss: 0.298199\tvalid_0's auc: 0.809844\n",
      "[300]\tvalid_0's binary_logloss: 0.273056\tvalid_0's auc: 0.810032\n",
      "[400]\tvalid_0's binary_logloss: 0.265941\tvalid_0's auc: 0.810238\n",
      "[500]\tvalid_0's binary_logloss: 0.2503\tvalid_0's auc: 0.810604\n",
      "[600]\tvalid_0's binary_logloss: 0.24453\tvalid_0's auc: 0.810899\n",
      "[700]\tvalid_0's binary_logloss: 0.24073\tvalid_0's auc: 0.811105\n",
      "[800]\tvalid_0's binary_logloss: 0.238571\tvalid_0's auc: 0.811165\n",
      "[900]\tvalid_0's binary_logloss: 0.236086\tvalid_0's auc: 0.811308\n",
      "[1000]\tvalid_0's binary_logloss: 0.234015\tvalid_0's auc: 0.811461\n",
      "[1100]\tvalid_0's binary_logloss: 0.232945\tvalid_0's auc: 0.811674\n",
      "[1200]\tvalid_0's binary_logloss: 0.232157\tvalid_0's auc: 0.811865\n",
      "Early stopping, best iteration is:\n",
      "[1171]\tvalid_0's binary_logloss: 0.231783\tvalid_0's auc: 0.811845\n",
      "cv score - on train:\n",
      "0.793824569543101\n",
      "('current score in fold:', 0.8094073211474969, 32)\n"
     ]
    }
   ],
   "source": [
    "final_cv_train = np.zeros(len(labels_train))\n",
    "final_cv_pred = np.zeros(len( test_ids ))\n",
    "\n",
    "NFOLDS = 5 \n",
    "\n",
    "M = 32 \n",
    "x_score = []\n",
    "for s in range( M ):\n",
    "    \n",
    "    params['seed'] = s\n",
    "    \n",
    "    cv_train = np.zeros( len( labels_train ))\n",
    "    cv_pred = np.zeros( len( test_ids ) )\n",
    "    kfold = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=s)\n",
    "    kf  = kfold.split(  new_train , labels_train )\n",
    "    \n",
    "    for i, (train_fold, validate) in enumerate(kf):\n",
    "        \n",
    "        X_train, X_validate, label_train, label_validate = new_train[train_fold, :], new_train[validate, :], labels_train[train_fold], labels_train[validate]\n",
    "    \n",
    "    #X_train, X_validate, label_train, label_validate = X[train_fold, :], X[validate, :], labels_train[train_fold], labels_train[validate]\n",
    "        dtrain = lgb.Dataset( X_train , label_train  )\n",
    "    \n",
    "        dvalid = lgb.Dataset(  X_validate  , label_validate , reference=dtrain )\n",
    "        bst = lgb.train(params, dtrain , num_boost_round , valid_sets=[dvalid ] , verbose_eval = 100 , early_stopping_rounds = 100 )\n",
    "    #best_trees.append(bst.best_iteration)    \n",
    "        cv_pred +=  bst.predict(  new_test , num_iteration = bst.best_iteration )\n",
    "    #cv_eval_total += bst.predict( x_val , num_iteration = bst.best_iteration )          \n",
    "        cv_train[validate] += bst.predict( X_validate )\n",
    "        \n",
    "        \n",
    "    cv_pred /= NFOLDS\n",
    "    \n",
    "    final_cv_train += cv_train\n",
    "    final_cv_pred += cv_pred\n",
    "    \n",
    "    print(\"cv score - on train:\")\n",
    "    print( roc_auc_score(labels_train, cv_train))\n",
    "    print( \"current score in fold:\", roc_auc_score( labels_train , final_cv_train / (s + 1.)), s+1)\n",
    "    \n",
    "    x_score.append(roc_auc_score( labels_train , cv_train))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7987769984548989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8034499487255756,\n",
       " 0.7922649210441692,\n",
       " 0.8037118935582123,\n",
       " 0.8028072287622634,\n",
       " 0.8099148464301225,\n",
       " 0.7957325275998088,\n",
       " 0.8104329385240773,\n",
       " 0.7947093041055542,\n",
       " 0.8098990459090402,\n",
       " 0.8106626515505313,\n",
       " 0.8054755700992036,\n",
       " 0.7877350738259302,\n",
       " 0.8102617486139418,\n",
       " 0.7863474088042445,\n",
       " 0.8064907774826636,\n",
       " 0.8108442207456327,\n",
       " 0.8005212320918111,\n",
       " 0.7876745094366978,\n",
       " 0.750899955476026,\n",
       " 0.8024170939855985,\n",
       " 0.8077684367751766,\n",
       " 0.7969797519762924,\n",
       " 0.8001050767497597,\n",
       " 0.8001182690726727,\n",
       " 0.7968490304976077,\n",
       " 0.789256754506167,\n",
       " 0.7833206751613117,\n",
       " 0.8084362762938483,\n",
       " 0.8017240973635453,\n",
       " 0.8106310520045874,\n",
       " 0.7895970638415906,\n",
       " 0.793824569543101]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( np.array(x_score).mean())\n",
    "x_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred_lgb = final_cv_pred/32.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist( final_pred_lgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGboost model with oof_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "num_leaves = 30\n",
    "min_data_in_leaf = 2000\n",
    "feature_fraction = 0.9\n",
    "num_boost_round = 5000\n",
    "params = {\"booster\": \"gbtree\",\n",
    "         \"eta\" : learning_rate , \n",
    "          \"max_depth\" : 5 , \n",
    "          \"colsample_bytree\" : feature_fraction , \n",
    "          \"lambda\" : 100 , \n",
    "           \"tree_method\" : \"hist\" , \n",
    "          \"max_bin\" : 256 , \n",
    "          \"rate_drop\": 0.01 , \n",
    "          'objective': 'binary:logistic' , \n",
    "          \"eval_metric\" : \"auc\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.770092\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.801389\n",
      "[200]\teval-auc:0.805189\n",
      "[300]\teval-auc:0.806782\n",
      "[400]\teval-auc:0.807197\n",
      "[500]\teval-auc:0.807641\n",
      "[600]\teval-auc:0.807878\n",
      "[700]\teval-auc:0.807975\n",
      "[800]\teval-auc:0.808022\n",
      "[900]\teval-auc:0.808076\n",
      "[1000]\teval-auc:0.808163\n",
      "[1100]\teval-auc:0.808198\n",
      "[1200]\teval-auc:0.808281\n",
      "[1300]\teval-auc:0.808447\n",
      "[1400]\teval-auc:0.808528\n",
      "[1500]\teval-auc:0.808578\n",
      "[1600]\teval-auc:0.808586\n",
      "Stopping. Best iteration:\n",
      "[1582]\teval-auc:0.808602\n",
      "\n",
      "[0]\teval-auc:0.776482\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.805602\n",
      "[200]\teval-auc:0.808829\n",
      "[300]\teval-auc:0.809492\n",
      "[400]\teval-auc:0.810059\n",
      "[500]\teval-auc:0.810274\n",
      "[600]\teval-auc:0.810493\n",
      "[700]\teval-auc:0.810617\n",
      "[800]\teval-auc:0.810672\n",
      "[900]\teval-auc:0.810712\n",
      "[1000]\teval-auc:0.810723\n",
      "[1100]\teval-auc:0.810806\n",
      "[1200]\teval-auc:0.810852\n",
      "[1300]\teval-auc:0.810838\n",
      "Stopping. Best iteration:\n",
      "[1232]\teval-auc:0.810857\n",
      "\n",
      "[0]\teval-auc:0.77627\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.801865\n",
      "[200]\teval-auc:0.80555\n",
      "[300]\teval-auc:0.806779\n",
      "[400]\teval-auc:0.807406\n",
      "[500]\teval-auc:0.807878\n",
      "[600]\teval-auc:0.80805\n",
      "[700]\teval-auc:0.808086\n",
      "[800]\teval-auc:0.808124\n",
      "[900]\teval-auc:0.808139\n",
      "[1000]\teval-auc:0.808159\n",
      "[1100]\teval-auc:0.80817\n",
      "[1200]\teval-auc:0.808223\n",
      "[1300]\teval-auc:0.80825\n",
      "[1400]\teval-auc:0.808289\n",
      "Stopping. Best iteration:\n",
      "[1360]\teval-auc:0.808301\n",
      "\n",
      "[0]\teval-auc:0.781971\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.809042\n",
      "[200]\teval-auc:0.812227\n",
      "[300]\teval-auc:0.813441\n",
      "[400]\teval-auc:0.813923\n",
      "[500]\teval-auc:0.814275\n",
      "[600]\teval-auc:0.814487\n",
      "[700]\teval-auc:0.81458\n",
      "[800]\teval-auc:0.814618\n",
      "[900]\teval-auc:0.814652\n",
      "[1000]\teval-auc:0.814708\n",
      "[1100]\teval-auc:0.814788\n",
      "[1200]\teval-auc:0.814893\n",
      "[1300]\teval-auc:0.814997\n",
      "[1400]\teval-auc:0.815084\n",
      "[1500]\teval-auc:0.815178\n",
      "[1600]\teval-auc:0.815261\n",
      "[1700]\teval-auc:0.815417\n",
      "[1800]\teval-auc:0.815484\n",
      "[1900]\teval-auc:0.815551\n",
      "[2000]\teval-auc:0.815667\n",
      "[2100]\teval-auc:0.815802\n",
      "[2200]\teval-auc:0.815818\n",
      "[2300]\teval-auc:0.815832\n",
      "[2400]\teval-auc:0.815842\n",
      "[2500]\teval-auc:0.815857\n",
      "[2600]\teval-auc:0.815886\n",
      "[2700]\teval-auc:0.815954\n",
      "[2800]\teval-auc:0.81606\n",
      "[2900]\teval-auc:0.816079\n",
      "[3000]\teval-auc:0.816113\n",
      "[3100]\teval-auc:0.816102\n",
      "Stopping. Best iteration:\n",
      "[3027]\teval-auc:0.816126\n",
      "\n",
      "[0]\teval-auc:0.778807\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.80549\n",
      "[200]\teval-auc:0.809606\n",
      "[300]\teval-auc:0.810938\n",
      "[400]\teval-auc:0.811228\n",
      "[500]\teval-auc:0.811398\n",
      "[600]\teval-auc:0.811497\n",
      "[700]\teval-auc:0.811604\n",
      "[800]\teval-auc:0.811643\n",
      "Stopping. Best iteration:\n",
      "[759]\teval-auc:0.811669\n",
      "\n",
      "cv score - on train:\n",
      "0.8110132925768436\n",
      "('current score in fold:', 0.8110132925768436, 1)\n",
      "[0]\teval-auc:0.77429\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.802968\n",
      "[200]\teval-auc:0.805535\n",
      "[300]\teval-auc:0.807111\n",
      "[400]\teval-auc:0.807378\n",
      "[500]\teval-auc:0.807611\n",
      "[600]\teval-auc:0.807685\n",
      "[700]\teval-auc:0.807865\n",
      "[800]\teval-auc:0.807887\n",
      "[900]\teval-auc:0.807922\n",
      "[1000]\teval-auc:0.807965\n",
      "[1100]\teval-auc:0.807991\n",
      "[1200]\teval-auc:0.80807\n",
      "[1300]\teval-auc:0.808101\n",
      "[1400]\teval-auc:0.808161\n",
      "[1500]\teval-auc:0.808215\n",
      "[1600]\teval-auc:0.808239\n",
      "Stopping. Best iteration:\n",
      "[1573]\teval-auc:0.808251\n",
      "\n",
      "[0]\teval-auc:0.779397\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.804124\n",
      "[200]\teval-auc:0.810373\n",
      "[300]\teval-auc:0.81116\n",
      "[400]\teval-auc:0.811594\n",
      "[500]\teval-auc:0.811861\n",
      "[600]\teval-auc:0.811954\n",
      "[700]\teval-auc:0.812018\n",
      "[800]\teval-auc:0.812021\n",
      "[900]\teval-auc:0.812049\n",
      "[1000]\teval-auc:0.812088\n",
      "[1100]\teval-auc:0.812102\n",
      "[1200]\teval-auc:0.8122\n",
      "[1300]\teval-auc:0.812349\n",
      "[1400]\teval-auc:0.812382\n",
      "[1500]\teval-auc:0.812444\n",
      "[1600]\teval-auc:0.812501\n",
      "[1700]\teval-auc:0.812554\n",
      "[1800]\teval-auc:0.812563\n",
      "Stopping. Best iteration:\n",
      "[1726]\teval-auc:0.812572\n",
      "\n",
      "[0]\teval-auc:0.775335\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.806055\n",
      "[200]\teval-auc:0.809438\n",
      "[300]\teval-auc:0.810554\n",
      "[400]\teval-auc:0.811528\n",
      "[500]\teval-auc:0.812073\n",
      "[600]\teval-auc:0.812203\n",
      "[700]\teval-auc:0.812261\n",
      "[800]\teval-auc:0.812353\n",
      "[900]\teval-auc:0.812406\n",
      "[1000]\teval-auc:0.812463\n",
      "[1100]\teval-auc:0.812473\n",
      "[1200]\teval-auc:0.812499\n",
      "[1300]\teval-auc:0.81257\n",
      "[1400]\teval-auc:0.812594\n",
      "[1500]\teval-auc:0.812627\n",
      "[1600]\teval-auc:0.812661\n",
      "[1700]\teval-auc:0.81271\n",
      "[1800]\teval-auc:0.812763\n",
      "[1900]\teval-auc:0.812803\n",
      "[2000]\teval-auc:0.812824\n",
      "[2100]\teval-auc:0.812867\n",
      "[2200]\teval-auc:0.812935\n",
      "[2300]\teval-auc:0.813015\n",
      "[2400]\teval-auc:0.813056\n",
      "[2500]\teval-auc:0.813097\n",
      "[2600]\teval-auc:0.813149\n",
      "[2700]\teval-auc:0.813194\n",
      "[2800]\teval-auc:0.813248\n",
      "[2900]\teval-auc:0.81328\n",
      "[3000]\teval-auc:0.813313\n",
      "[3100]\teval-auc:0.813362\n",
      "[3200]\teval-auc:0.813402\n",
      "[3300]\teval-auc:0.813423\n",
      "[3400]\teval-auc:0.813429\n",
      "[3500]\teval-auc:0.813429\n",
      "[3600]\teval-auc:0.813446\n",
      "[3700]\teval-auc:0.81347\n",
      "[3800]\teval-auc:0.81349\n",
      "[3900]\teval-auc:0.813503\n",
      "Stopping. Best iteration:\n",
      "[3861]\teval-auc:0.813506\n",
      "\n",
      "[0]\teval-auc:0.778668\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.8029\n",
      "[200]\teval-auc:0.808125\n",
      "[300]\teval-auc:0.809465\n",
      "[400]\teval-auc:0.809991\n",
      "[500]\teval-auc:0.810311\n",
      "[600]\teval-auc:0.810485\n",
      "[700]\teval-auc:0.810631\n",
      "[800]\teval-auc:0.810725\n",
      "[900]\teval-auc:0.810772\n",
      "[1000]\teval-auc:0.810815\n",
      "[1100]\teval-auc:0.810895\n",
      "[1200]\teval-auc:0.810999\n",
      "[1300]\teval-auc:0.811112\n",
      "[1400]\teval-auc:0.811279\n",
      "[1500]\teval-auc:0.811429\n",
      "[1600]\teval-auc:0.811556\n",
      "[1700]\teval-auc:0.811676\n",
      "[1800]\teval-auc:0.811802\n",
      "[1900]\teval-auc:0.811858\n",
      "[2000]\teval-auc:0.81187\n",
      "[2100]\teval-auc:0.811889\n",
      "[2200]\teval-auc:0.811905\n",
      "[2300]\teval-auc:0.811919\n",
      "[2400]\teval-auc:0.811923\n",
      "[2500]\teval-auc:0.811942\n",
      "[2600]\teval-auc:0.811953\n",
      "[2700]\teval-auc:0.811989\n",
      "[2800]\teval-auc:0.812004\n",
      "[2900]\teval-auc:0.812004\n",
      "[3000]\teval-auc:0.812045\n",
      "[3100]\teval-auc:0.812087\n",
      "[3200]\teval-auc:0.812113\n",
      "[3300]\teval-auc:0.812151\n",
      "[3400]\teval-auc:0.812173\n",
      "[3500]\teval-auc:0.812183\n",
      "[3600]\teval-auc:0.812195\n",
      "[3700]\teval-auc:0.812203\n",
      "[3800]\teval-auc:0.81222\n",
      "[3900]\teval-auc:0.81222\n",
      "[4000]\teval-auc:0.812251\n",
      "[4100]\teval-auc:0.812264\n",
      "[4200]\teval-auc:0.812279\n",
      "[4300]\teval-auc:0.812309\n",
      "[4400]\teval-auc:0.812302\n",
      "Stopping. Best iteration:\n",
      "[4302]\teval-auc:0.812311\n",
      "\n",
      "[0]\teval-auc:0.771944\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.804853\n",
      "[200]\teval-auc:0.807492\n",
      "[300]\teval-auc:0.808924\n",
      "[400]\teval-auc:0.809626\n",
      "[500]\teval-auc:0.810039\n",
      "[600]\teval-auc:0.810337\n",
      "[700]\teval-auc:0.810397\n",
      "[800]\teval-auc:0.81053\n",
      "[900]\teval-auc:0.810649\n",
      "[1000]\teval-auc:0.810778\n",
      "[1100]\teval-auc:0.810925\n",
      "[1200]\teval-auc:0.811023\n",
      "[1300]\teval-auc:0.811061\n",
      "[1400]\teval-auc:0.811066\n",
      "[1500]\teval-auc:0.81107\n",
      "Stopping. Best iteration:\n",
      "[1410]\teval-auc:0.811074\n",
      "\n",
      "cv score - on train:\n",
      "0.8114674393208827\n",
      "('current score in fold:', 0.8115558961192011, 2)\n",
      "[0]\teval-auc:0.764958\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.800495\n",
      "[200]\teval-auc:0.804271\n",
      "[300]\teval-auc:0.805297\n",
      "[400]\teval-auc:0.80593\n",
      "[500]\teval-auc:0.806149\n",
      "[600]\teval-auc:0.806196\n",
      "[700]\teval-auc:0.806241\n",
      "[800]\teval-auc:0.806246\n",
      "[900]\teval-auc:0.806285\n",
      "[1000]\teval-auc:0.806263\n",
      "Stopping. Best iteration:\n",
      "[946]\teval-auc:0.806294\n",
      "\n",
      "[0]\teval-auc:0.76945\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.803306\n",
      "[200]\teval-auc:0.806802\n",
      "[300]\teval-auc:0.807767\n",
      "[400]\teval-auc:0.808257\n",
      "[500]\teval-auc:0.808605\n",
      "[600]\teval-auc:0.808831\n",
      "[700]\teval-auc:0.808987\n",
      "[800]\teval-auc:0.809064\n",
      "[900]\teval-auc:0.809109\n",
      "[1000]\teval-auc:0.809126\n",
      "[1100]\teval-auc:0.80919\n",
      "[1200]\teval-auc:0.80934\n",
      "[1300]\teval-auc:0.80941\n",
      "[1400]\teval-auc:0.809437\n",
      "[1500]\teval-auc:0.809463\n",
      "[1600]\teval-auc:0.809481\n",
      "[1700]\teval-auc:0.809527\n",
      "[1800]\teval-auc:0.809591\n",
      "[1900]\teval-auc:0.809652\n",
      "[2000]\teval-auc:0.809691\n",
      "[2100]\teval-auc:0.809729\n",
      "[2200]\teval-auc:0.809747\n",
      "[2300]\teval-auc:0.809764\n",
      "[2400]\teval-auc:0.809776\n",
      "[2500]\teval-auc:0.809792\n",
      "[2600]\teval-auc:0.809804\n",
      "[2700]\teval-auc:0.809825\n",
      "[2800]\teval-auc:0.809846\n",
      "[2900]\teval-auc:0.809864\n",
      "[3000]\teval-auc:0.809861\n",
      "Stopping. Best iteration:\n",
      "[2901]\teval-auc:0.809865\n",
      "\n",
      "[0]\teval-auc:0.770572\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.805958\n",
      "[200]\teval-auc:0.809525\n",
      "[300]\teval-auc:0.810903\n",
      "[400]\teval-auc:0.811266\n",
      "[500]\teval-auc:0.811587\n",
      "[600]\teval-auc:0.81178\n",
      "[700]\teval-auc:0.81188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[800]\teval-auc:0.811959\n",
      "[900]\teval-auc:0.812014\n",
      "[1000]\teval-auc:0.812092\n",
      "[1100]\teval-auc:0.812121\n",
      "[1200]\teval-auc:0.812192\n",
      "[1300]\teval-auc:0.812209\n",
      "[1400]\teval-auc:0.812267\n",
      "[1500]\teval-auc:0.812343\n",
      "[1600]\teval-auc:0.812373\n",
      "[1700]\teval-auc:0.812416\n",
      "[1800]\teval-auc:0.812424\n",
      "Stopping. Best iteration:\n",
      "[1794]\teval-auc:0.812429\n",
      "\n",
      "[0]\teval-auc:0.774159\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.808837\n",
      "[200]\teval-auc:0.812703\n",
      "[300]\teval-auc:0.81393\n",
      "[400]\teval-auc:0.814346\n",
      "[500]\teval-auc:0.814869\n",
      "[600]\teval-auc:0.815095\n",
      "[700]\teval-auc:0.815287\n",
      "[800]\teval-auc:0.815351\n",
      "[900]\teval-auc:0.81551\n",
      "[1000]\teval-auc:0.815599\n",
      "Stopping. Best iteration:\n",
      "[994]\teval-auc:0.815605\n",
      "\n",
      "[0]\teval-auc:0.776046\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.804621\n",
      "[200]\teval-auc:0.808338\n",
      "[300]\teval-auc:0.809269\n",
      "[400]\teval-auc:0.80978\n",
      "[500]\teval-auc:0.810152\n",
      "[600]\teval-auc:0.810406\n",
      "[700]\teval-auc:0.810514\n",
      "[800]\teval-auc:0.810563\n",
      "[900]\teval-auc:0.810612\n",
      "[1000]\teval-auc:0.810671\n",
      "[1100]\teval-auc:0.810697\n",
      "[1200]\teval-auc:0.810736\n",
      "[1300]\teval-auc:0.810784\n",
      "[1400]\teval-auc:0.810852\n",
      "[1500]\teval-auc:0.810921\n",
      "[1600]\teval-auc:0.81097\n",
      "[1700]\teval-auc:0.811046\n",
      "[1800]\teval-auc:0.811102\n",
      "[1900]\teval-auc:0.811152\n",
      "[2000]\teval-auc:0.811188\n",
      "[2100]\teval-auc:0.811205\n",
      "[2200]\teval-auc:0.811224\n",
      "[2300]\teval-auc:0.811247\n",
      "[2400]\teval-auc:0.811266\n",
      "[2500]\teval-auc:0.811285\n",
      "[2600]\teval-auc:0.811288\n",
      "[2700]\teval-auc:0.81129\n",
      "Stopping. Best iteration:\n",
      "[2665]\teval-auc:0.811292\n",
      "\n",
      "cv score - on train:\n",
      "0.8110139806247505\n",
      "('current score in fold:', 0.8115740204139689, 3)\n",
      "[0]\teval-auc:0.769171\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.800974\n",
      "[200]\teval-auc:0.805145\n",
      "[300]\teval-auc:0.806342\n",
      "[400]\teval-auc:0.807091\n",
      "[500]\teval-auc:0.80743\n",
      "[600]\teval-auc:0.807479\n",
      "[700]\teval-auc:0.807536\n",
      "[800]\teval-auc:0.807551\n",
      "[900]\teval-auc:0.807576\n",
      "[1000]\teval-auc:0.807586\n",
      "Stopping. Best iteration:\n",
      "[959]\teval-auc:0.807593\n",
      "\n",
      "[0]\teval-auc:0.775653\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.805005\n",
      "[200]\teval-auc:0.807827\n",
      "[300]\teval-auc:0.809282\n",
      "[400]\teval-auc:0.809974\n",
      "[500]\teval-auc:0.810336\n",
      "[600]\teval-auc:0.810594\n",
      "[700]\teval-auc:0.810672\n",
      "[800]\teval-auc:0.810689\n",
      "[900]\teval-auc:0.810703\n",
      "Stopping. Best iteration:\n",
      "[887]\teval-auc:0.810717\n",
      "\n",
      "[0]\teval-auc:0.780766\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.805834\n",
      "[200]\teval-auc:0.811333\n",
      "[300]\teval-auc:0.812083\n",
      "[400]\teval-auc:0.81234\n",
      "[500]\teval-auc:0.812605\n",
      "[600]\teval-auc:0.812807\n",
      "[700]\teval-auc:0.812886\n",
      "[800]\teval-auc:0.812902\n",
      "[900]\teval-auc:0.812963\n",
      "[1000]\teval-auc:0.813022\n",
      "[1100]\teval-auc:0.813002\n",
      "Stopping. Best iteration:\n",
      "[1017]\teval-auc:0.813034\n",
      "\n",
      "[0]\teval-auc:0.770861\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.801855\n",
      "[200]\teval-auc:0.805711\n",
      "[300]\teval-auc:0.806591\n",
      "[400]\teval-auc:0.807151\n",
      "[500]\teval-auc:0.807677\n",
      "[600]\teval-auc:0.807884\n",
      "[700]\teval-auc:0.807908\n",
      "[800]\teval-auc:0.807903\n",
      "[900]\teval-auc:0.807976\n",
      "[1000]\teval-auc:0.808024\n",
      "[1100]\teval-auc:0.808078\n",
      "[1200]\teval-auc:0.808134\n",
      "[1300]\teval-auc:0.808256\n",
      "[1400]\teval-auc:0.808372\n",
      "[1500]\teval-auc:0.808452\n",
      "[1600]\teval-auc:0.808544\n",
      "[1700]\teval-auc:0.808635\n",
      "[1800]\teval-auc:0.808732\n",
      "[1900]\teval-auc:0.808772\n",
      "[2000]\teval-auc:0.808823\n",
      "[2100]\teval-auc:0.808838\n",
      "[2200]\teval-auc:0.808829\n",
      "Stopping. Best iteration:\n",
      "[2110]\teval-auc:0.80884\n",
      "\n",
      "[0]\teval-auc:0.780498\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.809014\n",
      "[200]\teval-auc:0.811713\n",
      "[300]\teval-auc:0.813099\n",
      "[400]\teval-auc:0.8134\n",
      "[500]\teval-auc:0.813895\n",
      "[600]\teval-auc:0.814172\n",
      "[700]\teval-auc:0.814297\n",
      "[800]\teval-auc:0.814392\n",
      "[900]\teval-auc:0.814455\n",
      "[1000]\teval-auc:0.814504\n",
      "[1100]\teval-auc:0.814545\n",
      "[1200]\teval-auc:0.814567\n",
      "[1300]\teval-auc:0.814613\n",
      "[1400]\teval-auc:0.814671\n",
      "[1500]\teval-auc:0.8147\n",
      "Stopping. Best iteration:\n",
      "[1476]\teval-auc:0.814707\n",
      "\n",
      "cv score - on train:\n",
      "0.8109090703830117\n",
      "('current score in fold:', 0.8115317084245199, 4)\n",
      "[0]\teval-auc:0.775982\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.802444\n",
      "[200]\teval-auc:0.807037\n",
      "[300]\teval-auc:0.808433\n",
      "[400]\teval-auc:0.808664\n",
      "[500]\teval-auc:0.809067\n",
      "[600]\teval-auc:0.809355\n",
      "[700]\teval-auc:0.80946\n",
      "[800]\teval-auc:0.809494\n",
      "[900]\teval-auc:0.809518\n",
      "[1000]\teval-auc:0.809562\n",
      "[1100]\teval-auc:0.809597\n",
      "[1200]\teval-auc:0.809623\n",
      "[1300]\teval-auc:0.809666\n",
      "[1400]\teval-auc:0.80977\n",
      "[1500]\teval-auc:0.809889\n",
      "[1600]\teval-auc:0.809971\n",
      "[1700]\teval-auc:0.810012\n",
      "[1800]\teval-auc:0.810029\n",
      "[1900]\teval-auc:0.810032\n",
      "[2000]\teval-auc:0.810084\n",
      "[2100]\teval-auc:0.810098\n",
      "[2200]\teval-auc:0.810104\n",
      "Stopping. Best iteration:\n",
      "[2138]\teval-auc:0.810112\n",
      "\n",
      "[0]\teval-auc:0.777983\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.806543\n",
      "[200]\teval-auc:0.809481\n",
      "[300]\teval-auc:0.81092\n",
      "[400]\teval-auc:0.811402\n",
      "[500]\teval-auc:0.81185\n",
      "[600]\teval-auc:0.812007\n",
      "[700]\teval-auc:0.812055\n",
      "[800]\teval-auc:0.812068\n",
      "[900]\teval-auc:0.812141\n",
      "[1000]\teval-auc:0.812159\n",
      "[1100]\teval-auc:0.812122\n",
      "Stopping. Best iteration:\n",
      "[1012]\teval-auc:0.812167\n",
      "\n",
      "[0]\teval-auc:0.77153\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.799942\n",
      "[200]\teval-auc:0.803983\n",
      "[300]\teval-auc:0.804905\n",
      "[400]\teval-auc:0.805456\n",
      "[500]\teval-auc:0.805825\n",
      "[600]\teval-auc:0.806059\n",
      "[700]\teval-auc:0.806186\n",
      "[800]\teval-auc:0.806313\n",
      "[900]\teval-auc:0.806371\n",
      "[1000]\teval-auc:0.806417\n",
      "[1100]\teval-auc:0.806502\n",
      "[1200]\teval-auc:0.806591\n",
      "[1300]\teval-auc:0.806701\n",
      "[1400]\teval-auc:0.806797\n",
      "[1500]\teval-auc:0.806881\n",
      "[1600]\teval-auc:0.806942\n",
      "[1700]\teval-auc:0.806999\n",
      "[1800]\teval-auc:0.807028\n",
      "[1900]\teval-auc:0.807053\n",
      "[2000]\teval-auc:0.807037\n",
      "Stopping. Best iteration:\n",
      "[1938]\teval-auc:0.807072\n",
      "\n",
      "[0]\teval-auc:0.77467\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.805965\n",
      "[200]\teval-auc:0.808834\n",
      "[300]\teval-auc:0.810378\n",
      "[400]\teval-auc:0.811155\n",
      "[500]\teval-auc:0.811492\n",
      "[600]\teval-auc:0.811577\n",
      "[700]\teval-auc:0.8117\n",
      "[800]\teval-auc:0.811826\n",
      "[900]\teval-auc:0.811872\n",
      "[1000]\teval-auc:0.811904\n",
      "Stopping. Best iteration:\n",
      "[996]\teval-auc:0.811905\n",
      "\n",
      "[0]\teval-auc:0.780002\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.807646\n",
      "[200]\teval-auc:0.811278\n",
      "[300]\teval-auc:0.812832\n",
      "[400]\teval-auc:0.813257\n",
      "[500]\teval-auc:0.813597\n",
      "[600]\teval-auc:0.813771\n",
      "[700]\teval-auc:0.813789\n",
      "[800]\teval-auc:0.813815\n",
      "[900]\teval-auc:0.813825\n",
      "[1000]\teval-auc:0.813863\n",
      "[1100]\teval-auc:0.813821\n",
      "Stopping. Best iteration:\n",
      "[1006]\teval-auc:0.813864\n",
      "\n",
      "cv score - on train:\n",
      "0.8109532535036739\n",
      "('current score in fold:', 0.8115116031331695, 5)\n",
      "[0]\teval-auc:0.775699\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.804296\n",
      "[200]\teval-auc:0.808261\n",
      "[300]\teval-auc:0.809235\n",
      "[400]\teval-auc:0.809526\n",
      "[500]\teval-auc:0.809944\n",
      "[600]\teval-auc:0.810141\n",
      "[700]\teval-auc:0.810193\n",
      "[800]\teval-auc:0.810252\n",
      "[900]\teval-auc:0.810279\n",
      "[1000]\teval-auc:0.810317\n",
      "[1100]\teval-auc:0.810319\n",
      "Stopping. Best iteration:\n",
      "[1089]\teval-auc:0.810322\n",
      "\n",
      "[0]\teval-auc:0.774323\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.806704\n",
      "[200]\teval-auc:0.810645\n",
      "[300]\teval-auc:0.811705\n",
      "[400]\teval-auc:0.812152\n",
      "[500]\teval-auc:0.812533\n",
      "[600]\teval-auc:0.81271\n",
      "[700]\teval-auc:0.812851\n",
      "[800]\teval-auc:0.812997\n",
      "[900]\teval-auc:0.813076\n",
      "[1000]\teval-auc:0.81321\n",
      "[1100]\teval-auc:0.813276\n",
      "[1200]\teval-auc:0.813311\n",
      "[1300]\teval-auc:0.813368\n",
      "[1400]\teval-auc:0.813464\n",
      "[1500]\teval-auc:0.813545\n",
      "[1600]\teval-auc:0.813576\n",
      "Stopping. Best iteration:\n",
      "[1593]\teval-auc:0.813582\n",
      "\n",
      "[0]\teval-auc:0.773559\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.802386\n",
      "[200]\teval-auc:0.806329\n",
      "[300]\teval-auc:0.807312\n",
      "[400]\teval-auc:0.807924\n",
      "[500]\teval-auc:0.808128\n",
      "[600]\teval-auc:0.808376\n",
      "[700]\teval-auc:0.808407\n",
      "[800]\teval-auc:0.808492\n",
      "[900]\teval-auc:0.80854\n",
      "[1000]\teval-auc:0.808605\n",
      "[1100]\teval-auc:0.808688\n",
      "[1200]\teval-auc:0.808778\n",
      "[1300]\teval-auc:0.808869\n",
      "[1400]\teval-auc:0.808954\n",
      "[1500]\teval-auc:0.808994\n",
      "[1600]\teval-auc:0.809045\n",
      "[1700]\teval-auc:0.80908\n",
      "[1800]\teval-auc:0.809145\n",
      "[1900]\teval-auc:0.809218\n",
      "[2000]\teval-auc:0.809255\n",
      "[2100]\teval-auc:0.809284\n",
      "[2200]\teval-auc:0.809296\n",
      "[2300]\teval-auc:0.809321\n",
      "[2400]\teval-auc:0.809346\n",
      "[2500]\teval-auc:0.809361\n",
      "[2600]\teval-auc:0.809397\n",
      "[2700]\teval-auc:0.809441\n",
      "[2800]\teval-auc:0.809482\n",
      "[2900]\teval-auc:0.809523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3000]\teval-auc:0.809541\n",
      "[3100]\teval-auc:0.809566\n",
      "[3200]\teval-auc:0.809597\n",
      "[3300]\teval-auc:0.809614\n",
      "[3400]\teval-auc:0.809625\n",
      "[3500]\teval-auc:0.80964\n",
      "[3600]\teval-auc:0.80966\n",
      "[3700]\teval-auc:0.809668\n",
      "[3800]\teval-auc:0.809678\n",
      "[3900]\teval-auc:0.80968\n",
      "Stopping. Best iteration:\n",
      "[3827]\teval-auc:0.809691\n",
      "\n",
      "[0]\teval-auc:0.777423\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.805645\n",
      "[200]\teval-auc:0.808736\n",
      "[300]\teval-auc:0.810928\n",
      "[400]\teval-auc:0.811289\n",
      "[500]\teval-auc:0.811709\n",
      "[600]\teval-auc:0.811854\n",
      "[700]\teval-auc:0.812016\n",
      "[800]\teval-auc:0.812123\n",
      "[900]\teval-auc:0.812205\n",
      "[1000]\teval-auc:0.812277\n",
      "[1100]\teval-auc:0.81232\n",
      "[1200]\teval-auc:0.812389\n",
      "[1300]\teval-auc:0.812501\n",
      "[1400]\teval-auc:0.812671\n",
      "[1500]\teval-auc:0.812762\n",
      "[1600]\teval-auc:0.812828\n",
      "[1700]\teval-auc:0.812907\n",
      "[1800]\teval-auc:0.812944\n",
      "[1900]\teval-auc:0.812979\n",
      "[2000]\teval-auc:0.812992\n",
      "Stopping. Best iteration:\n",
      "[1942]\teval-auc:0.812993\n",
      "\n",
      "[0]\teval-auc:0.774375\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.80341\n",
      "[200]\teval-auc:0.807268\n",
      "[300]\teval-auc:0.80829\n",
      "[400]\teval-auc:0.809109\n",
      "[500]\teval-auc:0.809441\n",
      "[600]\teval-auc:0.809517\n",
      "[700]\teval-auc:0.809589\n",
      "[800]\teval-auc:0.809685\n",
      "[900]\teval-auc:0.809713\n",
      "[1000]\teval-auc:0.809744\n",
      "[1100]\teval-auc:0.809781\n",
      "[1200]\teval-auc:0.80978\n",
      "Stopping. Best iteration:\n",
      "[1149]\teval-auc:0.809796\n",
      "\n",
      "cv score - on train:\n",
      "0.811188341383394\n",
      "('current score in fold:', 0.8115558184582071, 6)\n",
      "[0]\teval-auc:0.77813\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.80543\n",
      "[200]\teval-auc:0.809113\n",
      "[300]\teval-auc:0.810116\n",
      "[400]\teval-auc:0.810501\n",
      "[500]\teval-auc:0.81088\n",
      "[600]\teval-auc:0.811037\n",
      "[700]\teval-auc:0.811158\n",
      "[800]\teval-auc:0.81126\n",
      "[900]\teval-auc:0.811328\n",
      "[1000]\teval-auc:0.811351\n",
      "Stopping. Best iteration:\n",
      "[975]\teval-auc:0.811356\n",
      "\n",
      "[0]\teval-auc:0.771695\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.801824\n",
      "[200]\teval-auc:0.804615\n",
      "[300]\teval-auc:0.805942\n",
      "[400]\teval-auc:0.806244\n",
      "[500]\teval-auc:0.806583\n",
      "[600]\teval-auc:0.806815\n",
      "[700]\teval-auc:0.806883\n",
      "[800]\teval-auc:0.806973\n",
      "[900]\teval-auc:0.807037\n",
      "[1000]\teval-auc:0.807119\n",
      "[1100]\teval-auc:0.807185\n",
      "[1200]\teval-auc:0.80723\n",
      "[1300]\teval-auc:0.807246\n",
      "[1400]\teval-auc:0.807299\n",
      "[1500]\teval-auc:0.807339\n",
      "[1600]\teval-auc:0.807399\n",
      "[1700]\teval-auc:0.807493\n",
      "[1800]\teval-auc:0.807544\n",
      "[1900]\teval-auc:0.807611\n",
      "[2000]\teval-auc:0.807652\n",
      "[2100]\teval-auc:0.807675\n",
      "[2200]\teval-auc:0.8077\n",
      "[2300]\teval-auc:0.807701\n",
      "Stopping. Best iteration:\n",
      "[2247]\teval-auc:0.807705\n",
      "\n",
      "[0]\teval-auc:0.773165\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.803334\n",
      "[200]\teval-auc:0.808764\n",
      "[300]\teval-auc:0.809885\n",
      "[400]\teval-auc:0.81022\n",
      "[500]\teval-auc:0.810546\n",
      "[600]\teval-auc:0.810805\n",
      "[700]\teval-auc:0.810922\n",
      "[800]\teval-auc:0.811013\n",
      "[900]\teval-auc:0.811122\n",
      "[1000]\teval-auc:0.811229\n",
      "[1100]\teval-auc:0.811283\n",
      "[1200]\teval-auc:0.811356\n",
      "[1300]\teval-auc:0.811449\n",
      "[1400]\teval-auc:0.811503\n",
      "[1500]\teval-auc:0.811493\n",
      "Stopping. Best iteration:\n",
      "[1402]\teval-auc:0.811506\n",
      "\n",
      "[0]\teval-auc:0.779936\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.806827\n",
      "[200]\teval-auc:0.809752\n",
      "[300]\teval-auc:0.810479\n",
      "[400]\teval-auc:0.810966\n",
      "[500]\teval-auc:0.811332\n",
      "[600]\teval-auc:0.811469\n",
      "[700]\teval-auc:0.811498\n",
      "Stopping. Best iteration:\n",
      "[661]\teval-auc:0.811502\n",
      "\n",
      "[0]\teval-auc:0.779807\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.807203\n",
      "[200]\teval-auc:0.810527\n",
      "[300]\teval-auc:0.811934\n",
      "[400]\teval-auc:0.812753\n",
      "[500]\teval-auc:0.813102\n",
      "[600]\teval-auc:0.813223\n",
      "[700]\teval-auc:0.813216\n",
      "Stopping. Best iteration:\n",
      "[640]\teval-auc:0.813233\n",
      "\n",
      "cv score - on train:\n",
      "0.8109613108674185\n",
      "('current score in fold:', 0.8115385325459306, 7)\n",
      "[0]\teval-auc:0.775116\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.803606\n",
      "[200]\teval-auc:0.806823\n",
      "[300]\teval-auc:0.807713\n",
      "[400]\teval-auc:0.808079\n",
      "[500]\teval-auc:0.808462\n",
      "[600]\teval-auc:0.808648\n",
      "[700]\teval-auc:0.808824\n",
      "[800]\teval-auc:0.808898\n",
      "[900]\teval-auc:0.808999\n",
      "[1000]\teval-auc:0.809066\n",
      "[1100]\teval-auc:0.809135\n",
      "[1200]\teval-auc:0.809214\n",
      "[1300]\teval-auc:0.809255\n",
      "[1400]\teval-auc:0.809342\n",
      "[1500]\teval-auc:0.809455\n",
      "[1600]\teval-auc:0.80952\n",
      "[1700]\teval-auc:0.809571\n",
      "[1800]\teval-auc:0.809608\n",
      "[1900]\teval-auc:0.809665\n",
      "[2000]\teval-auc:0.809716\n",
      "[2100]\teval-auc:0.809725\n",
      "Stopping. Best iteration:\n",
      "[2090]\teval-auc:0.809726\n",
      "\n",
      "[0]\teval-auc:0.77618\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.803562\n",
      "[200]\teval-auc:0.807448\n",
      "[300]\teval-auc:0.808241\n",
      "[400]\teval-auc:0.808651\n",
      "[500]\teval-auc:0.809084\n",
      "[600]\teval-auc:0.809264\n",
      "[700]\teval-auc:0.80934\n",
      "[800]\teval-auc:0.809367\n",
      "[900]\teval-auc:0.809389\n",
      "[1000]\teval-auc:0.809392\n",
      "Stopping. Best iteration:\n",
      "[954]\teval-auc:0.809415\n",
      "\n",
      "[0]\teval-auc:0.772124\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.800652\n",
      "[200]\teval-auc:0.804238\n",
      "[300]\teval-auc:0.805473\n",
      "[400]\teval-auc:0.80608\n",
      "[500]\teval-auc:0.806393\n",
      "[600]\teval-auc:0.806584\n",
      "[700]\teval-auc:0.806675\n",
      "[800]\teval-auc:0.806765\n",
      "[900]\teval-auc:0.806811\n",
      "Stopping. Best iteration:\n",
      "[878]\teval-auc:0.806835\n",
      "\n",
      "[0]\teval-auc:0.777517\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.807349\n",
      "[200]\teval-auc:0.811019\n",
      "[300]\teval-auc:0.812178\n",
      "[400]\teval-auc:0.81258\n",
      "[500]\teval-auc:0.812993\n",
      "[600]\teval-auc:0.813197\n",
      "[700]\teval-auc:0.813242\n",
      "[800]\teval-auc:0.813308\n",
      "[900]\teval-auc:0.813334\n",
      "[1000]\teval-auc:0.81337\n",
      "[1100]\teval-auc:0.813414\n",
      "[1200]\teval-auc:0.813482\n",
      "[1300]\teval-auc:0.813522\n",
      "[1400]\teval-auc:0.813619\n",
      "[1500]\teval-auc:0.813772\n",
      "[1600]\teval-auc:0.813902\n",
      "[1700]\teval-auc:0.813929\n",
      "[1800]\teval-auc:0.813938\n",
      "[1900]\teval-auc:0.81395\n",
      "[2000]\teval-auc:0.81397\n",
      "[2100]\teval-auc:0.813993\n",
      "[2200]\teval-auc:0.814015\n",
      "Stopping. Best iteration:\n",
      "[2178]\teval-auc:0.814019\n",
      "\n",
      "[0]\teval-auc:0.782606\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.80938\n",
      "[200]\teval-auc:0.812598\n",
      "[300]\teval-auc:0.813804\n",
      "[400]\teval-auc:0.814373\n",
      "[500]\teval-auc:0.814601\n",
      "[600]\teval-auc:0.814822\n",
      "[700]\teval-auc:0.814887\n",
      "[800]\teval-auc:0.814925\n",
      "[900]\teval-auc:0.814939\n",
      "[1000]\teval-auc:0.81499\n",
      "Stopping. Best iteration:\n",
      "[977]\teval-auc:0.815006\n",
      "\n",
      "cv score - on train:\n",
      "0.8109453302298291\n",
      "('current score in fold:', 0.8115215406767019, 8)\n",
      "[0]\teval-auc:0.779756\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.808289\n",
      "[200]\teval-auc:0.811058\n",
      "[300]\teval-auc:0.812554\n",
      "[400]\teval-auc:0.813475\n",
      "[500]\teval-auc:0.814094\n",
      "[600]\teval-auc:0.81433\n",
      "[700]\teval-auc:0.814345\n",
      "[800]\teval-auc:0.814417\n",
      "[900]\teval-auc:0.814484\n",
      "[1000]\teval-auc:0.81456\n",
      "[1100]\teval-auc:0.814634\n",
      "[1200]\teval-auc:0.814722\n",
      "[1300]\teval-auc:0.814851\n",
      "[1400]\teval-auc:0.815048\n",
      "[1500]\teval-auc:0.815154\n",
      "[1600]\teval-auc:0.815228\n",
      "[1700]\teval-auc:0.81528\n",
      "[1800]\teval-auc:0.815346\n",
      "[1900]\teval-auc:0.815399\n",
      "[2000]\teval-auc:0.815449\n",
      "[2100]\teval-auc:0.815468\n",
      "[2200]\teval-auc:0.815499\n",
      "[2300]\teval-auc:0.815561\n",
      "[2400]\teval-auc:0.815608\n",
      "[2500]\teval-auc:0.815646\n",
      "[2600]\teval-auc:0.815712\n",
      "[2700]\teval-auc:0.815742\n",
      "[2800]\teval-auc:0.815764\n",
      "[2900]\teval-auc:0.815805\n",
      "[3000]\teval-auc:0.815827\n",
      "[3100]\teval-auc:0.815835\n",
      "Stopping. Best iteration:\n",
      "[3073]\teval-auc:0.815842\n",
      "\n",
      "[0]\teval-auc:0.78187\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.80912\n",
      "[200]\teval-auc:0.812984\n",
      "[300]\teval-auc:0.813982\n",
      "[400]\teval-auc:0.814314\n",
      "[500]\teval-auc:0.814891\n",
      "[600]\teval-auc:0.814991\n",
      "[700]\teval-auc:0.815069\n",
      "[800]\teval-auc:0.815107\n",
      "Stopping. Best iteration:\n",
      "[766]\teval-auc:0.815123\n",
      "\n",
      "[0]\teval-auc:0.775577\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.803674\n",
      "[200]\teval-auc:0.807567\n",
      "[300]\teval-auc:0.80892\n",
      "[400]\teval-auc:0.809523\n",
      "[500]\teval-auc:0.809837\n",
      "[600]\teval-auc:0.809962\n",
      "[700]\teval-auc:0.810147\n",
      "[800]\teval-auc:0.81018\n",
      "[900]\teval-auc:0.810201\n",
      "[1000]\teval-auc:0.81031\n",
      "[1100]\teval-auc:0.8104\n",
      "[1200]\teval-auc:0.810427\n",
      "[1300]\teval-auc:0.810479\n",
      "[1400]\teval-auc:0.810545\n",
      "[1500]\teval-auc:0.81062\n",
      "[1600]\teval-auc:0.810691\n",
      "[1700]\teval-auc:0.810749\n",
      "[1800]\teval-auc:0.810812\n",
      "[1900]\teval-auc:0.810863\n",
      "[2000]\teval-auc:0.81094\n",
      "[2100]\teval-auc:0.810981\n",
      "[2200]\teval-auc:0.811017\n",
      "[2300]\teval-auc:0.811036\n",
      "[2400]\teval-auc:0.811073\n",
      "[2500]\teval-auc:0.811107\n",
      "[2600]\teval-auc:0.811144\n",
      "[2700]\teval-auc:0.811174\n",
      "[2800]\teval-auc:0.811196\n",
      "Stopping. Best iteration:\n",
      "[2768]\teval-auc:0.811201\n",
      "\n",
      "[0]\teval-auc:0.771302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.800825\n",
      "[200]\teval-auc:0.80443\n",
      "[300]\teval-auc:0.805542\n",
      "[400]\teval-auc:0.805962\n",
      "[500]\teval-auc:0.806331\n",
      "[600]\teval-auc:0.806409\n",
      "[700]\teval-auc:0.806473\n",
      "[800]\teval-auc:0.806467\n",
      "Stopping. Best iteration:\n",
      "[709]\teval-auc:0.80648\n",
      "\n",
      "[0]\teval-auc:0.771167\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.801138\n",
      "[200]\teval-auc:0.805253\n",
      "[300]\teval-auc:0.80635\n",
      "[400]\teval-auc:0.807005\n",
      "[500]\teval-auc:0.807439\n",
      "[600]\teval-auc:0.807605\n",
      "[700]\teval-auc:0.807777\n",
      "[800]\teval-auc:0.807826\n",
      "[900]\teval-auc:0.807883\n",
      "[1000]\teval-auc:0.808017\n",
      "[1100]\teval-auc:0.808067\n",
      "[1200]\teval-auc:0.808136\n",
      "[1300]\teval-auc:0.808231\n",
      "[1400]\teval-auc:0.808331\n",
      "[1500]\teval-auc:0.808377\n",
      "[1600]\teval-auc:0.808397\n",
      "[1700]\teval-auc:0.808432\n",
      "[1800]\teval-auc:0.808452\n",
      "[1900]\teval-auc:0.808479\n",
      "[2000]\teval-auc:0.808471\n",
      "Stopping. Best iteration:\n",
      "[1910]\teval-auc:0.808487\n",
      "\n",
      "cv score - on train:\n",
      "0.811311920330593\n",
      "('current score in fold:', 0.8115717518579626, 9)\n",
      "[0]\teval-auc:0.773525\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.802089\n",
      "[200]\teval-auc:0.804938\n",
      "[300]\teval-auc:0.806673\n",
      "[400]\teval-auc:0.807158\n",
      "[500]\teval-auc:0.807584\n",
      "[600]\teval-auc:0.807766\n",
      "[700]\teval-auc:0.807842\n",
      "[800]\teval-auc:0.807885\n",
      "[900]\teval-auc:0.807974\n",
      "[1000]\teval-auc:0.808079\n",
      "[1100]\teval-auc:0.808169\n",
      "[1200]\teval-auc:0.808259\n",
      "[1300]\teval-auc:0.808241\n",
      "Stopping. Best iteration:\n",
      "[1212]\teval-auc:0.808262\n",
      "\n",
      "[0]\teval-auc:0.775132\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.801846\n",
      "[200]\teval-auc:0.806726\n",
      "[300]\teval-auc:0.807471\n",
      "[400]\teval-auc:0.807924\n",
      "[500]\teval-auc:0.808382\n",
      "[600]\teval-auc:0.808616\n",
      "[700]\teval-auc:0.808752\n",
      "[800]\teval-auc:0.80885\n",
      "[900]\teval-auc:0.808907\n",
      "[1000]\teval-auc:0.808934\n",
      "[1100]\teval-auc:0.808997\n",
      "[1200]\teval-auc:0.809079\n",
      "[1300]\teval-auc:0.809188\n",
      "[1400]\teval-auc:0.809278\n",
      "[1500]\teval-auc:0.80935\n",
      "[1600]\teval-auc:0.809383\n",
      "[1700]\teval-auc:0.809435\n",
      "[1800]\teval-auc:0.80945\n",
      "[1900]\teval-auc:0.809478\n",
      "[2000]\teval-auc:0.809494\n",
      "[2100]\teval-auc:0.80953\n",
      "[2200]\teval-auc:0.809525\n",
      "Stopping. Best iteration:\n",
      "[2115]\teval-auc:0.809534\n",
      "\n",
      "[0]\teval-auc:0.777255\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.805979\n",
      "[200]\teval-auc:0.808521\n",
      "[300]\teval-auc:0.809443\n",
      "[400]\teval-auc:0.810182\n",
      "[500]\teval-auc:0.81055\n",
      "[600]\teval-auc:0.810837\n",
      "[700]\teval-auc:0.810879\n",
      "[800]\teval-auc:0.810943\n",
      "[900]\teval-auc:0.810958\n",
      "Stopping. Best iteration:\n",
      "[860]\teval-auc:0.810972\n",
      "\n",
      "[0]\teval-auc:0.780281\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.80707\n",
      "[200]\teval-auc:0.810832\n",
      "[300]\teval-auc:0.812258\n",
      "[400]\teval-auc:0.812791\n",
      "[500]\teval-auc:0.813092\n",
      "[600]\teval-auc:0.813211\n",
      "[700]\teval-auc:0.813315\n",
      "[800]\teval-auc:0.813313\n",
      "Stopping. Best iteration:\n",
      "[754]\teval-auc:0.813336\n",
      "\n",
      "[0]\teval-auc:0.779483\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.806947\n",
      "[200]\teval-auc:0.809558\n",
      "[300]\teval-auc:0.810933\n",
      "[400]\teval-auc:0.811339\n",
      "[500]\teval-auc:0.811771\n",
      "[600]\teval-auc:0.811829\n",
      "[700]\teval-auc:0.811898\n",
      "[800]\teval-auc:0.811957\n",
      "[900]\teval-auc:0.811994\n",
      "[1000]\teval-auc:0.812064\n",
      "[1100]\teval-auc:0.812073\n",
      "[1200]\teval-auc:0.812118\n",
      "[1300]\teval-auc:0.8122\n",
      "[1400]\teval-auc:0.81224\n",
      "[1500]\teval-auc:0.812275\n",
      "[1600]\teval-auc:0.812306\n",
      "[1700]\teval-auc:0.81233\n",
      "[1800]\teval-auc:0.81237\n",
      "[1900]\teval-auc:0.812406\n",
      "[2000]\teval-auc:0.812449\n",
      "Stopping. Best iteration:\n",
      "[1997]\teval-auc:0.812452\n",
      "\n",
      "cv score - on train:\n",
      "0.8108230320477924\n",
      "('current score in fold:', 0.8115460053147622, 10)\n",
      "[0]\teval-auc:0.775873\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.8075\n",
      "[200]\teval-auc:0.811079\n",
      "[300]\teval-auc:0.812028\n",
      "[400]\teval-auc:0.812459\n",
      "[500]\teval-auc:0.812762\n",
      "[600]\teval-auc:0.812964\n",
      "[700]\teval-auc:0.813115\n",
      "[800]\teval-auc:0.813176\n",
      "[900]\teval-auc:0.81323\n",
      "[1000]\teval-auc:0.813314\n",
      "[1100]\teval-auc:0.813356\n",
      "[1200]\teval-auc:0.813392\n",
      "[1300]\teval-auc:0.813436\n",
      "[1400]\teval-auc:0.813493\n",
      "[1500]\teval-auc:0.813521\n",
      "[1600]\teval-auc:0.813545\n",
      "[1700]\teval-auc:0.813566\n",
      "[1800]\teval-auc:0.813567\n",
      "[1900]\teval-auc:0.813618\n",
      "[2000]\teval-auc:0.813657\n",
      "[2100]\teval-auc:0.813655\n",
      "[2200]\teval-auc:0.813664\n",
      "Stopping. Best iteration:\n",
      "[2149]\teval-auc:0.813683\n",
      "\n",
      "[0]\teval-auc:0.779188\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.807367\n",
      "[200]\teval-auc:0.811083\n",
      "[300]\teval-auc:0.812639\n",
      "[400]\teval-auc:0.813264\n",
      "[500]\teval-auc:0.813655\n",
      "[600]\teval-auc:0.813863\n",
      "[700]\teval-auc:0.814\n",
      "[800]\teval-auc:0.814074\n",
      "[900]\teval-auc:0.81412\n",
      "[1000]\teval-auc:0.814169\n",
      "[1100]\teval-auc:0.81434\n",
      "[1200]\teval-auc:0.814439\n",
      "[1300]\teval-auc:0.814566\n",
      "[1400]\teval-auc:0.814638\n",
      "[1500]\teval-auc:0.814663\n",
      "[1600]\teval-auc:0.814675\n",
      "[1700]\teval-auc:0.81472\n",
      "[1800]\teval-auc:0.814729\n",
      "[1900]\teval-auc:0.814732\n",
      "Stopping. Best iteration:\n",
      "[1884]\teval-auc:0.814733\n",
      "\n",
      "[0]\teval-auc:0.773654\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.802005\n",
      "[200]\teval-auc:0.805722\n",
      "[300]\teval-auc:0.806571\n",
      "[400]\teval-auc:0.806893\n",
      "[500]\teval-auc:0.807292\n",
      "[600]\teval-auc:0.807487\n",
      "[700]\teval-auc:0.807596\n",
      "[800]\teval-auc:0.807682\n",
      "[900]\teval-auc:0.807757\n",
      "[1000]\teval-auc:0.80782\n",
      "[1100]\teval-auc:0.807877\n",
      "[1200]\teval-auc:0.808055\n",
      "[1300]\teval-auc:0.808151\n",
      "[1400]\teval-auc:0.808178\n",
      "[1500]\teval-auc:0.808244\n",
      "[1600]\teval-auc:0.808301\n",
      "[1700]\teval-auc:0.808349\n",
      "[1800]\teval-auc:0.80839\n",
      "[1900]\teval-auc:0.808399\n",
      "[2000]\teval-auc:0.80845\n",
      "[2100]\teval-auc:0.808476\n",
      "[2200]\teval-auc:0.808516\n",
      "[2300]\teval-auc:0.808558\n",
      "[2400]\teval-auc:0.80861\n",
      "[2500]\teval-auc:0.808657\n",
      "[2600]\teval-auc:0.808658\n",
      "[2700]\teval-auc:0.808687\n",
      "[2800]\teval-auc:0.808687\n",
      "[2900]\teval-auc:0.808699\n",
      "[3000]\teval-auc:0.80871\n",
      "[3100]\teval-auc:0.808722\n",
      "[3200]\teval-auc:0.808732\n",
      "[3300]\teval-auc:0.808735\n",
      "Stopping. Best iteration:\n",
      "[3248]\teval-auc:0.80874\n",
      "\n",
      "[0]\teval-auc:0.774167\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.802994\n",
      "[200]\teval-auc:0.806962\n",
      "[300]\teval-auc:0.80836\n",
      "[400]\teval-auc:0.808588\n",
      "[500]\teval-auc:0.808954\n",
      "[600]\teval-auc:0.809043\n",
      "[700]\teval-auc:0.809104\n",
      "[800]\teval-auc:0.809153\n",
      "[900]\teval-auc:0.809219\n",
      "[1000]\teval-auc:0.809253\n",
      "Stopping. Best iteration:\n",
      "[974]\teval-auc:0.809274\n",
      "\n",
      "[0]\teval-auc:0.777529\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.803471\n",
      "[200]\teval-auc:0.806955\n",
      "[300]\teval-auc:0.80798\n",
      "[400]\teval-auc:0.80848\n",
      "[500]\teval-auc:0.808818\n",
      "[600]\teval-auc:0.808995\n",
      "[700]\teval-auc:0.809055\n",
      "[800]\teval-auc:0.809158\n",
      "[900]\teval-auc:0.809237\n",
      "[1000]\teval-auc:0.809291\n",
      "[1100]\teval-auc:0.80934\n",
      "[1200]\teval-auc:0.809417\n",
      "[1300]\teval-auc:0.809493\n",
      "[1400]\teval-auc:0.80951\n",
      "[1500]\teval-auc:0.809533\n",
      "[1600]\teval-auc:0.809586\n",
      "[1700]\teval-auc:0.809635\n",
      "[1800]\teval-auc:0.809664\n",
      "[1900]\teval-auc:0.809711\n",
      "[2000]\teval-auc:0.8098\n",
      "[2100]\teval-auc:0.809874\n",
      "[2200]\teval-auc:0.809923\n",
      "[2300]\teval-auc:0.809924\n",
      "Stopping. Best iteration:\n",
      "[2223]\teval-auc:0.809948\n",
      "\n",
      "cv score - on train:\n",
      "0.8111782753073542\n",
      "('current score in fold:', 0.8115680630319996, 11)\n",
      "[0]\teval-auc:0.77456\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.801346\n",
      "[200]\teval-auc:0.806794\n",
      "[300]\teval-auc:0.808083\n",
      "[400]\teval-auc:0.808812\n",
      "[500]\teval-auc:0.809197\n",
      "[600]\teval-auc:0.809411\n",
      "[700]\teval-auc:0.809522\n",
      "[800]\teval-auc:0.809623\n",
      "[900]\teval-auc:0.809689\n",
      "[1000]\teval-auc:0.809771\n",
      "[1100]\teval-auc:0.809828\n",
      "[1200]\teval-auc:0.809851\n",
      "[1300]\teval-auc:0.809891\n",
      "[1400]\teval-auc:0.809951\n",
      "[1500]\teval-auc:0.810004\n",
      "[1600]\teval-auc:0.810026\n",
      "[1700]\teval-auc:0.810081\n",
      "[1800]\teval-auc:0.810142\n",
      "[1900]\teval-auc:0.810183\n",
      "[2000]\teval-auc:0.810217\n",
      "[2100]\teval-auc:0.810234\n",
      "[2200]\teval-auc:0.810269\n",
      "[2300]\teval-auc:0.810313\n",
      "[2400]\teval-auc:0.810357\n",
      "[2500]\teval-auc:0.810387\n",
      "Stopping. Best iteration:\n",
      "[2480]\teval-auc:0.810393\n",
      "\n",
      "[0]\teval-auc:0.77832\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.804292\n",
      "[200]\teval-auc:0.80795\n",
      "[300]\teval-auc:0.80916\n",
      "[400]\teval-auc:0.809473\n",
      "[500]\teval-auc:0.810016\n",
      "[600]\teval-auc:0.810159\n",
      "[700]\teval-auc:0.810227\n",
      "[800]\teval-auc:0.810251\n",
      "Stopping. Best iteration:\n",
      "[750]\teval-auc:0.810258\n",
      "\n",
      "[0]\teval-auc:0.776161\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.804984\n",
      "[200]\teval-auc:0.80729\n",
      "[300]\teval-auc:0.808342\n",
      "[400]\teval-auc:0.808825\n",
      "[500]\teval-auc:0.809345\n",
      "[600]\teval-auc:0.80956\n",
      "[700]\teval-auc:0.809613\n",
      "[800]\teval-auc:0.809721\n",
      "[900]\teval-auc:0.809805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\teval-auc:0.80987\n",
      "[1100]\teval-auc:0.809943\n",
      "[1200]\teval-auc:0.810001\n",
      "[1300]\teval-auc:0.810154\n",
      "[1400]\teval-auc:0.810271\n",
      "[1500]\teval-auc:0.810394\n",
      "[1600]\teval-auc:0.810446\n",
      "[1700]\teval-auc:0.810452\n",
      "Stopping. Best iteration:\n",
      "[1625]\teval-auc:0.810459\n",
      "\n",
      "[0]\teval-auc:0.77568\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.806057\n",
      "[200]\teval-auc:0.809921\n",
      "[300]\teval-auc:0.810656\n",
      "[400]\teval-auc:0.811088\n",
      "[500]\teval-auc:0.811263\n",
      "[600]\teval-auc:0.811434\n",
      "[700]\teval-auc:0.811497\n",
      "[800]\teval-auc:0.811564\n",
      "[900]\teval-auc:0.811607\n",
      "[1000]\teval-auc:0.811622\n",
      "Stopping. Best iteration:\n",
      "[971]\teval-auc:0.811649\n",
      "\n",
      "[0]\teval-auc:0.777663\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.805238\n",
      "[200]\teval-auc:0.809315\n",
      "[300]\teval-auc:0.810749\n",
      "[400]\teval-auc:0.811243\n",
      "[500]\teval-auc:0.811737\n",
      "[600]\teval-auc:0.811928\n",
      "[700]\teval-auc:0.811993\n",
      "[800]\teval-auc:0.812065\n",
      "[900]\teval-auc:0.81212\n",
      "Stopping. Best iteration:\n",
      "[893]\teval-auc:0.812123\n",
      "\n",
      "cv score - on train:\n",
      "0.8108524912139945\n",
      "('current score in fold:', 0.8115472979071952, 12)\n",
      "[0]\teval-auc:0.775468\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.803907\n",
      "[200]\teval-auc:0.80597\n",
      "[300]\teval-auc:0.807398\n",
      "[400]\teval-auc:0.807731\n",
      "[500]\teval-auc:0.808033\n",
      "[600]\teval-auc:0.808474\n",
      "[700]\teval-auc:0.808605\n",
      "[800]\teval-auc:0.808677\n",
      "[900]\teval-auc:0.808717\n",
      "[1000]\teval-auc:0.808787\n",
      "[1100]\teval-auc:0.808837\n",
      "[1200]\teval-auc:0.808889\n",
      "[1300]\teval-auc:0.808906\n",
      "[1400]\teval-auc:0.808998\n",
      "[1500]\teval-auc:0.809067\n",
      "[1600]\teval-auc:0.809199\n",
      "[1700]\teval-auc:0.809273\n",
      "[1800]\teval-auc:0.80935\n",
      "[1900]\teval-auc:0.809405\n",
      "[2000]\teval-auc:0.809483\n",
      "[2100]\teval-auc:0.809556\n",
      "[2200]\teval-auc:0.809612\n",
      "[2300]\teval-auc:0.80962\n",
      "[2400]\teval-auc:0.809622\n",
      "Stopping. Best iteration:\n",
      "[2335]\teval-auc:0.809622\n",
      "\n",
      "[0]\teval-auc:0.760182\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.798887\n",
      "[200]\teval-auc:0.805167\n",
      "[300]\teval-auc:0.806177\n",
      "[400]\teval-auc:0.806441\n",
      "[500]\teval-auc:0.80689\n",
      "[600]\teval-auc:0.807099\n",
      "[700]\teval-auc:0.8071\n",
      "[800]\teval-auc:0.807131\n",
      "[900]\teval-auc:0.807155\n",
      "[1000]\teval-auc:0.807187\n",
      "Stopping. Best iteration:\n",
      "[980]\teval-auc:0.807195\n",
      "\n",
      "[0]\teval-auc:0.782727\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.809981\n",
      "[200]\teval-auc:0.81338\n",
      "[300]\teval-auc:0.81461\n",
      "[400]\teval-auc:0.815098\n",
      "[500]\teval-auc:0.815552\n",
      "[600]\teval-auc:0.815708\n",
      "[700]\teval-auc:0.815776\n",
      "[800]\teval-auc:0.815863\n",
      "[900]\teval-auc:0.815914\n",
      "[1000]\teval-auc:0.815934\n",
      "[1100]\teval-auc:0.81604\n",
      "[1200]\teval-auc:0.816137\n",
      "[1300]\teval-auc:0.816185\n",
      "[1400]\teval-auc:0.816255\n",
      "[1500]\teval-auc:0.816322\n",
      "[1600]\teval-auc:0.816392\n",
      "[1700]\teval-auc:0.816514\n",
      "[1800]\teval-auc:0.816606\n",
      "[1900]\teval-auc:0.816645\n",
      "Stopping. Best iteration:\n",
      "[1868]\teval-auc:0.816647\n",
      "\n",
      "[0]\teval-auc:0.770041\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.802043\n",
      "[200]\teval-auc:0.805691\n",
      "[300]\teval-auc:0.807128\n",
      "[400]\teval-auc:0.80769\n",
      "[500]\teval-auc:0.808026\n",
      "[600]\teval-auc:0.808202\n",
      "[700]\teval-auc:0.808317\n",
      "[800]\teval-auc:0.80836\n",
      "[900]\teval-auc:0.808434\n",
      "[1000]\teval-auc:0.808504\n",
      "[1100]\teval-auc:0.808541\n",
      "[1200]\teval-auc:0.808605\n",
      "[1300]\teval-auc:0.808713\n",
      "[1400]\teval-auc:0.808811\n",
      "[1500]\teval-auc:0.808882\n",
      "[1600]\teval-auc:0.808894\n",
      "[1700]\teval-auc:0.808916\n",
      "Stopping. Best iteration:\n",
      "[1678]\teval-auc:0.808926\n",
      "\n",
      "[0]\teval-auc:0.778336\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.80854\n",
      "[200]\teval-auc:0.810803\n",
      "[300]\teval-auc:0.812328\n",
      "[400]\teval-auc:0.81279\n",
      "[500]\teval-auc:0.813177\n",
      "[600]\teval-auc:0.813336\n",
      "[700]\teval-auc:0.813384\n",
      "[800]\teval-auc:0.813469\n",
      "[900]\teval-auc:0.81357\n",
      "[1000]\teval-auc:0.813615\n",
      "[1100]\teval-auc:0.813632\n",
      "[1200]\teval-auc:0.813689\n",
      "[1300]\teval-auc:0.813755\n",
      "[1400]\teval-auc:0.813797\n",
      "[1500]\teval-auc:0.813815\n",
      "[1600]\teval-auc:0.813853\n",
      "[1700]\teval-auc:0.81392\n",
      "[1800]\teval-auc:0.814007\n",
      "[1900]\teval-auc:0.814065\n",
      "[2000]\teval-auc:0.814105\n",
      "[2100]\teval-auc:0.814138\n",
      "[2200]\teval-auc:0.814151\n",
      "[2300]\teval-auc:0.814171\n",
      "Stopping. Best iteration:\n",
      "[2254]\teval-auc:0.814174\n",
      "\n",
      "cv score - on train:\n",
      "0.8112130109324805\n",
      "('current score in fold:', 0.8115606251037424, 13)\n",
      "[0]\teval-auc:0.776638\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.802348\n",
      "[200]\teval-auc:0.806604\n",
      "[300]\teval-auc:0.807949\n",
      "[400]\teval-auc:0.808063\n",
      "[500]\teval-auc:0.808595\n",
      "[600]\teval-auc:0.808687\n",
      "[700]\teval-auc:0.808689\n",
      "Stopping. Best iteration:\n",
      "[608]\teval-auc:0.808693\n",
      "\n",
      "[0]\teval-auc:0.778808\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.808682\n",
      "[200]\teval-auc:0.812008\n",
      "[300]\teval-auc:0.813158\n",
      "[400]\teval-auc:0.813557\n",
      "[500]\teval-auc:0.813971\n",
      "[600]\teval-auc:0.81413\n",
      "[700]\teval-auc:0.814288\n",
      "[800]\teval-auc:0.814337\n",
      "[900]\teval-auc:0.814375\n",
      "[1000]\teval-auc:0.814438\n",
      "[1100]\teval-auc:0.814462\n",
      "[1200]\teval-auc:0.81459\n",
      "[1300]\teval-auc:0.814672\n",
      "[1400]\teval-auc:0.814767\n",
      "[1500]\teval-auc:0.814874\n",
      "[1600]\teval-auc:0.814941\n",
      "[1700]\teval-auc:0.814993\n",
      "[1800]\teval-auc:0.815055\n",
      "[1900]\teval-auc:0.815111\n",
      "[2000]\teval-auc:0.815119\n",
      "[2100]\teval-auc:0.8152\n",
      "[2200]\teval-auc:0.815298\n",
      "[2300]\teval-auc:0.81534\n",
      "[2400]\teval-auc:0.815364\n",
      "[2500]\teval-auc:0.815401\n",
      "[2600]\teval-auc:0.815412\n",
      "[2700]\teval-auc:0.815414\n",
      "Stopping. Best iteration:\n",
      "[2670]\teval-auc:0.815416\n",
      "\n",
      "[0]\teval-auc:0.770077\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.801941\n",
      "[200]\teval-auc:0.806004\n",
      "[300]\teval-auc:0.807242\n",
      "[400]\teval-auc:0.807917\n",
      "[500]\teval-auc:0.808197\n",
      "[600]\teval-auc:0.808376\n",
      "[700]\teval-auc:0.808568\n",
      "[800]\teval-auc:0.808685\n",
      "[900]\teval-auc:0.808698\n",
      "[1000]\teval-auc:0.808699\n",
      "Stopping. Best iteration:\n",
      "[951]\teval-auc:0.808713\n",
      "\n",
      "[0]\teval-auc:0.778408\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.803298\n",
      "[200]\teval-auc:0.808154\n",
      "[300]\teval-auc:0.809127\n",
      "[400]\teval-auc:0.809652\n",
      "[500]\teval-auc:0.809961\n",
      "[600]\teval-auc:0.810254\n",
      "[700]\teval-auc:0.81033\n",
      "[800]\teval-auc:0.810435\n",
      "[900]\teval-auc:0.810495\n",
      "[1000]\teval-auc:0.810555\n",
      "[1100]\teval-auc:0.810622\n",
      "[1200]\teval-auc:0.810681\n",
      "[1300]\teval-auc:0.810777\n",
      "[1400]\teval-auc:0.8109\n",
      "[1500]\teval-auc:0.810998\n",
      "[1600]\teval-auc:0.811038\n",
      "[1700]\teval-auc:0.811083\n",
      "[1800]\teval-auc:0.81112\n",
      "[1900]\teval-auc:0.811125\n",
      "[2000]\teval-auc:0.811173\n",
      "[2100]\teval-auc:0.811214\n",
      "[2200]\teval-auc:0.811262\n",
      "[2300]\teval-auc:0.811282\n",
      "[2400]\teval-auc:0.811299\n",
      "[2500]\teval-auc:0.811316\n",
      "[2600]\teval-auc:0.811343\n",
      "[2700]\teval-auc:0.811346\n",
      "[2800]\teval-auc:0.811356\n",
      "[2900]\teval-auc:0.811358\n",
      "Stopping. Best iteration:\n",
      "[2830]\teval-auc:0.81136\n",
      "\n",
      "[0]\teval-auc:0.775282\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.80609\n",
      "[200]\teval-auc:0.809305\n",
      "[300]\teval-auc:0.81038\n",
      "[400]\teval-auc:0.810813\n",
      "[500]\teval-auc:0.81121\n",
      "[600]\teval-auc:0.811396\n",
      "[700]\teval-auc:0.811451\n",
      "[800]\teval-auc:0.811484\n",
      "[900]\teval-auc:0.811525\n",
      "[1000]\teval-auc:0.811567\n",
      "[1100]\teval-auc:0.811665\n",
      "[1200]\teval-auc:0.811729\n",
      "[1300]\teval-auc:0.811815\n",
      "[1400]\teval-auc:0.811903\n",
      "[1500]\teval-auc:0.812016\n",
      "[1600]\teval-auc:0.81204\n",
      "Stopping. Best iteration:\n",
      "[1581]\teval-auc:0.81206\n",
      "\n",
      "cv score - on train:\n",
      "0.8111309476289241\n",
      "('current score in fold:', 0.8115710187809291, 14)\n",
      "[0]\teval-auc:0.780975\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.805432\n",
      "[200]\teval-auc:0.811679\n",
      "[300]\teval-auc:0.812871\n",
      "[400]\teval-auc:0.813365\n",
      "[500]\teval-auc:0.813789\n",
      "[600]\teval-auc:0.813877\n",
      "[700]\teval-auc:0.813949\n",
      "[800]\teval-auc:0.813956\n",
      "Stopping. Best iteration:\n",
      "[764]\teval-auc:0.81396\n",
      "\n",
      "[0]\teval-auc:0.777366\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.808141\n",
      "[200]\teval-auc:0.812355\n",
      "[300]\teval-auc:0.813587\n",
      "[400]\teval-auc:0.814141\n",
      "[500]\teval-auc:0.814547\n",
      "[600]\teval-auc:0.814685\n",
      "[700]\teval-auc:0.814748\n",
      "[800]\teval-auc:0.814837\n",
      "[900]\teval-auc:0.814867\n",
      "[1000]\teval-auc:0.814878\n",
      "[1100]\teval-auc:0.814906\n",
      "[1200]\teval-auc:0.814954\n",
      "[1300]\teval-auc:0.815012\n",
      "[1400]\teval-auc:0.815078\n",
      "[1500]\teval-auc:0.815191\n",
      "[1600]\teval-auc:0.815303\n",
      "[1700]\teval-auc:0.815384\n",
      "[1800]\teval-auc:0.815439\n",
      "[1900]\teval-auc:0.815435\n",
      "Stopping. Best iteration:\n",
      "[1800]\teval-auc:0.815439\n",
      "\n",
      "[0]\teval-auc:0.772847\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.800265\n",
      "[200]\teval-auc:0.80212\n",
      "[300]\teval-auc:0.803298\n",
      "[400]\teval-auc:0.8037\n",
      "[500]\teval-auc:0.804147\n",
      "[600]\teval-auc:0.804311\n",
      "[700]\teval-auc:0.804416\n",
      "[800]\teval-auc:0.804504\n",
      "[900]\teval-auc:0.804588\n",
      "[1000]\teval-auc:0.804684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1100]\teval-auc:0.80479\n",
      "[1200]\teval-auc:0.804902\n",
      "[1300]\teval-auc:0.804968\n",
      "[1400]\teval-auc:0.805054\n",
      "[1500]\teval-auc:0.805119\n",
      "[1600]\teval-auc:0.805153\n",
      "[1700]\teval-auc:0.805169\n",
      "[1800]\teval-auc:0.805223\n",
      "[1900]\teval-auc:0.805262\n",
      "[2000]\teval-auc:0.805296\n",
      "[2100]\teval-auc:0.805307\n",
      "[2200]\teval-auc:0.805329\n",
      "Stopping. Best iteration:\n",
      "[2180]\teval-auc:0.805336\n",
      "\n",
      "[0]\teval-auc:0.778488\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.806372\n",
      "[200]\teval-auc:0.809049\n",
      "[300]\teval-auc:0.810217\n",
      "[400]\teval-auc:0.810693\n",
      "[500]\teval-auc:0.811062\n",
      "[600]\teval-auc:0.811258\n",
      "[700]\teval-auc:0.811448\n",
      "[800]\teval-auc:0.8115\n",
      "[900]\teval-auc:0.811593\n",
      "[1000]\teval-auc:0.811628\n",
      "[1100]\teval-auc:0.81165\n",
      "[1200]\teval-auc:0.811717\n",
      "[1300]\teval-auc:0.81185\n",
      "[1400]\teval-auc:0.811973\n",
      "[1500]\teval-auc:0.812037\n",
      "[1600]\teval-auc:0.812101\n",
      "[1700]\teval-auc:0.812131\n",
      "[1800]\teval-auc:0.812167\n",
      "[1900]\teval-auc:0.812195\n",
      "[2000]\teval-auc:0.812233\n",
      "[2100]\teval-auc:0.812237\n",
      "[2200]\teval-auc:0.812248\n",
      "[2300]\teval-auc:0.812259\n",
      "[2400]\teval-auc:0.812271\n",
      "[2500]\teval-auc:0.812282\n",
      "[2600]\teval-auc:0.812287\n",
      "[2700]\teval-auc:0.812318\n",
      "[2800]\teval-auc:0.81232\n",
      "Stopping. Best iteration:\n",
      "[2725]\teval-auc:0.812332\n",
      "\n",
      "[0]\teval-auc:0.77476\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.804601\n",
      "[200]\teval-auc:0.806618\n",
      "[300]\teval-auc:0.808128\n",
      "[400]\teval-auc:0.808801\n",
      "[500]\teval-auc:0.809214\n",
      "[600]\teval-auc:0.809289\n",
      "[700]\teval-auc:0.809339\n",
      "[800]\teval-auc:0.809373\n",
      "[900]\teval-auc:0.809448\n",
      "[1000]\teval-auc:0.809489\n",
      "[1100]\teval-auc:0.809606\n",
      "[1200]\teval-auc:0.809762\n",
      "[1300]\teval-auc:0.809892\n",
      "[1400]\teval-auc:0.810015\n",
      "[1500]\teval-auc:0.810116\n",
      "[1600]\teval-auc:0.8102\n",
      "[1700]\teval-auc:0.810271\n",
      "[1800]\teval-auc:0.810292\n",
      "[1900]\teval-auc:0.810305\n",
      "[2000]\teval-auc:0.810307\n",
      "[2100]\teval-auc:0.81032\n",
      "[2200]\teval-auc:0.810347\n",
      "[2300]\teval-auc:0.810376\n",
      "[2400]\teval-auc:0.810396\n",
      "[2500]\teval-auc:0.810407\n",
      "[2600]\teval-auc:0.810437\n",
      "[2700]\teval-auc:0.810469\n",
      "[2800]\teval-auc:0.810524\n",
      "[2900]\teval-auc:0.810574\n",
      "[3000]\teval-auc:0.810603\n",
      "[3100]\teval-auc:0.810646\n",
      "[3200]\teval-auc:0.810663\n",
      "[3300]\teval-auc:0.810673\n",
      "Stopping. Best iteration:\n",
      "[3263]\teval-auc:0.810677\n",
      "\n",
      "cv score - on train:\n",
      "0.811431946322944\n",
      "('current score in fold:', 0.8116034425308893, 15)\n",
      "[0]\teval-auc:0.782715\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.808958\n",
      "[200]\teval-auc:0.812948\n",
      "[300]\teval-auc:0.814262\n",
      "[400]\teval-auc:0.81465\n",
      "[500]\teval-auc:0.81505\n",
      "[600]\teval-auc:0.815286\n",
      "[700]\teval-auc:0.815431\n",
      "[800]\teval-auc:0.815522\n",
      "[900]\teval-auc:0.815618\n",
      "[1000]\teval-auc:0.815674\n",
      "[1100]\teval-auc:0.815745\n",
      "[1200]\teval-auc:0.815776\n",
      "[1300]\teval-auc:0.815786\n",
      "[1400]\teval-auc:0.815822\n",
      "[1500]\teval-auc:0.815856\n",
      "[1600]\teval-auc:0.815917\n",
      "[1700]\teval-auc:0.815986\n",
      "[1800]\teval-auc:0.816028\n",
      "[1900]\teval-auc:0.816047\n",
      "[2000]\teval-auc:0.816146\n",
      "[2100]\teval-auc:0.816185\n",
      "[2200]\teval-auc:0.816183\n",
      "[2300]\teval-auc:0.816211\n",
      "[2400]\teval-auc:0.816237\n",
      "[2500]\teval-auc:0.816252\n",
      "[2600]\teval-auc:0.816277\n",
      "[2700]\teval-auc:0.816299\n",
      "[2800]\teval-auc:0.816329\n",
      "[2900]\teval-auc:0.816361\n",
      "[3000]\teval-auc:0.816369\n",
      "Stopping. Best iteration:\n",
      "[2928]\teval-auc:0.816378\n",
      "\n",
      "[0]\teval-auc:0.779317\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.80551\n",
      "[200]\teval-auc:0.809691\n",
      "[300]\teval-auc:0.810973\n",
      "[400]\teval-auc:0.811668\n",
      "[500]\teval-auc:0.812083\n",
      "[600]\teval-auc:0.812205\n",
      "[700]\teval-auc:0.812247\n",
      "Stopping. Best iteration:\n",
      "[650]\teval-auc:0.812264\n",
      "\n",
      "[0]\teval-auc:0.772485\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.802855\n",
      "[200]\teval-auc:0.806576\n",
      "[300]\teval-auc:0.807803\n",
      "[400]\teval-auc:0.80829\n",
      "[500]\teval-auc:0.808689\n",
      "[600]\teval-auc:0.808908\n",
      "[700]\teval-auc:0.809007\n",
      "[800]\teval-auc:0.809064\n",
      "[900]\teval-auc:0.809099\n",
      "[1000]\teval-auc:0.809141\n",
      "[1100]\teval-auc:0.809232\n",
      "[1200]\teval-auc:0.809399\n",
      "[1300]\teval-auc:0.809463\n",
      "[1400]\teval-auc:0.80955\n",
      "[1500]\teval-auc:0.809617\n",
      "[1600]\teval-auc:0.809627\n",
      "[1700]\teval-auc:0.809624\n",
      "[1800]\teval-auc:0.809651\n",
      "[1900]\teval-auc:0.809675\n",
      "[2000]\teval-auc:0.809675\n",
      "Stopping. Best iteration:\n",
      "[1905]\teval-auc:0.809677\n",
      "\n",
      "[0]\teval-auc:0.772885\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.801202\n",
      "[200]\teval-auc:0.803721\n",
      "[300]\teval-auc:0.804973\n",
      "[400]\teval-auc:0.805512\n",
      "[500]\teval-auc:0.805931\n",
      "[600]\teval-auc:0.806215\n",
      "[700]\teval-auc:0.806339\n",
      "[800]\teval-auc:0.806428\n",
      "[900]\teval-auc:0.806466\n",
      "[1000]\teval-auc:0.806467\n",
      "Stopping. Best iteration:\n",
      "[929]\teval-auc:0.806477\n",
      "\n",
      "[0]\teval-auc:0.776764\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.805438\n",
      "[200]\teval-auc:0.808242\n",
      "[300]\teval-auc:0.809613\n",
      "[400]\teval-auc:0.80987\n",
      "[500]\teval-auc:0.810334\n",
      "[600]\teval-auc:0.810541\n",
      "[700]\teval-auc:0.810703\n",
      "[800]\teval-auc:0.810765\n",
      "[900]\teval-auc:0.810799\n",
      "[1000]\teval-auc:0.81084\n",
      "[1100]\teval-auc:0.810901\n",
      "[1200]\teval-auc:0.810943\n",
      "[1300]\teval-auc:0.811009\n",
      "[1400]\teval-auc:0.811078\n",
      "[1500]\teval-auc:0.811132\n",
      "[1600]\teval-auc:0.811198\n",
      "[1700]\teval-auc:0.811227\n",
      "[1800]\teval-auc:0.81129\n",
      "[1900]\teval-auc:0.811317\n",
      "[2000]\teval-auc:0.811367\n",
      "[2100]\teval-auc:0.811428\n",
      "[2200]\teval-auc:0.811469\n",
      "Stopping. Best iteration:\n",
      "[2190]\teval-auc:0.81147\n",
      "\n",
      "cv score - on train:\n",
      "0.811094041913382\n",
      "('current score in fold:', 0.8116120572013262, 16)\n",
      "[0]\teval-auc:0.77919\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.80497\n",
      "[200]\teval-auc:0.809995\n",
      "[300]\teval-auc:0.810819\n",
      "[400]\teval-auc:0.811136\n",
      "[500]\teval-auc:0.811487\n",
      "[600]\teval-auc:0.811563\n",
      "[700]\teval-auc:0.811683\n",
      "[800]\teval-auc:0.811732\n",
      "[900]\teval-auc:0.811807\n",
      "[1000]\teval-auc:0.811882\n",
      "[1100]\teval-auc:0.811932\n",
      "[1200]\teval-auc:0.81195\n",
      "[1300]\teval-auc:0.811972\n",
      "[1400]\teval-auc:0.812009\n",
      "[1500]\teval-auc:0.812048\n",
      "[1600]\teval-auc:0.812086\n",
      "[1700]\teval-auc:0.812091\n",
      "[1800]\teval-auc:0.81211\n",
      "Stopping. Best iteration:\n",
      "[1758]\teval-auc:0.81213\n",
      "\n",
      "[0]\teval-auc:0.77477\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.803208\n",
      "[200]\teval-auc:0.806009\n",
      "[300]\teval-auc:0.807341\n",
      "[400]\teval-auc:0.807987\n",
      "[500]\teval-auc:0.808414\n",
      "[600]\teval-auc:0.808567\n",
      "[700]\teval-auc:0.808622\n",
      "[800]\teval-auc:0.8087\n",
      "[900]\teval-auc:0.808736\n",
      "[1000]\teval-auc:0.808784\n",
      "[1100]\teval-auc:0.808838\n",
      "[1200]\teval-auc:0.808834\n",
      "Stopping. Best iteration:\n",
      "[1104]\teval-auc:0.808841\n",
      "\n",
      "[0]\teval-auc:0.778188\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.809619\n",
      "[200]\teval-auc:0.812573\n",
      "[300]\teval-auc:0.813613\n",
      "[400]\teval-auc:0.814148\n",
      "[500]\teval-auc:0.814335\n",
      "[600]\teval-auc:0.814582\n",
      "[700]\teval-auc:0.814766\n",
      "[800]\teval-auc:0.814826\n",
      "[900]\teval-auc:0.814899\n",
      "[1000]\teval-auc:0.814953\n",
      "[1100]\teval-auc:0.815006\n",
      "[1200]\teval-auc:0.815063\n",
      "[1300]\teval-auc:0.815114\n",
      "[1400]\teval-auc:0.815249\n",
      "[1500]\teval-auc:0.815337\n",
      "[1600]\teval-auc:0.815408\n",
      "[1700]\teval-auc:0.815445\n",
      "[1800]\teval-auc:0.815502\n",
      "[1900]\teval-auc:0.81554\n",
      "[2000]\teval-auc:0.815577\n",
      "[2100]\teval-auc:0.815611\n",
      "[2200]\teval-auc:0.815621\n",
      "[2300]\teval-auc:0.815665\n",
      "[2400]\teval-auc:0.815691\n",
      "[2500]\teval-auc:0.815729\n",
      "[2600]\teval-auc:0.815754\n",
      "[2700]\teval-auc:0.815798\n",
      "[2800]\teval-auc:0.81584\n",
      "[2900]\teval-auc:0.81585\n",
      "Stopping. Best iteration:\n",
      "[2825]\teval-auc:0.815856\n",
      "\n",
      "[0]\teval-auc:0.774591\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.802241\n",
      "[200]\teval-auc:0.806457\n",
      "[300]\teval-auc:0.807311\n",
      "[400]\teval-auc:0.80784\n",
      "[500]\teval-auc:0.808408\n",
      "[600]\teval-auc:0.808591\n",
      "[700]\teval-auc:0.808716\n",
      "[800]\teval-auc:0.808784\n",
      "[900]\teval-auc:0.808872\n",
      "[1000]\teval-auc:0.80894\n",
      "[1100]\teval-auc:0.809098\n",
      "[1200]\teval-auc:0.809218\n",
      "[1300]\teval-auc:0.809348\n",
      "[1400]\teval-auc:0.80941\n",
      "[1500]\teval-auc:0.809524\n",
      "[1600]\teval-auc:0.809612\n",
      "[1700]\teval-auc:0.809684\n",
      "[1800]\teval-auc:0.809736\n",
      "[1900]\teval-auc:0.809798\n",
      "[2000]\teval-auc:0.809834\n",
      "[2100]\teval-auc:0.809826\n",
      "[2200]\teval-auc:0.809861\n",
      "[2300]\teval-auc:0.80987\n",
      "[2400]\teval-auc:0.809893\n",
      "[2500]\teval-auc:0.809897\n",
      "Stopping. Best iteration:\n",
      "[2452]\teval-auc:0.809908\n",
      "\n",
      "[0]\teval-auc:0.776536\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.803191\n",
      "[200]\teval-auc:0.805879\n",
      "[300]\teval-auc:0.808522\n",
      "[400]\teval-auc:0.809019\n",
      "[500]\teval-auc:0.80929\n",
      "[600]\teval-auc:0.809539\n",
      "[700]\teval-auc:0.80963\n",
      "[800]\teval-auc:0.809679\n",
      "[900]\teval-auc:0.809684\n",
      "Stopping. Best iteration:\n",
      "[856]\teval-auc:0.809688\n",
      "\n",
      "cv score - on train:\n",
      "0.8112025918195372\n",
      "('current score in fold:', 0.8116192887223364, 17)\n",
      "[0]\teval-auc:0.780867\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\teval-auc:0.805432\n",
      "[200]\teval-auc:0.809973\n",
      "[300]\teval-auc:0.810663\n",
      "[400]\teval-auc:0.811057\n",
      "[500]\teval-auc:0.811465\n",
      "[600]\teval-auc:0.811784\n",
      "[700]\teval-auc:0.811859\n",
      "[800]\teval-auc:0.811976\n",
      "[900]\teval-auc:0.812025\n",
      "[1000]\teval-auc:0.812134\n",
      "[1100]\teval-auc:0.81219\n",
      "[1200]\teval-auc:0.8122\n",
      "[1300]\teval-auc:0.812396\n",
      "[1400]\teval-auc:0.812526\n",
      "[1500]\teval-auc:0.812614\n",
      "[1600]\teval-auc:0.81265\n",
      "[1700]\teval-auc:0.812682\n",
      "[1800]\teval-auc:0.812683\n",
      "[1900]\teval-auc:0.812706\n",
      "[2000]\teval-auc:0.812701\n",
      "Stopping. Best iteration:\n",
      "[1931]\teval-auc:0.812717\n",
      "\n",
      "[0]\teval-auc:0.774087\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.803521\n",
      "[200]\teval-auc:0.806731\n",
      "[300]\teval-auc:0.807905\n",
      "[400]\teval-auc:0.808764\n",
      "[500]\teval-auc:0.80899\n",
      "[600]\teval-auc:0.809183\n",
      "[700]\teval-auc:0.809308\n",
      "[800]\teval-auc:0.809428\n",
      "[900]\teval-auc:0.809482\n",
      "[1000]\teval-auc:0.80951\n",
      "[1100]\teval-auc:0.809581\n",
      "[1200]\teval-auc:0.809635\n",
      "[1300]\teval-auc:0.809739\n",
      "[1400]\teval-auc:0.809836\n",
      "[1500]\teval-auc:0.8099\n",
      "[1600]\teval-auc:0.809945\n",
      "[1700]\teval-auc:0.809985\n",
      "[1800]\teval-auc:0.81001\n",
      "[1900]\teval-auc:0.810035\n",
      "[2000]\teval-auc:0.810053\n",
      "[2100]\teval-auc:0.810098\n",
      "[2200]\teval-auc:0.810142\n",
      "[2300]\teval-auc:0.810174\n",
      "[2400]\teval-auc:0.810207\n",
      "[2500]\teval-auc:0.810227\n",
      "[2600]\teval-auc:0.810262\n",
      "[2700]\teval-auc:0.810286\n",
      "[2800]\teval-auc:0.810293\n",
      "[2900]\teval-auc:0.810304\n",
      "[3000]\teval-auc:0.810308\n",
      "[3100]\teval-auc:0.810314\n",
      "[3200]\teval-auc:0.810321\n",
      "Stopping. Best iteration:\n",
      "[3147]\teval-auc:0.810329\n",
      "\n",
      "[0]\teval-auc:0.77373\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.804547\n",
      "[200]\teval-auc:0.809684\n",
      "[300]\teval-auc:0.810721\n",
      "[400]\teval-auc:0.811347\n",
      "[500]\teval-auc:0.811678\n",
      "[600]\teval-auc:0.811808\n",
      "[700]\teval-auc:0.811838\n",
      "[800]\teval-auc:0.811845\n",
      "[900]\teval-auc:0.811871\n",
      "Stopping. Best iteration:\n",
      "[887]\teval-auc:0.811876\n",
      "\n",
      "[0]\teval-auc:0.773189\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.803278\n",
      "[200]\teval-auc:0.806803\n",
      "[300]\teval-auc:0.808094\n",
      "[400]\teval-auc:0.808351\n",
      "[500]\teval-auc:0.808572\n",
      "[600]\teval-auc:0.808838\n",
      "[700]\teval-auc:0.808896\n",
      "[800]\teval-auc:0.80897\n",
      "[900]\teval-auc:0.809028\n",
      "[1000]\teval-auc:0.809027\n",
      "[1100]\teval-auc:0.809035\n",
      "[1200]\teval-auc:0.809077\n",
      "[1300]\teval-auc:0.809166\n",
      "[1400]\teval-auc:0.809211\n",
      "[1500]\teval-auc:0.809232\n",
      "[1600]\teval-auc:0.809321\n",
      "[1700]\teval-auc:0.809331\n",
      "[1800]\teval-auc:0.809368\n",
      "[1900]\teval-auc:0.80938\n",
      "Stopping. Best iteration:\n",
      "[1858]\teval-auc:0.809381\n",
      "\n",
      "[0]\teval-auc:0.778023\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.806819\n",
      "[200]\teval-auc:0.808731\n",
      "[300]\teval-auc:0.809981\n",
      "[400]\teval-auc:0.810459\n",
      "[500]\teval-auc:0.810898\n",
      "[600]\teval-auc:0.811015\n",
      "[700]\teval-auc:0.811058\n",
      "[800]\teval-auc:0.811205\n",
      "[900]\teval-auc:0.811354\n",
      "[1000]\teval-auc:0.811448\n",
      "[1100]\teval-auc:0.81148\n",
      "[1200]\teval-auc:0.811513\n",
      "[1300]\teval-auc:0.811598\n",
      "[1400]\teval-auc:0.811691\n",
      "[1500]\teval-auc:0.811765\n",
      "[1600]\teval-auc:0.811834\n",
      "[1700]\teval-auc:0.811888\n",
      "[1800]\teval-auc:0.811907\n",
      "[1900]\teval-auc:0.811907\n",
      "Stopping. Best iteration:\n",
      "[1856]\teval-auc:0.811922\n",
      "\n",
      "cv score - on train:\n",
      "0.8111397156263873\n",
      "('current score in fold:', 0.8116276600074929, 18)\n",
      "[0]\teval-auc:0.776883\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.799971\n",
      "[200]\teval-auc:0.80467\n",
      "[300]\teval-auc:0.805983\n",
      "[400]\teval-auc:0.806615\n",
      "[500]\teval-auc:0.806751\n",
      "[600]\teval-auc:0.80707\n",
      "[700]\teval-auc:0.807177\n",
      "[800]\teval-auc:0.807223\n",
      "[900]\teval-auc:0.807269\n",
      "[1000]\teval-auc:0.807302\n",
      "[1100]\teval-auc:0.807393\n",
      "[1200]\teval-auc:0.807483\n",
      "[1300]\teval-auc:0.807587\n",
      "[1400]\teval-auc:0.807651\n",
      "[1500]\teval-auc:0.807765\n",
      "[1600]\teval-auc:0.807772\n",
      "[1700]\teval-auc:0.807791\n",
      "[1800]\teval-auc:0.807834\n",
      "[1900]\teval-auc:0.80784\n",
      "[2000]\teval-auc:0.807861\n",
      "[2100]\teval-auc:0.807877\n",
      "[2200]\teval-auc:0.80793\n",
      "[2300]\teval-auc:0.807982\n",
      "[2400]\teval-auc:0.807997\n",
      "[2500]\teval-auc:0.808015\n",
      "[2600]\teval-auc:0.808047\n",
      "[2700]\teval-auc:0.808105\n",
      "[2800]\teval-auc:0.808094\n",
      "Stopping. Best iteration:\n",
      "[2720]\teval-auc:0.808111\n",
      "\n",
      "[0]\teval-auc:0.778532\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.804546\n",
      "[200]\teval-auc:0.808434\n",
      "[300]\teval-auc:0.809441\n",
      "[400]\teval-auc:0.809932\n",
      "[500]\teval-auc:0.810508\n",
      "[600]\teval-auc:0.810671\n",
      "[700]\teval-auc:0.810825\n",
      "[800]\teval-auc:0.810898\n",
      "[900]\teval-auc:0.810945\n",
      "[1000]\teval-auc:0.811007\n",
      "[1100]\teval-auc:0.811095\n",
      "[1200]\teval-auc:0.811133\n",
      "[1300]\teval-auc:0.811206\n",
      "[1400]\teval-auc:0.811255\n",
      "[1500]\teval-auc:0.811321\n",
      "[1600]\teval-auc:0.811378\n",
      "[1700]\teval-auc:0.81144\n",
      "[1800]\teval-auc:0.811484\n",
      "[1900]\teval-auc:0.811511\n",
      "[2000]\teval-auc:0.811522\n",
      "[2100]\teval-auc:0.81152\n",
      "Stopping. Best iteration:\n",
      "[2019]\teval-auc:0.811529\n",
      "\n",
      "[0]\teval-auc:0.777893\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.806501\n",
      "[200]\teval-auc:0.808399\n",
      "[300]\teval-auc:0.810084\n",
      "[400]\teval-auc:0.810763\n",
      "[500]\teval-auc:0.811144\n",
      "[600]\teval-auc:0.811383\n",
      "[700]\teval-auc:0.811447\n",
      "[800]\teval-auc:0.811478\n",
      "[900]\teval-auc:0.81156\n",
      "[1000]\teval-auc:0.81163\n",
      "[1100]\teval-auc:0.811674\n",
      "[1200]\teval-auc:0.811673\n",
      "[1300]\teval-auc:0.811718\n",
      "Stopping. Best iteration:\n",
      "[1267]\teval-auc:0.81173\n",
      "\n",
      "[0]\teval-auc:0.771142\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.803017\n",
      "[200]\teval-auc:0.806201\n",
      "[300]\teval-auc:0.807458\n",
      "[400]\teval-auc:0.807719\n",
      "[500]\teval-auc:0.807946\n",
      "[600]\teval-auc:0.808064\n",
      "[700]\teval-auc:0.808216\n",
      "[800]\teval-auc:0.808269\n",
      "[900]\teval-auc:0.80833\n",
      "[1000]\teval-auc:0.808361\n",
      "Stopping. Best iteration:\n",
      "[971]\teval-auc:0.808369\n",
      "\n",
      "[0]\teval-auc:0.78026\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.809308\n",
      "[200]\teval-auc:0.812978\n",
      "[300]\teval-auc:0.813961\n",
      "[400]\teval-auc:0.814281\n",
      "[500]\teval-auc:0.814767\n",
      "[600]\teval-auc:0.814961\n",
      "[700]\teval-auc:0.815013\n",
      "[800]\teval-auc:0.815049\n",
      "[900]\teval-auc:0.815079\n",
      "[1000]\teval-auc:0.81513\n",
      "[1100]\teval-auc:0.815161\n",
      "[1200]\teval-auc:0.815164\n",
      "[1300]\teval-auc:0.815187\n",
      "[1400]\teval-auc:0.815291\n",
      "[1500]\teval-auc:0.815298\n",
      "[1600]\teval-auc:0.815353\n",
      "[1700]\teval-auc:0.815402\n",
      "[1800]\teval-auc:0.815418\n",
      "[1900]\teval-auc:0.815453\n",
      "[2000]\teval-auc:0.815481\n",
      "[2100]\teval-auc:0.815484\n",
      "[2200]\teval-auc:0.815504\n",
      "[2300]\teval-auc:0.815517\n",
      "[2400]\teval-auc:0.815581\n",
      "[2500]\teval-auc:0.815627\n",
      "[2600]\teval-auc:0.815646\n",
      "[2700]\teval-auc:0.815668\n",
      "[2800]\teval-auc:0.815675\n",
      "[2900]\teval-auc:0.815696\n",
      "[3000]\teval-auc:0.815713\n",
      "[3100]\teval-auc:0.815733\n",
      "[3200]\teval-auc:0.815759\n",
      "[3300]\teval-auc:0.815791\n",
      "[3400]\teval-auc:0.815809\n",
      "[3500]\teval-auc:0.81583\n",
      "[3600]\teval-auc:0.815834\n",
      "[3700]\teval-auc:0.815836\n",
      "Stopping. Best iteration:\n",
      "[3645]\teval-auc:0.815847\n",
      "\n",
      "cv score - on train:\n",
      "0.811027077830758\n",
      "('current score in fold:', 0.8116291038607424, 19)\n",
      "[0]\teval-auc:0.76684\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.801728\n",
      "[200]\teval-auc:0.803579\n",
      "[300]\teval-auc:0.804888\n",
      "[400]\teval-auc:0.805577\n",
      "[500]\teval-auc:0.806191\n",
      "[600]\teval-auc:0.8064\n",
      "[700]\teval-auc:0.80643\n",
      "Stopping. Best iteration:\n",
      "[649]\teval-auc:0.806454\n",
      "\n",
      "[0]\teval-auc:0.778293\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.81206\n",
      "[200]\teval-auc:0.814987\n",
      "[300]\teval-auc:0.816134\n",
      "[400]\teval-auc:0.816505\n",
      "[500]\teval-auc:0.816861\n",
      "[600]\teval-auc:0.817008\n",
      "[700]\teval-auc:0.817114\n",
      "[800]\teval-auc:0.817167\n",
      "[900]\teval-auc:0.817178\n",
      "Stopping. Best iteration:\n",
      "[862]\teval-auc:0.817184\n",
      "\n",
      "[0]\teval-auc:0.77775\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.809158\n",
      "[200]\teval-auc:0.811996\n",
      "[300]\teval-auc:0.813113\n",
      "[400]\teval-auc:0.813489\n",
      "[500]\teval-auc:0.813872\n",
      "[600]\teval-auc:0.813974\n",
      "[700]\teval-auc:0.814175\n",
      "[800]\teval-auc:0.814259\n",
      "[900]\teval-auc:0.814348\n",
      "[1000]\teval-auc:0.814447\n",
      "[1100]\teval-auc:0.814592\n",
      "[1200]\teval-auc:0.814643\n",
      "[1300]\teval-auc:0.814727\n",
      "[1400]\teval-auc:0.814798\n",
      "[1500]\teval-auc:0.814813\n",
      "Stopping. Best iteration:\n",
      "[1442]\teval-auc:0.814835\n",
      "\n",
      "[0]\teval-auc:0.771608\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.805546\n",
      "[200]\teval-auc:0.808999\n",
      "[300]\teval-auc:0.810189\n",
      "[400]\teval-auc:0.810906\n",
      "[500]\teval-auc:0.811285\n",
      "[600]\teval-auc:0.811437\n",
      "[700]\teval-auc:0.811494\n",
      "[800]\teval-auc:0.811542\n",
      "[900]\teval-auc:0.811556\n",
      "[1000]\teval-auc:0.811601\n",
      "[1100]\teval-auc:0.811662\n",
      "[1200]\teval-auc:0.811699\n",
      "[1300]\teval-auc:0.811831\n",
      "[1400]\teval-auc:0.811921\n",
      "[1500]\teval-auc:0.812015\n",
      "[1600]\teval-auc:0.812025\n",
      "Stopping. Best iteration:\n",
      "[1557]\teval-auc:0.812036\n",
      "\n",
      "[0]\teval-auc:0.764563\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\teval-auc:0.796902\n",
      "[200]\teval-auc:0.801863\n",
      "[300]\teval-auc:0.802918\n",
      "[400]\teval-auc:0.803491\n",
      "[500]\teval-auc:0.803835\n",
      "[600]\teval-auc:0.804025\n",
      "[700]\teval-auc:0.804208\n",
      "[800]\teval-auc:0.80427\n",
      "[900]\teval-auc:0.804328\n",
      "[1000]\teval-auc:0.804342\n",
      "[1100]\teval-auc:0.804369\n",
      "[1200]\teval-auc:0.804411\n",
      "[1300]\teval-auc:0.804467\n",
      "[1400]\teval-auc:0.804479\n",
      "Stopping. Best iteration:\n",
      "[1391]\teval-auc:0.804483\n",
      "\n",
      "cv score - on train:\n",
      "0.8108349275033553\n",
      "('current score in fold:', 0.8116118995993826, 20)\n",
      "[0]\teval-auc:0.773334\n",
      "Will train until eval-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.801025\n",
      "[200]\teval-auc:0.804089\n",
      "[300]\teval-auc:0.805311\n",
      "[400]\teval-auc:0.805988\n"
     ]
    }
   ],
   "source": [
    "final_cv_train_xgbst = np.zeros(len(labels_train))\n",
    "final_cv_pred_xgbst = np.zeros(len( test_ids ))\n",
    "\n",
    "NFOLDS = 5 \n",
    "\n",
    "M = 32 \n",
    "x_score_xgbst = []\n",
    "dtest = xgb.DMatrix( new_test )\n",
    "for s in range( M ):\n",
    "    \n",
    "    params['seed'] = s\n",
    "    \n",
    "    cv_train = np.zeros( len( labels_train ))\n",
    "    cv_pred = np.zeros( len( test_ids ) )\n",
    "    kfold = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=s)\n",
    "    kf  = kfold.split(  new_train , labels_train )\n",
    "    \n",
    "    for i, (train_fold, validate) in enumerate(kf):\n",
    "        \n",
    "        X_train, X_validate, label_train, label_validate = new_train[train_fold, :], new_train[validate, :], labels_train[train_fold], labels_train[validate]\n",
    "\n",
    "        dtrain = xgb.DMatrix( X_train , label=label_train )\n",
    "        dvalid = xgb.DMatrix( X_validate , label = label_validate )\n",
    "        evallist = [ (dvalid, 'eval') ]\n",
    "        bst = xgb.train(params, dtrain, num_boost_round, evallist  , early_stopping_rounds=100 , verbose_eval=100 )\n",
    "        #bst = lgb.train(params, dtrain , num_boost_round , valid_sets=[dvalid ] , verbose_eval = 100 , early_stopping_rounds = 100 )\n",
    "    #best_trees.append(bst.best_iteration)    \n",
    "        #cv_pred +=  bst.predict(  new_test , num_iteration = bst.best_iteration )\n",
    "        \n",
    "        cv_pred += bst.predict( dtest, ntree_limit=bst.best_ntree_limit )\n",
    "    #cv_eval_total += bst.predict( x_val , num_iteration = bst.best_iteration )          \n",
    "        cv_train[validate] += bst.predict( dvalid , ntree_limit=bst.best_ntree_limit )\n",
    "    \n",
    "    cv_pred /= NFOLDS\n",
    "    \n",
    "    final_cv_train_xgbst += cv_train\n",
    "    final_cv_pred_xgbst += cv_pred\n",
    "    \n",
    "    print(\"cv score - on train:\")\n",
    "    print( roc_auc_score(labels_train, cv_train))\n",
    "    print( \"current score in fold:\", roc_auc_score( labels_train , final_cv_train_xgbst / (s + 1.)), s+1)\n",
    "    \n",
    "    x_score_xgbst.append(roc_auc_score( labels_train , cv_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array( x_score_xgbst).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_xgb = final_cv_pred_xgbst/32.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07206896, 0.16173474, 0.03109069, ..., 0.01995817, 0.04282659,\n",
       "       0.18700212])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final_cv_pred/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train = final_cv_train_xgbst/32.0\n",
    "final_train_lgb = final_cv_train/32.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pos = final_train[ labels_train == 1  ]\n",
    "final_neg = final_train[labels_train == 0 ]\n",
    "final_pos_lgb = final_train_lgb[ labels_train == 1  ]\n",
    "final_neg_lgb = final_train_lgb[labels_train == 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7987769984548989\n"
     ]
    }
   ],
   "source": [
    "print( np.array( x_score).mean() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8094073211474969"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score( labels_train , final_cv_train/32 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = len(final_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = len(final_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.hist( final_pos , density = True , bins = 100 , label = \"pos_xgb\" )\n",
    "plt.hist(  final_neg  , density = True , bins = 100 , alpha = 0.7 , label = \"neg_xgb\")\n",
    "#plt.hist( final_pos_lgb , density = True , bins = 100 , label = \"pos_lgb\" )\n",
    "plt.hist(  final_neg_lgb , density = True , bins = 100 , alpha = 0.7 , label = \"neg_lgb\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist( final_xgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511,)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_logi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': final_pred_lgb }).to_csv('../data/pred_xgb_oof.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot feature importances...\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa0AAAEWCAYAAADVW8iBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3XucznX+//HHyyGniUGRcpwixhjjlCxpJMphK/FtQ2Vqq91O6leJEpuyaY1yaNq2siUlJOTUKmHYbVeFBhGlTIzklME4Dr1+f3w+c3XN+Zox11xzXdfrfrtdtz7X+/oc3q+Jeft8Pu/r+RFVxRhjjAkG5QLdAWOMMcZXNmgZY4wJGjZoGWOMCRo2aBljjAkaNmgZY4wJGjZoGWOMCRo2aBkTIkTkHyIyKtD9MMafxL6nZcKdiKQCdYGzXs3NVPWnc9hnPPCuqtY/t94FJxGZBqSp6tOB7osJLXamZYzj96oa4fUq9oBVEkSkQiCPfy5EpHyg+2BClw1axhRARK4Ukf+KSLqIbHDPoLI+u1NEvhGRoyLyg4j8yW2vBvwLuFhEMtzXxSIyTUTGem0fLyJpXu9TRWS4iGwEjolIBXe7uSKyX0R2iMjQAvrq2X/WvkXkCRHZJyJ7ROQmEektIt+KyC8i8pTXts+IyAciMtutZ72ItPb6vIWIJLs/h80ickOO474qIh+JyDHgj8Bg4Am39kXueiNE5Ht3/1tEpJ/XPhJE5D8iMkFEDrm19vL6vJaIvCUiP7mff+j1WV8RSXH79l8RifX5f7AJOjZoGZMPEbkEWAKMBWoBjwNzReRCd5V9QF+gOnAnMFFE2qrqMaAX8FMxztwGAn2ASOBXYBGwAbgE6A48IiLX+bivi4DK7rajgTeA24B2wFXAKBFp4rX+jcAct9b3gA9FpKKIVHT78QlQB3gImCEil3ttOwj4K3A+MB2YAYx3a/+9u8737nFrAGOAd0Wkntc+OgLbgAuA8cA/RUTcz94BqgIt3T5MBBCRNsCbwJ+A2sBrwEIRqeTjz8gEGRu0jHF86P5LPd3rX/G3AR+p6keq+quqLgPWAr0BVHWJqn6vjlU4v9SvOsd+TFHVXap6AugAXKiqz6rqaVX9AWfgudXHfWUCf1XVTGAWzmAwWVWPqupmYAvQ2mv9dar6gbv+SzgD3pXuKwJ4we3HCmAxzgCbZYGqfub+nE7m1RlVnaOqP7nrzAa+A67wWuVHVX1DVc8CbwP1gLruwNYL+LOqHlLVTPfnDXAv8Jqqfq6qZ1X1beCU22cTgoL2urkxJewmVf00R1sj4P9E5PdebRWBlQDu5au/AM1w/gFYFdh0jv3YleP4F4tIuldbeeDfPu7roDsAAJxw/7vX6/MTOINRrmOr6q/upcuLsz5T1V+91v0R5wwur37nSUTuAB4FGrtNETgDaZafvY5/3D3JisA58/tFVQ/lsdtGwBARecir7TyvfpsQY4OWMfnbBbyjqvfk/MC9/DQXuAPnLCPTPUPLupyV17TcYzgDW5aL8ljHe7tdwA5VbVqczhdDg6wFESkH1AeyLms2EJFyXgNXQ+Bbr21z1pvtvYg0wjlL7A78T1XPikgKv/28CrILqCUikaqansdnf1XVv/qwHxMC7PKgMfl7F/i9iFwnIuVFpLI7waE+zr/mKwH7gTPuWVdPr233ArVFpIZXWwrQ251UcBHwSCHH/wI46k7OqOL2IUZEOpRYhdm1E5Gb3ZmLj+BcZlsDfA4cx5lYUdGdjPJ7nEuO+dkLRHm9r4YzkO0HZxILEONLp1R1D87Elr+LSE23D13dj98A/iwiHcVRTUT6iMj5PtZsgowNWsbkQ1V34UxOeArnl+0uYBhQTlWPAkOB94FDOBMRFnptuxWYCfzg3ie7GGcywQYgFef+1+xCjn8WZ6JHHLADOABMxZnI4A8LgD/g1HM7cLN7/+g0ziDVy+3D34E73Brz808gOuseoapuAV4E/oczoLUCPitC327HuUe3FWcCzCMAqroWuAdIcvu9HUgown5NkLEvFxtjEJFngMtU9bZA98WYgtiZljHGmKBhg5YxxpigYZcHjTHGBA070zLGGBM07HtaJSwyMlIvu+yyQHcjII4dO0a1atUC3Y2AsNqt9nDij7rXrVt3QFUvLGw9G7RKWN26dVm7dm2guxEQycnJxMfHB7obAWG1xwe6GwERrrX7o24R+dGX9ezyoDHGmKBhg5YxxpigYYOWMcaYoGGDljHGmKBhg5YxxpigYYOWMcaYoGGDljHGmKBhg5Yxxphczp49S5s2bejbty8Ay5cvp23btsTFxfHQQw+xffv2bOvPnTsXEfF8T3XZsmW0a9eOVq1a0a5dO1asWFEi/bJByxhjTC6TJ0+mRYsWnvf33XcfM2bMICUlhe7duzN27FjPZ0ePHmXy5Ml07NjR03bBBRewaNEiNm3axNtvv83tt99eIv0KyKAlIheJyCwR+V5E1onIRyLSLJ91G4vI16XdR/fYA0Vkk4hsFJGlInJBIPphjDGlKS0tjSVLlnD33Xd72kSEI0eOAE6M08UXX+z5bNSoUQwfPpzKlSt72tq0aeNZp2XLlpw4cYJTp06dc99KPcZJRASYD7ytqre6ba2BusC3pd2f/LiPHJ8MRKvqAREZDzwIPFPQdicyz9J4xJJS6GHZ81irMyRY7WHHag+d2lNf6APAI488wvjx4zl69Kjns6lTp9K7d2+qVKlChQoV2LhxIwDr169n165d9OnTh8TExDz3O3fuXNq2bUulSpXOuY+ByB7sBmSq6j+yGlR1gzgScR7prcBYVc32OHIRSQDaq+qD7vvFwARVTRaRDOBVoDewB+cR6eOBhsAjqrrQ3f4GoCpwKTBfVZ/Ip5/ivqqJyEGgOs6jvHOvKHIvcC/ABRdcyOhWZ4r4IwkNdas4f4nDkdVutYeC5ORk/ve//5GZmcnRo0dJSUnh4MGDJCcnM3r0aJ577jmio6OZPn06AwcO5LHHHuPRRx9lxIgRJCcnk56ezrp168jIyPDsc8eOHTz99NOMHz+e5OTkc++kqpbqCxgKTMyjvT+wDCiPc9a1E6gHNAa+dtdJAJK8tlkMxLvLCvRyl+cDnwAVgdZAitf2PwA1gMrAj0CDAvo6ADiCMwiuBsoXVl+zZs00XK1cuTLQXQgYqz08hWLtI0aM0EsuuUQbNWqkdevW1SpVqmjv3r01KirKs86sWbO0RYsWmp6errVr19ZGjRppo0aNtFKlSlqvXj398ssvVVV1165d2rRpU/3Pf/5T6HGBterDGFKWJmJ0AWaq6llV3QusAjoUYfvTwFJ3eROwSlUz3eXGXustV9XDqnoS2AI0ymtnIlIRuA9oA1wMbASeLEJ/jDEm6IwbN460tDRSU1OZNWsW11xzDQsWLODw4cN8+61zB2ft2rW0aNGCGjVqcODAAVJTU0lNTeXKK69k4cKFtG/fnvT0dPr06cMLL7xA586dS6x/gbg8uBnnDKY4zpB98khlr+VMd7QG+BU4BaCqv7r3p7J43wk8S/4/gzh3++8BROR9YEQx+22MMUGrQoUKvPHGG/Tv359y5cohIsybN6/AbZKSkti+fTvPPvsszz77LACffPIJderUObe+nNPWxbMCeF5E7lXV1wFEJBZIB/4gIm8DtYCuwDCyD0ypwP0iUg64BLjCj/3cDUSLyIWquh/oAXzjx+MZY0yZEh8f73luVr9+/ejXrx/g3PuKiorKtb73Paunn36ap59+usT7VOqDlqqqiPQDJonIcOAkzmD0CBABbMC5P/WEqv4sIo29Nv8M2IFzWe8bYL0f+/mTiIwBVotIJs79rwR/Hc8YY0zhAvLkYlX9Cbglj4+GuS/vdVOBGHdZgcH57DPCa/mZvD5T1WnANK/2voX08x/APwpaxxhjTOkpSxMxjDHGmAIF5EyrrBGRz4Gc33q7XVU3BaI/xhhj8mZnWoCqdlTVuBwvG7CMMWVKzhDbLEOHDiUiwnOHhNWrV9O2bVsqVKjABx984GlPSUmhU6dOtGzZktjYWGbPzpbfEBTsTMsYY4JEVohtVgYgON+ZOnToULb1GjZsyLRp05gwYUK29qpVqzJ9+nSaNm3KTz/9RLt27bjuuuuIjIwslf6XBAvMLYCI/MENy90sIn8LRB+MMQbyDrE9e/Ysw4YNY/z48dnWbdy4MbGxsZQrl/1XfLNmzWjatCkAF198MXXq1GH//v3+73wJssDcfIhIbSARaKeq+0XkbRHprqrLC9rOAnOt9nBjtfu39oJCbJOSkrjhhhuoV69ekff7xRdfcPr0aS699NIS62tpsMDc/ANzo4Dv3C8WA3yKk4+Ya9CywFxHqIWHFoXVbrX7S34hth988AFTp05l0qRJJCcnc/bs2VyBtD///DObN2/mgguyP1Xp4MGD/L//9/8YMWIEq1evLnKfMjIySib8tjh8CSgsyRdBEpgL1ATS3ONXAOYCiwqrzwJzw5PVHp5Kq/a8QmwjIyO1bt26nrBaEdFLL70023ZDhgzROXPmZGs7fPiwtmnTJld7Ufijbiww99wCc1X1EE5g7mzg3zipHWeL0B9jjCkReYXYHjp0iJ9//tkTVlu1alW2b8/z6Ukep0+fpl+/ftxxxx0MGFDcCNjACsSgtRloV8xtixWYS/bLoL4G5qKqi9SZDt8J2EYZuudmjDH5+fLLL6lfvz5z5szhT3/6Ey1btgTg/fffZ/Xq1UybNo24uDji4uJISUkJcG+LxgJzCyAidVR1n4jUBO4n7+gpY4wpNd4htt68H7zYoUMH0tLScq1z2223cdttt/mze35ngbkFm+zObAR4VlXtTMsYYwLIAnML7ufAgj43xhhTusrSRAxjjDGmQBbjhAXmGmNMsLAzLSww1xhT9uQMx/3jH/9I69atiY2NZcCAAdkmXgDMnTsXEWHt2rWetnHjxnHZZZdx+eWX8/HHH5dq//3Fr4NWEGUM/lVEdrmpGt7tCSKyX0RS3Nfd+e3DGGNKUlY4bpaJEyeyYcMGNm7cSMOGDUlKSvJ8dvToUSZPnkzHjh09bVu2bGHWrFls3ryZpUuXcv/993P2bPB/1dRvlweDJWPQtQhIAr7L47PZ6sZG+cKyB632cGO1l2ztqS/08YTjjhw5kpdeegmA6tWrA06K0YkTJ3B+xTpGjRrF8OHDSUxM9LQtWLCAW2+9lUqVKtGkSRMuu+wyvvjiCzp16lSi/S1t/jzTyjNjEPiPiCSKyNcisklE/pBzQ/cMJ8nr/WIRiXeXM9ztN4vIpyJyhYgki8gPInKD1/bzRGSpiHwnIuNzHsObqq5R1T0lVLcxxpyTrHDcnCntd955JxdddBFbt27loYceAmD9+vXs2rWLPn36ZFt39+7dNGjQwPO+fv367N692/+d9zN/TsSIAdbl0X4zEIeTCXgB8KWIFCWxsRqwQlWHich8YCzQA4gG3gYWuuvFAW1wEjC2icjLqrqrGHX0F5GuOGeH/y+vfVhgrsOCU632cOOP2seNG5crHDcrnHbIkCHcdtttTJkyhTFjxnDdddfx6KOPMmLECJKTk0lPT2fdunVkZGSwe/duvvnmG8+2e/bsyTM8tzhCMjCX/INxJwJ3eb1/Byd5vTG+BeOeAsRdfhYY6S6XA9K9tn/Da/t/AV186HNGjve1gUru8p9wBksLzM2HBaeGJ6u9ZOUVjjt48OBs66xatUr79Omj6enpWrt2bU9obqVKlbRevXr65Zdf6vPPP6/PP/+8Z5uePXvqf//73xLpY6gG5gZNxmB+VPWgqmbtZyrFr8cYY3ySVzjuO++84wnDVVUWLlxI8+bNqVGjBgcOHPCE5l555ZUsXLiQ9u3bc8MNNzBr1ixOnTrFjh07+O6777jiCr8m35UKfw5aK4BK7qUzIFfGYHkRuRAnY/CLHNumAnEiUk5EGuDnjMH8iIj3k9VuwImOMsaYUqWqDBkyhFatWtGqVSv27NnD6NGjC9ymZcuW3HLLLURHR3P99dfzyiuvUL58+VLqsf/47Z6WavBkDLoTNQYBVUUkDZiqThTUUHdyxxngF5zLjsYYUyq8w3E/++yzQtfPeZ9p5MiRjBw50g89Cxy/JmJo8GQMPgHkeoKxqj4JPFnQtsYYY0qPJWIYY4wJGmGVPWgZg8YYE9zC6kxLLWPQGBNgOTMFk5KSuOyyyxARDhw44FkvMTHR83ThmJgYypcvzy+//JLvfsJFWA1axhgTaDkzBTt37synn35Ko0aNsq03bNgwUlJSSElJYdy4cVx99dXUqlUr3/2Ei4AMWkEUpHueiLwuIt+KyFYR6R+IfhhjQkNWpuDdd/+Wvd2mTRsaN25c4HYzZ85k4MDfnkmb137CRanf0wqyIN2RwD5VbSYi5YBahW1ggblWe7ix2guvPfUFJxcwK1Pw6NGjPh/j+PHjLF26NFuqe3H2EyoCcaYVNEG6wF3AOLePv6rqgULWN8aYPC1evJg6derQrl3RgnUWLVpE586dPZcGi7ufUBGI2YNBEaQrIpHu4nPuwPg98KCq7s1jXQvMxYJTrfbw42vtycnJzJw5k08++YR58+Zx+vRpjh8/To8ePTxf/j158iSfffYZNWrUyLZtUlISV199teeLw4XtpzSEZGBufi+CJEgXZ+BUYID7/lHgncLqs8Dc8GS1h6fi1r5y5Urt06dPtrZGjRrp/v37s7Wlp6drzZo1NSMjw+f9lIZQDczNT7AE6R4EjgPz3PdzgLbF67YxxuRtypQp1K9fn7S0NGJjY7NNrpg/fz49e/akWrVqAexh2RKIQSsognTdAXAREO82dcfJQjTGmHMSHx/P4sWLARg6dChpaWmcOXOGn376ialTp3rWS0hIYNasWT7tJ1yU+j0t1eAJ0gWGA++IyCRgP3Cnn49njDGmAAGJcdLgCdL9EeeMzxhjTBlgiRjGGGOCRlgF5ubHgnSNMSY42JkWFqRrjPEvX0NyZ8yYQWxsLK1ateJ3v/sdGzZs8Hw2efJkYmJiaNmyJZMmTSr1GsoKG7SMMcbPfA3JbdKkCatWrWLTpk2MGjWKe+91Jll//fXXvPHGG3zxxRds2LCBxYsXs3379lKtoazw66AVRMG4fxWRXSKSkc/n/UVERaR9affNGBPcihKS+7vf/Y6aNWsCcOWVV5KWlgbAN998Q8eOHalatSoVKlTg6quvZt68ebm2Dwd+u6cVZMG4i4Ak4LucH4jI+cDDwOe+7MgCc632cGO151976gt9ih1u+89//pNevXoBEBMTw8iRIzl48CBVqlTho48+on378Pw3tD8nYuQZjCuORKAXzvexxqrqbO8NRSQBaK+qD7rvFwMTVDXZPRt6FegN7AGeAsYDDYFHVHWhu/0NQFXgUmC+qj6RX0dVdY17nLw+fg74Gzmm4ufor2UPYhl0Vnv4Kaz2cePGkZmZydGjR0lJSeHgwYPZMvvyyxv86quvePnll5kyZYpn/RtvvJFOnTpRpUoVGjduzJ49ewKW/xfI7EF/DlpBEYxbEBFpCzRQ1SUiku+gpaqvA68DNIy6TF/cFJ6TMh9rdQarPfxY7fnXPlCOsG7dOhISEjh58iRHjhxh6tSpvPvuuwBUrlyZzp07c8EFF3i22bhxI0lJSSxbtoxmzX67mxIfH09iYiIATz31FPXr1yc+Pt4/hRUiOTk5YMcOxJ+0LsBMVT0L7BWRVUAHYKOP258GlrrLm4BTqpopIptwwnWzLFfVwwAisgVoBPg8aLnPz3oJJ2TXZ1Uqlmeb++yccJOcnEzq4PhAdyMgrPb4QHcjIAqvvQ/jxo3zrDthwgTPgJWXnTt3cvPNN/POO+9kG7AA9u3bR506ddi5cyfz5s1jzZo1JVBB8PHnRIxgCcbNz/k4Z4vJIpIKXAkstMkYxphzlV9I7rPPPsvBgwe5//77iYuLy3bfqn///kRHR/P73/+eV155hcjIyPx2H9L8eaa1AnheRO51L5/lDMZ9G+dJwF1x7hd5D0ypwP3u2c4l+DEYNz/uWZrnnF1EkoHHVXVtaffFGBP84uPjPZfUhg4dytChQ3OtM3Xq1GyBud7+/e9/+7N7QcNvZ1ru2VA/4Fp3yvtmnKcAv4dzKXADzsD2hKr+nGNz72DcKfg5GFdExotIGlBVRNJE5Bl/Hs8YY0zx+PWeVhAF4z4B5Du70F0nvqDPjTHG+J8lYhhjjAkaYTVP1YJxjTEmuIXVmZYF4xpjiuPkyZNcccUVtG7dmpYtW/KXv/wFgHXr1tG2bVvi4uLo0qWLJw/wxx9/pHv37sTGxhIfH++JYwIYPnw4MTExxMTEMHv27DyPZ/IXVoOWMcYUR6VKlVixYgUbNmwgJSWFpUuXsmbNGiZNmsSMGTNISUlh0KBBjB07FoDHH3+cO+64g40bNzJ69GiefPJJAJYsWcL69etJSUnh888/Z8KECRw5ciSQpQWdgAxawRKk69WHhYHugzEmcESEiAhnDlhmZiaZmZmICCLiGXQOHz7MxRdfDMCWLVu45pprAOjWrRsLFizwtHft2pUKFSpQrVo1YmNjWbp0aR5HNPkp9XtaQRaki4jcDOSZ/p4XC8y12sNNqNee6ibcnD17lnbt2rF9+3YeeOABOnbsyOOPP07v3r2pUqUK1atX96RUtG7dmnnz5vHwww8zf/58jh49ysGDB2ndujVjxozhscce4/jx46xcuZLo6OhAlhd05LdwiVI6oMg1wDOq2jVHu+AE32YL0hWRxsBiVY0p7SBdEYnAiYy6F3hfVWPyWc87MLfd6ElvFPnnEgrqVoG9JwLdi8Cw2gPdC/9pdUn2MNuMjAxGjRrF0KFDeeONN7jtttuIjo5m1qxZ7Nq1i2HDhnHgwAGmTJnCnj17iI2NZfXq1bz11ltERETw7rvvkpycTGRkJJGRkTRv3pwBAwYEqLriycjI8Jx5lpRu3bqtU9XCE4dUtVRfwFBgYh7t/YFlQHmcs66dQD2cPMGv3XUSgCSvbRYD8e6yAr3c5fnAJ0BFnGDeFK/tfwBq4CRw/IgTiJtfXyfifEHa04fCXs2aNdNwtXLlykB3IWCs9vAyZswYHT9+vF588cWeth9//FFbtGiRa92jR4/qJZdckud+Bg4cqEuWLPFbP/3FH//PgbXqw+/YsjQRwxOkq6p7gawgXV/lDNJdpaqZ7nJjr/WWq+phVT2Jk7iR/dGhLhGJAy5V1flFK8MYE2r2799Peno6ACdOnGDZsmW0aNGCjIwMvv3WuauR1QZw4MABfv31V8B5PMldd90FOJcYDx48CDhp7hs3bqRnz56lXU5QC8T3tDYDxT0XLlaQrogUJ0i3E9DeDcutANQRkWS1ZAxjws6ePXsYMmQIZ8+e5ddff+WWW26hb9++PP744/Tv359y5cpRs2ZN3nzzTcBJdH/yyScREbp27corr7wCOJM4rrrqKgCqV6/Ou+++S4UKYfV12XMWiJ9WUATpquqrOPfI8LqvFu+v4xljyq7Y2Fi++uqrXO1XXXUVo0aNytU+YMCAPO9TVa5cmS1btvilj+Gi1ActVVUR6QdMEpHhwEmcwegRIAInSFdxg3TdASOLd5DuN/g5SNcYY0zZEpDzUg2SIN28+mCMMSZwytJEDGOMMaZAdgcQC9I1xphgYWdaWJCuMSZ/+YXlLl++nHvvvbdIYblvv/02TZs2pWnTprz99tsBqSfY2aBljDEFyC8s97777mPkyJE+h+X+8ssvjBkzhs8//5wvvviCMWPGcOjQoUCWFpT8OmgFSzCuiPxVRHa5UVDe7Y+KyBYR2Sgiy0Ukzy8iG2NCV0FhuceOHQN8C8v9+OOP6dGjB7Vq1aJmzZr06NHDwnKLwW/3tIIsGHcRkAR8l6P9K5ysw+Mich9OluEfCtqRBeZa7eEm1GtPfaFPnmG5U6dOpW/fvjz//PM+heXu3r2bBg0aePZbv359du/eHaiyglaRA3NFpCZOXt/GQtYLmmBcr75leE+dz/FZG5zcw855fGaBuYR+cGpBrPZA98J/vANzvcNy33rrLW688UbatWvnU1jukiVLOH36NLfffjsA06dPp1KlSvzhDwX+O7hMKvOBuUAyUB0nqWIH8DnwUiHbBE0wrtdxMgr4LAl4urB9WGBueLLaw0dWWG5UVJSndl/Cct977z299957PZ/de++9+t5775VKn0taMATm1lDVI8DNwHRV7Qhc6+O2OZWpYFxfiMhtQHsgsbj7MMYEp/zCcg8fPsyuXbsA38Jyr7vuOj755BMOHTrEoUOH+OSTT7juuusCUFFw8/WeVgURqYeTYjHSx22CJRi3QCJyLU7NV6vqqcLWN8aElvzCct944w0ee+wxJkyY4FNYbq1atRg1ahQdOjj/Rh89ejS1atUKWF3Bytdf5M8CHwOfqeqXIhJF7kkLOQVFMG5B3PtYrwHXq+q+QPTBGBNY+YXl9uvXj5o1axIfH5+tPb+wXIC77rrLc+ZlisenQUtV5wBzvN7/gHNvqqBtgiYYV0TGA4OAqiKSBkxVJ78w0e3rHGf+CDtV9QZ/9sUYY0z+fBq03O9WvQrUVWd2Xyxwg6qOLWg7DZJgXHVmFuaaXaiqxb1vZ4wxxg98nYjxBvAkkAmgznT3W/3VKWOMMSYvvt7TqqqqX7iXyLKc8UN//MqCcY0xJrj5eqZ1QEQuxbkHhYgMwPlib1BRC8Y1xhRRUQNzd+7cSbdu3WjTpg2xsbF89NFHABw8eJBu3boRERHBgw8+GLB6gp2vg9YDOLPomovIbpzJFH8u7kGDKJNwqYhsEJHNIvIPESkfiH4YYwKnqIG5Y8eO5ZZbbuGrr75i1qxZ3H///QBUrlyZ5557jgkTJgSynKBX6OVBd9p5e1W9VkSqAeVU9WhxDxhkmYS3qOoRt88fAP8HzCpoA8setNrDTSjXnvpCnyIH5ooIR44cydVerVq1bGdkpngKPdNS1V9xZ9ap6rFzGbBc3XC+IPwPr2NsAP4jIoki8rWIbBKRXIFcIpIgIkle7xeLSLy7nOFuv1lEPhWRK0QkWUR+EJEbvLaf555BfedOdS+o9iPuYgXgPNzLo8aY8HL27Fni4uKoU6cOPXr08ATmPvnkk9SvX5933nmHESOqnYn/AAAgAElEQVRGAPDMM8/w7rvvUr9+fXr37s3LL78c4N6HFl8nYnwqIo8Ds4FjWY2q+ksxjhkDrMuj/WYgDidD8ALgSxFZXYT9VgNWqOowEZkPjAV6ANHA28BCd704oA1OYsY2EXlZVXflt1MR+Rjny83/wjnbymsd78BcRrcKujkqJaJuFedf3eHIag/N2pOTkz3LkyZN8gTmNm/enLfeeovRo0d7AnMHDhzIsGHDeP/997nqqqu45ZZb2Lx5M/379+fNN9+kXDnnHGHr1q3s3r07276DTUZGRsD67+uglXXW84BXmwJRJdgXTyYhsFdEsjIJC0yT95Izk/CUqmaKSJ6ZhAAikpVJmO+gparXiUhlYAZwDU7Yb851XgdeB7j88sv1ocE3+tjl0JKcnMwtOdIBwoXVHh/obpSa9evXc+DAAXbv3k27du2Ij48nKiqK66+/nvj4eB544AGWLl1KgwYNiI+P58UXXyQmJoY6deoAkJqaSkZGRq4kjWCSnJwcsP77NBFDVZvk8SrugLUZaFfMbYuVSUj2wbnImYRu6O4CIDxHI2PCWFEDcxs2bMjy5csB+Oabbzh58iQXXnhhYDofgnxNxLgjr3ZVnV6MYwZFJqGIRADnq+oeN4i3D/Bvfx3PGFM2FTUw98UXX+See+5h4sSJiAjTpk0j6zuujRs35siRI5w+fZoPP/yQTz75hOjo6ECWF3R8vTzo/eiQykB3nDzAIg9aQZRJWA1YKCKVcM7uVgL/KHgTY0yoKWpgbnR0NJ999lme+0pNTfVDD8OLr4G5D3m/F5FICpn6Xcj+ynwmofusr6I858sYY4yf+frl4pyOAU1KsiPGGGNMYXy9p7WI376jVA5nGvmc/LcILpZJaIwxwcHXM60JwIvuaxzQVVWH+61XpcwyCY0xeSkod7Bt27bcfffduVIu3n//faKjo2nZsiWDBg3ytA8fPpyYmBhiYmKYPXt2qdcSKnydiNE75yAlIn8LpYHLGGNyysodjIiIIDMzky5dutCrVy/uu+8+FixYwN69e9myZQtjx45l2rRpfPfdd4wbN47PPvuMmjVrsm+f88DzJUuWsH79elJSUjh16hTx8fH06tWL6tWrB7jC4OPrmVaPPNp6FfegwRCYKyLni0iK1+uAiEwq7X4YYwKnoNzBvPIF33jjDR544AFq1qwJ4PlC8ZYtW+jatSsVKlSgWrVqxMbGsnTp0jyOaApT4JmWiNwH3A9EiYh3MsX5ONPPiyxYAnPdjMW4rPcisg6YV9h2FphrtYebUK099YU+gJM72K5dO7Zv384DDzzgyR3s3bs35cqV48ILL2TNmjUAfPut8yusc+fOnD17lmeeeYbrr7+e1q1bM2bMGB577DGOHz/OypUr7ftZxVTY5cH3cDL3xgEjvNqPFjN3EPIJzBVHIs4ZnAJjVTXbhV8RScBJnH/Qfb8YmKCqySKSAbwK9MZ51tdTwHigIfCIqi50t78BqApcCsxX1ScK67B7FliHfL5cbNmDjlDOoCuM1R56tReWO/jcc8/RsGFDFi9e7Mkd3Lt3LwcPHmTMmDHs37+fO+64gzfffJOIiAhatGhBbGwskZGRREVFsWPHjqDNHyyz2YNuRt9hYCCAiNTB+XJxhIhEqOrOYhwzqAJzXbcCs71iorLxzh5sGHWZvrjJ11uFoeWxVmew2sNPqNaeOjg+V5t37uD9999PcnIyTz31lCd3sHXr1nTs2JFrr70WgKlTp1K3bl06dOiQ7UvIgwYNonfv3kGbPxjI7EFfp7z/HngJuBjYhxMy+w3QsgT7UiYDc123Arf70okqFcuzzb2sEG6Sk5Pz/IseDqz2+EB3wy/2799PxYoViYyM9OQODh8+nMOHD3suBXrnDt50003MnDmTO++8kwMHDvDtt98SFRXF2bNnSU9Pp3bt2mzcuJGNGzfSs2fPQJYWtHz959FY4ErgU1VtIyLdgNuKeczNwIBibluswFw3OzBLkQJz3fttFVQ1r7NDY0wIKyh3sH///hw/fpwGDRp4cgevu+46T55g+fLlSUxMpHbt2pw8eZKrrroKgOrVq/Puu+9SoULonZ2WBl9/apmqelBEyolIOVVdeQ4z6YIiMNfLQGBmKRzHGFPGFJQ72K9fv1yXyUSEl156iZdeeinb+pUrV2bLli3+7m5Y8HXQSndTz/8NzBCRfXg9DLIogigwN8stOJM7jDHGBJivg9aNwAmcgWUwUAN4trgHDYbAXK91SvJBl8YYY86Brynvx0SkEdBUVd8WkapAef92zRhjjMnO19mD9+B8D6kWzvebLsF5tlR3/3Wt9FhgrjHGBAdfY5weADoDRwBU9TucL9uGBAvMNcbkVFhYblxcHA899FC2sFyAuXPnIiKsXbsWcOKfhgwZQqtWrWjRogXjxo0r9VpCia+D1ilVPZ31xp1CnucXbY0xJhRkheVu2LCBlJQUli5dypo1a7jvvvuYMWMGKSkpdO/enbFjx3q2OXr0KJMnT6Zjx46etjlz5nDq1Ck2bdrEunXreO211+wJxufA10FrlYg8BVQRkR44z9JaVNyDBkNgrnvsv4rILjciyhgTRnwJyz127JgnLBdg1KhRDB8+nMqVK2fbz7Fjxzhz5gwnTpzgvPPOs3T3c+Dr7MERwB9xkib+BHwETC3OAYMlMNe1CEgCvvN1AwvMtdrDTSjW7ktYbpUqVahQoQIbNzqhPevXr2fXrl306dOHxMREz74GDBjAggULqFevHsePH2fixInUqlUrIHWFgsLSIBqq6k5V/RV4w32dq6AJzFXVNe5xCizIAnMdoRqc6gurPbRq9yUsNzo6munTpzNw4EAee+wxHn30UUaMGEFycjLp6emsW7eOjIwMNm3axIEDB5g5cyZHjx7l4YcfJiIiItsZWrAps4G5wIdAWwARmauq/UvgmMEYmFsgC8x1hGpwqi+s9tCq3ZewXIC9e/cyZswY2rVrR1paGiNGOA/D+PnnnxkzZgwLFy5k69atDBkyxBOiu2jRIipUqBC0YblQtgNzvU8x/P0l27IcmOszC8yND3Q3AsJqjw90N0pcYWG5zZo1Y+3atbRo0YIaNWpw4MABz7bx8fFMmDCB9u3bs3z5clasWMHtt9/OsWPHWLNmDY888kgAKwtuhQ1ams/yuQiqwFxjTHgqLCy3XLlyiAjz5hX8bNgHHniAO++8k5YtW6Kq3HnnncTGxpZSFaGnsF/YrUXkCM4ZVxV3Gfe9qmpxpsAEW2CuMSYMFRaWC85ZZlRU7otQ3vd7IiIimDNnjt/6GW4KewhkiUc1BVNgroiMBwYBVUUkDZiaM9fQGGNM6QnIpbFgCcx1ZxbmO7vQGGNM6fL1y8XGGGNMwNkkBCww1xhjgoWdaWGBucaY3/gSlNulSxdPUO7q1atp27YtFSpU4IMPPsi1vyNHjlC/fn0efPDBUq0jVNmgZYwxXnwJyh00aJAnKLdhw4ZMmzaNQYMG5bm/UaNG0bVr19IsIaT5ddAK9mBcEakkIrNFZLuIfJ5jJqMxJgT5EpR7+PBhTwxT48aNiY2NpVy53L9O161bx969e+nZs2fpFRDi/HZPK0SCcf8IHFLVy0TkVuBvwB8K2pEF5lrt4SaUavc1KLd69eqsWbOG9evz/9bNr7/+ymOPPca7777Lp59+WlolhDx/TsQIhWDcG4Fn3OUPgCQREa/kjaz+WmAuoRmc6iurPTRq9zUod9asWQwcOJD77rvPs83PP//M5s2bueCCCwCYP38+l19+Odu3b2fr1q3s3r07YCGzJS2Qgbmoql9ewFBgYh7t/YFlQHmcs66dQD2cfMCv3XUSgCSvbRYD8e6yAr3c5fnAJ0BFnKDdFK/tfwBq4CRq/Ag08KHPGTnefw3U93r/PXBBQfto1qyZhquVK1cGugsBY7WHrjFjxuj48eM1KirK0/bjjz9qixYtstU+ZMgQnTNnjuf9oEGDtEGDBtqoUSOtXbu2nn/++Tp8+PDS7Lrf+OP/ObBWfRhbAjERwxOMq6p7gaxgXF/lDMZdpaqZ7nJjr/WWq+phVT2Jk6DR6Jx7bowJefv37yc9PR3AE5TbokULT1Au4GkryIwZM9i5cyepqalMmDCBO+64gxdeeMHv/Q91/rw8GArBuLuBBkCau+8awMFi7McYEyR8CcqtWbMmb775Jjt37uTLL7+kX79+HDp0iEWLFvGXv/yFzZs3B7qMkOXPQSsUgnEXAkOA/+EMwCu8BkxjTAjyJSg3y86dO+nQoQNpaWkF7jMhIYGEhISS7GbY8tugpRoSwbj/BN4Rke3AL8Ct/uyHMcaYgvk1xkmDPBjXvR/2fwVta4wxpvRYIoYxxpigEVaBuRaMa4wxwS2sBi1V7RjoPhhjyp6TJ0/StWtXTp06xZkzZxgwYABjxozhqquu4ujRowDs27ePK664gg8//JDExERmzJhBRkYGlStX5ptvvmH//v3UqlWL9PR07r77br7++mtEhDfffJNOnToFuMLQEVaDljHG5CUrJDciIoLMzEy6dOlCr169+Pe//+1Zp3///tx4440ADBs2jGHDhpGcnMzRo0eZOHEitWrVAuDhhx/m+uuv54MPPuD06dMcP348IDWFqoDc0wqiIN12IrLJDcydInnkPBljgl9+IblZjhw5wooVK7jppptybTtz5kwGDhwIOEG6q1ev5o9//CMA5513HpGRkaVQQfgo9TOtIAvSfRW4B/gc+Ai4HvhXQRtYYK7VHm6CvfaCQnKzfPjhh3Tv3p3q1atn2/bkyZMsXbqUpKQkAHbs2MGFF17InXfeyYYNG2jXrh2TJ0+mWrVqpVdQiAvE5cGgCNIVkXpAdf0tTHc6cBN5DFoWmOsIpeDUorLag7f2gkJymzRpAsArr7xC7969c4XErly5kubNm7Nx40YAtm3bxrp16zxfJn755Ze57777uOuuu0qrnFIRkoG5+b0IkiBdoD3wqdf7q4DFhdVngbnhyWoPLWPGjNHExERVVd2/f7/WqlVLT5w4kWu9Ll266IwZMzzv9+zZo40aNfK8X716tfbu3dvv/S1t4RaYmx8L0jXGBEReIbnNmzcH4IMPPqBv375Urlw52zaHDx9mw4YNnskZABdddBENGjRg27ZtACxfvpzo6OhSqiI8BOLyYLAE6e4G6nu9r++2GWNCTH4huQCzZs1ixIgRubaZP38+7du3z3W/6uWXX2bw4MGcPn2aqKgo3nrrrVKpIVwEYtAKiiBdVd0jIkdE5EqciRh3AC/763jGmMDJLyQXyPfeTUJCAo0bN87VHhcXx9q1a0uwd8ZbqQ9aqsETpAvcj5NhWAVnAkaBMweNMcb4V0C+XKzBE6S7NuvYxhhjAq8sTcQwxhhjCmSDFk6Qroik5Hi1CnS/jDEl6+TJk1xxxRW0bt2ali1b8pe//AVwvvozcuRImjVrRosWLZgyZQoAiYmJxMXFERcXR0xMDOXLl+eXX35h165ddOvWjYSEBFq2bMnkyZMDWVZYsexBLEjXmHCRX8bgN998w65du9i6dSvlypVj3759wG8ZgwCLFi3yZAyeOnWKF198kSNHjtCuXTvatWtHjx49bHp7KfDrmVYQZQz+VUR2uaka3u1/drMHU0TkPyJifyKNCWL5ZQy++uqrjB49mnLlnF+JderUybWtd8ZgvXr1aNu2LQDnn38+LVq0YPdu+0ZMafDbmVaQZQwuApKA73K0v6du3JSI3AC8hJM/mC/LHrTaw02w1F5QxuD333/P7NmzmT9/PhdeeCFTpkyhadOmnm2PHz+eLWMw235TU/nqq6+yZRUa//HnmVaeGYPAf0QkUUS+ds9i/pBzQxFJEJEkr/eLRSTeXc5wt98sIp+KyBUikiwiP7gDS9b280RkqYh8JyLjC+qoqq5R1T15tB/xelsNZyq+MSaIlS9fnpSUFNLS0vjiiy/4+uuvOXXqFJUrV2bt2rXcc889ubICFy1aROfOnT2PH8ly4sQJ+vfvz6RJk3KF6Rr/8Oc9rRhgXR7tNwNxOJmAFwBfisjqIuy3GrBCVYeJyHxgLNADiAbeBha668UBbXASMLaJyMuququoRYjIA8CjwHnANfmsY4G5BH9w6rmw2st+7Xl9Sbhx48a88sor1KpVi4svvpjk5GRq1qzJV199lW39pKQkrr766mxtZ86cYeTIkVx55ZXUqlUrcAGyARDIwNxATMTwZAwCe0UkK2Nwo4/b58wYPKWqmSKSZ8YggIhkZQwWedBS1VeAV0RkEPA0MCSPdV4HXge4/PLL9aHBN+ZcJSwkJydzS3x8oLsREFZ7fKC74ZP9+/dTsWJFIiMjOXHiBKNGjWL48OHUqFGDEydOEB8fT3JyMi1atCDerenw4cNs3ryZpUuXeiKbVJUhQ4YQFRXF3//+9wBWFBjJycmen09p8+egFSwZg76ahfPoE2NMkMovY7BLly4MHjyYiRMnEhERwdSpUz3bzJ8/n549e2bLGPzss8945513iIqKIi4uDoDnn3+e3r17l3pN4cafg1ZQZAwWRESaqmrW5Iw+5J6oYYwJIvllDEZGRrJkSd6TSbKejeWtS5cuqGpAzzjCld8GrWDKGHQnagwCqopIGjDVjYJ6UESuBTKBQ+RxadAYY0zp8es9rSDKGHwCyPUEY1V9uKDtjDHGlC6LcTLGGBM0wirGSUQ+ByrlaL5dVTcFoj/GGGOKJqzOtFS1o6rG5XjZgGVMiCpqQO7WrVvp1KkTlSpVYsKECZ79bNu2zROcGxcXR/Xq1Zk0aVJAagp3YXWmZYwJL0UNyK1VqxZTpkzhww8/zLafyy+/nJSUFMCJgbrkkkvo168fO3bsKPWawp0F5lJgYG5XEVkvImdEpLjfOTPGBEhRA3Lr1KlDhw4dqFixYr77XL58OZdeeimNGjXyfwEmFwvMdeQXmLsTSAAe93VHFphrtYebslr7uQTkFmTWrFmetHdT+vx5eTDPwFxxJAK9cL6nNVZVZ3tvKCIJQHtVfdB9vxiYoKrJ7tnQq0BvYA/wFDAeaAg8oqoL3e1vAKoClwLz3WnteVLVNe5xcranuu2/FlSoZQ86giWDzh+s9rJXu3c23qRJk8jIyGDUqFE0b96c48ePs3v3biZMmMDq1avp37+/574WOMntVapUyZWvl5mZydy5c+nbty/JyckBzeALpFDNHgyJwFxfeGcPNoy6TF/cFJ63Ch9rdQarPfyU1dpTB8fnalu/fj0HDx6kUaNGDBs2jCZNmnD11Vfz4osvZku2SE5OJiIiIlfaxYIFC+jYsSM333yzZ71wTMQI1ezB/ARVYG5RValYnm3uZYlwk5ycnOcvinBgtccHuht5yhmQu2zZMoYPH85NN93EypUradKkCatWraJZszxvtefi/SBIExgWmGuMCVlFDcj9+eefad++PUeOHKFcuXJMmjSJLVu2UL16dY4dO8ayZct47bXXAlxVeLPAXGNMyCpqQO5FF11EWlpanvuqVq0aBw8eLPE+mqLx25R392yoH3CtO+V9MzAOeA/nUuAGnIHtCVX9Ocfm3oG5UyiFwFw3KLeqiKSJyDNuewe3/f+A19wajDHGBIgF5lJgYO6XQP2CtjXGGFN6wirGyRhjTHALq8kJFphrjDHBLazOtCww15iyKb9g28GDB3P55ZcTExPDXXfdRWZmJgCJiYme8NqYmBjKly/PL7/8AsBdd91FnTp1iImJCVg9xn/CatAyxpRNWcG2GzZsICUlhaVLl7JmzRoGDx7M1q1b2bRpEydOnPBMTR82bBgpKSmkpKQwbtw4rr76amrVqgVAQkICS5cuLehwJogFZNAKhiBdEakqIktEZKuIbBaRF0q7D8aEi/yCbXv37o2IICJcccUVeU5Hz/mF365du3oGMBN6Sv2eVpAF6U5Q1ZUich6wXER6qeq/CtrAAnOt9nBTErWnvtAnz2DbLJmZmbzzzjtMnjw523bHjx9n6dKlJCUlndPxTfAIxESMoAjSVdXjwEp3+bSIrCef6e8WmOsoq8GppcFqP7fas8JXcwbbNmnSBIAJEyYQFRXF2bNnswW1rlixgubNm7NxY/YUuJ9//pljx475PdTVAnMDQFVL9QUMBSbm0d4fWAaUxznr2gnUw8kT/NpdJwFI8tpmMRDvLivQy12eD3wCVMQJ5k3x2v4HoAZOAsePQAMf+hzpbhdV2LrNmjXTcLVy5cpAdyFgrPaSNWbMGE1MTFRV1WeeeUZvvPFGPXv2bK71brrpJp0xY0au9h07dmjLli1LvF85hev/d3/UDaxVH8aQsjQRwxOkq6p7gawgXV/lDNJdpaqZ7nJjr/WWq+phVT2Jk7hR4JPc3DzDmcAUVf2hCP0xxvho//79pKenA3iCbZs3b87UqVP5+OOPmTlzpueBjVkOHz7MqlWruPHGGwPRZRMggRi0NgPtirltsYJ0yX4ZtKhBuq8D36nqpGL12BhTqD179tCtWzdiY2Pp0KEDPXr0oG/fvvz5z39m7969dOrUibi4OJ599lnPNvPnz6dnz55Uq1Yt274GDhxIp06d2LZtG/Xr1+ef//xnaZdj/CgQ97SCJkhXRMbiXEq825/HMSbc5Rdse+ZM/vfKEhISSEhIyNU+c+bMkuyaKWNKfdBSVRWRfsAkERkOnMQZjB4BInCCdBU3SFdEGntt7h2k+w1+DNIVkfrASGArsN59qnGSqk711zGNMcYULCAxThoEQbqqmgZIAWUYY4wpZWVpIoYxxhhToLAKzM2PBekaY0xwsDMtLEjXGH/LLxA3KSmJyy67DBHhwIEDnvUXLFhAbGwscXFxtG/fnv/85z+ez3bu3EnPnj1p0aIF0dHRpKamlnY5JoDsTMsY43dZgbgRERFkZmbSpUsXevXqRefOnenbty/x8fHZ1u/evTs33HADIsLGjRu55ZZb2Lp1KwB33HEHI0eOpEePHmRkZOT6/pYJbQEZtETkImASzpeH04G9OFFLubIH3dmDi1W11J8zICLJOKkcJ9ymnqq6r7T7YUywyy8Qt02bNnmun7UuwLFjx3Bn77JlyxbOnDlDjx49cq1nwoMF5hZusKqu9XVlC8y12sNNYbWnvtAHoMBA3LzMnz+fJ598kn379rFkibP/b7/9lsjISG6++WZ27NjBtddeywsvvED58uVLriBTpslvIRKldECRa4BnVLVrjnbBCbjNFpjrfaZVmoG57v6TgccLG7RyBOa2Gz3pDd9/ICGkbhXYe6Lw9UKR1Z7/560uqZHtfVYg7tChQz2BuLfeeiuvvfYaNWrUyLX9hg0bmD59Oi+++CKrVq0iMTGR119/nbp16zJmzBg6duxInz59SrQmX2VkZITl2Z4/6u7Wrds6VW1f6Iq+BBSW5IsgCswFknGyC1OAUbiDfEEvC8wNT1Z70XgH4qqqNmrUSPfv35/v+k2aNNH9+/fr//73P+3ataunffr06Xr//fcX+fglJVz/v1tgrqMsBuYOVtVWwFXu6/Yi9McY48ovEDc/27dvz/qHI+vXr+fUqVPUrl2bDh06kJ6ezv79+wHn0STR0dH+L8CUGRaYW8B9PVXd7f73KPAefs46NCZU5ReIO2XKFOrXr09aWhqxsbHcfbcT8zl37lxiYmKIi4vjgQceYPbs2YgI5cuXZ8KECXTv3p1WrVqhqtxzzz0Brs6UJgvMzYf7SJJIVT0gIhWBvsCn/jqeMaEsv0DcoUOHMnTo0Fztw4cPZ/jw4Xnuq0ePHrke+mjChwXm5q8S8LE7YJXHGbDCc4aFMcaUERaYm38fj1H8y5jGGGP8oCxNxDDGGGMKZDFOWGCuMcYECxu0cAJzA90HY4wxhbPLg8YYY4KGDVrGGGOChg1axhhjgkapB+aGOhE5CmwLdD8C5ALgQKFrhSarPTyFa+3+qLuRql5Y2Eo2EaPkbVNfkopDkIistdrDj9UefrUHsm67PGiMMSZo2KBljDEmaNigVfJeD3QHAshqD09We/gJWN02EcMYY0zQsDMtY4wxQcMGLWOMMUHDBq0SJCLXi8g2EdkuIiMC3Z9zJSJvisg+Efnaq62WiCwTke/c/9Z020VEpri1bxSRtl7bDHHX/05EhgSilqISkQYislJEtojIZhF52G0P+fpFpLKIfCEiG9zax7jtTUTkc7fG2SJyntteyX2/3f28sde+nnTbt4nIdYGpqGhEpLyIfCUii933YVE3gIikisgmEUkRkbVuW9n6M6+q9iqBF86DIr8HooDzcB5mGR3ofp1jTV2BtsDXXm3jgRHu8gjgb+5yb+BfgABXAp+77bWAH9z/1nSXawa6Nh9qrwe0dZfPB74FosOhfreGCHe5IvC5W9P7wK1u+z+A+9zl+4F/uMu3ArPd5Wj370EloIn796N8oOvzof5HgfeAxe77sKjb7XsqcEGOtjL1Z97OtErOFcB2Vf1BVU8Ds4AbA9ync6Kqq4FfcjTfCLztLr8N3OTVPl0da4BIEakHXAcsU9VfVPUQsAy43v+9PzequkdV17vLR3GelH0JYVC/W0OG+7ai+1LgGuADtz1n7Vk/kw+A7iIibvssVT2lqjuA7Th/T8osEakP9AGmuu+FMKi7EGXqz7wNWiXnEmCX1/s0ty3U1FXVPe7yz0Bddzm/+oP+5+Je9mmDc8YRFvW7l8hSgH04v3S+B9JV9Yy7incdnhrdzw8DtQnO2icBTwC/uu9rEx51Z1HgExFZJyL3um1l6s+8xTiZYlNVFZGQ/s6EiEQAc4FHVPWI8w9pRyjXr6pngTgRiQTmA80D3CW/E5G+wD5VXSci8YHuT4B0UdXdIlIHWCYiW70/LAt/5u1Mq+TsBhp4va/vtoWave4lANz/7nPb86s/aH8uIlIRZ8Caoarz3OawqR9AVdOBlUAnnMs/Wf/Q9a7DU6P7eQ3gIMFXe2fgBhFJxbm8fw0wmdCv20NVd7v/3Yfzj/e/GtkAAAUlSURBVJUrKGN/5m3QKjlfAk3dmUbn4dyYXRjgPvnDQiBrNtAQYIFX+x3ujKIrgcPuJYWPgZ4iUtOdddTTbSvT3HsT/wS+UdWXvD4K+fpF5EL3DAsRqQL0wLmntxIY4K6Ws/asn8kAYIU6d+QXAre6s+yaAE2BL0qniqJT1SdVtb6qNsb5+7tCVQcT4nVnEZFqInJ+1jLOn9WvKWt/5gM9WyWUXjizab7Fuf4/MtD9KYF6ZgJ7gEyc69J/xLlmvxz4DvgUqOWuK8Arbu2bgPZe+7kL52b0duDOQNflY+1dcK7vbwRS3FfvcKgfiAW+cmv/Ghjttkfh/PLdDswBKrntld33293Po7z2NdL9mWwDegW6tiL8DOL5bfZgWNTt1rnBfW3O+h1W1v7MW4yTMcaYoGGXB40xxgQNG7SMMcYEDRu0jDHGBA0btIwxxgQNG7SMMcYEDRu0jPGRiJx106+zXo2LsY9IEbm/5Hvn2f8NUspPGBCRm0QkujSPacKXTXk3xkcikqGqEee4j8Y43/+JKeJ25dWJVipT3CSIqTg1fVDY+sacKzvTMuYcuMGyiSLypftMoT+57REislxE1rvPJ8pK/H8BuNQ9U0sUkXhxn9vkbpckIgnucqqI/E1E1gP/JyKXishSN8z03yKSKw9QRBJEJMldniYir4rIGhH5wT3WmyLyjYhM89omQ0QmivPsrOUicqHbHuduu1FE5stvz1FKFpFJ4jxvaThwA5Do1nSpiNzj/jw2iMhcEanq1Z8pIvJftz8DvPow3P05bRCRF9y2Qus1YSjQ38K2l72C5QWc5bd0jPlu273A0+5yJWAtzjOUKgDV3fYLcJIBBGhM9ueTxeMmL7jvk4AEdzkVeMLrs+VAU3e5I05sUM4+JgBJ7vI0nAy9rMdlHAFa4fxjdR0Q566nwGB3ebTX9huBq93lZ4FJ7nIy8HevY04DBni9r+21PBZ4yGu9Oe7xo3Ee5QPQC/gvUNV9X8vXeu0Vfi9LeTfGdydUNS5HW08g1uusoQZO1lwa8LyIdMV5zMUl/PZIh6KYDZ60+d8Bc+S3pPlKPmy/SFVVRDYBe1V1k7u/zTgDaIrbv9nu+u8C80SkBhCpqqvc9rdxBpxs/cpHjIiMBSKBCLLnzn2oqr8CW0Qk6+dxLfCWqh4HUNVfzqFeE+Js0DLm3AjOmUS2QND/397dq8QVhGEc/z9bpVkUwdoiYJFGIWIXiPECYmOjJBCs0mvpFXgFQoo0geAVJFgJsRNFEbGTkCJVCCpbiJI3xYzkuDm7mrgrjD6/5uz5GObMwDLMzOF98xLfMPA0Is6VIoc/qil/wdVl+vZnWvnYIOV1ah80r3OWj78qvy/PO/3/b7LR3epy7z0wExG7uR+e17wPpL7r5H/ba/ec97TMbucz8FYpjQmSRnOE7AFSbqZzSVPASH7+FGhWyn8FnuSI4IPAdF0lEXECHEmazfVI0liP2tDgTxTzOeBLRBwDPyU9y9dfARt1hfm7TU3ge+6T+RvUvw68qex9DfW5vVYwD1pmt/MOOAC2Je0Dq6QZzAdgIi/LvQYOASLiB7ApaV/SSkR8A9ZI0dTXSNHVO5kHFiRdRuF+2eXZf9ECJvP7vyDtX0FKQ7EiaQ8Yr1xv9xFYkrQj6TGwTMryvEludzcR8YmU5mJLKVvyYr7Vr/ZawfzJu9kD14tP+c3uimdaZmZWDM+0zMysGJ5pmZlZMTxomZlZMTxomZlZMTxomZlZMTxomZlZMX4DAFmyEJxxGkUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Plot feature importances...')\n",
    "ax = lgb.plot_importance( bst , max_num_features=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
